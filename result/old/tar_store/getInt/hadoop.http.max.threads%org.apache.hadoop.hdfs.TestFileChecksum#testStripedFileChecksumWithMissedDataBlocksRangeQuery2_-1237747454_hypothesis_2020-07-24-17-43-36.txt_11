reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267248978-172.17.0.13-1595612934613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41297,DS-a301a947-a233-4f34-93c3-ad0f14a76108,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-0ec12c0f-988a-4b37-b971-ee4efae717fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-359847e4-d0f3-461d-9fd2-2d93624c1af9,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-fe4d7f2d-f99e-45c9-b749-6b827b17a1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-dc1eaad9-9434-467d-9267-2b8d4e33ab2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-a64f12cc-5123-47a0-9004-df22ba528fca,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-04400280-8454-4d3a-947d-87f71073eb50,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-d0c1bea2-6393-486d-86fb-6ab1afa83d1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267248978-172.17.0.13-1595612934613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41297,DS-a301a947-a233-4f34-93c3-ad0f14a76108,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-0ec12c0f-988a-4b37-b971-ee4efae717fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-359847e4-d0f3-461d-9fd2-2d93624c1af9,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-fe4d7f2d-f99e-45c9-b749-6b827b17a1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-dc1eaad9-9434-467d-9267-2b8d4e33ab2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-a64f12cc-5123-47a0-9004-df22ba528fca,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-04400280-8454-4d3a-947d-87f71073eb50,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-d0c1bea2-6393-486d-86fb-6ab1afa83d1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803607650-172.17.0.13-1595613124311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35116,DS-36a00a64-e0fe-48e0-98eb-c54a65449501,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-b0e44d2b-8670-4214-a550-25325b7518c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-ba9c9da0-3f97-41aa-b844-b2cb334829b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-98e19d14-7c94-4668-85e7-1994c0aa654e,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-19408671-e646-4c67-8181-7ef93b894213,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-32f01c13-90c4-4ed3-b520-a6b8ea273f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-92dcbfa5-6e14-4cf8-86aa-e90733d1dc28,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-04606ebf-0b1a-45ca-b540-997cea54ebd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803607650-172.17.0.13-1595613124311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35116,DS-36a00a64-e0fe-48e0-98eb-c54a65449501,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-b0e44d2b-8670-4214-a550-25325b7518c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42693,DS-ba9c9da0-3f97-41aa-b844-b2cb334829b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-98e19d14-7c94-4668-85e7-1994c0aa654e,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-19408671-e646-4c67-8181-7ef93b894213,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-32f01c13-90c4-4ed3-b520-a6b8ea273f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-92dcbfa5-6e14-4cf8-86aa-e90733d1dc28,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-04606ebf-0b1a-45ca-b540-997cea54ebd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511254747-172.17.0.13-1595613158171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36316,DS-1c3d1dc9-0278-4757-bba9-620ef1798a57,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-ac1bd981-ac7e-441e-9593-63a667ef620a,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-edfbcf32-eda8-4b8f-a4c8-38ea59ab20c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-ffb66805-84fe-4aeb-ad53-4624e175ef42,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-e8290e5d-8a11-4b4f-8efd-7854d185a49e,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-fee84fe7-1397-40b9-bc3f-345d536d6eae,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-bc9cc856-5003-470b-97b1-b0bd02a1c79e,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-82a9b80d-803f-4068-b778-1d3d406e52c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511254747-172.17.0.13-1595613158171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36316,DS-1c3d1dc9-0278-4757-bba9-620ef1798a57,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-ac1bd981-ac7e-441e-9593-63a667ef620a,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-edfbcf32-eda8-4b8f-a4c8-38ea59ab20c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-ffb66805-84fe-4aeb-ad53-4624e175ef42,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-e8290e5d-8a11-4b4f-8efd-7854d185a49e,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-fee84fe7-1397-40b9-bc3f-345d536d6eae,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-bc9cc856-5003-470b-97b1-b0bd02a1c79e,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-82a9b80d-803f-4068-b778-1d3d406e52c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119556544-172.17.0.13-1595613279632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40822,DS-cc3a380f-42a1-45ef-abf3-2221f85e7ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-9fac0795-0ac8-4928-b1ad-ccd352660c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-de4882fc-4730-455e-92a3-6b874fb24d38,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-4e3017d8-293c-46e3-9811-a4b8000d4dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-0d765766-37aa-41dd-8f11-47681d066b94,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-0a331297-71c2-4640-b0cd-6bb86c00579c,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-a00289a8-c681-48dc-bcdf-ed4b0e993fad,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-f9c5773b-db6c-4b41-b9eb-6bb9c956d7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119556544-172.17.0.13-1595613279632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40822,DS-cc3a380f-42a1-45ef-abf3-2221f85e7ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-9fac0795-0ac8-4928-b1ad-ccd352660c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-de4882fc-4730-455e-92a3-6b874fb24d38,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-4e3017d8-293c-46e3-9811-a4b8000d4dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-0d765766-37aa-41dd-8f11-47681d066b94,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-0a331297-71c2-4640-b0cd-6bb86c00579c,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-a00289a8-c681-48dc-bcdf-ed4b0e993fad,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-f9c5773b-db6c-4b41-b9eb-6bb9c956d7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806549919-172.17.0.13-1595613363845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46427,DS-4858dff3-da17-494f-a5a0-91390ab9df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-ebcb847d-dfc0-46eb-a796-0f61bad6ec93,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-87600e36-6227-46c0-a14e-268e25a8550b,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-31c668c7-7064-4c29-a22d-ee414232e968,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-9fdb3913-fa01-49ce-94ca-35137f0cd161,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-4dbf1419-8706-482e-bda4-174a07824670,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-e7c1fd2f-baea-4393-94c6-5d99a28873f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-8f5e503b-f720-4576-b794-313e2b9c4527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806549919-172.17.0.13-1595613363845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46427,DS-4858dff3-da17-494f-a5a0-91390ab9df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-ebcb847d-dfc0-46eb-a796-0f61bad6ec93,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-87600e36-6227-46c0-a14e-268e25a8550b,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-31c668c7-7064-4c29-a22d-ee414232e968,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-9fdb3913-fa01-49ce-94ca-35137f0cd161,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-4dbf1419-8706-482e-bda4-174a07824670,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-e7c1fd2f-baea-4393-94c6-5d99a28873f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-8f5e503b-f720-4576-b794-313e2b9c4527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703606713-172.17.0.13-1595613748901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45443,DS-3a3318b9-6dac-4ffe-ab48-b36e232c8e75,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-b8b1b4f3-b070-431f-9944-814af2aef779,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-51f1a1e3-ce0b-4467-b3b1-4829aaed8879,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-94331193-52e6-4478-aecc-94e7816b0aae,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-efa8ac81-1391-4a50-a700-2bafa03341c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-2c646c08-d2d2-4051-9688-9bc10a6681f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-5ee33081-8d56-4861-a59b-4c29f127f336,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-89264250-de53-48dd-b0ae-927d749574f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703606713-172.17.0.13-1595613748901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45443,DS-3a3318b9-6dac-4ffe-ab48-b36e232c8e75,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-b8b1b4f3-b070-431f-9944-814af2aef779,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-51f1a1e3-ce0b-4467-b3b1-4829aaed8879,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-94331193-52e6-4478-aecc-94e7816b0aae,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-efa8ac81-1391-4a50-a700-2bafa03341c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-2c646c08-d2d2-4051-9688-9bc10a6681f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-5ee33081-8d56-4861-a59b-4c29f127f336,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-89264250-de53-48dd-b0ae-927d749574f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191892713-172.17.0.13-1595613854977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34911,DS-1905d895-d3b8-418f-802b-1e8472eb6a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-efbb93b4-e90e-440a-ad7b-485ba8f937a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-5c032fb3-4866-4830-a847-4e9c6d26dae7,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-c07eb800-afbe-4df8-a65f-deb988d377ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-b473aee4-dc11-411e-9e00-789ef7a32427,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-7df02374-4d2f-48c2-9322-1bc74a960aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-8fb41c6b-5e50-4d7e-94e7-1afbc3c89384,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-6b223532-88c9-452b-8c59-49429a04d723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191892713-172.17.0.13-1595613854977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34911,DS-1905d895-d3b8-418f-802b-1e8472eb6a54,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-efbb93b4-e90e-440a-ad7b-485ba8f937a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-5c032fb3-4866-4830-a847-4e9c6d26dae7,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-c07eb800-afbe-4df8-a65f-deb988d377ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-b473aee4-dc11-411e-9e00-789ef7a32427,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-7df02374-4d2f-48c2-9322-1bc74a960aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-8fb41c6b-5e50-4d7e-94e7-1afbc3c89384,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-6b223532-88c9-452b-8c59-49429a04d723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47703647-172.17.0.13-1595614236047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34222,DS-4958e927-ebf1-4df7-9861-45e39062c926,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-c667c2d5-baae-46d8-b0af-4d30bea8b799,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-6cbeccc7-4a14-4ce8-88d4-61e75c7fbbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-744efbd2-0854-4e3b-9803-224bbe1a9098,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-afb8f3c5-ec38-4059-9484-dc1289da9064,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-63275702-270e-4ba2-9ad9-7927aa90e52a,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-862bf158-4fe3-49e9-85ae-66f85c265ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-5980e2cc-fa50-4679-9c85-defdcdc90e2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47703647-172.17.0.13-1595614236047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34222,DS-4958e927-ebf1-4df7-9861-45e39062c926,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-c667c2d5-baae-46d8-b0af-4d30bea8b799,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-6cbeccc7-4a14-4ce8-88d4-61e75c7fbbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-744efbd2-0854-4e3b-9803-224bbe1a9098,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-afb8f3c5-ec38-4059-9484-dc1289da9064,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-63275702-270e-4ba2-9ad9-7927aa90e52a,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-862bf158-4fe3-49e9-85ae-66f85c265ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-5980e2cc-fa50-4679-9c85-defdcdc90e2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109728534-172.17.0.13-1595614513043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36401,DS-8698d38a-31ce-486c-bed1-a63c0fba1bad,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-d1e532df-9286-4db5-b165-0ac671a2f9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-efe38950-2f6b-4d42-ac52-6097f036569b,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-26c6b905-fffc-481c-9371-bb57549185a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-74097a59-dd31-44ea-9eb8-f4419683e883,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-da75e7a3-e78c-431c-b82c-c224088cef65,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-f6fd5e74-75a4-4983-b96d-25908fbf2311,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-dfc6260c-7d41-424a-9eb4-29f5625f0d9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109728534-172.17.0.13-1595614513043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36401,DS-8698d38a-31ce-486c-bed1-a63c0fba1bad,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-d1e532df-9286-4db5-b165-0ac671a2f9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-efe38950-2f6b-4d42-ac52-6097f036569b,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-26c6b905-fffc-481c-9371-bb57549185a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-74097a59-dd31-44ea-9eb8-f4419683e883,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-da75e7a3-e78c-431c-b82c-c224088cef65,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-f6fd5e74-75a4-4983-b96d-25908fbf2311,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-dfc6260c-7d41-424a-9eb4-29f5625f0d9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391820052-172.17.0.13-1595614731223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41519,DS-912bdec0-39c4-4823-8dbe-786430465bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-81620321-1096-42c0-a416-4743af788bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-337ece91-7cd1-4e3f-9b91-a80d54c7abfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-88718ded-3468-4463-b251-812b3fabf879,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-a2454331-1966-4a6f-a2a5-7cc75e185bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-4aaf5cef-b55a-4991-ae00-b30e7c5e31b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-a37a383a-f3e0-4d51-a2be-9133d73a42bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-cd19a03d-d6f4-4e72-984e-22e07b4d0189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391820052-172.17.0.13-1595614731223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41519,DS-912bdec0-39c4-4823-8dbe-786430465bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-81620321-1096-42c0-a416-4743af788bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-337ece91-7cd1-4e3f-9b91-a80d54c7abfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-88718ded-3468-4463-b251-812b3fabf879,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-a2454331-1966-4a6f-a2a5-7cc75e185bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-4aaf5cef-b55a-4991-ae00-b30e7c5e31b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-a37a383a-f3e0-4d51-a2be-9133d73a42bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-cd19a03d-d6f4-4e72-984e-22e07b4d0189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781317257-172.17.0.13-1595614804687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40468,DS-173489e7-c7e1-4140-92ab-6fd5b8705ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-a17d6075-406d-4343-9d4b-072660e717f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-52565842-d88a-4f45-a762-cf5577b50f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-164af822-5db0-40ae-a490-947d7a16acf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-87877b73-24ef-4ab1-b819-c51100984bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-579a3772-4e50-4366-b2ac-2ff5df943993,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-cb1d7b6c-e426-487d-8274-8275a827463b,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-65a5dcea-1cae-4c7f-bcc9-c5ae2adb38f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781317257-172.17.0.13-1595614804687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40468,DS-173489e7-c7e1-4140-92ab-6fd5b8705ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-a17d6075-406d-4343-9d4b-072660e717f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-52565842-d88a-4f45-a762-cf5577b50f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-164af822-5db0-40ae-a490-947d7a16acf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-87877b73-24ef-4ab1-b819-c51100984bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-579a3772-4e50-4366-b2ac-2ff5df943993,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-cb1d7b6c-e426-487d-8274-8275a827463b,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-65a5dcea-1cae-4c7f-bcc9-c5ae2adb38f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874122736-172.17.0.13-1595614874700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-6eb81890-45c8-4911-8b95-dd1b63d5e0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-65e4938e-96c9-4427-abfc-1114e467b288,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-10e1f6c1-93fa-4a1a-a713-05be3d2ab8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-1a5c876e-1323-409d-86fe-35b8e82852c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-d58ebe6e-6fd4-47ef-8436-fbea87c82d04,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-50bbda0f-328f-408b-be4d-b50a2a23904a,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-eb2657de-396e-495d-bfe3-2e8fa775d3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-b01bd3a5-647e-4c7f-8d9c-7b1066a399b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874122736-172.17.0.13-1595614874700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-6eb81890-45c8-4911-8b95-dd1b63d5e0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-65e4938e-96c9-4427-abfc-1114e467b288,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-10e1f6c1-93fa-4a1a-a713-05be3d2ab8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-1a5c876e-1323-409d-86fe-35b8e82852c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-d58ebe6e-6fd4-47ef-8436-fbea87c82d04,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-50bbda0f-328f-408b-be4d-b50a2a23904a,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-eb2657de-396e-495d-bfe3-2e8fa775d3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-b01bd3a5-647e-4c7f-8d9c-7b1066a399b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537861226-172.17.0.13-1595614903966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33935,DS-5dc3d209-e778-4d1e-aa2b-39f918e3835a,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-9ee33942-7b63-4543-933c-4ec0c15bb94a,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-108ee7d1-dbe8-48bd-a1a3-9767b27b4a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-5ef07ecd-a50f-46fb-8236-c7e12ae1567d,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-09ab0891-af78-4363-ab73-9f1b6ddebcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-48e8c88d-f4ff-4e88-b76f-ec676b4c8fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-a1f0910a-8db3-4592-99b4-9d54724fd828,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-67e08c90-1307-4fde-9b83-02a0f396e929,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537861226-172.17.0.13-1595614903966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33935,DS-5dc3d209-e778-4d1e-aa2b-39f918e3835a,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-9ee33942-7b63-4543-933c-4ec0c15bb94a,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-108ee7d1-dbe8-48bd-a1a3-9767b27b4a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-5ef07ecd-a50f-46fb-8236-c7e12ae1567d,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-09ab0891-af78-4363-ab73-9f1b6ddebcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-48e8c88d-f4ff-4e88-b76f-ec676b4c8fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-a1f0910a-8db3-4592-99b4-9d54724fd828,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-67e08c90-1307-4fde-9b83-02a0f396e929,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514471880-172.17.0.13-1595614940998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40281,DS-63499b00-17aa-4389-acc2-087fa8b8d7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-8cdb384d-9348-469e-9b18-a30e88e763f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-8e8c9a35-90dd-40ca-8061-912bed59ce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-dbd55724-bdd7-4c10-b6c2-518a030dabcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-89801771-2056-48ea-8174-ae625d9ebad2,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-b5d4f25a-6365-4092-845c-d97fae67a281,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-68b9fa72-dcff-45ef-8db2-db8653245331,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-f0163890-28b4-49e3-951f-6e34b17a398e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514471880-172.17.0.13-1595614940998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40281,DS-63499b00-17aa-4389-acc2-087fa8b8d7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-8cdb384d-9348-469e-9b18-a30e88e763f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-8e8c9a35-90dd-40ca-8061-912bed59ce1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-dbd55724-bdd7-4c10-b6c2-518a030dabcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-89801771-2056-48ea-8174-ae625d9ebad2,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-b5d4f25a-6365-4092-845c-d97fae67a281,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-68b9fa72-dcff-45ef-8db2-db8653245331,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-f0163890-28b4-49e3-951f-6e34b17a398e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831805267-172.17.0.13-1595615051632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33506,DS-bd427e83-318c-425c-a0e7-d2a6be169e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-0e32a2bd-8b54-4c8c-93a4-aa6fd8a8fa98,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-8b9d98ac-07b6-46a5-b562-069fe0dd8142,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-62a5e88f-85de-4598-9537-807d75246969,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-762be709-3137-40ec-993a-63f9c5403b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-abdacfdb-0c1b-45fd-805e-09ba31185d25,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-abc7376b-d7b4-485d-9fb2-93c1dbe29982,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-a5d7b537-f779-4968-acf7-ac3b9dd0c0da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831805267-172.17.0.13-1595615051632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33506,DS-bd427e83-318c-425c-a0e7-d2a6be169e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-0e32a2bd-8b54-4c8c-93a4-aa6fd8a8fa98,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-8b9d98ac-07b6-46a5-b562-069fe0dd8142,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-62a5e88f-85de-4598-9537-807d75246969,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-762be709-3137-40ec-993a-63f9c5403b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-abdacfdb-0c1b-45fd-805e-09ba31185d25,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-abc7376b-d7b4-485d-9fb2-93c1dbe29982,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-a5d7b537-f779-4968-acf7-ac3b9dd0c0da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693982291-172.17.0.13-1595615357244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46099,DS-f1e93eae-d178-4f6d-b267-4302c3d21640,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-2aaf5014-bc3f-4b6a-9bd4-bcf7b4343f82,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-8fd808da-31f8-46a3-9456-229aebcd86dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-670f156a-4ddc-49c9-9f3f-80345f7042b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-a053e559-7b74-4769-9237-c0fba090f0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-4f390da0-1edc-48f2-b582-c9e124b78041,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-272db0cb-14bf-4e5b-a467-635c5104bea6,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-0068ed87-5981-4d66-99db-dc39dbf5643b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693982291-172.17.0.13-1595615357244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46099,DS-f1e93eae-d178-4f6d-b267-4302c3d21640,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-2aaf5014-bc3f-4b6a-9bd4-bcf7b4343f82,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-8fd808da-31f8-46a3-9456-229aebcd86dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-670f156a-4ddc-49c9-9f3f-80345f7042b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-a053e559-7b74-4769-9237-c0fba090f0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-4f390da0-1edc-48f2-b582-c9e124b78041,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-272db0cb-14bf-4e5b-a467-635c5104bea6,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-0068ed87-5981-4d66-99db-dc39dbf5643b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981748562-172.17.0.13-1595616193078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35340,DS-9d659849-52f2-4463-8903-745726e82816,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-8d7a52ca-b9f9-4aff-ba80-cc56cbea6b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-a87d87e4-8d48-4b5c-85c0-a03d4660a1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-8d9ca250-e9e7-4b41-a2ce-663dcea2a58e,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-264cf184-8370-4209-ac22-01c14482ca0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-1c41378f-33db-4e7f-8166-38268a8d5c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-18d7e049-b09b-4ab3-b408-e82f4d550eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-154c5d72-25c2-48d1-b0be-700a35466fde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981748562-172.17.0.13-1595616193078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35340,DS-9d659849-52f2-4463-8903-745726e82816,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-8d7a52ca-b9f9-4aff-ba80-cc56cbea6b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-a87d87e4-8d48-4b5c-85c0-a03d4660a1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-8d9ca250-e9e7-4b41-a2ce-663dcea2a58e,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-264cf184-8370-4209-ac22-01c14482ca0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-1c41378f-33db-4e7f-8166-38268a8d5c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-18d7e049-b09b-4ab3-b408-e82f4d550eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-154c5d72-25c2-48d1-b0be-700a35466fde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381700794-172.17.0.13-1595616258191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33398,DS-a0ba52a4-da89-4b10-9d56-766874afdaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-aae9fc74-0a21-4490-aeda-5c96892f1dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-1312ca86-0de8-473b-8d7c-6499445e04a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-0ad21dac-9baf-4520-a496-b06613cc6965,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-5b14d823-9f47-42a7-bc02-5e086c221c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-d1cc398c-1ce5-4d0a-b2b7-cc765bf5ac88,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-f96b3029-f038-4792-85ae-51b3f6634b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-630c8642-a7f6-4710-89cb-5edce67d7e0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381700794-172.17.0.13-1595616258191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33398,DS-a0ba52a4-da89-4b10-9d56-766874afdaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-aae9fc74-0a21-4490-aeda-5c96892f1dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-1312ca86-0de8-473b-8d7c-6499445e04a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-0ad21dac-9baf-4520-a496-b06613cc6965,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-5b14d823-9f47-42a7-bc02-5e086c221c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-d1cc398c-1ce5-4d0a-b2b7-cc765bf5ac88,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-f96b3029-f038-4792-85ae-51b3f6634b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-630c8642-a7f6-4710-89cb-5edce67d7e0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042737665-172.17.0.13-1595616655747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46143,DS-c661781a-3da2-466e-9b44-e48485d15a19,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-7b6fd721-e6f2-4365-bc5f-3de37b9504ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-a40e2863-cea5-4945-8fc1-f0978fc2e229,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-c7b3a04a-1059-45fb-8ba3-112df63b34a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-898b7364-44a2-4502-b3d0-6ff651fb22f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-63f5462e-762e-44cc-9313-ccdeb7b9751f,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-7c7a5d4d-f2a8-477e-b098-bfbaf0542cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-059ecfde-9b09-4e53-a087-11fc8814835c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042737665-172.17.0.13-1595616655747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46143,DS-c661781a-3da2-466e-9b44-e48485d15a19,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-7b6fd721-e6f2-4365-bc5f-3de37b9504ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-a40e2863-cea5-4945-8fc1-f0978fc2e229,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-c7b3a04a-1059-45fb-8ba3-112df63b34a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-898b7364-44a2-4502-b3d0-6ff651fb22f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-63f5462e-762e-44cc-9313-ccdeb7b9751f,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-7c7a5d4d-f2a8-477e-b098-bfbaf0542cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-059ecfde-9b09-4e53-a087-11fc8814835c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213484064-172.17.0.13-1595617326627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42483,DS-10161a8e-0299-4d33-b22c-2c52fb18eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-b08c4408-0c3d-4392-9c9f-50f5007083e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-85333d7f-b451-4fd6-b0b0-80ed7003c361,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-32c4af0c-3e25-49a2-8dee-2f437a9307c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-922d9d99-a88b-4f37-89e7-55151991a4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-64605319-8e1e-4949-9e11-e0c3e3d563e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-d14bf597-6cd2-4e5a-98c4-021bf914612c,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-b349150d-dd8c-4ef9-b5fd-3ee1e89d7edf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213484064-172.17.0.13-1595617326627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42483,DS-10161a8e-0299-4d33-b22c-2c52fb18eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-b08c4408-0c3d-4392-9c9f-50f5007083e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-85333d7f-b451-4fd6-b0b0-80ed7003c361,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-32c4af0c-3e25-49a2-8dee-2f437a9307c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-922d9d99-a88b-4f37-89e7-55151991a4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-64605319-8e1e-4949-9e11-e0c3e3d563e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-d14bf597-6cd2-4e5a-98c4-021bf914612c,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-b349150d-dd8c-4ef9-b5fd-3ee1e89d7edf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784920174-172.17.0.13-1595617359668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42994,DS-627ebeb8-49c9-475a-bc32-f5b360f0cd40,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-f80728b7-0f01-4c2b-a4e9-c959493766a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-8ac3fea5-5541-417a-9600-43bc38d19684,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-321d2c7b-e1c3-4380-b4d6-af4dd256ed7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-e2d8ac0f-f03c-4513-8c95-a6608713a7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-7eacf19e-96f5-4f19-ba12-fca06ae48837,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-6f3b746a-1f1e-4ed6-a1b2-917bfe2d68c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-2d07408b-b51e-44ff-98ad-23eef4406f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784920174-172.17.0.13-1595617359668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42994,DS-627ebeb8-49c9-475a-bc32-f5b360f0cd40,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-f80728b7-0f01-4c2b-a4e9-c959493766a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-8ac3fea5-5541-417a-9600-43bc38d19684,DISK], DatanodeInfoWithStorage[127.0.0.1:43849,DS-321d2c7b-e1c3-4380-b4d6-af4dd256ed7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-e2d8ac0f-f03c-4513-8c95-a6608713a7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-7eacf19e-96f5-4f19-ba12-fca06ae48837,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-6f3b746a-1f1e-4ed6-a1b2-917bfe2d68c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-2d07408b-b51e-44ff-98ad-23eef4406f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047385783-172.17.0.13-1595617550319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-9c07be02-0903-4ac6-aa48-fd1c4855c079,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-29264b6a-90a1-4ec0-950f-15985f1213ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-0c66a373-6076-42a5-b472-078265af7352,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-e5e2b1a2-3314-497e-b6bc-a765d03e15f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-c2882166-c89c-43fe-a6d6-c072175447e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-37bf947b-1d50-44bd-8dc3-0182ba76af94,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-6a33ab52-04ac-40e0-8a26-b2d643b0b10e,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-8a6266b7-73cf-4952-9683-f9d32606de27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047385783-172.17.0.13-1595617550319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-9c07be02-0903-4ac6-aa48-fd1c4855c079,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-29264b6a-90a1-4ec0-950f-15985f1213ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-0c66a373-6076-42a5-b472-078265af7352,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-e5e2b1a2-3314-497e-b6bc-a765d03e15f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-c2882166-c89c-43fe-a6d6-c072175447e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-37bf947b-1d50-44bd-8dc3-0182ba76af94,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-6a33ab52-04ac-40e0-8a26-b2d643b0b10e,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-8a6266b7-73cf-4952-9683-f9d32606de27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5649
