reconf_parameter: dfs.client.hedged.read.threadpool.size
component: hdfs:NameNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threadpool.size
component: hdfs:NameNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458518579-172.17.0.2-1595980080712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36875,DS-12ae6e84-5668-4468-971a-f9233b6aaeb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-25d4b023-d94c-4158-80ad-af65177ad3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-f4ac07a0-f3d0-4f7d-a047-df1f454f0bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-3b8a14d6-e25f-433f-a1ac-8431866bcbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-a884423d-d111-463e-8fce-0464e3bceec4,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-708b70a7-d198-4516-93c8-6525c99f7c91,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-13025660-bef1-49d6-81c9-1ba01e1de194,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-b08013c7-6212-4724-9a98-a8248ec546fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458518579-172.17.0.2-1595980080712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36875,DS-12ae6e84-5668-4468-971a-f9233b6aaeb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-25d4b023-d94c-4158-80ad-af65177ad3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-f4ac07a0-f3d0-4f7d-a047-df1f454f0bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-3b8a14d6-e25f-433f-a1ac-8431866bcbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-a884423d-d111-463e-8fce-0464e3bceec4,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-708b70a7-d198-4516-93c8-6525c99f7c91,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-13025660-bef1-49d6-81c9-1ba01e1de194,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-b08013c7-6212-4724-9a98-a8248ec546fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threadpool.size
component: hdfs:NameNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250167056-172.17.0.2-1595980115740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34858,DS-320be421-38ac-462f-8f41-3b2feab169f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-5f53577d-0e24-4ae2-81fa-3db2b4197025,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-148a0dec-0ef7-470b-a356-a905db94a35c,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-54f6cfb3-8bac-4d35-a004-ca49df31b2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-e8162438-f7a5-40ad-bc51-66dda4cd4efc,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-70a4be09-e122-4776-81ab-5ebd5a34a225,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-c8396180-7d38-4c97-8860-cd9588eee273,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-920e7dd4-928f-4c24-89af-5067b7991377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250167056-172.17.0.2-1595980115740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34858,DS-320be421-38ac-462f-8f41-3b2feab169f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-5f53577d-0e24-4ae2-81fa-3db2b4197025,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-148a0dec-0ef7-470b-a356-a905db94a35c,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-54f6cfb3-8bac-4d35-a004-ca49df31b2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-e8162438-f7a5-40ad-bc51-66dda4cd4efc,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-70a4be09-e122-4776-81ab-5ebd5a34a225,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-c8396180-7d38-4c97-8860-cd9588eee273,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-920e7dd4-928f-4c24-89af-5067b7991377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threadpool.size
component: hdfs:NameNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878914479-172.17.0.2-1595980181488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43992,DS-f06824f2-b2d2-4b5e-bdc4-54d71f3784aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-34b89c42-f01b-45ea-9e40-0b82a8f27702,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-7764051e-5fea-4ac9-8a98-87c9c48c75ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-95acffcb-7c6b-46e5-8b48-4027915cd0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-7d0e241e-77f2-46c1-8865-b2abf70f3506,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-2ee02727-fdb0-4d64-97fd-78e019304a27,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-a7204c40-e64e-4314-bf9b-b2828fb5a0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-b260dcec-5c2d-40f9-99d7-6e8393815cba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1878914479-172.17.0.2-1595980181488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43992,DS-f06824f2-b2d2-4b5e-bdc4-54d71f3784aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-34b89c42-f01b-45ea-9e40-0b82a8f27702,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-7764051e-5fea-4ac9-8a98-87c9c48c75ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-95acffcb-7c6b-46e5-8b48-4027915cd0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-7d0e241e-77f2-46c1-8865-b2abf70f3506,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-2ee02727-fdb0-4d64-97fd-78e019304a27,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-a7204c40-e64e-4314-bf9b-b2828fb5a0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-b260dcec-5c2d-40f9-99d7-6e8393815cba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threadpool.size
component: hdfs:NameNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1570111308-172.17.0.2-1595980611460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34126,DS-f3eeada1-5ab6-40e2-a4bd-6fb228f0dc23,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-11e10c43-bb8a-4617-b4e3-43b2322d0d53,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-1ba0fb8e-8eea-4c7a-87c8-2b3ed8934eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-06ccec26-e8b8-4937-94f8-3705315cb038,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-88f33ed5-84c6-48d8-aaeb-5dd976ad904e,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-8be38b4d-88d9-4375-b830-5bb3d9a51766,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-0c8d0007-b164-4ef4-81fe-cbb9b7e6a7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-cbe18c83-83ee-4838-83de-9244c72418ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1570111308-172.17.0.2-1595980611460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34126,DS-f3eeada1-5ab6-40e2-a4bd-6fb228f0dc23,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-11e10c43-bb8a-4617-b4e3-43b2322d0d53,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-1ba0fb8e-8eea-4c7a-87c8-2b3ed8934eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-06ccec26-e8b8-4937-94f8-3705315cb038,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-88f33ed5-84c6-48d8-aaeb-5dd976ad904e,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-8be38b4d-88d9-4375-b830-5bb3d9a51766,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-0c8d0007-b164-4ef4-81fe-cbb9b7e6a7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-cbe18c83-83ee-4838-83de-9244c72418ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threadpool.size
component: hdfs:NameNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836268501-172.17.0.2-1595980801024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35212,DS-36272752-64f2-4a3e-b83f-8255d34f9d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-78d1b9bf-2f30-4719-89e6-cb5d09f5acba,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-c0a60d88-62da-426b-ab4e-2ce0a477ba8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-1106b535-c420-4a2a-83d8-939d9473fb03,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-bda275a2-79be-4e92-8052-577853b5d70f,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-96df06e7-17b2-44a7-a6e1-e1bda8cf5719,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-a24a6fc6-55b5-43a9-9f89-2a0b9af1257a,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-23948c26-c95a-4aee-9350-405f9cd1968d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836268501-172.17.0.2-1595980801024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35212,DS-36272752-64f2-4a3e-b83f-8255d34f9d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-78d1b9bf-2f30-4719-89e6-cb5d09f5acba,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-c0a60d88-62da-426b-ab4e-2ce0a477ba8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-1106b535-c420-4a2a-83d8-939d9473fb03,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-bda275a2-79be-4e92-8052-577853b5d70f,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-96df06e7-17b2-44a7-a6e1-e1bda8cf5719,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-a24a6fc6-55b5-43a9-9f89-2a0b9af1257a,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-23948c26-c95a-4aee-9350-405f9cd1968d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threadpool.size
component: hdfs:NameNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841220840-172.17.0.2-1595981248275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35804,DS-ffad24eb-4cd5-4a49-bc5d-dba8d9a3c8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-f3615763-3e46-41c2-b7c8-d6f7f340eab7,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-9f4415cb-688e-4159-99f6-a5130677d88a,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-d833f67c-e4e6-462f-a65c-3180e54eb664,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-47c431f7-4478-4143-92ff-3bba8b32b6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-d1f84b90-190c-4268-bb41-1aaba7de6389,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-580d3849-0af3-4d89-88d6-83be667aa940,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-33a83241-4e3e-43d1-81ab-56da21b1d0e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841220840-172.17.0.2-1595981248275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35804,DS-ffad24eb-4cd5-4a49-bc5d-dba8d9a3c8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-f3615763-3e46-41c2-b7c8-d6f7f340eab7,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-9f4415cb-688e-4159-99f6-a5130677d88a,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-d833f67c-e4e6-462f-a65c-3180e54eb664,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-47c431f7-4478-4143-92ff-3bba8b32b6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-d1f84b90-190c-4268-bb41-1aaba7de6389,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-580d3849-0af3-4d89-88d6-83be667aa940,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-33a83241-4e3e-43d1-81ab-56da21b1d0e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threadpool.size
component: hdfs:NameNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386770602-172.17.0.2-1595981930072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36421,DS-a87c5769-d1c9-4263-b062-8ca531aac38b,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-81045986-298a-4ff2-ab63-a0ba20bf66f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-fde41be1-c874-4233-baa7-1bac4c6c3707,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-4dea8b3f-00da-4da4-849d-8c8af8eccd18,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-49b17e73-c77e-4bb7-a0c3-cdb47548d027,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-c88efd7b-397c-43cd-b5b6-0df3bdfcbf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-eb804f8d-c086-4214-b39c-298a91aa22d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-d72eaed8-27a1-4993-9d38-c920b855366e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386770602-172.17.0.2-1595981930072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36421,DS-a87c5769-d1c9-4263-b062-8ca531aac38b,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-81045986-298a-4ff2-ab63-a0ba20bf66f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-fde41be1-c874-4233-baa7-1bac4c6c3707,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-4dea8b3f-00da-4da4-849d-8c8af8eccd18,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-49b17e73-c77e-4bb7-a0c3-cdb47548d027,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-c88efd7b-397c-43cd-b5b6-0df3bdfcbf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-eb804f8d-c086-4214-b39c-298a91aa22d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-d72eaed8-27a1-4993-9d38-c920b855366e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threadpool.size
component: hdfs:NameNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178582880-172.17.0.2-1595984009134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34876,DS-14680d88-27f0-4c96-81bc-4c2224e82b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-3113cf60-0523-4519-b6f2-a932a68f8270,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-946e0c8d-d1bf-451f-a970-8539516de592,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-90a22970-dc51-4f50-8072-0329d2417a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-08fd82ab-8c4c-4781-a2ee-cd2c9994dd98,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-3e74fb29-b8a0-4e20-a90f-ca05ea0f61ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-4460f83c-d335-4fbd-bf66-04121a2a3184,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-f7675ce6-fadb-40aa-aea8-7eedc2d00f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178582880-172.17.0.2-1595984009134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34876,DS-14680d88-27f0-4c96-81bc-4c2224e82b84,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-3113cf60-0523-4519-b6f2-a932a68f8270,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-946e0c8d-d1bf-451f-a970-8539516de592,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-90a22970-dc51-4f50-8072-0329d2417a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-08fd82ab-8c4c-4781-a2ee-cd2c9994dd98,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-3e74fb29-b8a0-4e20-a90f-ca05ea0f61ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-4460f83c-d335-4fbd-bf66-04121a2a3184,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-f7675ce6-fadb-40aa-aea8-7eedc2d00f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.hedged.read.threadpool.size
component: hdfs:NameNode
v1: 0
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453440428-172.17.0.2-1595984397176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33523,DS-e5fd0973-5eed-4717-a164-505a2252fe0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-33169c26-33ef-48ad-bdc0-fe3a3478e0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-7737d434-2d71-43f2-bf0f-da95c1d686ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-88ddabc7-b746-4ab6-b4ef-9c91ed8ea84d,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-a209c50b-ae7b-4910-95c6-53e9726ace51,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-6c9bc8fa-717e-4402-9592-992a1a020950,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-a1718224-4434-4628-acc3-010fa57b0f39,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-568e8e3a-984a-4a44-b96c-b6c36e82c5e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453440428-172.17.0.2-1595984397176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33523,DS-e5fd0973-5eed-4717-a164-505a2252fe0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-33169c26-33ef-48ad-bdc0-fe3a3478e0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-7737d434-2d71-43f2-bf0f-da95c1d686ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-88ddabc7-b746-4ab6-b4ef-9c91ed8ea84d,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-a209c50b-ae7b-4910-95c6-53e9726ace51,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-6c9bc8fa-717e-4402-9592-992a1a020950,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-a1718224-4434-4628-acc3-010fa57b0f39,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-568e8e3a-984a-4a44-b96c-b6c36e82c5e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 4955
