reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550908705-172.17.0.5-1595629106234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42149,DS-89a10b0e-d660-4d3b-8291-99bd3930b832,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-28dc2f7f-a167-4c9c-aa6d-316a935a8d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-96aeb7df-3215-463b-9dbd-67177b20929e,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-496e3a29-6740-4aa8-a145-15b3ce472ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-69a2792b-8b66-4f10-a705-4505392e8d36,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-47ea8b42-472a-47cb-b8de-d980d573aaad,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-95101c93-18ef-471c-b96e-590f700c478d,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-babcfaa8-633d-4697-9054-8e32321e1874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550908705-172.17.0.5-1595629106234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42149,DS-89a10b0e-d660-4d3b-8291-99bd3930b832,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-28dc2f7f-a167-4c9c-aa6d-316a935a8d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-96aeb7df-3215-463b-9dbd-67177b20929e,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-496e3a29-6740-4aa8-a145-15b3ce472ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-69a2792b-8b66-4f10-a705-4505392e8d36,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-47ea8b42-472a-47cb-b8de-d980d573aaad,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-95101c93-18ef-471c-b96e-590f700c478d,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-babcfaa8-633d-4697-9054-8e32321e1874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148211732-172.17.0.5-1595629769583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43272,DS-ef330a8f-0150-4df6-9d6c-4286e6c8432e,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-02bb477b-255d-4d1e-80d3-4620e926ee50,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-83982b76-b566-4f41-8cb5-3a68eb5c55d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-22295442-f459-45e2-a819-e2280e9a2695,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-23eb9c9b-bea8-45e8-8500-2df272df5031,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-347fa582-52f0-4d50-bbf6-180b6c0fdb67,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-36eccc59-09ef-4952-8b50-78ad3f1bbb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-b89d3196-9c72-4fba-897d-0e894e768a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148211732-172.17.0.5-1595629769583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43272,DS-ef330a8f-0150-4df6-9d6c-4286e6c8432e,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-02bb477b-255d-4d1e-80d3-4620e926ee50,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-83982b76-b566-4f41-8cb5-3a68eb5c55d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-22295442-f459-45e2-a819-e2280e9a2695,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-23eb9c9b-bea8-45e8-8500-2df272df5031,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-347fa582-52f0-4d50-bbf6-180b6c0fdb67,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-36eccc59-09ef-4952-8b50-78ad3f1bbb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-b89d3196-9c72-4fba-897d-0e894e768a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069516336-172.17.0.5-1595630099329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42863,DS-b5064e6e-2a7f-4ef3-8306-122b132267af,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-617e7dbb-7845-445b-b3d6-8b777b7d6d44,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-32ba1db0-8b45-4e79-b5c1-67647ecd4b16,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-7025c9bc-545f-4a8d-9f8f-36323d039b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-0708fc0e-a458-40fa-b227-c1eaae9a5112,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-81a1ea1a-595c-4d92-8450-6c0a2e1b4ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-fe5d8f20-d65e-4fb3-9fa8-e8e3e7ddfe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-7035ca9c-2574-4fe2-9b86-3b4e54542262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069516336-172.17.0.5-1595630099329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42863,DS-b5064e6e-2a7f-4ef3-8306-122b132267af,DISK], DatanodeInfoWithStorage[127.0.0.1:33137,DS-617e7dbb-7845-445b-b3d6-8b777b7d6d44,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-32ba1db0-8b45-4e79-b5c1-67647ecd4b16,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-7025c9bc-545f-4a8d-9f8f-36323d039b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-0708fc0e-a458-40fa-b227-c1eaae9a5112,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-81a1ea1a-595c-4d92-8450-6c0a2e1b4ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-fe5d8f20-d65e-4fb3-9fa8-e8e3e7ddfe1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-7035ca9c-2574-4fe2-9b86-3b4e54542262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239154105-172.17.0.5-1595630313166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44360,DS-a44c7fea-ced5-46f7-a8ae-84b86c88e4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-299196a6-ae8f-456f-904b-4072ab47bb01,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-4ec9a5f0-22a9-4021-ad16-f840c881b98e,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-f5ceb44f-0994-465a-9e01-37367dd599a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-9c43f4d3-b05e-4828-8362-66d4e8a921a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-b95adf33-bb58-4433-b710-5982a9ee2a62,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-43d72a7c-decc-46c5-9a41-276d4fffcb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-250ee61d-6632-45fc-b09b-4268de12a72e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239154105-172.17.0.5-1595630313166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44360,DS-a44c7fea-ced5-46f7-a8ae-84b86c88e4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-299196a6-ae8f-456f-904b-4072ab47bb01,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-4ec9a5f0-22a9-4021-ad16-f840c881b98e,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-f5ceb44f-0994-465a-9e01-37367dd599a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-9c43f4d3-b05e-4828-8362-66d4e8a921a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-b95adf33-bb58-4433-b710-5982a9ee2a62,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-43d72a7c-decc-46c5-9a41-276d4fffcb04,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-250ee61d-6632-45fc-b09b-4268de12a72e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768709117-172.17.0.5-1595630659937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38272,DS-30432829-d34a-4aa3-8a9a-cab868dbfde9,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-bc3eb889-3418-41b7-9387-512d3d0f6fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-8ce7f978-f033-4e9e-9d7b-db1283e5143a,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-7031f9a7-c49b-4187-93f5-eb1ea58c4ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-b54b2a2f-acf0-414c-a1be-59fb55deb36d,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-bed1532c-b97d-47c8-be48-5d7e379cacbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-0254d7ae-cdc1-4417-94c2-91f348ef06bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-ede8d7c6-00ab-4997-adc9-f24f9a5de28e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768709117-172.17.0.5-1595630659937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38272,DS-30432829-d34a-4aa3-8a9a-cab868dbfde9,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-bc3eb889-3418-41b7-9387-512d3d0f6fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-8ce7f978-f033-4e9e-9d7b-db1283e5143a,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-7031f9a7-c49b-4187-93f5-eb1ea58c4ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-b54b2a2f-acf0-414c-a1be-59fb55deb36d,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-bed1532c-b97d-47c8-be48-5d7e379cacbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-0254d7ae-cdc1-4417-94c2-91f348ef06bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-ede8d7c6-00ab-4997-adc9-f24f9a5de28e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004564239-172.17.0.5-1595630833997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43359,DS-afaaafa6-bfb6-4878-baea-efde54bf86ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-6dee3f20-dcd2-4808-a114-47298d0d66e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-2d776fa6-dada-477d-aaa1-910052ed9610,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-3cf42f26-635e-430f-a637-da43f4dcdb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-64f49922-3c5e-432c-bf0f-2bc6799c59ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-a03a3b0c-508c-471b-bae0-8729e43a85fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-71635991-4e23-453e-a55d-01cb4e3f1eae,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-658f7ab5-e52d-4bbc-881e-aa3237121e58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004564239-172.17.0.5-1595630833997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43359,DS-afaaafa6-bfb6-4878-baea-efde54bf86ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-6dee3f20-dcd2-4808-a114-47298d0d66e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-2d776fa6-dada-477d-aaa1-910052ed9610,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-3cf42f26-635e-430f-a637-da43f4dcdb2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-64f49922-3c5e-432c-bf0f-2bc6799c59ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-a03a3b0c-508c-471b-bae0-8729e43a85fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-71635991-4e23-453e-a55d-01cb4e3f1eae,DISK], DatanodeInfoWithStorage[127.0.0.1:45721,DS-658f7ab5-e52d-4bbc-881e-aa3237121e58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386357557-172.17.0.5-1595630936847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43940,DS-7e842777-30c8-4d23-bb2a-2e9eae510787,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-6806867d-1f98-4575-b301-daa472a89f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-4295d803-b463-449e-9eb1-f916e510f4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-592a7d31-b517-4220-9621-128e0e988245,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-3c90cf48-371a-4d28-bbf7-02b5bc9e7027,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-fcc771f8-77a7-42ed-8578-0765a325b465,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-2a0043df-dc7b-47cf-a2a5-a0c4ba8c5ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-dd025e93-3816-40a1-9c20-69925a6999cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386357557-172.17.0.5-1595630936847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43940,DS-7e842777-30c8-4d23-bb2a-2e9eae510787,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-6806867d-1f98-4575-b301-daa472a89f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-4295d803-b463-449e-9eb1-f916e510f4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-592a7d31-b517-4220-9621-128e0e988245,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-3c90cf48-371a-4d28-bbf7-02b5bc9e7027,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-fcc771f8-77a7-42ed-8578-0765a325b465,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-2a0043df-dc7b-47cf-a2a5-a0c4ba8c5ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-dd025e93-3816-40a1-9c20-69925a6999cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009743700-172.17.0.5-1595631031166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36395,DS-d3e7dfd8-8ad0-462a-ac91-16d80ac2c6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-a18403bd-e0e5-4f16-a57a-ae9bb71d416b,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-3a94d0f1-9655-4ce1-a12b-33eab554d1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-62e137f9-baba-4a40-96ac-41e702cf0ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-ecda5fef-ffc8-4536-a726-59aba315e538,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-8f3b4f25-7d26-47ea-ba10-4cb8082cfde3,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-f37559c3-d647-4b62-a71d-5ce0b1b32f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-ea81df77-ac9b-4187-9a14-8725ce046e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009743700-172.17.0.5-1595631031166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36395,DS-d3e7dfd8-8ad0-462a-ac91-16d80ac2c6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-a18403bd-e0e5-4f16-a57a-ae9bb71d416b,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-3a94d0f1-9655-4ce1-a12b-33eab554d1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-62e137f9-baba-4a40-96ac-41e702cf0ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-ecda5fef-ffc8-4536-a726-59aba315e538,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-8f3b4f25-7d26-47ea-ba10-4cb8082cfde3,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-f37559c3-d647-4b62-a71d-5ce0b1b32f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-ea81df77-ac9b-4187-9a14-8725ce046e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791154574-172.17.0.5-1595631266483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36682,DS-1fcc0afa-6691-4418-b28f-3309acfa90ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-8b8a96d1-1308-47c6-89ea-587b181944fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-564fda9a-5449-4ab9-9ea5-cb1442405a54,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-0b30c351-a12d-4a8e-ae85-fc8f40077535,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-33a18bfe-9b50-4fc7-a3b4-473c195b59b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-6c831a68-ba15-460e-9661-72718dae512b,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-f27e05ec-cac0-43c8-a966-837aecd665ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-4afe02a9-fee1-4870-9bcf-0a89a3384e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791154574-172.17.0.5-1595631266483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36682,DS-1fcc0afa-6691-4418-b28f-3309acfa90ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-8b8a96d1-1308-47c6-89ea-587b181944fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-564fda9a-5449-4ab9-9ea5-cb1442405a54,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-0b30c351-a12d-4a8e-ae85-fc8f40077535,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-33a18bfe-9b50-4fc7-a3b4-473c195b59b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-6c831a68-ba15-460e-9661-72718dae512b,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-f27e05ec-cac0-43c8-a966-837aecd665ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-4afe02a9-fee1-4870-9bcf-0a89a3384e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566648539-172.17.0.5-1595631342789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39440,DS-a610404b-b3ae-4756-8f42-04eb3aa349f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-462cb638-0d42-4055-be82-f6f5209112c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-ea7b53e9-9b61-47ab-865f-1e863e810ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-006477f2-5cb1-441d-9ca5-0a6c84e36377,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-79f284f6-0e2c-4c8f-93ec-4ac9e22c54f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-e2a1b0ec-2a29-403a-9ce1-b772975ea406,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-0a232dcf-ad3d-4f17-81b3-03184f5674b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-bb740657-8916-4305-9582-30c30e29cec5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566648539-172.17.0.5-1595631342789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39440,DS-a610404b-b3ae-4756-8f42-04eb3aa349f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-462cb638-0d42-4055-be82-f6f5209112c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-ea7b53e9-9b61-47ab-865f-1e863e810ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-006477f2-5cb1-441d-9ca5-0a6c84e36377,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-79f284f6-0e2c-4c8f-93ec-4ac9e22c54f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-e2a1b0ec-2a29-403a-9ce1-b772975ea406,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-0a232dcf-ad3d-4f17-81b3-03184f5674b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-bb740657-8916-4305-9582-30c30e29cec5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27068801-172.17.0.5-1595632232880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-f2837a69-ad95-4d02-8b08-46245a782b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-9faa0c21-aaea-4d5c-969e-7d31fa67a78b,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-d0515eb3-1af5-43d4-babb-5b06558bdb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-3663c13d-3b14-4daa-aa95-7cbdafe94927,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-cd5aab88-0892-44a5-98f0-1c13ee574fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-3b53f178-f773-48d6-b14b-ebd656c5e9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-936a1455-c1f9-40b9-88ef-a31d81aeb86d,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-75565718-03e3-4252-9d6e-f82d664f1b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27068801-172.17.0.5-1595632232880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-f2837a69-ad95-4d02-8b08-46245a782b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-9faa0c21-aaea-4d5c-969e-7d31fa67a78b,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-d0515eb3-1af5-43d4-babb-5b06558bdb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-3663c13d-3b14-4daa-aa95-7cbdafe94927,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-cd5aab88-0892-44a5-98f0-1c13ee574fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-3b53f178-f773-48d6-b14b-ebd656c5e9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-936a1455-c1f9-40b9-88ef-a31d81aeb86d,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-75565718-03e3-4252-9d6e-f82d664f1b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819224239-172.17.0.5-1595632335754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46681,DS-2ad84d10-beb3-44d5-97bb-6e8a9179b6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-102c5ac7-22eb-4c90-91d0-69d0b81a73fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-39917d1b-6343-44fe-bcde-1341cb30b473,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-e0956ee6-5b71-4a4d-a628-57653daf649e,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-d0912780-12e7-4928-bf93-0e4085c1f0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-7a7969d7-123f-4284-b7d8-f0433ec0a9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-8dcc331a-c8b7-46e6-bfad-1e5019a2e036,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-39f312a5-8844-4785-b1d1-eb41df9f5334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819224239-172.17.0.5-1595632335754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46681,DS-2ad84d10-beb3-44d5-97bb-6e8a9179b6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-102c5ac7-22eb-4c90-91d0-69d0b81a73fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-39917d1b-6343-44fe-bcde-1341cb30b473,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-e0956ee6-5b71-4a4d-a628-57653daf649e,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-d0912780-12e7-4928-bf93-0e4085c1f0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-7a7969d7-123f-4284-b7d8-f0433ec0a9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-8dcc331a-c8b7-46e6-bfad-1e5019a2e036,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-39f312a5-8844-4785-b1d1-eb41df9f5334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287725101-172.17.0.5-1595632524589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46377,DS-2d4a40c1-5ce9-42cb-992e-0a486180eea3,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-841955ac-e3ed-48f6-843f-3cd48911891b,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-1d6f6df1-48aa-4fe7-a33c-6a95f89b5553,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-0f33988c-e206-4d05-812a-78c89255e79e,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-a187dbb3-3712-45e3-b4a1-b530175e98e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-6b24d7fe-37d7-4780-b170-38275cabb1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-9f243f59-8330-4310-9836-291055ee51b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-bab8f2d8-d692-44c7-bb75-da299d24943a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287725101-172.17.0.5-1595632524589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46377,DS-2d4a40c1-5ce9-42cb-992e-0a486180eea3,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-841955ac-e3ed-48f6-843f-3cd48911891b,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-1d6f6df1-48aa-4fe7-a33c-6a95f89b5553,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-0f33988c-e206-4d05-812a-78c89255e79e,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-a187dbb3-3712-45e3-b4a1-b530175e98e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-6b24d7fe-37d7-4780-b170-38275cabb1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-9f243f59-8330-4310-9836-291055ee51b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-bab8f2d8-d692-44c7-bb75-da299d24943a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176095701-172.17.0.5-1595632603893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34640,DS-46f31c9c-6392-40dd-bd35-287a47d0c791,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-76477ff7-09ad-476f-9aec-49f2247f4ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-8024fb8a-f80c-41c7-ae6e-877da81ef971,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-039bb9c9-a62b-4132-b721-7dc01a2d870b,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-9133b684-6764-4df9-b4dc-3e2b795589c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-2886d97c-da31-4a23-94aa-f5c5555e50dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-852abc44-e499-4cf1-b745-e00641f0809c,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-82f1fef3-9896-4980-b9b8-3e820a7560a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176095701-172.17.0.5-1595632603893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34640,DS-46f31c9c-6392-40dd-bd35-287a47d0c791,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-76477ff7-09ad-476f-9aec-49f2247f4ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-8024fb8a-f80c-41c7-ae6e-877da81ef971,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-039bb9c9-a62b-4132-b721-7dc01a2d870b,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-9133b684-6764-4df9-b4dc-3e2b795589c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-2886d97c-da31-4a23-94aa-f5c5555e50dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-852abc44-e499-4cf1-b745-e00641f0809c,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-82f1fef3-9896-4980-b9b8-3e820a7560a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008088964-172.17.0.5-1595632948292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35795,DS-c297fe67-3c0c-4a22-b550-e5bb4fea5053,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-930efadd-0613-4a02-a1d0-80062b3deef1,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-780a04e3-1b40-430b-8f0b-dfd3806475fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-fedd01ab-948a-433a-83b8-63837b844bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-6291942d-4fec-4170-86f7-fcf17a11ccf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-25909825-a8af-4719-a40c-7784234732ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-8a36365d-6057-434b-89b3-cb44cde2fa00,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-b38ecfa5-0484-4568-be28-47ca98cf0894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008088964-172.17.0.5-1595632948292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35795,DS-c297fe67-3c0c-4a22-b550-e5bb4fea5053,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-930efadd-0613-4a02-a1d0-80062b3deef1,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-780a04e3-1b40-430b-8f0b-dfd3806475fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-fedd01ab-948a-433a-83b8-63837b844bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-6291942d-4fec-4170-86f7-fcf17a11ccf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-25909825-a8af-4719-a40c-7784234732ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-8a36365d-6057-434b-89b3-cb44cde2fa00,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-b38ecfa5-0484-4568-be28-47ca98cf0894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52990722-172.17.0.5-1595633850992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45606,DS-470fd873-e3ad-492e-976b-0a0f3f069483,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-c514636b-0b28-42ab-be31-9b56d6aca8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-8a723d40-2023-43bc-8207-a32ad67b7036,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-0e4c262b-9e19-4add-81d2-052be6d1fcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-e58978e2-4941-4325-838f-b7db8ccd8767,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-b2994e64-2592-4bb5-ab63-7383162418b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-14bf779c-6c4c-4b8e-a206-890c138a215f,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-46728e86-3b6c-4428-8fc3-082d683cc4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52990722-172.17.0.5-1595633850992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45606,DS-470fd873-e3ad-492e-976b-0a0f3f069483,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-c514636b-0b28-42ab-be31-9b56d6aca8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-8a723d40-2023-43bc-8207-a32ad67b7036,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-0e4c262b-9e19-4add-81d2-052be6d1fcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-e58978e2-4941-4325-838f-b7db8ccd8767,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-b2994e64-2592-4bb5-ab63-7383162418b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-14bf779c-6c4c-4b8e-a206-890c138a215f,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-46728e86-3b6c-4428-8fc3-082d683cc4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396538559-172.17.0.5-1595634102361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43046,DS-1b2ff439-083b-47e8-b73b-9500e5092f23,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-71776095-cf18-4d7f-8a87-2936605c0c60,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-78a16741-99cd-42e5-ad68-8c23c933a910,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-c7df80e7-243d-481d-b7e3-fea734b83cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-efb34607-899e-4566-893e-80269c127709,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-e96a354f-ab7c-4a98-8584-d66e541466c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-ef8bec86-9df1-49c4-b4b4-57c9c1bb5c15,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-794fca10-de26-42c0-83af-f085f1d185e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396538559-172.17.0.5-1595634102361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43046,DS-1b2ff439-083b-47e8-b73b-9500e5092f23,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-71776095-cf18-4d7f-8a87-2936605c0c60,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-78a16741-99cd-42e5-ad68-8c23c933a910,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-c7df80e7-243d-481d-b7e3-fea734b83cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-efb34607-899e-4566-893e-80269c127709,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-e96a354f-ab7c-4a98-8584-d66e541466c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-ef8bec86-9df1-49c4-b4b4-57c9c1bb5c15,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-794fca10-de26-42c0-83af-f085f1d185e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5315
