reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-222659678-172.17.0.4-1595671309947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38335,DS-7c6a56b5-f52c-483a-bbd7-79f1b475797b,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-4c1269ca-2745-4051-854b-002aef6c49e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-f22888f7-7867-40a7-b26a-63a6992e258e,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-d1bf00df-9683-4025-aa5f-73f5492e9692,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-9a5807af-81be-47b9-b24a-0b2c20b295f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-9e861e8f-bb8e-41cb-96a3-1b34cb83011a,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-31a59ce4-d836-4e4a-8110-df0382cbd825,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-24c5398e-27f1-44f7-b60f-8b9415bed5a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-222659678-172.17.0.4-1595671309947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38335,DS-7c6a56b5-f52c-483a-bbd7-79f1b475797b,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-4c1269ca-2745-4051-854b-002aef6c49e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-f22888f7-7867-40a7-b26a-63a6992e258e,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-d1bf00df-9683-4025-aa5f-73f5492e9692,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-9a5807af-81be-47b9-b24a-0b2c20b295f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-9e861e8f-bb8e-41cb-96a3-1b34cb83011a,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-31a59ce4-d836-4e4a-8110-df0382cbd825,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-24c5398e-27f1-44f7-b60f-8b9415bed5a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892137706-172.17.0.4-1595673029171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35717,DS-ea794716-7a8e-4d44-a0ec-f3a1f1894015,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-b6141463-1dc3-46c2-a99d-bdb2bc2a4759,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-e0effe01-ee22-4c73-a872-e2536f2a8289,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-4e03ee4e-f6fa-4705-89e4-c20f6923def2,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-0f507a55-d2ad-4901-8bd8-028cc25d7cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-709e4eaf-4546-4a81-ae93-de12db1f0c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-d0ee5d9e-0c04-4f1f-adab-6fe14c600dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-cfda2c5b-2228-4f7c-b014-91a9cd2c9e81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892137706-172.17.0.4-1595673029171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35717,DS-ea794716-7a8e-4d44-a0ec-f3a1f1894015,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-b6141463-1dc3-46c2-a99d-bdb2bc2a4759,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-e0effe01-ee22-4c73-a872-e2536f2a8289,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-4e03ee4e-f6fa-4705-89e4-c20f6923def2,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-0f507a55-d2ad-4901-8bd8-028cc25d7cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-709e4eaf-4546-4a81-ae93-de12db1f0c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-d0ee5d9e-0c04-4f1f-adab-6fe14c600dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-cfda2c5b-2228-4f7c-b014-91a9cd2c9e81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467498163-172.17.0.4-1595673364404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46162,DS-ad1620ab-ad5e-4a7f-813b-313193a65b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-81cb711f-d743-4744-ab22-709d3ed32319,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-ebda48b8-5616-45ec-a404-b0d73100d261,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-a4911509-cfd9-4ff2-a10f-40cd3eef7d89,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-c8a6e8ff-7236-4a93-b36f-d0237bc8c13d,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-3e2ae3ba-f364-4ae2-b13f-cfdaee1ef337,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-a91f6932-6b0d-464f-8969-4aeed8512053,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-5183f5ca-a9ae-4767-93db-9705b6969f59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467498163-172.17.0.4-1595673364404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46162,DS-ad1620ab-ad5e-4a7f-813b-313193a65b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-81cb711f-d743-4744-ab22-709d3ed32319,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-ebda48b8-5616-45ec-a404-b0d73100d261,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-a4911509-cfd9-4ff2-a10f-40cd3eef7d89,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-c8a6e8ff-7236-4a93-b36f-d0237bc8c13d,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-3e2ae3ba-f364-4ae2-b13f-cfdaee1ef337,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-a91f6932-6b0d-464f-8969-4aeed8512053,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-5183f5ca-a9ae-4767-93db-9705b6969f59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460388539-172.17.0.4-1595673620608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44553,DS-7ca0eb4e-4dbf-474f-bde8-c73710117b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-b8e1bef6-230f-47f8-bb9e-226c8efb5b68,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-61094d02-d0c0-4648-a50d-b4cc99fe4f51,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-9c0d2f56-1e7c-48ef-8fe8-86f8998baaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-bd917e8f-6bea-4188-a37c-ce8e744995fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-622d0681-9d40-435f-b39c-91b5a96475e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-255af8e3-6285-430d-804f-afc58217b842,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-2ac20b3c-e503-4e44-8751-f450ed896cac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460388539-172.17.0.4-1595673620608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44553,DS-7ca0eb4e-4dbf-474f-bde8-c73710117b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-b8e1bef6-230f-47f8-bb9e-226c8efb5b68,DISK], DatanodeInfoWithStorage[127.0.0.1:36771,DS-61094d02-d0c0-4648-a50d-b4cc99fe4f51,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-9c0d2f56-1e7c-48ef-8fe8-86f8998baaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-bd917e8f-6bea-4188-a37c-ce8e744995fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-622d0681-9d40-435f-b39c-91b5a96475e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-255af8e3-6285-430d-804f-afc58217b842,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-2ac20b3c-e503-4e44-8751-f450ed896cac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098189098-172.17.0.4-1595673657617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41165,DS-87af800e-50a4-4747-b910-ce6b1f789815,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-0ce98257-9ab4-43f1-8d24-947da367e12c,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-c67a4b2c-0efc-4930-a047-466b54c919bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-cb12b315-c456-4d59-a931-c85bae765cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-8a246f03-2dfc-4eee-96f4-ca7d56999410,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-ededbdd8-4c6a-476f-a1fe-21c4b88e7d01,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-87fa64ee-a4b1-4af7-b253-28a21657ec30,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-7e48cdde-7b75-4e75-9371-edeff7acadd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098189098-172.17.0.4-1595673657617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41165,DS-87af800e-50a4-4747-b910-ce6b1f789815,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-0ce98257-9ab4-43f1-8d24-947da367e12c,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-c67a4b2c-0efc-4930-a047-466b54c919bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-cb12b315-c456-4d59-a931-c85bae765cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-8a246f03-2dfc-4eee-96f4-ca7d56999410,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-ededbdd8-4c6a-476f-a1fe-21c4b88e7d01,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-87fa64ee-a4b1-4af7-b253-28a21657ec30,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-7e48cdde-7b75-4e75-9371-edeff7acadd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956500988-172.17.0.4-1595674406147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42091,DS-b9b9ec13-2013-44e0-bf3f-4149e27c5e93,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-69d3c397-18ad-47fc-89dd-8640145e3c05,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-66474ace-7907-4fdd-804d-c7bcc44bd552,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-87baa9da-dac7-450e-b3f6-d74e286f77d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-c224451d-535e-4aeb-a711-6401e8cc8298,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-e8d78f6c-35b9-423a-aefc-fcef02fea395,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-06321dc2-4d93-48b0-b842-df1bb7f79075,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-fce04bde-5b3b-4bf5-b2bb-b7dcc730ed56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956500988-172.17.0.4-1595674406147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42091,DS-b9b9ec13-2013-44e0-bf3f-4149e27c5e93,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-69d3c397-18ad-47fc-89dd-8640145e3c05,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-66474ace-7907-4fdd-804d-c7bcc44bd552,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-87baa9da-dac7-450e-b3f6-d74e286f77d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39925,DS-c224451d-535e-4aeb-a711-6401e8cc8298,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-e8d78f6c-35b9-423a-aefc-fcef02fea395,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-06321dc2-4d93-48b0-b842-df1bb7f79075,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-fce04bde-5b3b-4bf5-b2bb-b7dcc730ed56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740932085-172.17.0.4-1595674471350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39455,DS-b683f6e0-dd29-4a38-90bb-61c145a587b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-165b2432-fac9-495f-a62c-f23570e87d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-00024b97-51b6-4c0c-b7a0-dc1d780e380d,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-ba029815-6ca2-4c56-b899-9328b76844ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-6ec16165-d489-44bb-89e0-ca249e219636,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-4655e2f1-8e2c-4c10-abad-b26dd723dfac,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-4a36a875-d51c-4f5b-abf9-12d0e2141b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-75030570-3b94-42da-9a77-090c579cc54f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740932085-172.17.0.4-1595674471350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39455,DS-b683f6e0-dd29-4a38-90bb-61c145a587b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-165b2432-fac9-495f-a62c-f23570e87d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-00024b97-51b6-4c0c-b7a0-dc1d780e380d,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-ba029815-6ca2-4c56-b899-9328b76844ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-6ec16165-d489-44bb-89e0-ca249e219636,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-4655e2f1-8e2c-4c10-abad-b26dd723dfac,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-4a36a875-d51c-4f5b-abf9-12d0e2141b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-75030570-3b94-42da-9a77-090c579cc54f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309759286-172.17.0.4-1595674836611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43299,DS-26a5226b-b38e-49da-b0fb-187308a58df3,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-91ded5e8-0ffc-4ce3-85cb-6f00a4b72ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-4fa4efaa-8e9a-40b2-90e8-7ccca682198c,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-59a89e2b-2076-4d8f-b2f8-9cd452bb754c,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-b300d0f2-ae96-490b-b9dd-8255b8d19e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-2eaf0e2e-eb72-494b-b873-89b09d6d6966,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-8ae04df1-dfd0-444e-8374-259cab615116,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-e53e2d80-619e-4d0b-8805-aa8d8d130312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309759286-172.17.0.4-1595674836611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43299,DS-26a5226b-b38e-49da-b0fb-187308a58df3,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-91ded5e8-0ffc-4ce3-85cb-6f00a4b72ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-4fa4efaa-8e9a-40b2-90e8-7ccca682198c,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-59a89e2b-2076-4d8f-b2f8-9cd452bb754c,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-b300d0f2-ae96-490b-b9dd-8255b8d19e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-2eaf0e2e-eb72-494b-b873-89b09d6d6966,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-8ae04df1-dfd0-444e-8374-259cab615116,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-e53e2d80-619e-4d0b-8805-aa8d8d130312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-662193737-172.17.0.4-1595675661826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34576,DS-5637bdb9-ff9c-4b85-b0fe-ea9fdfe4b26e,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-096253ff-91d2-4e1f-a1f3-46ece0fa03da,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-c1ddd0a2-9a8d-42fa-82e1-61e55184ccf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-922ef343-3b99-4f7b-8126-9f485dca6641,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-c2adf7ee-2a64-4efe-b293-8f4edab5de70,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-5b0b6d5c-dfb9-41ee-a7de-8f52ba43e028,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-7057d058-27f4-4e61-8ac4-498dd19a3689,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-67136b0c-894b-407f-9917-ac2e2bfaeb4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-662193737-172.17.0.4-1595675661826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34576,DS-5637bdb9-ff9c-4b85-b0fe-ea9fdfe4b26e,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-096253ff-91d2-4e1f-a1f3-46ece0fa03da,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-c1ddd0a2-9a8d-42fa-82e1-61e55184ccf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-922ef343-3b99-4f7b-8126-9f485dca6641,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-c2adf7ee-2a64-4efe-b293-8f4edab5de70,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-5b0b6d5c-dfb9-41ee-a7de-8f52ba43e028,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-7057d058-27f4-4e61-8ac4-498dd19a3689,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-67136b0c-894b-407f-9917-ac2e2bfaeb4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306752356-172.17.0.4-1595676508716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33697,DS-6788cb7b-2b01-4ee6-bc1f-f76f87f364e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-6b7f07e3-8376-463c-87b0-1a77185f2f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-59b47517-1c05-4339-937c-c62419f41bca,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-27edc059-5bff-4d78-b8bf-c1bb66201e95,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-fe749f12-b5ac-40e0-8ddd-160624df77a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-74c21d03-ca1b-4219-ab7b-877ea4ed0f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-31de4fba-caa7-4e14-9716-4c21e6090cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-8eabe9ba-93c9-41b1-9bfd-3eeca849b6f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306752356-172.17.0.4-1595676508716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33697,DS-6788cb7b-2b01-4ee6-bc1f-f76f87f364e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-6b7f07e3-8376-463c-87b0-1a77185f2f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-59b47517-1c05-4339-937c-c62419f41bca,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-27edc059-5bff-4d78-b8bf-c1bb66201e95,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-fe749f12-b5ac-40e0-8ddd-160624df77a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-74c21d03-ca1b-4219-ab7b-877ea4ed0f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-31de4fba-caa7-4e14-9716-4c21e6090cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-8eabe9ba-93c9-41b1-9bfd-3eeca849b6f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242302961-172.17.0.4-1595676582079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37864,DS-1ead5be9-54c7-4fdf-b978-50c4f6a847a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-39837aa9-c24b-4d47-ae66-0658e8c97947,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-413503a9-8c3b-40f0-b053-601f9455dd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-969bb919-d4fa-449a-abc6-3b267bde3bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-2b2c531c-ba0c-4146-8d83-b470a17a0b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-ecb98622-2e75-481e-9a42-a3a7dd3501a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-beae938d-51b5-4eab-8113-cbc1f167eb55,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-e71f2496-9869-4d09-a654-60809c5593bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1242302961-172.17.0.4-1595676582079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37864,DS-1ead5be9-54c7-4fdf-b978-50c4f6a847a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-39837aa9-c24b-4d47-ae66-0658e8c97947,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-413503a9-8c3b-40f0-b053-601f9455dd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-969bb919-d4fa-449a-abc6-3b267bde3bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-2b2c531c-ba0c-4146-8d83-b470a17a0b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-ecb98622-2e75-481e-9a42-a3a7dd3501a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-beae938d-51b5-4eab-8113-cbc1f167eb55,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-e71f2496-9869-4d09-a654-60809c5593bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647656531-172.17.0.4-1595676651634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-ce1f92e0-397e-455b-9b60-ea5cc587b6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-ca62510b-5460-44b7-86d1-224476cf70a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-4a72a148-102a-42d2-91f2-c4e6ff693d43,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-0d0f310c-0258-4000-953a-81e62de957d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-253bcb60-8e18-4f3c-b8f4-6fcad58d175d,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-94e223c7-6366-4750-ac43-2f49219b1055,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-a3a345b0-2425-49d7-9a6d-c0cae62413b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-f272e200-868e-4c07-aa64-954fba7d3433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647656531-172.17.0.4-1595676651634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-ce1f92e0-397e-455b-9b60-ea5cc587b6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-ca62510b-5460-44b7-86d1-224476cf70a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34919,DS-4a72a148-102a-42d2-91f2-c4e6ff693d43,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-0d0f310c-0258-4000-953a-81e62de957d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-253bcb60-8e18-4f3c-b8f4-6fcad58d175d,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-94e223c7-6366-4750-ac43-2f49219b1055,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-a3a345b0-2425-49d7-9a6d-c0cae62413b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-f272e200-868e-4c07-aa64-954fba7d3433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5536
