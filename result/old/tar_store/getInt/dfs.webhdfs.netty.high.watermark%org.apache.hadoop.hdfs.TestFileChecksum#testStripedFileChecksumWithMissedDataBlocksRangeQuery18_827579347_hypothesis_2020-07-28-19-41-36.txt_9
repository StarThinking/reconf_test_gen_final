reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501787309-172.17.0.20-1595965543894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41768,DS-e614229c-c3f9-4c95-ac4c-f46bb8519b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-304d05da-9fac-4cb0-a3c6-a59d187466ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-cac4734c-1abd-4f93-a616-a707812c3510,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-8a6823fb-904a-4636-a441-161056fd9585,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-c87dc3c1-d323-4156-9889-6075ed462a43,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-dc8e81e8-9db9-4be6-914c-c3d27782506d,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-eb137f88-10ed-4aee-96b0-94169875025b,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-25e06c79-f388-4262-980a-15e7c53c1c37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-501787309-172.17.0.20-1595965543894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41768,DS-e614229c-c3f9-4c95-ac4c-f46bb8519b46,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-304d05da-9fac-4cb0-a3c6-a59d187466ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-cac4734c-1abd-4f93-a616-a707812c3510,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-8a6823fb-904a-4636-a441-161056fd9585,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-c87dc3c1-d323-4156-9889-6075ed462a43,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-dc8e81e8-9db9-4be6-914c-c3d27782506d,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-eb137f88-10ed-4aee-96b0-94169875025b,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-25e06c79-f388-4262-980a-15e7c53c1c37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583609770-172.17.0.20-1595965828373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45606,DS-eeee53ec-e48b-4d8b-bbc4-41ebba3fab27,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-aab2b906-c566-4953-9edb-988e163dd6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-ddcc9355-f146-4aa5-a75b-b62a3864bd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-fc85ffff-84fb-4cca-bcdb-810c72678b18,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-3f19287a-1f3b-4642-bbff-3fb0d646b224,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-968118bc-e90a-4c42-96f0-f920fa289054,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-7f8218a2-86cb-4581-8ad2-d859887e92cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-ace3f294-8d82-4818-bfb0-6a5543cc6ad8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583609770-172.17.0.20-1595965828373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45606,DS-eeee53ec-e48b-4d8b-bbc4-41ebba3fab27,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-aab2b906-c566-4953-9edb-988e163dd6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-ddcc9355-f146-4aa5-a75b-b62a3864bd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-fc85ffff-84fb-4cca-bcdb-810c72678b18,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-3f19287a-1f3b-4642-bbff-3fb0d646b224,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-968118bc-e90a-4c42-96f0-f920fa289054,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-7f8218a2-86cb-4581-8ad2-d859887e92cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-ace3f294-8d82-4818-bfb0-6a5543cc6ad8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989647056-172.17.0.20-1595966157712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45489,DS-a8ab4591-db4f-4372-989f-0d8c9884db07,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-a06ba24f-09c4-45a9-b736-e9c47112dedf,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-505dc995-283a-4360-b005-da985fb9861c,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-24d4e7ab-76e8-4a13-93c9-4cfb3d5c6acf,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-08c72d61-e8ce-4d51-968d-489025427416,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-d07a3774-a4a4-4c7c-8449-820aad633f10,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-ad1bd6ab-1dc4-433e-a1b0-feb4d37df922,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-6b6feb02-92fa-4236-b37d-f1332e393009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989647056-172.17.0.20-1595966157712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45489,DS-a8ab4591-db4f-4372-989f-0d8c9884db07,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-a06ba24f-09c4-45a9-b736-e9c47112dedf,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-505dc995-283a-4360-b005-da985fb9861c,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-24d4e7ab-76e8-4a13-93c9-4cfb3d5c6acf,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-08c72d61-e8ce-4d51-968d-489025427416,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-d07a3774-a4a4-4c7c-8449-820aad633f10,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-ad1bd6ab-1dc4-433e-a1b0-feb4d37df922,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-6b6feb02-92fa-4236-b37d-f1332e393009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296958930-172.17.0.20-1595966914487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45982,DS-0f0d204a-1a6e-412e-8e1d-b3697b0b0853,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-f964ec9d-bb91-440d-9ed5-cfd7b97fdfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-b480b4ad-6c3d-485b-bb7c-d2f6252eb054,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-52d4e6b3-2470-43ff-8e65-e108ca97574f,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-2808eb6f-fe3f-43de-9fef-839bb29acb51,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-1f20067d-d109-4250-ab63-4835a124fdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-97e69a32-fe3d-411c-a77c-0ab57ff7e701,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-50974a63-4404-4029-9f3f-b54721ccfdc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296958930-172.17.0.20-1595966914487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45982,DS-0f0d204a-1a6e-412e-8e1d-b3697b0b0853,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-f964ec9d-bb91-440d-9ed5-cfd7b97fdfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-b480b4ad-6c3d-485b-bb7c-d2f6252eb054,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-52d4e6b3-2470-43ff-8e65-e108ca97574f,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-2808eb6f-fe3f-43de-9fef-839bb29acb51,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-1f20067d-d109-4250-ab63-4835a124fdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-97e69a32-fe3d-411c-a77c-0ab57ff7e701,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-50974a63-4404-4029-9f3f-b54721ccfdc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116814013-172.17.0.20-1595967262635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45539,DS-6f96ee1c-0585-416e-bee1-999dc0fc438a,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-96be8725-2bee-4028-b7da-28c5a46e9953,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-a7b002f2-42c5-454e-94e3-64604fb3e828,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-90315a08-92de-4196-8bfd-cd7a929af90e,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-ee0baaf6-6ce7-449d-a495-322bcfa48575,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-11139b3c-dbad-4db4-9514-fc0dedfdb5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-c4d9df58-69e0-4f41-b633-aae3a2b86465,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-5669c3fc-ea09-4efa-999a-a56067db29e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116814013-172.17.0.20-1595967262635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45539,DS-6f96ee1c-0585-416e-bee1-999dc0fc438a,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-96be8725-2bee-4028-b7da-28c5a46e9953,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-a7b002f2-42c5-454e-94e3-64604fb3e828,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-90315a08-92de-4196-8bfd-cd7a929af90e,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-ee0baaf6-6ce7-449d-a495-322bcfa48575,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-11139b3c-dbad-4db4-9514-fc0dedfdb5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-c4d9df58-69e0-4f41-b633-aae3a2b86465,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-5669c3fc-ea09-4efa-999a-a56067db29e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931881674-172.17.0.20-1595968923039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33973,DS-4da47e25-3bb1-410a-88b0-212bd1a2af64,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-da26e97c-d4ee-485c-81c3-cbc151710d61,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-f5496038-95e0-4ea7-9375-98ec0c215f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-eb9aaae6-29c7-4cfc-9567-3cc605b51b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-a7680413-18b5-418d-96ce-7ecbdca58fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-0d266660-ba95-4c9b-b978-de9167233556,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-924beeea-0501-4d76-a165-22b6984604ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-a7b2275a-9c21-41a2-86f2-a9abf8ff0e24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931881674-172.17.0.20-1595968923039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33973,DS-4da47e25-3bb1-410a-88b0-212bd1a2af64,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-da26e97c-d4ee-485c-81c3-cbc151710d61,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-f5496038-95e0-4ea7-9375-98ec0c215f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37562,DS-eb9aaae6-29c7-4cfc-9567-3cc605b51b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-a7680413-18b5-418d-96ce-7ecbdca58fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-0d266660-ba95-4c9b-b978-de9167233556,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-924beeea-0501-4d76-a165-22b6984604ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-a7b2275a-9c21-41a2-86f2-a9abf8ff0e24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519474880-172.17.0.20-1595969415281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40748,DS-191ef964-f529-4ed7-888d-c84e373db264,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-57b91351-4dbf-4fa3-9b31-3788d79d9d35,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-6141495e-e221-4bce-9af2-4b0b91e5b9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-0751ad20-e7a1-486a-b40f-7faf435902ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-c2bb7f88-d0b1-44b0-beb0-75bc058eb43a,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-dfc378e8-63b8-406f-a136-ac079276f20e,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-31c1b47d-b863-404d-a3ba-3c3f4b1a9761,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-6221a33a-7a2c-47a1-9540-dbb60c01b7f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1519474880-172.17.0.20-1595969415281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40748,DS-191ef964-f529-4ed7-888d-c84e373db264,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-57b91351-4dbf-4fa3-9b31-3788d79d9d35,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-6141495e-e221-4bce-9af2-4b0b91e5b9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-0751ad20-e7a1-486a-b40f-7faf435902ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-c2bb7f88-d0b1-44b0-beb0-75bc058eb43a,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-dfc378e8-63b8-406f-a136-ac079276f20e,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-31c1b47d-b863-404d-a3ba-3c3f4b1a9761,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-6221a33a-7a2c-47a1-9540-dbb60c01b7f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1666826230-172.17.0.20-1595970004988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42337,DS-a112bef9-fd5e-4bd2-abb2-76fc991844a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-74f9e1a2-0e77-4180-a9db-28541e552d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-57a3020c-2d22-4e77-852d-b7b95521452c,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-2a843b55-9431-40c2-9e83-c86a27e08921,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-5b8a790f-8bea-49ab-b066-66dadbd3619c,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-7102c686-1411-405e-adff-7dc0a1927a24,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-b313dad5-8f27-4800-999d-9aa5e15a64a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-8c0698b0-2183-45b2-ae3e-a4acaab20eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1666826230-172.17.0.20-1595970004988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42337,DS-a112bef9-fd5e-4bd2-abb2-76fc991844a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-74f9e1a2-0e77-4180-a9db-28541e552d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-57a3020c-2d22-4e77-852d-b7b95521452c,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-2a843b55-9431-40c2-9e83-c86a27e08921,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-5b8a790f-8bea-49ab-b066-66dadbd3619c,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-7102c686-1411-405e-adff-7dc0a1927a24,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-b313dad5-8f27-4800-999d-9aa5e15a64a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-8c0698b0-2183-45b2-ae3e-a4acaab20eb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843460031-172.17.0.20-1595970357651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41978,DS-d7c57302-24eb-47c6-92f8-f24e534400a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-61d33580-1a41-47d9-b6ab-1942bd12e0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-e3359f5d-24e9-4c70-80ba-cd322023e211,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-60bb902c-d4fc-4bb2-9d7e-ca16123a76b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-dd767d12-3a2e-4d6b-8877-466b9befbd09,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-e7dc5402-be80-4da4-a4ef-6033fd3e7c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-41e61578-25eb-4cd7-a70e-af446affb319,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-983739f7-0901-4b4d-8c15-b39e2c126980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843460031-172.17.0.20-1595970357651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41978,DS-d7c57302-24eb-47c6-92f8-f24e534400a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-61d33580-1a41-47d9-b6ab-1942bd12e0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-e3359f5d-24e9-4c70-80ba-cd322023e211,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-60bb902c-d4fc-4bb2-9d7e-ca16123a76b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-dd767d12-3a2e-4d6b-8877-466b9befbd09,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-e7dc5402-be80-4da4-a4ef-6033fd3e7c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-41e61578-25eb-4cd7-a70e-af446affb319,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-983739f7-0901-4b4d-8c15-b39e2c126980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5111
