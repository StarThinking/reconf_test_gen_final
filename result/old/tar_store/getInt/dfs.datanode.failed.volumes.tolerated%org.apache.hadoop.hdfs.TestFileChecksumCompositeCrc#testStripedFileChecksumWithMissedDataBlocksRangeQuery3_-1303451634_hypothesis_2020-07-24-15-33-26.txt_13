reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: -1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: -1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184694974-172.17.0.12-1595605522245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41474,DS-7a8792b4-6cd5-497f-a62c-8e69e0c6b860,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-7168d338-718f-4347-a426-e1cf0dc0bceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-7c0fac0e-a390-4842-982c-fa55d052b98f,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-6f364f9f-42e2-431c-b949-850f7e583eff,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-616783f5-7733-4cbf-be1d-dbf5864f5aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-623d4450-a62c-44cd-9eec-a1ef50cfb7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-c4cb8a60-3e7c-4409-8fa3-1e4e655199d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-c68f20a2-a410-407b-a454-6daa2a6adbd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184694974-172.17.0.12-1595605522245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41474,DS-7a8792b4-6cd5-497f-a62c-8e69e0c6b860,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-7168d338-718f-4347-a426-e1cf0dc0bceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-7c0fac0e-a390-4842-982c-fa55d052b98f,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-6f364f9f-42e2-431c-b949-850f7e583eff,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-616783f5-7733-4cbf-be1d-dbf5864f5aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-623d4450-a62c-44cd-9eec-a1ef50cfb7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-c4cb8a60-3e7c-4409-8fa3-1e4e655199d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-c68f20a2-a410-407b-a454-6daa2a6adbd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: -1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172504263-172.17.0.12-1595605599857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42526,DS-6628e600-4cb4-472f-9739-fbdf92040370,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-2de79eeb-dc3d-40bb-891d-e3ec8d688aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-643eb414-d4d9-4c59-bd55-678dbc282d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-4819b529-8902-48eb-84a2-567ffc7126b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-656d326c-0d30-4b91-8347-2253018f4a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-464a1c50-0af4-4665-a6bb-a04627c9e619,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-fc2ac7da-a771-4b1c-9bc8-61a769f7b0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-4b519ead-1ba8-4b54-88a5-c641cdc3357b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-172504263-172.17.0.12-1595605599857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42526,DS-6628e600-4cb4-472f-9739-fbdf92040370,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-2de79eeb-dc3d-40bb-891d-e3ec8d688aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-643eb414-d4d9-4c59-bd55-678dbc282d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-4819b529-8902-48eb-84a2-567ffc7126b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-656d326c-0d30-4b91-8347-2253018f4a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-464a1c50-0af4-4665-a6bb-a04627c9e619,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-fc2ac7da-a771-4b1c-9bc8-61a769f7b0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-4b519ead-1ba8-4b54-88a5-c641cdc3357b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: -1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761583471-172.17.0.12-1595605972673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40076,DS-ce498942-894a-4ff4-a201-9de622a0bf22,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-97e42f95-566b-4124-8422-3a4d8550045d,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-b49ac8b3-3018-4149-8b01-db8f145d8742,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-1e9370b4-05a1-4200-b752-740ccbf48b27,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-7684cf1c-a7fd-40f1-b1dc-059751e9636e,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-0d8bf30d-c275-42e4-96ed-007638e325d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-f241187d-5499-42ef-8b26-5410ec2d5b06,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-ed611dd3-ddd3-4585-a457-611a431f71b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761583471-172.17.0.12-1595605972673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40076,DS-ce498942-894a-4ff4-a201-9de622a0bf22,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-97e42f95-566b-4124-8422-3a4d8550045d,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-b49ac8b3-3018-4149-8b01-db8f145d8742,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-1e9370b4-05a1-4200-b752-740ccbf48b27,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-7684cf1c-a7fd-40f1-b1dc-059751e9636e,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-0d8bf30d-c275-42e4-96ed-007638e325d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-f241187d-5499-42ef-8b26-5410ec2d5b06,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-ed611dd3-ddd3-4585-a457-611a431f71b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: -1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32749270-172.17.0.12-1595606465481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39774,DS-19a48f15-af52-4ab3-bdeb-6953b5da8e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-15155a5b-b413-418b-962f-7f38f98f78df,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-b99127ea-c945-4e0e-b2cd-e9e4ad9c9872,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-64a3fc65-fa4d-474c-83fe-1f21bc2e71ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-6a2030df-2a57-4b31-bcdb-749f0d409a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-9b58d983-231a-42b2-b1ad-57b9eedd2931,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-fc0549cd-1fd3-4b58-b8fe-5ffd3dee30fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-740e52e8-3647-4d17-8ba5-80b216c87699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32749270-172.17.0.12-1595606465481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39774,DS-19a48f15-af52-4ab3-bdeb-6953b5da8e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-15155a5b-b413-418b-962f-7f38f98f78df,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-b99127ea-c945-4e0e-b2cd-e9e4ad9c9872,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-64a3fc65-fa4d-474c-83fe-1f21bc2e71ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-6a2030df-2a57-4b31-bcdb-749f0d409a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-9b58d983-231a-42b2-b1ad-57b9eedd2931,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-fc0549cd-1fd3-4b58-b8fe-5ffd3dee30fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-740e52e8-3647-4d17-8ba5-80b216c87699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: -1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017250504-172.17.0.12-1595606579845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42351,DS-5f565411-ef66-4af2-b13d-6ae376476516,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-d161d0c9-8df3-4cd0-9a30-442d18d8a90f,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-c583e1fd-c50e-42c6-841b-3fe42b356747,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-541c3ed6-ac00-4bc5-84df-6f3e49a8a24a,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-dba6d3d0-0100-4f1f-a94e-1b56ab9302bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-0da9a15b-253b-4d01-836b-e9249bf2d3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-8e3354bd-f5df-4a30-8d08-eebd0693e662,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-0d384853-a4bc-40ae-b825-67ae8350fcaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017250504-172.17.0.12-1595606579845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42351,DS-5f565411-ef66-4af2-b13d-6ae376476516,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-d161d0c9-8df3-4cd0-9a30-442d18d8a90f,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-c583e1fd-c50e-42c6-841b-3fe42b356747,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-541c3ed6-ac00-4bc5-84df-6f3e49a8a24a,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-dba6d3d0-0100-4f1f-a94e-1b56ab9302bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43098,DS-0da9a15b-253b-4d01-836b-e9249bf2d3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-8e3354bd-f5df-4a30-8d08-eebd0693e662,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-0d384853-a4bc-40ae-b825-67ae8350fcaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: -1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215137680-172.17.0.12-1595607529778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42316,DS-3a3c17be-3754-4028-9af5-efb64a25aa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-7d92669c-f72d-478b-aa9e-e3567de358d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-9e461855-d60d-4432-aae1-df5a87c0efca,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-ee770e9f-ef91-4754-8c5a-c374fa497cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-4f64e960-7983-4778-9bde-afa7d4d72365,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-573b95a6-cbba-4395-9beb-fb113ae58868,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-b9bce12f-2042-4ad2-b587-04eda6121b18,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-8798adb9-1446-42de-a98a-49104f493c68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215137680-172.17.0.12-1595607529778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42316,DS-3a3c17be-3754-4028-9af5-efb64a25aa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-7d92669c-f72d-478b-aa9e-e3567de358d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-9e461855-d60d-4432-aae1-df5a87c0efca,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-ee770e9f-ef91-4754-8c5a-c374fa497cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-4f64e960-7983-4778-9bde-afa7d4d72365,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-573b95a6-cbba-4395-9beb-fb113ae58868,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-b9bce12f-2042-4ad2-b587-04eda6121b18,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-8798adb9-1446-42de-a98a-49104f493c68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: -1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109642758-172.17.0.12-1595608202089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38859,DS-dd0e48c8-81fd-41cb-83bf-d49656458c35,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-6d3bf3c4-7210-4af4-b676-10f567e2db14,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-7347b19d-82b9-48b2-b259-bda90ae7e3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-ea831388-f2f1-4b97-9e8a-2cea9c1e5b64,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-c51ba5d1-c2cd-4a88-892f-78fff043f7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-65dd2325-27b2-409c-9d86-9da0d6d62c82,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-45e14f5d-76b4-4832-a28a-205496e550d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-7393958c-9f4d-42ba-a422-ff08003c9859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109642758-172.17.0.12-1595608202089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38859,DS-dd0e48c8-81fd-41cb-83bf-d49656458c35,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-6d3bf3c4-7210-4af4-b676-10f567e2db14,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-7347b19d-82b9-48b2-b259-bda90ae7e3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-ea831388-f2f1-4b97-9e8a-2cea9c1e5b64,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-c51ba5d1-c2cd-4a88-892f-78fff043f7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-65dd2325-27b2-409c-9d86-9da0d6d62c82,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-45e14f5d-76b4-4832-a28a-205496e550d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-7393958c-9f4d-42ba-a422-ff08003c9859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: -1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069448335-172.17.0.12-1595608239284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33667,DS-0f26e88f-798d-4178-8237-d1a261b72d38,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-16682bd6-782e-4470-b33e-fcb4690b6441,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-51fc9e86-47e8-4aa3-8c68-09b97fd1f8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-1a66c8b2-cff3-449f-a05f-c5a0fa4c9fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-b77bde13-25e7-4f4b-abd0-ba34c367d23e,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-01964f07-25a1-4b4d-a2b1-65bcb1a84a87,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-7c58ea73-b04c-44d3-87de-4dabca2e6f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-a72cab62-c605-4b61-ad04-709db3d318fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069448335-172.17.0.12-1595608239284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33667,DS-0f26e88f-798d-4178-8237-d1a261b72d38,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-16682bd6-782e-4470-b33e-fcb4690b6441,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-51fc9e86-47e8-4aa3-8c68-09b97fd1f8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-1a66c8b2-cff3-449f-a05f-c5a0fa4c9fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-b77bde13-25e7-4f4b-abd0-ba34c367d23e,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-01964f07-25a1-4b4d-a2b1-65bcb1a84a87,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-7c58ea73-b04c-44d3-87de-4dabca2e6f75,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-a72cab62-c605-4b61-ad04-709db3d318fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: -1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951193697-172.17.0.12-1595608420841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41863,DS-a47670d3-713b-4a33-8449-eb2a11d5045f,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-5862de8e-19bb-400e-8a80-2bd89417254f,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-6b38b46a-cb3b-456a-8f46-1c1417754184,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-cb44c0e4-2932-4ebe-a673-7bfca45a5100,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-e1810f7a-31bf-497c-af91-5a55e546331b,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-5ba58fc3-8359-4c60-86e0-5d48520030a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-719a1e1b-7e21-40eb-ace8-3e5995a1ab3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-dcc980cf-ba18-4ad3-97aa-efa338cd8562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951193697-172.17.0.12-1595608420841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41863,DS-a47670d3-713b-4a33-8449-eb2a11d5045f,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-5862de8e-19bb-400e-8a80-2bd89417254f,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-6b38b46a-cb3b-456a-8f46-1c1417754184,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-cb44c0e4-2932-4ebe-a673-7bfca45a5100,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-e1810f7a-31bf-497c-af91-5a55e546331b,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-5ba58fc3-8359-4c60-86e0-5d48520030a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-719a1e1b-7e21-40eb-ace8-3e5995a1ab3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-dcc980cf-ba18-4ad3-97aa-efa338cd8562,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: -1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236964966-172.17.0.12-1595608611265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33521,DS-3a51c392-3bfa-43b7-b7ff-a0cbf33ecee4,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-fd5400b6-7dcf-412a-992d-03bfc20d82d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-5550875e-4b6d-4a60-9c45-6c00539077f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-4e0efd1a-e43d-4ec5-ae3c-ba226c4f9bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-849f1133-1c85-410c-b70f-49c5d04c98bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-731a059a-cba0-4872-8f96-564e426cb6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-9cf4f207-6f7d-441f-b6e0-df010098fe25,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-1c24152f-2bb7-4709-a496-027a52e58198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236964966-172.17.0.12-1595608611265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33521,DS-3a51c392-3bfa-43b7-b7ff-a0cbf33ecee4,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-fd5400b6-7dcf-412a-992d-03bfc20d82d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-5550875e-4b6d-4a60-9c45-6c00539077f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-4e0efd1a-e43d-4ec5-ae3c-ba226c4f9bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-849f1133-1c85-410c-b70f-49c5d04c98bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-731a059a-cba0-4872-8f96-564e426cb6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-9cf4f207-6f7d-441f-b6e0-df010098fe25,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-1c24152f-2bb7-4709-a496-027a52e58198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: -1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937700837-172.17.0.12-1595609581735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40702,DS-b8e301ac-eb01-4380-a871-efd315e91615,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-ba5c3b9b-513b-4cc1-b6ae-5b48e64e3fee,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-519c0cd1-1000-4ca8-99e4-f30ad4271e10,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-d458f92b-9dcc-4e31-b8a4-13160a38bc50,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-02e7e58b-86ac-47ec-b4db-516f6d081ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-2daaee12-9722-44f4-8598-96f43d3c43b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-83c599b2-849b-4015-a826-0996f8d9c651,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-3d9bde41-3e3d-4163-83a9-f41a7cf6a4e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937700837-172.17.0.12-1595609581735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40702,DS-b8e301ac-eb01-4380-a871-efd315e91615,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-ba5c3b9b-513b-4cc1-b6ae-5b48e64e3fee,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-519c0cd1-1000-4ca8-99e4-f30ad4271e10,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-d458f92b-9dcc-4e31-b8a4-13160a38bc50,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-02e7e58b-86ac-47ec-b4db-516f6d081ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-2daaee12-9722-44f4-8598-96f43d3c43b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-83c599b2-849b-4015-a826-0996f8d9c651,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-3d9bde41-3e3d-4163-83a9-f41a7cf6a4e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: -1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926917417-172.17.0.12-1595610100080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45192,DS-23cf88bc-e40c-4b42-9803-3b7f4859dc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-70197968-9b89-4419-8071-a9cadf1f8ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-25fc2a17-6385-4e4c-8efb-7ef7e65a39dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-8a2258c4-f2c1-44e7-8980-75131e82be8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-b55eac7b-362e-4ba7-b5e8-469cfb176458,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-9f1bf646-8e18-4962-9c57-48a8ce253103,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-d5510127-d553-4e47-948a-75f118667367,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-b3d95a61-dc83-4696-8b9f-7eee6bd2a987,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926917417-172.17.0.12-1595610100080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45192,DS-23cf88bc-e40c-4b42-9803-3b7f4859dc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-70197968-9b89-4419-8071-a9cadf1f8ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-25fc2a17-6385-4e4c-8efb-7ef7e65a39dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-8a2258c4-f2c1-44e7-8980-75131e82be8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-b55eac7b-362e-4ba7-b5e8-469cfb176458,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-9f1bf646-8e18-4962-9c57-48a8ce253103,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-d5510127-d553-4e47-948a-75f118667367,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-b3d95a61-dc83-4696-8b9f-7eee6bd2a987,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.failed.volumes.tolerated
component: hdfs:DataNode
v1: -1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106269888-172.17.0.12-1595610387876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42028,DS-e17a149c-09d3-46e3-9b5e-27cecc24b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-e492b25d-7ea0-4641-a0ec-d386d5f89b76,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-39acd09f-8141-4b06-9fc7-50073bb2714e,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-c5136af6-b619-43d9-9d4c-39420ac74ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-13681e8b-518b-40d8-8c04-24da335e4382,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-6d13fe7d-eaab-4970-9e94-c521b3e22304,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-a8205f64-fbe5-4bb4-85f4-c3982fe18b05,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-c42ec554-9b72-41b6-a292-b46d9e6ceb4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106269888-172.17.0.12-1595610387876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42028,DS-e17a149c-09d3-46e3-9b5e-27cecc24b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-e492b25d-7ea0-4641-a0ec-d386d5f89b76,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-39acd09f-8141-4b06-9fc7-50073bb2714e,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-c5136af6-b619-43d9-9d4c-39420ac74ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-13681e8b-518b-40d8-8c04-24da335e4382,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-6d13fe7d-eaab-4970-9e94-c521b3e22304,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-a8205f64-fbe5-4bb4-85f4-c3982fe18b05,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-c42ec554-9b72-41b6-a292-b46d9e6ceb4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5635
