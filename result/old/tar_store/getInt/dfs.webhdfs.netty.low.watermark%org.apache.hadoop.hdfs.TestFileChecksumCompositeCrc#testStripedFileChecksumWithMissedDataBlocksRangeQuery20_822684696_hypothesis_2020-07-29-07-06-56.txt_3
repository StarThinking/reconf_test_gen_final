reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223694829-172.17.0.3-1596006662367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-a2f64f51-18fa-4a57-940f-a55ae890fc00,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-d487b701-aa1c-4453-b904-e8a75ec7c4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-741e02c1-de9e-4fbe-a482-234c854b6b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-adc0d1ba-1383-497b-968e-8ee569e9b8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-4fc93cf4-5713-4f2c-b223-c1664d80a36c,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-ac6609bb-d076-4e34-ac78-20e67439b2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-0290b6a8-3e75-4eb8-8b10-cda373b09ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-06bf2282-a1db-45c7-bb29-57d41d1c48fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223694829-172.17.0.3-1596006662367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-a2f64f51-18fa-4a57-940f-a55ae890fc00,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-d487b701-aa1c-4453-b904-e8a75ec7c4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-741e02c1-de9e-4fbe-a482-234c854b6b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-adc0d1ba-1383-497b-968e-8ee569e9b8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-4fc93cf4-5713-4f2c-b223-c1664d80a36c,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-ac6609bb-d076-4e34-ac78-20e67439b2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-0290b6a8-3e75-4eb8-8b10-cda373b09ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-06bf2282-a1db-45c7-bb29-57d41d1c48fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621942594-172.17.0.3-1596007981406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36068,DS-c989ca19-8eb9-4d8a-bd9f-996da1110279,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-50f191f1-4d49-46ba-9cf9-ecc6f6a35784,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-079fd334-5e20-428c-8ef7-2b3a2d8b6511,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-2bdef36f-5511-425d-87e8-68900d80065b,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-05897ce0-3120-466a-94d7-4253fba8abaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-c40a2d69-211d-4e05-a5ef-e3e4fec8160e,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-9331b9cd-90ce-4552-8dca-002e1b4e1314,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-46d1d567-8385-41da-8477-4ac08bae0f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621942594-172.17.0.3-1596007981406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36068,DS-c989ca19-8eb9-4d8a-bd9f-996da1110279,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-50f191f1-4d49-46ba-9cf9-ecc6f6a35784,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-079fd334-5e20-428c-8ef7-2b3a2d8b6511,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-2bdef36f-5511-425d-87e8-68900d80065b,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-05897ce0-3120-466a-94d7-4253fba8abaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-c40a2d69-211d-4e05-a5ef-e3e4fec8160e,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-9331b9cd-90ce-4552-8dca-002e1b4e1314,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-46d1d567-8385-41da-8477-4ac08bae0f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330947118-172.17.0.3-1596008388329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38113,DS-5e570b9a-dc1d-4d65-80f6-86aebbab95ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-df6338a6-71f8-4383-b32a-edfcdd97519e,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-207d1a11-6f08-419d-bc45-18ad165fb022,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-374c28c7-8f87-4e13-b4bf-a7494d634929,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-c7a6e9d5-38ff-4413-a4da-e74e4b45c206,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-49e7b970-f7ba-4428-8180-21bdfcbbaca7,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-1a8f0703-a9c5-4e69-af61-4dae8ae58798,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-22cd8666-87ef-41bb-ba23-32462153095f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330947118-172.17.0.3-1596008388329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38113,DS-5e570b9a-dc1d-4d65-80f6-86aebbab95ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-df6338a6-71f8-4383-b32a-edfcdd97519e,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-207d1a11-6f08-419d-bc45-18ad165fb022,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-374c28c7-8f87-4e13-b4bf-a7494d634929,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-c7a6e9d5-38ff-4413-a4da-e74e4b45c206,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-49e7b970-f7ba-4428-8180-21bdfcbbaca7,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-1a8f0703-a9c5-4e69-af61-4dae8ae58798,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-22cd8666-87ef-41bb-ba23-32462153095f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480623649-172.17.0.3-1596009086123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40688,DS-392eded6-484a-4a6d-80cc-61b770a26ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-612366a0-398b-4f88-b3be-8297fba90d34,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-65275480-cb35-4111-9ae0-0e5d7ea49467,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-dae4978f-6204-42be-9103-a803e8a8c5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-b16daaf8-9461-4031-a3bc-c61af9c0ddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-7f92eed3-e29a-4916-94b1-05c0fec4f058,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-5579a5cb-ea66-4373-8a73-6d3ef65b65a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-a0baaed5-b0c8-4d1d-a1ae-4ef6128d0e61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480623649-172.17.0.3-1596009086123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40688,DS-392eded6-484a-4a6d-80cc-61b770a26ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-612366a0-398b-4f88-b3be-8297fba90d34,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-65275480-cb35-4111-9ae0-0e5d7ea49467,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-dae4978f-6204-42be-9103-a803e8a8c5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-b16daaf8-9461-4031-a3bc-c61af9c0ddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-7f92eed3-e29a-4916-94b1-05c0fec4f058,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-5579a5cb-ea66-4373-8a73-6d3ef65b65a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-a0baaed5-b0c8-4d1d-a1ae-4ef6128d0e61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038502378-172.17.0.3-1596009312172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39342,DS-349518b5-6310-4a66-9165-1d48b3ab1180,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-39453477-1243-44ca-a612-b6642a6428e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-cf41a6fa-8856-4b65-82a1-5329c03b69a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-63f53b61-93ce-4c5b-b6ca-c4524f81fc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-a9423e9f-141d-4640-bda8-73972fc6836a,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-f62cf205-d525-4183-9c00-be95a69d98c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-2bfb701d-bf59-4944-bde1-8fd6334bd39b,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-1f9a43cf-4b42-4b12-ae62-a1059f043ed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038502378-172.17.0.3-1596009312172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39342,DS-349518b5-6310-4a66-9165-1d48b3ab1180,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-39453477-1243-44ca-a612-b6642a6428e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-cf41a6fa-8856-4b65-82a1-5329c03b69a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-63f53b61-93ce-4c5b-b6ca-c4524f81fc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-a9423e9f-141d-4640-bda8-73972fc6836a,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-f62cf205-d525-4183-9c00-be95a69d98c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-2bfb701d-bf59-4944-bde1-8fd6334bd39b,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-1f9a43cf-4b42-4b12-ae62-a1059f043ed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539711766-172.17.0.3-1596009516072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45152,DS-2b40d776-874e-4e67-b016-1e2ab53f5df9,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-75baa921-fdcc-407a-94cc-3aeb07e43660,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-371e80f7-b2c0-455d-a5d9-b7c7c76f7fde,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-cec520a5-77b0-4f52-9a2d-3d58463ce017,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-15ed904f-1694-48dc-a474-fdb7c2466c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-b3974b13-1e56-4d44-988d-d07fadfb6b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-5822a495-8811-44cc-82fe-a998d91d3ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-11d42aeb-fd28-4c6e-8538-db04ae8e049b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539711766-172.17.0.3-1596009516072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45152,DS-2b40d776-874e-4e67-b016-1e2ab53f5df9,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-75baa921-fdcc-407a-94cc-3aeb07e43660,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-371e80f7-b2c0-455d-a5d9-b7c7c76f7fde,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-cec520a5-77b0-4f52-9a2d-3d58463ce017,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-15ed904f-1694-48dc-a474-fdb7c2466c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-b3974b13-1e56-4d44-988d-d07fadfb6b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-5822a495-8811-44cc-82fe-a998d91d3ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-11d42aeb-fd28-4c6e-8538-db04ae8e049b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567297949-172.17.0.3-1596010147767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40705,DS-0fcb1574-115f-456f-a8f6-0fc8efe6ecef,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-22f35384-16ec-44c0-a971-1426d834e5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-0269cb2b-8b5e-434c-a571-3cf22954f994,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-c6d5f927-6a47-47ac-9c50-44a84749304f,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-d6f45801-2e8a-4484-b9d8-bd78300a5d38,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-fcb4d41b-a334-46ff-8906-a023b7527690,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-53ea03a8-b1d1-4218-9bf8-9be46e797df0,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-5f4abcb3-5de6-48fb-9a1f-83aeb99d6adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1567297949-172.17.0.3-1596010147767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40705,DS-0fcb1574-115f-456f-a8f6-0fc8efe6ecef,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-22f35384-16ec-44c0-a971-1426d834e5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-0269cb2b-8b5e-434c-a571-3cf22954f994,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-c6d5f927-6a47-47ac-9c50-44a84749304f,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-d6f45801-2e8a-4484-b9d8-bd78300a5d38,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-fcb4d41b-a334-46ff-8906-a023b7527690,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-53ea03a8-b1d1-4218-9bf8-9be46e797df0,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-5f4abcb3-5de6-48fb-9a1f-83aeb99d6adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310338591-172.17.0.3-1596010415261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34512,DS-003262c8-59e8-4bde-adaf-d05957cbe7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-811feaa1-f132-4078-9486-c52762e5c09d,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-9d06c5a4-8dba-485c-8f0c-dfc035d3b8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-45f58f5f-0161-4d81-a160-e39a14d25061,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-0f04a3e4-fa0f-4e39-ba16-6bb5641da37d,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-8253ba8e-a2d9-4134-800b-8d31b87ab36e,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-aab22402-1937-493b-857b-913b468f7f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-a0d5ae04-e3a1-40d1-a2dc-570e5426be4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310338591-172.17.0.3-1596010415261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34512,DS-003262c8-59e8-4bde-adaf-d05957cbe7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-811feaa1-f132-4078-9486-c52762e5c09d,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-9d06c5a4-8dba-485c-8f0c-dfc035d3b8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-45f58f5f-0161-4d81-a160-e39a14d25061,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-0f04a3e4-fa0f-4e39-ba16-6bb5641da37d,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-8253ba8e-a2d9-4134-800b-8d31b87ab36e,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-aab22402-1937-493b-857b-913b468f7f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-a0d5ae04-e3a1-40d1-a2dc-570e5426be4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785573794-172.17.0.3-1596010858357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38646,DS-1b3ece5c-ca82-41e3-8bc6-a2017a27e0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-f9404399-5607-4f76-bb3e-77cd28084387,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-a962df37-9f3e-4e62-b3ab-42ebfc357ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-2dd75487-3878-4e05-9eb1-b0cc905b60ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-91d95384-c150-4751-9c9c-2329a1bec75d,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-e6d941a8-4bfe-40d8-b000-54e25fb5ca2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-8ff7119c-7682-446b-97a0-9447073ecb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-254194a8-bb53-42e3-bf1e-167a5f66a71d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785573794-172.17.0.3-1596010858357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38646,DS-1b3ece5c-ca82-41e3-8bc6-a2017a27e0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-f9404399-5607-4f76-bb3e-77cd28084387,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-a962df37-9f3e-4e62-b3ab-42ebfc357ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-2dd75487-3878-4e05-9eb1-b0cc905b60ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-91d95384-c150-4751-9c9c-2329a1bec75d,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-e6d941a8-4bfe-40d8-b000-54e25fb5ca2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-8ff7119c-7682-446b-97a0-9447073ecb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-254194a8-bb53-42e3-bf1e-167a5f66a71d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395826807-172.17.0.3-1596011040565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39177,DS-5c009984-1eeb-4eab-990f-374c6dcbea77,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-e9c61b97-5e23-44dd-8699-38c4a4a8cb35,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-92165813-b4d1-4638-a209-70fe8462372c,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-8baf7f9e-0de1-4c44-b1f2-a0bb5b58db41,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-73ca232e-2826-42d6-a309-6a65cf07b4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-28e91e71-9b16-4c50-aec8-57cf00701e63,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-7620a8b4-e70c-4a99-8310-dc0533d9957f,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-db5db5a5-bc14-4eeb-aff7-c13e106c82a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395826807-172.17.0.3-1596011040565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39177,DS-5c009984-1eeb-4eab-990f-374c6dcbea77,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-e9c61b97-5e23-44dd-8699-38c4a4a8cb35,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-92165813-b4d1-4638-a209-70fe8462372c,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-8baf7f9e-0de1-4c44-b1f2-a0bb5b58db41,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-73ca232e-2826-42d6-a309-6a65cf07b4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-28e91e71-9b16-4c50-aec8-57cf00701e63,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-7620a8b4-e70c-4a99-8310-dc0533d9957f,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-db5db5a5-bc14-4eeb-aff7-c13e106c82a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043644780-172.17.0.3-1596011333793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34301,DS-5bcc6717-53c7-40ee-b607-c7a691a4e484,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-4d4faa30-fc54-4491-9ca1-1012a810511d,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-f90ec9dd-20e0-4635-8149-f750af04cece,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-46f2624f-bc64-4a34-b301-415de5a42716,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-7f5cfd84-fd5b-41c1-8a39-558ac7eadb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-085bcbc3-0e0e-4826-87a3-39f4d0b1859c,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-ce9fc81a-388c-474a-91cf-6a6eda7d9c50,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-61dbb429-ebab-4910-81e6-10ed97362fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043644780-172.17.0.3-1596011333793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34301,DS-5bcc6717-53c7-40ee-b607-c7a691a4e484,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-4d4faa30-fc54-4491-9ca1-1012a810511d,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-f90ec9dd-20e0-4635-8149-f750af04cece,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-46f2624f-bc64-4a34-b301-415de5a42716,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-7f5cfd84-fd5b-41c1-8a39-558ac7eadb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-085bcbc3-0e0e-4826-87a3-39f4d0b1859c,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-ce9fc81a-388c-474a-91cf-6a6eda7d9c50,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-61dbb429-ebab-4910-81e6-10ed97362fe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-146101772-172.17.0.3-1596011780982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45436,DS-b7d182c7-0ebb-48da-bc9d-4f7a0d1e553b,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-d5e2a800-b81b-4ca0-b32e-96a2def1dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-f3963cd7-a93f-40ba-9a35-606a23754a72,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-9a402f45-ca87-4776-b0ca-4418de4fbefb,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-7da92619-0774-4afd-865b-4c42ed479a18,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-ef183c5e-47e9-4039-a5e8-207b4913ac84,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-70167722-5256-4170-8954-432f67a40b25,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-242a4522-4ff0-4d68-bb61-6778862509d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-146101772-172.17.0.3-1596011780982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45436,DS-b7d182c7-0ebb-48da-bc9d-4f7a0d1e553b,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-d5e2a800-b81b-4ca0-b32e-96a2def1dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-f3963cd7-a93f-40ba-9a35-606a23754a72,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-9a402f45-ca87-4776-b0ca-4418de4fbefb,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-7da92619-0774-4afd-865b-4c42ed479a18,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-ef183c5e-47e9-4039-a5e8-207b4913ac84,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-70167722-5256-4170-8954-432f67a40b25,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-242a4522-4ff0-4d68-bb61-6778862509d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014490699-172.17.0.3-1596012146400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34435,DS-be1fc4d1-c151-407e-b6b6-98f1bd8b3b94,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-7934c2d8-0eda-45ce-9375-4c00bb4210e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-ef48d5bf-bc49-4502-8db5-4109097f9395,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-56635a14-1621-4fc1-b974-5276d714db11,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-74a5dbe7-793c-4335-838b-f4aecf4c5f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-5fa668b2-837f-4e14-9623-0339593624ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-ef866933-9d95-4888-846f-db4e07c0f898,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-f3578720-3801-464d-8394-acde7a9079ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014490699-172.17.0.3-1596012146400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34435,DS-be1fc4d1-c151-407e-b6b6-98f1bd8b3b94,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-7934c2d8-0eda-45ce-9375-4c00bb4210e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-ef48d5bf-bc49-4502-8db5-4109097f9395,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-56635a14-1621-4fc1-b974-5276d714db11,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-74a5dbe7-793c-4335-838b-f4aecf4c5f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-5fa668b2-837f-4e14-9623-0339593624ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-ef866933-9d95-4888-846f-db4e07c0f898,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-f3578720-3801-464d-8394-acde7a9079ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6575
