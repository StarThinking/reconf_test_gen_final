reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600348823-172.17.0.6-1595975070505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-796c1ca3-fd9f-4685-8f83-d08a37693bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-a9649e1a-8833-44a1-a108-2acab18dbac3,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-59d74e11-84b5-4321-b418-7369951f926a,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-16a4e3ae-0656-44cc-8c8e-2ed58f28f1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-d9dc1a79-d0ba-4695-ae20-8364f5e0e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-cc48b1d3-36fe-4ab5-ae1e-a7e9c999bdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-802de862-9338-4e59-85c6-ba67c906a01f,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-05c39a92-5cf1-48ad-a40e-ce2f86c78577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600348823-172.17.0.6-1595975070505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34281,DS-796c1ca3-fd9f-4685-8f83-d08a37693bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-a9649e1a-8833-44a1-a108-2acab18dbac3,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-59d74e11-84b5-4321-b418-7369951f926a,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-16a4e3ae-0656-44cc-8c8e-2ed58f28f1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-d9dc1a79-d0ba-4695-ae20-8364f5e0e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-cc48b1d3-36fe-4ab5-ae1e-a7e9c999bdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-802de862-9338-4e59-85c6-ba67c906a01f,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-05c39a92-5cf1-48ad-a40e-ce2f86c78577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536677983-172.17.0.6-1595975975424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38942,DS-ae27c6ab-378f-42e2-8f16-a217800aafaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-24395b7d-0583-447f-8b56-9afeed4902ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-e0fb4b28-c416-45fa-b198-8b4018bbeaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-24144d32-a93a-409c-98ca-2b00010fe277,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-37e90226-6243-4865-854f-8c87a1471fae,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-b92973f1-38a8-4815-8aa1-82bf334d1c02,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-3ac15dd2-6f05-48dd-88a9-8cbaeff436e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-afe4dff6-4836-4dca-b059-abd4fe690e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536677983-172.17.0.6-1595975975424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38942,DS-ae27c6ab-378f-42e2-8f16-a217800aafaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-24395b7d-0583-447f-8b56-9afeed4902ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-e0fb4b28-c416-45fa-b198-8b4018bbeaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-24144d32-a93a-409c-98ca-2b00010fe277,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-37e90226-6243-4865-854f-8c87a1471fae,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-b92973f1-38a8-4815-8aa1-82bf334d1c02,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-3ac15dd2-6f05-48dd-88a9-8cbaeff436e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-afe4dff6-4836-4dca-b059-abd4fe690e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440965872-172.17.0.6-1595976020770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36163,DS-7c4b7462-7ae0-4828-aee9-04d9ece365c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-3a0efbff-49be-46b7-82b8-7492b031e563,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-9ca0cb05-06c7-4814-abb7-2daf7994205a,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-c2dcd6a4-07b5-4ad4-862b-b500610ce8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-b4784730-f1bb-4a77-9494-009b162173e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-6591dcbf-5a2a-4011-9419-8dff6983643b,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-baa31c88-2c1f-4641-93c9-f3963a36751e,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-b27bd6c0-bfc8-40b9-9400-48dbb5b46c3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440965872-172.17.0.6-1595976020770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36163,DS-7c4b7462-7ae0-4828-aee9-04d9ece365c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-3a0efbff-49be-46b7-82b8-7492b031e563,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-9ca0cb05-06c7-4814-abb7-2daf7994205a,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-c2dcd6a4-07b5-4ad4-862b-b500610ce8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-b4784730-f1bb-4a77-9494-009b162173e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-6591dcbf-5a2a-4011-9419-8dff6983643b,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-baa31c88-2c1f-4641-93c9-f3963a36751e,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-b27bd6c0-bfc8-40b9-9400-48dbb5b46c3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962230963-172.17.0.6-1595978477928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43255,DS-64189cd7-46ee-448d-bad1-bd361a95eea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-f0e64381-f72f-444d-a802-4fef56c39597,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-b9473de4-fcfa-4ac1-9d77-08bd149a7d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-ca106bae-5404-4b23-acf6-ad154d1c1c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-e22b29da-ff30-4dcf-bd87-062e37b0f78d,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-17ed32f8-9e28-4840-8cbb-8a45ddcf1561,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-cf8f2a5c-514c-4fcc-8d24-6a166ca2f3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-a485c41f-3f30-4184-9703-e8a6477b07cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962230963-172.17.0.6-1595978477928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43255,DS-64189cd7-46ee-448d-bad1-bd361a95eea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-f0e64381-f72f-444d-a802-4fef56c39597,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-b9473de4-fcfa-4ac1-9d77-08bd149a7d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-ca106bae-5404-4b23-acf6-ad154d1c1c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-e22b29da-ff30-4dcf-bd87-062e37b0f78d,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-17ed32f8-9e28-4840-8cbb-8a45ddcf1561,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-cf8f2a5c-514c-4fcc-8d24-6a166ca2f3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-a485c41f-3f30-4184-9703-e8a6477b07cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2125621939-172.17.0.6-1595979329721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38558,DS-e33aefb4-9c13-43f3-b625-8922ef421123,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-6e1a4f35-56e1-432a-8a39-c592815d119f,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-f9c7387c-3708-4a4f-9c73-c89b2df4a05b,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-2ed7bb04-e214-47ad-975c-7eb83ca12deb,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-a79a68f8-f0e8-41d0-8b95-741eba1c603e,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-f910df22-3acf-44d5-9daa-5fe16bfef618,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-a689698d-de5a-485b-9f0b-f268566dd0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-4172a41b-613b-43f2-a4af-15ff719d0e86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2125621939-172.17.0.6-1595979329721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38558,DS-e33aefb4-9c13-43f3-b625-8922ef421123,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-6e1a4f35-56e1-432a-8a39-c592815d119f,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-f9c7387c-3708-4a4f-9c73-c89b2df4a05b,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-2ed7bb04-e214-47ad-975c-7eb83ca12deb,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-a79a68f8-f0e8-41d0-8b95-741eba1c603e,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-f910df22-3acf-44d5-9daa-5fe16bfef618,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-a689698d-de5a-485b-9f0b-f268566dd0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-4172a41b-613b-43f2-a4af-15ff719d0e86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: false positive !!!
Total execution time in seconds : 6898
