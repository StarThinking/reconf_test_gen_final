reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168688944-172.17.0.10-1595903096237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-8240a30a-ec44-4e6a-a440-38745350f7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-a49dfe1a-ccf7-411d-a3fd-ca6f549704c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-deea162c-d47e-4c79-b1a4-e56ce9549e78,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-0ade81e1-ac07-47ef-b4b7-1117a6ee91ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-88e939e9-6257-43ae-81ea-f312e53addbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-945f6451-b01c-4276-9d66-225ca7a630ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-27074527-241d-48a2-8a3b-8bab2a2cb8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-324a4529-5238-4da3-b671-d1587c812e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168688944-172.17.0.10-1595903096237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-8240a30a-ec44-4e6a-a440-38745350f7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-a49dfe1a-ccf7-411d-a3fd-ca6f549704c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-deea162c-d47e-4c79-b1a4-e56ce9549e78,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-0ade81e1-ac07-47ef-b4b7-1117a6ee91ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-88e939e9-6257-43ae-81ea-f312e53addbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-945f6451-b01c-4276-9d66-225ca7a630ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-27074527-241d-48a2-8a3b-8bab2a2cb8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-324a4529-5238-4da3-b671-d1587c812e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409523057-172.17.0.10-1595903437269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-e5c0976b-5ef9-4786-9a23-05774b3f58ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-1c2f5c54-5867-4abc-961c-3eebb0fb5893,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-506a770d-ca49-4706-964d-c9832d923dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-48fda8d4-d67a-4e02-aed3-f11b39ebe151,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-2049ef70-bf09-421e-b0fd-531763905d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-f985019b-8d7a-4849-8aa3-afadf2ba4995,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-37e16339-65e7-4f2f-8e04-f2863cdca4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-07b57327-5f90-4097-a658-5b158d7c8f85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409523057-172.17.0.10-1595903437269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-e5c0976b-5ef9-4786-9a23-05774b3f58ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-1c2f5c54-5867-4abc-961c-3eebb0fb5893,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-506a770d-ca49-4706-964d-c9832d923dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-48fda8d4-d67a-4e02-aed3-f11b39ebe151,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-2049ef70-bf09-421e-b0fd-531763905d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-f985019b-8d7a-4849-8aa3-afadf2ba4995,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-37e16339-65e7-4f2f-8e04-f2863cdca4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-07b57327-5f90-4097-a658-5b158d7c8f85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917217807-172.17.0.10-1595903991098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43426,DS-f623ef57-38aa-4961-bcee-d390203d2c76,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-47103479-6163-4e7d-beab-4c06f88d4c36,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-1a773bec-f2b3-49cf-9ab4-c70be439aec4,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-7214f30d-3306-40cf-aac3-fc31e6a32ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-b5a4bab0-078b-48fc-9638-61b69a78830f,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-d2b3c110-49a9-402b-8d4a-7d76e84e471d,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-21659ff8-362d-48e8-b220-8e39aa8d35e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-9c47cf61-46d4-4ed5-9b90-d743f3592c1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917217807-172.17.0.10-1595903991098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43426,DS-f623ef57-38aa-4961-bcee-d390203d2c76,DISK], DatanodeInfoWithStorage[127.0.0.1:38907,DS-47103479-6163-4e7d-beab-4c06f88d4c36,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-1a773bec-f2b3-49cf-9ab4-c70be439aec4,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-7214f30d-3306-40cf-aac3-fc31e6a32ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-b5a4bab0-078b-48fc-9638-61b69a78830f,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-d2b3c110-49a9-402b-8d4a-7d76e84e471d,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-21659ff8-362d-48e8-b220-8e39aa8d35e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-9c47cf61-46d4-4ed5-9b90-d743f3592c1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799289788-172.17.0.10-1595904964616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37677,DS-05a3e0c4-7d82-4a65-9850-b0c3684a7673,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-0664c765-8448-4229-a90b-cabbd3db03ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-acf0fb4e-8a1b-49e1-aa87-c54725a23091,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-14285f4c-263f-4869-8a02-a3ca2c10ba67,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-e9d24450-ffb5-4755-b3e4-6abc4c84c5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-92109582-def7-45f9-b2b0-c8f66e9e4d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-f19f664b-7234-4a5d-953f-193712e4d4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-9d75abda-5882-4978-a090-8529fd2702e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799289788-172.17.0.10-1595904964616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37677,DS-05a3e0c4-7d82-4a65-9850-b0c3684a7673,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-0664c765-8448-4229-a90b-cabbd3db03ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-acf0fb4e-8a1b-49e1-aa87-c54725a23091,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-14285f4c-263f-4869-8a02-a3ca2c10ba67,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-e9d24450-ffb5-4755-b3e4-6abc4c84c5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-92109582-def7-45f9-b2b0-c8f66e9e4d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-f19f664b-7234-4a5d-953f-193712e4d4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-9d75abda-5882-4978-a090-8529fd2702e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491790490-172.17.0.10-1595905210179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39663,DS-80d54091-c8b2-4f7d-b32e-5468b936d49d,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-7eeed5cc-bf3a-472c-9a4c-aa6ede4e46d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-2afbbc92-740c-49f9-93ba-97dede0450c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-63490d9e-f358-4adf-8731-9b604da4eccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-c7676184-2834-4121-a20b-6bdac75fe080,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-268f0492-a7ef-42ae-b7ba-b4d524a1f297,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-a0a6086a-85c3-43a6-925d-b8c609ee6838,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-9d874aad-584d-440c-8e64-6cf93085bc0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491790490-172.17.0.10-1595905210179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39663,DS-80d54091-c8b2-4f7d-b32e-5468b936d49d,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-7eeed5cc-bf3a-472c-9a4c-aa6ede4e46d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-2afbbc92-740c-49f9-93ba-97dede0450c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-63490d9e-f358-4adf-8731-9b604da4eccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-c7676184-2834-4121-a20b-6bdac75fe080,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-268f0492-a7ef-42ae-b7ba-b4d524a1f297,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-a0a6086a-85c3-43a6-925d-b8c609ee6838,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-9d874aad-584d-440c-8e64-6cf93085bc0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123566405-172.17.0.10-1595905387576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35826,DS-2db7759e-3fec-4cf0-96a9-aced1207f3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-63425afb-a97a-4e36-af6c-c9e9f0595c88,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-8dafb49c-99e5-4783-a7c9-49fbfa58ef05,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-9446c993-73f8-4df7-92d4-06bc3708ba89,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-eedcd4b1-a9fe-44ed-9123-9bc40ba3d1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-adc64048-ac99-478a-9ee0-de52378a6182,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-c8c90e66-5106-48b1-afa2-c2006534c3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-67ec9746-262a-43d4-ae80-fffea793d8c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123566405-172.17.0.10-1595905387576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35826,DS-2db7759e-3fec-4cf0-96a9-aced1207f3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-63425afb-a97a-4e36-af6c-c9e9f0595c88,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-8dafb49c-99e5-4783-a7c9-49fbfa58ef05,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-9446c993-73f8-4df7-92d4-06bc3708ba89,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-eedcd4b1-a9fe-44ed-9123-9bc40ba3d1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-adc64048-ac99-478a-9ee0-de52378a6182,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-c8c90e66-5106-48b1-afa2-c2006534c3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-67ec9746-262a-43d4-ae80-fffea793d8c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968553497-172.17.0.10-1595905678325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46465,DS-52f0a8f8-be4a-4448-845f-710b5582b67a,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-bcc90d80-19b0-4271-b9f4-5039cfec1539,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-b90e98dc-6566-48c0-abbc-83fccbc93761,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-efbb9fd6-85fc-45d0-95d2-824c106b5863,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-93d05b52-c6ca-4166-ad15-b4ba2973c981,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-e029f33e-cf18-406e-a904-f61c5b17cda7,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-dd3fb920-32f2-47e2-9cc0-4e59b121f2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-58a51286-7369-4161-9f04-234b2f90e498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968553497-172.17.0.10-1595905678325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46465,DS-52f0a8f8-be4a-4448-845f-710b5582b67a,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-bcc90d80-19b0-4271-b9f4-5039cfec1539,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-b90e98dc-6566-48c0-abbc-83fccbc93761,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-efbb9fd6-85fc-45d0-95d2-824c106b5863,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-93d05b52-c6ca-4166-ad15-b4ba2973c981,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-e029f33e-cf18-406e-a904-f61c5b17cda7,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-dd3fb920-32f2-47e2-9cc0-4e59b121f2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-58a51286-7369-4161-9f04-234b2f90e498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041216699-172.17.0.10-1595905966928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40658,DS-7008b545-5a00-490a-9764-97383bbbc01f,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-b9adbd9d-0a9d-45fa-8604-fe350a28480b,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-7d7bf0d5-32fa-4fa5-ae4f-66461336ca3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-c59cf2ca-cb5b-4f83-b462-563a656e93cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-e4117300-e8c4-4ad9-bb49-f3385e66a137,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-fbc89338-8e6b-42d6-9ca0-ba9faf6027d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-7fdc127a-170e-44c5-9005-e8fccd71980a,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-e40797ce-b364-4d5c-96dd-078c8d8ddcbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041216699-172.17.0.10-1595905966928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40658,DS-7008b545-5a00-490a-9764-97383bbbc01f,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-b9adbd9d-0a9d-45fa-8604-fe350a28480b,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-7d7bf0d5-32fa-4fa5-ae4f-66461336ca3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-c59cf2ca-cb5b-4f83-b462-563a656e93cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-e4117300-e8c4-4ad9-bb49-f3385e66a137,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-fbc89338-8e6b-42d6-9ca0-ba9faf6027d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-7fdc127a-170e-44c5-9005-e8fccd71980a,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-e40797ce-b364-4d5c-96dd-078c8d8ddcbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851060488-172.17.0.10-1595906185987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32774,DS-4fcaacc1-4a32-42bf-8f98-c2041178e1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-cf90ac8d-dab9-4fbd-80eb-542316e10206,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-40b5f636-259b-477f-902b-4995962a2293,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-9fa6bb8d-0a5e-4c84-8911-2bcae3f41c10,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-e2ced74d-b8df-4b8f-8d13-b5aca1633fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-0db58d6b-744c-4f92-96ac-b5ac3c13e03e,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-653b4a02-736e-43dc-b09b-b12826b31bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-fc376a8b-8a60-4774-b99a-cf56cfb27c93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851060488-172.17.0.10-1595906185987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32774,DS-4fcaacc1-4a32-42bf-8f98-c2041178e1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-cf90ac8d-dab9-4fbd-80eb-542316e10206,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-40b5f636-259b-477f-902b-4995962a2293,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-9fa6bb8d-0a5e-4c84-8911-2bcae3f41c10,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-e2ced74d-b8df-4b8f-8d13-b5aca1633fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-0db58d6b-744c-4f92-96ac-b5ac3c13e03e,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-653b4a02-736e-43dc-b09b-b12826b31bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-fc376a8b-8a60-4774-b99a-cf56cfb27c93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269804496-172.17.0.10-1595907412261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43928,DS-73a02bb5-9f7a-48e1-8231-f67dd5b77a58,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-2659907f-7d90-43a0-8f5c-5cd895009b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-cbf5bcfb-412b-4054-bc7e-976144ea4b16,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-b54dd772-2fca-413f-8931-2d3dd2727d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-f5e50ef6-1afd-4876-9019-1dec717cf193,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-b477b5df-9b3e-40f0-bb97-eb10492681a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-f751dd19-b3fd-4fc3-94f8-3f0763f1dc40,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-4932cbc5-170d-4b8c-84ae-e27cca72cdd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269804496-172.17.0.10-1595907412261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43928,DS-73a02bb5-9f7a-48e1-8231-f67dd5b77a58,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-2659907f-7d90-43a0-8f5c-5cd895009b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-cbf5bcfb-412b-4054-bc7e-976144ea4b16,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-b54dd772-2fca-413f-8931-2d3dd2727d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-f5e50ef6-1afd-4876-9019-1dec717cf193,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-b477b5df-9b3e-40f0-bb97-eb10492681a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-f751dd19-b3fd-4fc3-94f8-3f0763f1dc40,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-4932cbc5-170d-4b8c-84ae-e27cca72cdd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595582097-172.17.0.10-1595908166268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43547,DS-7a5541cb-d0bc-417b-883b-713c6d279cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-e30d6670-a19b-4c14-8ee2-a34ee2e6c0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-b5ae2a38-cfd1-4b6b-99a7-fc3a6f013d33,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-91c3b624-e7ad-40a8-8078-e1d62be4cdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-ba11fcc9-40ae-4422-82db-5bcb79af05fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-fe748a0b-d82e-4357-a652-c85e4ee0c1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-3146a605-7696-46b6-8918-3f436e96ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-9b2f2645-dbeb-4adc-b69f-8f2a66fb44ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595582097-172.17.0.10-1595908166268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43547,DS-7a5541cb-d0bc-417b-883b-713c6d279cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-e30d6670-a19b-4c14-8ee2-a34ee2e6c0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-b5ae2a38-cfd1-4b6b-99a7-fc3a6f013d33,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-91c3b624-e7ad-40a8-8078-e1d62be4cdbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-ba11fcc9-40ae-4422-82db-5bcb79af05fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-fe748a0b-d82e-4357-a652-c85e4ee0c1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-3146a605-7696-46b6-8918-3f436e96ca59,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-9b2f2645-dbeb-4adc-b69f-8f2a66fb44ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505106115-172.17.0.10-1595908408737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44937,DS-43bf6308-dc34-443e-a8fd-95a1bd15920c,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-4978fc6d-bde3-4609-842a-f66843b2be69,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-1a6496e7-afdc-4252-aa97-0c2c3c7e74e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-e56008b7-f7af-41e7-81c1-5eedc679735a,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-2b3a0866-be86-4872-86bd-27441e13e67c,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-deadc421-e63b-4d76-b75e-310f15da2c52,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-0061eb81-f429-49a4-90ad-dc879402a4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-e56548f3-c996-49e0-82d2-c1d72da3a1ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505106115-172.17.0.10-1595908408737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44937,DS-43bf6308-dc34-443e-a8fd-95a1bd15920c,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-4978fc6d-bde3-4609-842a-f66843b2be69,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-1a6496e7-afdc-4252-aa97-0c2c3c7e74e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-e56008b7-f7af-41e7-81c1-5eedc679735a,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-2b3a0866-be86-4872-86bd-27441e13e67c,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-deadc421-e63b-4d76-b75e-310f15da2c52,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-0061eb81-f429-49a4-90ad-dc879402a4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-e56548f3-c996-49e0-82d2-c1d72da3a1ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471104484-172.17.0.10-1595908536937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41544,DS-7a0f4d9b-ae8d-4fc1-b460-d9cac548133e,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-b23db9b4-1121-4a64-9ab7-8c13c7282fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-3db8ab39-e552-491c-826c-bd8e0a3686c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-f0511836-be15-464f-b277-cf1cc03f8257,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-8103f94a-0d43-435e-8ac1-64916abb14a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-d46a2fe5-decd-48c7-8a92-4659905cceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-6bfec893-dc45-48b7-bd72-ad3e0d67b41d,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-2a0a1b06-1548-4eb4-8efb-062df513ca56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1471104484-172.17.0.10-1595908536937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41544,DS-7a0f4d9b-ae8d-4fc1-b460-d9cac548133e,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-b23db9b4-1121-4a64-9ab7-8c13c7282fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-3db8ab39-e552-491c-826c-bd8e0a3686c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-f0511836-be15-464f-b277-cf1cc03f8257,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-8103f94a-0d43-435e-8ac1-64916abb14a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-d46a2fe5-decd-48c7-8a92-4659905cceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-6bfec893-dc45-48b7-bd72-ad3e0d67b41d,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-2a0a1b06-1548-4eb4-8efb-062df513ca56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637517551-172.17.0.10-1595908790150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37056,DS-6c16d3f3-bc71-4fa9-b892-18d5260d43d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-bac17006-54c6-4ced-b411-136006e3479a,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-90a23eb9-ccc1-441d-bcb6-7da3223cc319,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-9eff66b2-8494-4d0d-8bf4-67ea0af34100,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-1c6fbf48-600a-4876-84b9-c2e9a4144a79,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-b589cea7-da84-4382-9866-a5f8e3603f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-bf038482-98da-4f30-97bf-6e27e3cdf037,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-d1207262-04c4-41b1-94f3-2953b5c06781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637517551-172.17.0.10-1595908790150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37056,DS-6c16d3f3-bc71-4fa9-b892-18d5260d43d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-bac17006-54c6-4ced-b411-136006e3479a,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-90a23eb9-ccc1-441d-bcb6-7da3223cc319,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-9eff66b2-8494-4d0d-8bf4-67ea0af34100,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-1c6fbf48-600a-4876-84b9-c2e9a4144a79,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-b589cea7-da84-4382-9866-a5f8e3603f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-bf038482-98da-4f30-97bf-6e27e3cdf037,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-d1207262-04c4-41b1-94f3-2953b5c06781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719588771-172.17.0.10-1595908828819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43692,DS-6da8b1ec-3c0d-4298-8fea-e491716cf286,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-cd341a7b-ea6e-4a5a-96df-dcb8935b5b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-eaac1220-6ca4-4154-8d93-87d0d8fd3555,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-6ba8f15e-b653-4698-b2c3-2b40a82bf231,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-2cbd400d-50d9-4fb0-80ca-0a544af7dabe,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-e6351e64-704c-4221-bd01-1ffa3367cd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-a1738ee6-8803-4a25-9d3e-b1a3f690f9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-1027adc8-09d6-4897-b014-40dfed56538a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719588771-172.17.0.10-1595908828819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43692,DS-6da8b1ec-3c0d-4298-8fea-e491716cf286,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-cd341a7b-ea6e-4a5a-96df-dcb8935b5b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-eaac1220-6ca4-4154-8d93-87d0d8fd3555,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-6ba8f15e-b653-4698-b2c3-2b40a82bf231,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-2cbd400d-50d9-4fb0-80ca-0a544af7dabe,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-e6351e64-704c-4221-bd01-1ffa3367cd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-a1738ee6-8803-4a25-9d3e-b1a3f690f9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40094,DS-1027adc8-09d6-4897-b014-40dfed56538a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009327295-172.17.0.10-1595909010996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46854,DS-4a739ae8-86c7-4a50-87e5-2d4145394bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-18b93daa-2b79-4178-b112-ea58ca4cfb66,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-60559411-7646-4509-a3f2-8612774f76ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-92cba13f-e27f-45f4-8953-ae28c09dfaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-11fa8ed1-7725-40a0-a6d7-6c47bd4fad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-6fdabb27-0aa5-4039-8f19-c52a43846070,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-c7d84d04-14e3-494e-bc8b-24fb4a86a5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-6f58bae6-3f0a-461a-a690-34f0f69a2605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009327295-172.17.0.10-1595909010996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46854,DS-4a739ae8-86c7-4a50-87e5-2d4145394bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-18b93daa-2b79-4178-b112-ea58ca4cfb66,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-60559411-7646-4509-a3f2-8612774f76ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-92cba13f-e27f-45f4-8953-ae28c09dfaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-11fa8ed1-7725-40a0-a6d7-6c47bd4fad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-6fdabb27-0aa5-4039-8f19-c52a43846070,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-c7d84d04-14e3-494e-bc8b-24fb4a86a5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-6f58bae6-3f0a-461a-a690-34f0f69a2605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 6985
