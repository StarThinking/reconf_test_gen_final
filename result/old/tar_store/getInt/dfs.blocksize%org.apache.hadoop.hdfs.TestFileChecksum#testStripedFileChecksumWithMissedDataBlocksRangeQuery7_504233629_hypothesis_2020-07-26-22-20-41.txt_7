reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683241302-172.17.0.12-1595802054641:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35998,DS-c8907431-7b2d-4f0c-8d5d-7ca5b752c963,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-337c4cb8-61b3-4066-b67d-d99641973dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-018d1de4-6bca-4d90-9d18-ed8db7e7d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-8988c212-a1f5-4bd3-bc6a-0d79bce6bf62,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-4c1be1eb-1e5b-4452-9edc-afa4af39835f,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-d5b8c4e3-c177-4514-805b-ad9710efc2de,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-7ae6ab9e-3ebc-4262-bb3b-a77e76d0344b,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-b8b44710-d390-423a-8e14-43d699d39bc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683241302-172.17.0.12-1595802054641:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35998,DS-c8907431-7b2d-4f0c-8d5d-7ca5b752c963,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-337c4cb8-61b3-4066-b67d-d99641973dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-018d1de4-6bca-4d90-9d18-ed8db7e7d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-8988c212-a1f5-4bd3-bc6a-0d79bce6bf62,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-4c1be1eb-1e5b-4452-9edc-afa4af39835f,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-d5b8c4e3-c177-4514-805b-ad9710efc2de,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-7ae6ab9e-3ebc-4262-bb3b-a77e76d0344b,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-b8b44710-d390-423a-8e14-43d699d39bc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107515942-172.17.0.12-1595802178236:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44559,DS-60f4e7ee-977a-4493-bd9f-bdc8896e1f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-656b156e-fc0a-4392-8042-c56a188cf2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-38c16ce4-8da4-42a1-a8e4-03f5360bb29d,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-cf9ae765-311c-45fd-ad02-92dd39f9e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-f11cf33c-0621-4eb4-a0dd-fc084a5eb0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-5ff4c69c-9bd8-4aaa-a20d-c071d76f304c,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-e0281471-1486-41f6-bc27-3a8e397f648b,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-904a469d-fd61-476a-8e4e-6badb4186b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107515942-172.17.0.12-1595802178236:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44559,DS-60f4e7ee-977a-4493-bd9f-bdc8896e1f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-656b156e-fc0a-4392-8042-c56a188cf2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-38c16ce4-8da4-42a1-a8e4-03f5360bb29d,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-cf9ae765-311c-45fd-ad02-92dd39f9e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-f11cf33c-0621-4eb4-a0dd-fc084a5eb0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-5ff4c69c-9bd8-4aaa-a20d-c071d76f304c,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-e0281471-1486-41f6-bc27-3a8e397f648b,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-904a469d-fd61-476a-8e4e-6badb4186b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276175427-172.17.0.12-1595802552957:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43625,DS-28712253-cbe5-46d6-ae51-8b14186821c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-6fc1a325-1638-4a61-bca2-68e08b70863e,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-be8f385e-3be4-4ef1-8c46-76c64cba0c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-e179483b-7114-4d73-b7a3-22b855e0ce05,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-a89f20eb-4974-4caf-bd98-04173405b4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-c0117d87-298a-4917-adb2-01af3fb33b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-6700e9db-43a1-470d-993d-21a26d1c40d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-58d27990-21ef-46b3-b04a-a32fc829d914,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276175427-172.17.0.12-1595802552957:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43625,DS-28712253-cbe5-46d6-ae51-8b14186821c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-6fc1a325-1638-4a61-bca2-68e08b70863e,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-be8f385e-3be4-4ef1-8c46-76c64cba0c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-e179483b-7114-4d73-b7a3-22b855e0ce05,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-a89f20eb-4974-4caf-bd98-04173405b4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-c0117d87-298a-4917-adb2-01af3fb33b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-6700e9db-43a1-470d-993d-21a26d1c40d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-58d27990-21ef-46b3-b04a-a32fc829d914,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567526708-172.17.0.12-1595802619424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38533,DS-9275ed25-0145-4625-9a88-7dbedfc7ed22,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-38796fc2-328c-4742-bae0-91c61a525d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-dc349ded-8a84-49e2-9ab1-c1e2b905446b,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-524a0e3a-58cf-4c58-9cda-41f5f07e9690,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-afcae07b-3a1c-4b0f-82cb-90b9f25c71b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-b8fc6746-c475-4f56-a26c-8097c2023f15,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-bc95dbc6-5d60-4ed0-997e-d74c5f78760d,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-41d81d77-9698-40b1-9bb1-47d6c0045330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567526708-172.17.0.12-1595802619424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38533,DS-9275ed25-0145-4625-9a88-7dbedfc7ed22,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-38796fc2-328c-4742-bae0-91c61a525d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-dc349ded-8a84-49e2-9ab1-c1e2b905446b,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-524a0e3a-58cf-4c58-9cda-41f5f07e9690,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-afcae07b-3a1c-4b0f-82cb-90b9f25c71b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-b8fc6746-c475-4f56-a26c-8097c2023f15,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-bc95dbc6-5d60-4ed0-997e-d74c5f78760d,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-41d81d77-9698-40b1-9bb1-47d6c0045330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673984962-172.17.0.12-1595802684447:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41410,DS-4c855e85-7f9a-41fb-b5a0-f2d3b9d639d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-4ee3d132-78ee-4c74-b783-cb19c94962f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-e25deca8-e6a4-4b09-a99c-bc87856e51cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-b6de0459-5b89-4224-9b91-f9d29048c6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-108610f5-3ba1-468f-8c17-9035f26497d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-d090952f-c9b9-460e-adae-353daf5c86e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-89ed03a1-70d2-4dff-955d-f335c140e826,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-c56e6df7-7760-4a7a-9ff3-6e6e447c24e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673984962-172.17.0.12-1595802684447:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41410,DS-4c855e85-7f9a-41fb-b5a0-f2d3b9d639d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-4ee3d132-78ee-4c74-b783-cb19c94962f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-e25deca8-e6a4-4b09-a99c-bc87856e51cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-b6de0459-5b89-4224-9b91-f9d29048c6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-108610f5-3ba1-468f-8c17-9035f26497d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-d090952f-c9b9-460e-adae-353daf5c86e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-89ed03a1-70d2-4dff-955d-f335c140e826,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-c56e6df7-7760-4a7a-9ff3-6e6e447c24e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290847803-172.17.0.12-1595802884086:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40227,DS-419685cb-d387-4475-b816-113cf1fca06c,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-513059d3-5c4f-40c1-b11c-43ff77dcb6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-62d81bf2-19f8-47d4-9b5e-618ce2d858b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-59bc9945-15ee-4e35-a12d-2804d785e4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-927993fc-f12a-4e20-9a38-4abfa7a5f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-53639fc4-674b-4570-9fb0-dd86adb9d04c,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-1b07132e-c45d-4675-bd74-bac643a737ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-48cdd4c4-ebca-4d7c-b462-09282c0a01d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290847803-172.17.0.12-1595802884086:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40227,DS-419685cb-d387-4475-b816-113cf1fca06c,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-513059d3-5c4f-40c1-b11c-43ff77dcb6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-62d81bf2-19f8-47d4-9b5e-618ce2d858b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-59bc9945-15ee-4e35-a12d-2804d785e4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-927993fc-f12a-4e20-9a38-4abfa7a5f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-53639fc4-674b-4570-9fb0-dd86adb9d04c,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-1b07132e-c45d-4675-bd74-bac643a737ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-48cdd4c4-ebca-4d7c-b462-09282c0a01d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268227402-172.17.0.12-1595803282473:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35865,DS-14a720cc-6dd5-4f2a-a467-1d92711021e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-840dded9-bbc9-4375-9f22-525f1a83545d,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-f7a57fc5-d703-4f6f-bb7f-b809316dfd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-72cee387-48ea-4b7f-98d1-196324cb838c,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-819e439a-2611-4b03-bac6-2357c1f4961c,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-64132211-5b49-459c-bf3a-5a8df7f8aa90,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-d55b2151-f414-4336-a331-6c6b95218e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-32fd5b88-c5cf-4bfe-9357-d485171dcfde,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268227402-172.17.0.12-1595803282473:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35865,DS-14a720cc-6dd5-4f2a-a467-1d92711021e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-840dded9-bbc9-4375-9f22-525f1a83545d,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-f7a57fc5-d703-4f6f-bb7f-b809316dfd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-72cee387-48ea-4b7f-98d1-196324cb838c,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-819e439a-2611-4b03-bac6-2357c1f4961c,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-64132211-5b49-459c-bf3a-5a8df7f8aa90,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-d55b2151-f414-4336-a331-6c6b95218e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-32fd5b88-c5cf-4bfe-9357-d485171dcfde,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550260680-172.17.0.12-1595803317724:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45798,DS-3f9bbabd-9d6f-44b1-ab0d-c6adaed8274b,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-633e9ac4-7555-46c2-8bd2-e262fd382d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-190fc370-50e2-492e-a5b7-4110235fcabf,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-4144d94d-7370-47e9-8b1a-691a314eb253,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-7dea852c-f2b8-4e9b-affa-f3d57b1668be,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-f942c815-5b02-4d47-9c8a-5eebb7e3d439,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-c07ea4d7-c786-4cbf-b97a-de340e9236f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-1f75b00f-2b6c-49ad-be86-a8afdb5144c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550260680-172.17.0.12-1595803317724:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45798,DS-3f9bbabd-9d6f-44b1-ab0d-c6adaed8274b,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-633e9ac4-7555-46c2-8bd2-e262fd382d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-190fc370-50e2-492e-a5b7-4110235fcabf,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-4144d94d-7370-47e9-8b1a-691a314eb253,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-7dea852c-f2b8-4e9b-affa-f3d57b1668be,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-f942c815-5b02-4d47-9c8a-5eebb7e3d439,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-c07ea4d7-c786-4cbf-b97a-de340e9236f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-1f75b00f-2b6c-49ad-be86-a8afdb5144c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080190616-172.17.0.12-1595803355546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37451,DS-f41744da-1dd5-4ab5-84a0-da1d89e89896,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-dadeeaee-7eaf-4831-83b5-f8107ae9e53d,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-823c8686-ba21-4e0d-a0fa-0e6ddd1964da,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-5facde95-6fe7-4852-bb38-621566f753d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-1105a440-6923-4d5f-bee4-2fab8d9a05d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-f92124be-f805-4b25-9018-8394cfd36afb,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-02eebe01-bc01-4b00-95a0-891dfe85391f,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-03b99aac-aa51-4786-b1e7-fbd416e31bdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080190616-172.17.0.12-1595803355546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37451,DS-f41744da-1dd5-4ab5-84a0-da1d89e89896,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-dadeeaee-7eaf-4831-83b5-f8107ae9e53d,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-823c8686-ba21-4e0d-a0fa-0e6ddd1964da,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-5facde95-6fe7-4852-bb38-621566f753d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-1105a440-6923-4d5f-bee4-2fab8d9a05d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-f92124be-f805-4b25-9018-8394cfd36afb,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-02eebe01-bc01-4b00-95a0-891dfe85391f,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-03b99aac-aa51-4786-b1e7-fbd416e31bdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960969066-172.17.0.12-1595803496232:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-639fabd9-4b83-4790-957c-6324c7218492,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-eae62744-c5d2-41fa-ad9a-cf562d49ac13,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-10bbcae2-09f1-4d8c-b4a8-2690655c081a,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-311c399a-2021-4274-96e8-49e13ce79bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-739d0fa6-03a1-4be1-b45f-cd50dd190985,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-39090494-8612-4970-ad8d-c0b57a99a715,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-9e27ad1e-c95d-4b0e-a588-f84f642324ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-14e8bf73-63e1-4b56-8309-0abadfef537f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960969066-172.17.0.12-1595803496232:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-639fabd9-4b83-4790-957c-6324c7218492,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-eae62744-c5d2-41fa-ad9a-cf562d49ac13,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-10bbcae2-09f1-4d8c-b4a8-2690655c081a,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-311c399a-2021-4274-96e8-49e13ce79bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-739d0fa6-03a1-4be1-b45f-cd50dd190985,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-39090494-8612-4970-ad8d-c0b57a99a715,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-9e27ad1e-c95d-4b0e-a588-f84f642324ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-14e8bf73-63e1-4b56-8309-0abadfef537f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297446155-172.17.0.12-1595803714772:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35703,DS-604c053e-bffc-4b90-b1f4-b81813a4d91c,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-c678027b-40df-41a0-bc61-52c5c1bad038,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-2561f939-0b4a-4e80-8aea-cbab9792e977,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-0d5d2b0a-d800-41ad-a507-5627e9e35a09,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-0aafd7c0-c185-47a6-bb9d-22d0e07025e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-2e0e3810-63f1-4da5-a4f9-bc9a67502627,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-4d3f7326-ec9a-4fa7-bd72-3d32b40c19ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-13ca31de-36e6-4f50-8e59-b70f797a119b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297446155-172.17.0.12-1595803714772:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35703,DS-604c053e-bffc-4b90-b1f4-b81813a4d91c,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-c678027b-40df-41a0-bc61-52c5c1bad038,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-2561f939-0b4a-4e80-8aea-cbab9792e977,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-0d5d2b0a-d800-41ad-a507-5627e9e35a09,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-0aafd7c0-c185-47a6-bb9d-22d0e07025e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-2e0e3810-63f1-4da5-a4f9-bc9a67502627,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-4d3f7326-ec9a-4fa7-bd72-3d32b40c19ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-13ca31de-36e6-4f50-8e59-b70f797a119b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482903911-172.17.0.12-1595803927642:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36226,DS-d89f4818-d7c6-485b-ad90-6b4b6806ceea,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-8e097ea7-82e9-408b-aaf1-15f8da23a2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-42b23781-8ae4-49b5-9491-e7a8b6b8fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-165b2201-712c-4f21-b542-640c7df6cda2,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-e4bfbff2-9243-4823-aaf4-8d66233be0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-f8d1a3a5-f199-4444-b922-bcb3189c62b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-e1c3a220-708c-410f-862a-5ae0c436cb24,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-87cd5ad4-d5be-4b1b-9e68-b069a1f7fe74,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1482903911-172.17.0.12-1595803927642:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36226,DS-d89f4818-d7c6-485b-ad90-6b4b6806ceea,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-8e097ea7-82e9-408b-aaf1-15f8da23a2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-42b23781-8ae4-49b5-9491-e7a8b6b8fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:38132,DS-165b2201-712c-4f21-b542-640c7df6cda2,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-e4bfbff2-9243-4823-aaf4-8d66233be0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-f8d1a3a5-f199-4444-b922-bcb3189c62b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-e1c3a220-708c-410f-862a-5ae0c436cb24,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-87cd5ad4-d5be-4b1b-9e68-b069a1f7fe74,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234428118-172.17.0.12-1595804277211:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35803,DS-d154a1bf-58f7-409a-87e5-4ece5e7e678c,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-ee240af5-9528-42fc-b4d2-e8579f025ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-7a154145-99e3-4ff2-865c-eac40dbab100,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-0ce328f0-0e4b-4944-a342-fabf0d3de636,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-da8cf366-9236-47a5-ad60-2e32eb8c5062,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-0546387d-b2de-4ef5-a89d-d1cef0c78139,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-60242a66-3165-4174-a855-b16586b101b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-6a52c93a-4f14-407d-88ab-2d1050576a51,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234428118-172.17.0.12-1595804277211:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35803,DS-d154a1bf-58f7-409a-87e5-4ece5e7e678c,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-ee240af5-9528-42fc-b4d2-e8579f025ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-7a154145-99e3-4ff2-865c-eac40dbab100,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-0ce328f0-0e4b-4944-a342-fabf0d3de636,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-da8cf366-9236-47a5-ad60-2e32eb8c5062,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-0546387d-b2de-4ef5-a89d-d1cef0c78139,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-60242a66-3165-4174-a855-b16586b101b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-6a52c93a-4f14-407d-88ab-2d1050576a51,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966730241-172.17.0.12-1595804424473:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44331,DS-cc539203-5f37-44e8-bc36-a2e6515c5cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-6c62a6d7-5cb4-49ac-8b8c-e49f41ee0e36,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-613a0800-2de1-428d-8e00-6ae0bc77c678,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-88e37092-a3de-4bd1-8498-1524ea80ea8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-68565c5f-c81c-4b7c-a046-a92ea2beadc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-e8c0ab64-36f4-4412-acaa-7e55075ed663,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-ef2915e7-2bf1-4478-a156-34d3a1976c29,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-a1a5c18b-db20-422a-9dfe-645d81195d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966730241-172.17.0.12-1595804424473:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44331,DS-cc539203-5f37-44e8-bc36-a2e6515c5cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-6c62a6d7-5cb4-49ac-8b8c-e49f41ee0e36,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-613a0800-2de1-428d-8e00-6ae0bc77c678,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-88e37092-a3de-4bd1-8498-1524ea80ea8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-68565c5f-c81c-4b7c-a046-a92ea2beadc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-e8c0ab64-36f4-4412-acaa-7e55075ed663,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-ef2915e7-2bf1-4478-a156-34d3a1976c29,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-a1a5c18b-db20-422a-9dfe-645d81195d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804966259-172.17.0.12-1595804561654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39394,DS-6c0d516b-612a-4928-859f-29ae5b2dbd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-0ef1c23a-b553-4703-9f98-cf1c81ae2b11,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-ec3ce205-0049-44ae-949b-031649f748a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-ed0a97ed-e60a-439c-be18-d4df9be731c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-4df30cf5-4534-48c1-b065-be164dfdb611,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-e43d45bd-faaa-4f7a-8e2c-4afcc553ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-7ab72fc8-47d9-4452-8b91-e23335b7f29c,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-8edc32b6-69b8-47cb-abe5-c79a5df522a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804966259-172.17.0.12-1595804561654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39394,DS-6c0d516b-612a-4928-859f-29ae5b2dbd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-0ef1c23a-b553-4703-9f98-cf1c81ae2b11,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-ec3ce205-0049-44ae-949b-031649f748a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-ed0a97ed-e60a-439c-be18-d4df9be731c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-4df30cf5-4534-48c1-b065-be164dfdb611,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-e43d45bd-faaa-4f7a-8e2c-4afcc553ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-7ab72fc8-47d9-4452-8b91-e23335b7f29c,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-8edc32b6-69b8-47cb-abe5-c79a5df522a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998802401-172.17.0.12-1595804602821:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36045,DS-7c2a4b8a-23c9-4346-af2a-0e6707966797,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-fb564f93-ab6f-43de-9e43-f2c5ce611245,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-fb9420b4-8391-48aa-bcc1-9b74f2cb5e42,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-b68290f4-8df7-47a2-ba72-cac19b86d4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-bf659e10-a929-46c6-94ff-0e156497f9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-feaea9a3-ad7e-42a6-98d7-b48e95ebb6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-1b1b13bc-4a56-407a-ad09-79ab383748fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-03fd8634-0379-4c78-a79e-ac51ef3e7ec8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998802401-172.17.0.12-1595804602821:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36045,DS-7c2a4b8a-23c9-4346-af2a-0e6707966797,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-fb564f93-ab6f-43de-9e43-f2c5ce611245,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-fb9420b4-8391-48aa-bcc1-9b74f2cb5e42,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-b68290f4-8df7-47a2-ba72-cac19b86d4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-bf659e10-a929-46c6-94ff-0e156497f9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-feaea9a3-ad7e-42a6-98d7-b48e95ebb6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-1b1b13bc-4a56-407a-ad09-79ab383748fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-03fd8634-0379-4c78-a79e-ac51ef3e7ec8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672374147-172.17.0.12-1595805178149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45832,DS-df75d2d7-34b7-4561-8da9-28076cc03f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-e542be2b-0622-4ecf-9598-dcb3013a4d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-a5556fd9-029b-495c-94e0-95a11954586f,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-5767c76d-2211-4a62-828f-fd65591efc77,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-a0059818-9750-4875-b693-b95923a3023c,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-89e3d327-7532-4701-af98-4596778d6869,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-35ab34e4-88e9-44d8-a408-be62c36a8966,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-aaff2545-806b-46f4-8428-fa403294d33d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1672374147-172.17.0.12-1595805178149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45832,DS-df75d2d7-34b7-4561-8da9-28076cc03f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-e542be2b-0622-4ecf-9598-dcb3013a4d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-a5556fd9-029b-495c-94e0-95a11954586f,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-5767c76d-2211-4a62-828f-fd65591efc77,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-a0059818-9750-4875-b693-b95923a3023c,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-89e3d327-7532-4701-af98-4596778d6869,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-35ab34e4-88e9-44d8-a408-be62c36a8966,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-aaff2545-806b-46f4-8428-fa403294d33d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605652960-172.17.0.12-1595805299417:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45597,DS-e142c338-9952-4897-a9e2-4fc4c1fbe06c,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-cd3a631a-9102-4d62-a34d-7d2c5366f722,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-7729795f-4ff9-4d23-b3fb-7a4691e39f38,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-02579388-7c43-43a8-bcc8-f2019a534d54,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-bc687e8d-8695-4daa-843b-1c09cad7449c,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-3686c410-0c64-4fea-b3f0-9ef7912891f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-fa86969a-c3fd-46c3-a960-fa0446631d08,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-63ed4ef5-8dfc-44d0-ba93-082b3d9b66aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605652960-172.17.0.12-1595805299417:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45597,DS-e142c338-9952-4897-a9e2-4fc4c1fbe06c,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-cd3a631a-9102-4d62-a34d-7d2c5366f722,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-7729795f-4ff9-4d23-b3fb-7a4691e39f38,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-02579388-7c43-43a8-bcc8-f2019a534d54,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-bc687e8d-8695-4daa-843b-1c09cad7449c,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-3686c410-0c64-4fea-b3f0-9ef7912891f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-fa86969a-c3fd-46c3-a960-fa0446631d08,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-63ed4ef5-8dfc-44d0-ba93-082b3d9b66aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393410042-172.17.0.12-1595805392794:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46635,DS-489e9b18-6f25-4cdd-a8f8-64b5b7990f95,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-792d82ac-636b-4a10-b3ff-6436dcfba030,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-ddb16402-991c-4572-8c48-1d09a02bbea9,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-7345d12b-71d1-41a1-ac94-0ee1ab5f2b93,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-32fa847a-6edf-4b92-a9a6-a8939c856359,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-e4089020-e581-4231-8e80-39b3ca1863d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-d537fd3c-591e-41a2-87f1-d4c8517ba097,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-b47e1e12-5878-47ed-844c-3d43d2f69346,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393410042-172.17.0.12-1595805392794:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46635,DS-489e9b18-6f25-4cdd-a8f8-64b5b7990f95,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-792d82ac-636b-4a10-b3ff-6436dcfba030,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-ddb16402-991c-4572-8c48-1d09a02bbea9,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-7345d12b-71d1-41a1-ac94-0ee1ab5f2b93,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-32fa847a-6edf-4b92-a9a6-a8939c856359,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-e4089020-e581-4231-8e80-39b3ca1863d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-d537fd3c-591e-41a2-87f1-d4c8517ba097,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-b47e1e12-5878-47ed-844c-3d43d2f69346,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008395231-172.17.0.12-1595805736289:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39998,DS-90c656bf-d85d-4d16-8b80-0066ddc8512b,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-e7328833-44a4-4643-ac41-883021d8e3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-08a0a381-2136-42ce-b15e-9c4d35216549,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-15b7503f-6a70-4e84-bc88-fc60d5748c77,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-71239085-41dc-435d-a4d8-a9d2e0af2ead,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-609a4161-a3f5-4524-bc7a-38894391417a,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-db03e3bf-99d4-4824-8630-65d603e88de9,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-788224c4-5cbe-4b1f-b6bb-6af31a08dc3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008395231-172.17.0.12-1595805736289:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39998,DS-90c656bf-d85d-4d16-8b80-0066ddc8512b,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-e7328833-44a4-4643-ac41-883021d8e3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-08a0a381-2136-42ce-b15e-9c4d35216549,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-15b7503f-6a70-4e84-bc88-fc60d5748c77,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-71239085-41dc-435d-a4d8-a9d2e0af2ead,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-609a4161-a3f5-4524-bc7a-38894391417a,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-db03e3bf-99d4-4824-8630-65d603e88de9,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-788224c4-5cbe-4b1f-b6bb-6af31a08dc3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721482707-172.17.0.12-1595805801069:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36164,DS-74c3db7b-615b-4949-991c-54d8a82b7206,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-7a5b05df-1ca2-4faf-8ebf-ce30d8dfc808,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-366f4800-efd8-460f-82ee-6a8def00f29a,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-59c72907-f5d9-4b36-b474-6cb8bbe34835,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-0cf13cb4-22a3-42eb-8999-93ede3e21457,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-b71d029f-47ee-4112-b06d-4e8cc67da3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-fa197704-727f-4764-8849-b3bdc8cb4f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-3815af0d-afa0-4e15-a000-6fd490fbc1ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721482707-172.17.0.12-1595805801069:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36164,DS-74c3db7b-615b-4949-991c-54d8a82b7206,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-7a5b05df-1ca2-4faf-8ebf-ce30d8dfc808,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-366f4800-efd8-460f-82ee-6a8def00f29a,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-59c72907-f5d9-4b36-b474-6cb8bbe34835,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-0cf13cb4-22a3-42eb-8999-93ede3e21457,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-b71d029f-47ee-4112-b06d-4e8cc67da3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-fa197704-727f-4764-8849-b3bdc8cb4f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-3815af0d-afa0-4e15-a000-6fd490fbc1ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684059503-172.17.0.12-1595805942757:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42694,DS-5e06a8a2-6ceb-4c97-baab-c0749d09561d,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-3581ae1a-f785-4811-b618-f0246fe24b26,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-970be744-4deb-4834-8e1e-67abc7638e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-40b97ddb-0f25-4b9e-af94-de7c54c13ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-1ea6cc67-a816-49d2-b154-04b7267c024e,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-bffaba86-da05-440e-b5d4-6956c6ff379d,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-46fadb58-3ddf-451a-9388-342b28586590,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-265d00aa-b1c7-4372-ae66-e8e9ccf31333,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-684059503-172.17.0.12-1595805942757:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42694,DS-5e06a8a2-6ceb-4c97-baab-c0749d09561d,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-3581ae1a-f785-4811-b618-f0246fe24b26,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-970be744-4deb-4834-8e1e-67abc7638e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-40b97ddb-0f25-4b9e-af94-de7c54c13ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-1ea6cc67-a816-49d2-b154-04b7267c024e,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-bffaba86-da05-440e-b5d4-6956c6ff379d,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-46fadb58-3ddf-451a-9388-342b28586590,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-265d00aa-b1c7-4372-ae66-e8e9ccf31333,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063746245-172.17.0.12-1595805977030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43792,DS-3c71f02c-de28-4b4f-aadc-71ccd04feac9,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-1db36b23-2a1e-486d-8941-14cd7569953e,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-7fcd7e07-0cf2-4649-ada5-0e3b30c359a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-c07ac35c-bef7-499b-87f5-6b9d99887e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-4cf9d2d2-52a6-4f7a-b299-a633631cb300,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-4e399be6-d939-464c-9dad-59e3183593c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-209c3ea1-237c-4c70-a19a-6dfd62792cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-082e3a04-ef30-4ce6-86ac-b88ee9f3c4df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063746245-172.17.0.12-1595805977030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43792,DS-3c71f02c-de28-4b4f-aadc-71ccd04feac9,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-1db36b23-2a1e-486d-8941-14cd7569953e,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-7fcd7e07-0cf2-4649-ada5-0e3b30c359a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-c07ac35c-bef7-499b-87f5-6b9d99887e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-4cf9d2d2-52a6-4f7a-b299-a633631cb300,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-4e399be6-d939-464c-9dad-59e3183593c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-209c3ea1-237c-4c70-a19a-6dfd62792cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-082e3a04-ef30-4ce6-86ac-b88ee9f3c4df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-184269373-172.17.0.12-1595806003792:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33857,DS-180189b5-75bf-47be-82c8-7ae4f3a6a99a,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-98c12fca-ab55-4a5d-8b0e-b9430bcffc99,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-82daf27e-0039-41da-af93-958e795a12aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-2e545ccf-514f-4231-a455-efcb8baafeba,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-e7d106d3-38df-4c83-9b72-071d5a91c9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-7c92547a-e4c7-4f3e-b7fb-239a11d0fde9,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-40900af0-6c0c-4eae-b058-193d6202a140,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-f4c1767c-7a71-4096-bd66-0f42aaadfa99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-184269373-172.17.0.12-1595806003792:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33857,DS-180189b5-75bf-47be-82c8-7ae4f3a6a99a,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-98c12fca-ab55-4a5d-8b0e-b9430bcffc99,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-82daf27e-0039-41da-af93-958e795a12aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-2e545ccf-514f-4231-a455-efcb8baafeba,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-e7d106d3-38df-4c83-9b72-071d5a91c9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-7c92547a-e4c7-4f3e-b7fb-239a11d0fde9,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-40900af0-6c0c-4eae-b058-193d6202a140,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-f4c1767c-7a71-4096-bd66-0f42aaadfa99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562878074-172.17.0.12-1595806103545:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34491,DS-75ad9440-280b-4f6c-94da-7d839104020a,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-9fe20d8e-dec9-4bd7-a4f0-3f7738cf1688,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-96b22380-e410-4807-988a-c6c5e65bbf45,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-23a65917-c040-401d-a945-1ee341eb31ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-f437d839-e870-4283-a3b8-2affe14b4825,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-c4a0121e-c2ef-4f1b-97a2-33e433e75423,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-1a22f48b-bcb9-4a59-81ab-b7bae7981a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-f59610c4-f6e7-42b4-b5b0-05c1706bc312,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562878074-172.17.0.12-1595806103545:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34491,DS-75ad9440-280b-4f6c-94da-7d839104020a,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-9fe20d8e-dec9-4bd7-a4f0-3f7738cf1688,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-96b22380-e410-4807-988a-c6c5e65bbf45,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-23a65917-c040-401d-a945-1ee341eb31ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-f437d839-e870-4283-a3b8-2affe14b4825,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-c4a0121e-c2ef-4f1b-97a2-33e433e75423,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-1a22f48b-bcb9-4a59-81ab-b7bae7981a96,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-f59610c4-f6e7-42b4-b5b0-05c1706bc312,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72276669-172.17.0.12-1595806136790:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41369,DS-1478f030-eca4-4f78-bf6b-d9e58d1d51ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-dab22fa1-89de-479f-ae2d-6bd42209087d,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-08a9161e-6b7e-4f4a-8f8c-16afb946e4be,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-998f6783-5dd8-4f14-ba38-08fbd1fea7be,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-89891d23-86ef-44a7-8832-e01a5f9209fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-81318c1a-2e8e-4534-8a50-9c1edcddb7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-88c00ecb-d9fb-455c-85aa-a944374348b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-c2f24c92-ac12-4407-93a7-6d58f701c08a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72276669-172.17.0.12-1595806136790:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41369,DS-1478f030-eca4-4f78-bf6b-d9e58d1d51ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-dab22fa1-89de-479f-ae2d-6bd42209087d,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-08a9161e-6b7e-4f4a-8f8c-16afb946e4be,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-998f6783-5dd8-4f14-ba38-08fbd1fea7be,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-89891d23-86ef-44a7-8832-e01a5f9209fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-81318c1a-2e8e-4534-8a50-9c1edcddb7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-88c00ecb-d9fb-455c-85aa-a944374348b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-c2f24c92-ac12-4407-93a7-6d58f701c08a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028934735-172.17.0.12-1595806267694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34949,DS-d82de435-57b2-4846-bc05-d05424e2f916,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-c5fe8484-965e-44dc-a08f-389e885f67a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-f3f69f9a-38bc-426d-8c20-07d7f5cc1fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-422298f7-4cb9-40d1-9d13-b317280778de,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-c1a45f22-2c73-44d8-b73b-63ef461b6137,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-e270df07-1ba2-441b-a947-da27325b1b62,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-ce93ba3a-7f93-4f62-a3b4-454f9605ae90,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-40639582-51a6-4c40-a7ad-43e410ef0245,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028934735-172.17.0.12-1595806267694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34949,DS-d82de435-57b2-4846-bc05-d05424e2f916,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-c5fe8484-965e-44dc-a08f-389e885f67a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-f3f69f9a-38bc-426d-8c20-07d7f5cc1fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-422298f7-4cb9-40d1-9d13-b317280778de,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-c1a45f22-2c73-44d8-b73b-63ef461b6137,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-e270df07-1ba2-441b-a947-da27325b1b62,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-ce93ba3a-7f93-4f62-a3b4-454f9605ae90,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-40639582-51a6-4c40-a7ad-43e410ef0245,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261834401-172.17.0.12-1595806501151:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36994,DS-8b95c495-9e06-4ae4-ba54-82fb11a6a1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-8c6784fb-ccc6-4c89-9291-e3c43a1ae89c,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-5b4c5742-3b7b-44b5-9b97-d1ee1083cdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-af989b90-a381-4905-9309-c3f970a99d72,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-19ffe5e8-7ccf-4692-a63d-e5f0876a7a62,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-2e224fdd-7590-4f25-a6ec-b1b8a01fa97f,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-65440a20-41a3-4c9f-b638-960dd2a3775a,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-5cc92fca-a67b-4687-8e62-c6a99c0cf9df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261834401-172.17.0.12-1595806501151:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36994,DS-8b95c495-9e06-4ae4-ba54-82fb11a6a1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-8c6784fb-ccc6-4c89-9291-e3c43a1ae89c,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-5b4c5742-3b7b-44b5-9b97-d1ee1083cdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-af989b90-a381-4905-9309-c3f970a99d72,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-19ffe5e8-7ccf-4692-a63d-e5f0876a7a62,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-2e224fdd-7590-4f25-a6ec-b1b8a01fa97f,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-65440a20-41a3-4c9f-b638-960dd2a3775a,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-5cc92fca-a67b-4687-8e62-c6a99c0cf9df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1357743721-172.17.0.12-1595806569272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45946,DS-6f2bd99d-efb3-4840-a9ef-5d89a693dca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-50f4b968-146b-4753-b082-82310caf38d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-8dc120df-8151-4b91-9dae-6f4c7ed583d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-5a50537c-7c4b-4f08-a545-423c6952ee53,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-fe8481e6-03c9-474b-ba6e-89ebeccbec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-47c6dafd-09d7-4b49-8d9c-f13c6602fece,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-10b9df43-52e4-4e70-9ad3-242bd2ffee32,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-097197ab-05b6-497a-9d26-5289142c3a67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1357743721-172.17.0.12-1595806569272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45946,DS-6f2bd99d-efb3-4840-a9ef-5d89a693dca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-50f4b968-146b-4753-b082-82310caf38d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-8dc120df-8151-4b91-9dae-6f4c7ed583d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-5a50537c-7c4b-4f08-a545-423c6952ee53,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-fe8481e6-03c9-474b-ba6e-89ebeccbec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-47c6dafd-09d7-4b49-8d9c-f13c6602fece,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-10b9df43-52e4-4e70-9ad3-242bd2ffee32,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-097197ab-05b6-497a-9d26-5289142c3a67,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218555266-172.17.0.12-1595806671901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41781,DS-43444721-37cf-45c1-8749-cf84f6dddc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-ca611d06-cbea-425a-903d-1a8e59c5bc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-a3f70a23-3245-44c9-a287-e0e378b0ec73,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-890d91bb-5fe7-4461-b06a-4aa3f80d81ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-af77ee9b-f8fc-4bd0-a1b0-c0382465144f,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-0bd6c998-881e-4949-b250-34057381d609,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-683688aa-fad2-42d7-a0bc-1e2e352ad8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-01e2165f-ea8c-4075-bd64-4a83585242d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218555266-172.17.0.12-1595806671901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41781,DS-43444721-37cf-45c1-8749-cf84f6dddc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-ca611d06-cbea-425a-903d-1a8e59c5bc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-a3f70a23-3245-44c9-a287-e0e378b0ec73,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-890d91bb-5fe7-4461-b06a-4aa3f80d81ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-af77ee9b-f8fc-4bd0-a1b0-c0382465144f,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-0bd6c998-881e-4949-b250-34057381d609,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-683688aa-fad2-42d7-a0bc-1e2e352ad8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-01e2165f-ea8c-4075-bd64-4a83585242d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502379709-172.17.0.12-1595806706845:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-3b4ea1b6-8e31-4df2-831d-55f7086d7a08,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-bbf95632-3042-48ba-9bd6-f37e455e1f86,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-8e53cb32-4191-48ea-80ca-d72fb31a79ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-972129a8-d41c-4422-98ef-8068a8c80111,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-776a58d0-cafb-494e-8f54-6fa8cf7d85a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-9d88952a-7cc3-4905-b4c7-64325cfed861,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-bd5c3f25-6ab9-403e-b39d-2de41055d455,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-63d109a2-1ed4-498c-8204-4565e51afa35,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502379709-172.17.0.12-1595806706845:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-3b4ea1b6-8e31-4df2-831d-55f7086d7a08,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-bbf95632-3042-48ba-9bd6-f37e455e1f86,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-8e53cb32-4191-48ea-80ca-d72fb31a79ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-972129a8-d41c-4422-98ef-8068a8c80111,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-776a58d0-cafb-494e-8f54-6fa8cf7d85a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-9d88952a-7cc3-4905-b4c7-64325cfed861,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-bd5c3f25-6ab9-403e-b39d-2de41055d455,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-63d109a2-1ed4-498c-8204-4565e51afa35,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744937673-172.17.0.12-1595806738834:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36602,DS-3cd06203-c588-4664-998b-395078aaf626,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-1641b092-ef31-4ab3-8420-f1e8d9501744,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-b8503e03-aaec-4891-9036-78a6ab5a70e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-86a949bc-306e-4d76-b58b-1e9020022747,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-1fc30026-6692-4200-8c72-e25597b19e48,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-1b735a83-2254-44ca-bda4-db81916578b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-f8633205-1b87-412b-ad9b-d6bc87fb27bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-b2740efa-bb0c-4b42-9e6b-587e5a8f6927,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744937673-172.17.0.12-1595806738834:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36602,DS-3cd06203-c588-4664-998b-395078aaf626,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-1641b092-ef31-4ab3-8420-f1e8d9501744,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-b8503e03-aaec-4891-9036-78a6ab5a70e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-86a949bc-306e-4d76-b58b-1e9020022747,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-1fc30026-6692-4200-8c72-e25597b19e48,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-1b735a83-2254-44ca-bda4-db81916578b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-f8633205-1b87-412b-ad9b-d6bc87fb27bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-b2740efa-bb0c-4b42-9e6b-587e5a8f6927,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5162
