reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272200193-172.17.0.13-1595897602265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44633,DS-1f6c4896-7bdb-4659-8b4e-8c9862beaa41,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-336f804d-5e28-483c-91d1-36c1ce6b77b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-6cbbc093-1145-4ddb-9ee4-df6494b023fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-2eba96af-2014-4034-af93-04da90e80c20,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-1f656378-628c-4120-ada3-ccf9f4f4a2db,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-488f96e8-aefd-4c59-ba9c-a94a8d1689eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-a4b9c120-dee8-4204-b003-87548884b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-13abb279-a2cc-4028-8f49-730305390aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272200193-172.17.0.13-1595897602265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44633,DS-1f6c4896-7bdb-4659-8b4e-8c9862beaa41,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-336f804d-5e28-483c-91d1-36c1ce6b77b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-6cbbc093-1145-4ddb-9ee4-df6494b023fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-2eba96af-2014-4034-af93-04da90e80c20,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-1f656378-628c-4120-ada3-ccf9f4f4a2db,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-488f96e8-aefd-4c59-ba9c-a94a8d1689eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-a4b9c120-dee8-4204-b003-87548884b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-13abb279-a2cc-4028-8f49-730305390aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274198413-172.17.0.13-1595897913300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43592,DS-7bb53e8e-8725-4d58-9596-36dd7d173ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-3e5da455-40bd-4ec4-8db1-64a63dd1a0db,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-ad2d7ee7-0da8-4713-93ba-7318d48fbaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-70efc1c1-1a6b-49b3-bb63-e88c474e3a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-590e8233-7882-4e1c-b29a-a6c504ee9e31,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-1279d9ce-a224-48be-9981-0bec53820428,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-3173eec5-11fe-4d75-b873-4bf6d022548f,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-27a957a3-aa66-4960-8bea-db9b283a0775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274198413-172.17.0.13-1595897913300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43592,DS-7bb53e8e-8725-4d58-9596-36dd7d173ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-3e5da455-40bd-4ec4-8db1-64a63dd1a0db,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-ad2d7ee7-0da8-4713-93ba-7318d48fbaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-70efc1c1-1a6b-49b3-bb63-e88c474e3a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-590e8233-7882-4e1c-b29a-a6c504ee9e31,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-1279d9ce-a224-48be-9981-0bec53820428,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-3173eec5-11fe-4d75-b873-4bf6d022548f,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-27a957a3-aa66-4960-8bea-db9b283a0775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-543115075-172.17.0.13-1595898281395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42210,DS-f59085eb-4c58-47a0-ab88-9331900b969d,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-a0b31559-a1a0-4a94-973a-d65f7d796cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-112ef417-e4c6-4ca7-a027-8dad80b078f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-4230b684-aa93-4c1c-9117-1cd786ea4336,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-25a6b9e4-52b3-41c7-b13e-b259a8d77a66,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-06d79196-3e1e-4041-a70a-52627ee3054f,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-ae371218-41a0-4635-9a52-22b8756d9fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-0aed6413-be33-447a-a18c-cf526d5d1df7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-543115075-172.17.0.13-1595898281395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42210,DS-f59085eb-4c58-47a0-ab88-9331900b969d,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-a0b31559-a1a0-4a94-973a-d65f7d796cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-112ef417-e4c6-4ca7-a027-8dad80b078f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-4230b684-aa93-4c1c-9117-1cd786ea4336,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-25a6b9e4-52b3-41c7-b13e-b259a8d77a66,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-06d79196-3e1e-4041-a70a-52627ee3054f,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-ae371218-41a0-4635-9a52-22b8756d9fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-0aed6413-be33-447a-a18c-cf526d5d1df7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955629307-172.17.0.13-1595898383924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36124,DS-ff1f67f4-6ac8-4ae3-957e-4058b4c5a450,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-c9ace9a2-1c1c-4e32-a10b-2b140651a61c,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-862a38f1-4c07-41d3-bc28-fdc57a8c3f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-6d566e90-b9b0-44b2-8e4f-d6e46a519d44,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-32595875-aa26-4c9c-a665-bf5cbb967d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-f6c9d9f7-ae63-4c5e-bd7c-e695bccfced0,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-cb195036-05bd-494b-828b-0bc629afd095,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-fb6ce4b0-8b92-44d5-8281-6362ca1b2c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955629307-172.17.0.13-1595898383924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36124,DS-ff1f67f4-6ac8-4ae3-957e-4058b4c5a450,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-c9ace9a2-1c1c-4e32-a10b-2b140651a61c,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-862a38f1-4c07-41d3-bc28-fdc57a8c3f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-6d566e90-b9b0-44b2-8e4f-d6e46a519d44,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-32595875-aa26-4c9c-a665-bf5cbb967d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-f6c9d9f7-ae63-4c5e-bd7c-e695bccfced0,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-cb195036-05bd-494b-828b-0bc629afd095,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-fb6ce4b0-8b92-44d5-8281-6362ca1b2c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606625516-172.17.0.13-1595899155876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-edc6464d-b575-47b9-b8c3-11e168ea3525,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-1bd1c866-936b-4a0b-9410-401f8a927d11,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-6d1b4537-62fa-4448-9d72-56fde8eedcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-96f85c79-1c21-4f3d-a3f9-8a8c3cb1802a,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-3decc8eb-c829-4488-8235-d4aef1eef1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-073735f7-7db1-443e-ae35-df055d9e04c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-589bdefb-02d1-4f12-949f-f7bc004d9120,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-e3dcab0d-ada3-4a58-a3cd-5bc3bb4c1958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606625516-172.17.0.13-1595899155876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-edc6464d-b575-47b9-b8c3-11e168ea3525,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-1bd1c866-936b-4a0b-9410-401f8a927d11,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-6d1b4537-62fa-4448-9d72-56fde8eedcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-96f85c79-1c21-4f3d-a3f9-8a8c3cb1802a,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-3decc8eb-c829-4488-8235-d4aef1eef1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-073735f7-7db1-443e-ae35-df055d9e04c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-589bdefb-02d1-4f12-949f-f7bc004d9120,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-e3dcab0d-ada3-4a58-a3cd-5bc3bb4c1958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965870838-172.17.0.13-1595899254714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46515,DS-85a9a683-bf86-4bb8-929f-c9a88da142e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-18ae7d56-277b-47ea-8645-4b974796e827,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-f8847b44-3c86-499d-9453-7790f4c3ec9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-196892e0-d149-4861-b5a0-8b73dce7885f,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-b7c053da-36e0-4dc0-891e-b2964ec20459,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-adc4c3f1-79ee-4912-80e2-6ab92dc6ccb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-960e5a38-5422-43c5-9375-5f4336d4f6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-cb35ec93-75a2-4f1e-9e53-de8999367a38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965870838-172.17.0.13-1595899254714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46515,DS-85a9a683-bf86-4bb8-929f-c9a88da142e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-18ae7d56-277b-47ea-8645-4b974796e827,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-f8847b44-3c86-499d-9453-7790f4c3ec9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-196892e0-d149-4861-b5a0-8b73dce7885f,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-b7c053da-36e0-4dc0-891e-b2964ec20459,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-adc4c3f1-79ee-4912-80e2-6ab92dc6ccb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-960e5a38-5422-43c5-9375-5f4336d4f6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-cb35ec93-75a2-4f1e-9e53-de8999367a38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441218138-172.17.0.13-1595899476366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-fb044cc6-3208-4588-b169-01d1b0f6b19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-449db434-2bb5-4e67-bd19-9a69943b0603,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-bfdaf642-d20e-403e-b8be-64709d436f16,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-ac72fa76-679a-4274-8942-09655e10bb65,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-67b3a3ff-f693-4ce0-8534-8e1159befdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-ab6ed9ef-e6cf-4113-bb1e-1f4c4835ca3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-88a2721c-20b6-401c-a540-cc3d64c0d4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-93ae895e-67de-4fac-9e5c-2d3288e77ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441218138-172.17.0.13-1595899476366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-fb044cc6-3208-4588-b169-01d1b0f6b19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-449db434-2bb5-4e67-bd19-9a69943b0603,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-bfdaf642-d20e-403e-b8be-64709d436f16,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-ac72fa76-679a-4274-8942-09655e10bb65,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-67b3a3ff-f693-4ce0-8534-8e1159befdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-ab6ed9ef-e6cf-4113-bb1e-1f4c4835ca3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-88a2721c-20b6-401c-a540-cc3d64c0d4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-93ae895e-67de-4fac-9e5c-2d3288e77ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058750556-172.17.0.13-1595899555376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35825,DS-6d7b846b-3325-4e53-952d-0ef69dc5f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-7429cf0c-ead3-4d6f-8dd9-281d1ba97af4,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-1284cc2c-fe30-4e72-99b7-973f958185e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-5b95e3e8-9478-47a4-8711-cb10efc1cfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-99c48d76-316b-4869-97d8-ceb646d2dd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-80ca8c7c-5574-41df-bb50-006f17ca543c,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-a0f28501-beb5-49fb-bc4c-84eadcb6a3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-5f2d8897-fd8a-46a4-a645-196d993b545a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1058750556-172.17.0.13-1595899555376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35825,DS-6d7b846b-3325-4e53-952d-0ef69dc5f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-7429cf0c-ead3-4d6f-8dd9-281d1ba97af4,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-1284cc2c-fe30-4e72-99b7-973f958185e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-5b95e3e8-9478-47a4-8711-cb10efc1cfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-99c48d76-316b-4869-97d8-ceb646d2dd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-80ca8c7c-5574-41df-bb50-006f17ca543c,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-a0f28501-beb5-49fb-bc4c-84eadcb6a3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-5f2d8897-fd8a-46a4-a645-196d993b545a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603625543-172.17.0.13-1595899866563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38018,DS-24c1dbab-1ffd-4ab7-b71c-f198bf6d0162,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-2a647780-ffcf-4d51-bd33-1978b8b4fd42,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-1a211342-e010-4e31-ae0e-9a82d3aa74b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-05b7c530-8f25-4a95-99a0-d0765da15c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-c3e72647-2c7a-4ce5-b35c-e6129f48d1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-15e196c2-5cd2-45e7-836d-1ad850e49c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-e8640329-f395-496b-bda3-4f0f5c9e3735,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-612d087f-cf6e-45e5-84a0-0d5ace1c9d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603625543-172.17.0.13-1595899866563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38018,DS-24c1dbab-1ffd-4ab7-b71c-f198bf6d0162,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-2a647780-ffcf-4d51-bd33-1978b8b4fd42,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-1a211342-e010-4e31-ae0e-9a82d3aa74b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-05b7c530-8f25-4a95-99a0-d0765da15c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-c3e72647-2c7a-4ce5-b35c-e6129f48d1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-15e196c2-5cd2-45e7-836d-1ad850e49c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-e8640329-f395-496b-bda3-4f0f5c9e3735,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-612d087f-cf6e-45e5-84a0-0d5ace1c9d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550121130-172.17.0.13-1595900127260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40818,DS-2c682af9-226d-46f4-8261-68fe46063abe,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-be31018d-446b-4ca2-908f-477c96f51417,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-5269771d-53e1-47f7-b0ad-1dcf5561a83e,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-a55fb630-a533-44fb-bead-0dd3bbb7560b,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-1a6505f9-1864-45a1-af93-e0ac436ddf16,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-91e2fb37-af95-49eb-b5fd-18c56874ba7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-fdabf614-b24c-407c-84b1-fb014ce89ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-e2afb876-e623-416a-8a2c-9d8fbc3fc286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-550121130-172.17.0.13-1595900127260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40818,DS-2c682af9-226d-46f4-8261-68fe46063abe,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-be31018d-446b-4ca2-908f-477c96f51417,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-5269771d-53e1-47f7-b0ad-1dcf5561a83e,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-a55fb630-a533-44fb-bead-0dd3bbb7560b,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-1a6505f9-1864-45a1-af93-e0ac436ddf16,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-91e2fb37-af95-49eb-b5fd-18c56874ba7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-fdabf614-b24c-407c-84b1-fb014ce89ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-e2afb876-e623-416a-8a2c-9d8fbc3fc286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-185469607-172.17.0.13-1595900814676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43014,DS-f9123806-df91-4800-a3b1-c101f8cd8ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-799badf5-a6ac-4f88-b15a-70c56eded3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-cd4e7ce5-20f8-49fd-9351-066a62520c87,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-2bc7e3a7-79fc-4ac3-a473-6fac812620f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-293a7a53-72f5-4290-8dc1-92e5d7814b02,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-ceac49b1-80cf-4d91-aeed-d85051e8c44f,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-a38971a9-fa17-4020-82d2-6358516810f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-a69affda-892a-4056-9e42-6eda28205a01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-185469607-172.17.0.13-1595900814676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43014,DS-f9123806-df91-4800-a3b1-c101f8cd8ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-799badf5-a6ac-4f88-b15a-70c56eded3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-cd4e7ce5-20f8-49fd-9351-066a62520c87,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-2bc7e3a7-79fc-4ac3-a473-6fac812620f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-293a7a53-72f5-4290-8dc1-92e5d7814b02,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-ceac49b1-80cf-4d91-aeed-d85051e8c44f,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-a38971a9-fa17-4020-82d2-6358516810f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-a69affda-892a-4056-9e42-6eda28205a01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311166136-172.17.0.13-1595901622628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46414,DS-43113ad5-f745-4813-b7bd-3bd7dc894b24,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-75692745-1e9d-4df3-8ff9-f80ce3f7e6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-edf98dbb-a35e-4268-9f1b-09785e26cf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-637d28e1-5bb4-4bd0-83ed-91d160016690,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-a5cee3ca-9cbb-4a17-93e9-83365d387080,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-c71a5cbf-d06a-4877-9c1a-4ab2e173a439,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-0b6e6e90-afa5-4855-b2d1-73a0b296ae8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-e27f697a-f135-4fd1-b140-14791256ee1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311166136-172.17.0.13-1595901622628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46414,DS-43113ad5-f745-4813-b7bd-3bd7dc894b24,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-75692745-1e9d-4df3-8ff9-f80ce3f7e6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39410,DS-edf98dbb-a35e-4268-9f1b-09785e26cf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-637d28e1-5bb4-4bd0-83ed-91d160016690,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-a5cee3ca-9cbb-4a17-93e9-83365d387080,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-c71a5cbf-d06a-4877-9c1a-4ab2e173a439,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-0b6e6e90-afa5-4855-b2d1-73a0b296ae8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-e27f697a-f135-4fd1-b140-14791256ee1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5185
