reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369676836-172.17.0.13-1595538549308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44133,DS-6e40e656-3c7c-4d38-9475-99d1d4fc2aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-7a26f0af-3bb7-4b20-8117-dd557a1536cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-9291e8c7-28df-40c2-97be-fb68030d7949,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-7b3fae80-0d3f-4c0b-9cb6-24383a192cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-3fa3f6f9-b526-42c3-b182-27a90b4ebb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-7808e93d-a8f7-4d07-87dc-b765b0ff3b60,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-9d839dc3-680b-4ebf-9a35-9b3b874f61c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-8cbe9e16-1bc3-46c0-8053-8de54831a24e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369676836-172.17.0.13-1595538549308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44133,DS-6e40e656-3c7c-4d38-9475-99d1d4fc2aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-7a26f0af-3bb7-4b20-8117-dd557a1536cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-9291e8c7-28df-40c2-97be-fb68030d7949,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-7b3fae80-0d3f-4c0b-9cb6-24383a192cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-3fa3f6f9-b526-42c3-b182-27a90b4ebb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-7808e93d-a8f7-4d07-87dc-b765b0ff3b60,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-9d839dc3-680b-4ebf-9a35-9b3b874f61c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-8cbe9e16-1bc3-46c0-8053-8de54831a24e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773683384-172.17.0.13-1595538644482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-ffd5a4c7-6f23-49f6-844f-1ba1215d357d,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-7176f8f1-1afe-48e6-adc2-771a450b0abe,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-f7757bc4-04bf-4dbb-96e5-4ea612cd8135,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-25a12a56-b443-460d-988f-d77aa5d38736,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-61f90519-8a10-4048-b092-8c24b96bbdba,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-b24b5801-5c06-45c7-881a-c8c109ab8ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-33393348-43c2-488c-95c4-aa98e9557180,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-c9f1d91e-3409-4833-8448-e607c8fb5bfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773683384-172.17.0.13-1595538644482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-ffd5a4c7-6f23-49f6-844f-1ba1215d357d,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-7176f8f1-1afe-48e6-adc2-771a450b0abe,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-f7757bc4-04bf-4dbb-96e5-4ea612cd8135,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-25a12a56-b443-460d-988f-d77aa5d38736,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-61f90519-8a10-4048-b092-8c24b96bbdba,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-b24b5801-5c06-45c7-881a-c8c109ab8ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-33393348-43c2-488c-95c4-aa98e9557180,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-c9f1d91e-3409-4833-8448-e607c8fb5bfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1514577620-172.17.0.13-1595538738183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44829,DS-ec40f39b-8032-4374-a0b2-e44483748f60,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-e5946388-1fd1-4563-bd93-6018d3dc0fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-87af525c-dcdb-4df9-8847-8d174d8511bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-5be13ac2-4b07-42c1-ab88-4b2f241c2054,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-013ccec7-2e65-415f-ac4d-7fbf5265e676,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-1ed0f421-f307-456d-8867-822a63627b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-be5662c9-0900-4564-875b-e210811c97b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-e05a0bce-c926-47d0-8548-979b46fb9665,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1514577620-172.17.0.13-1595538738183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44829,DS-ec40f39b-8032-4374-a0b2-e44483748f60,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-e5946388-1fd1-4563-bd93-6018d3dc0fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-87af525c-dcdb-4df9-8847-8d174d8511bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-5be13ac2-4b07-42c1-ab88-4b2f241c2054,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-013ccec7-2e65-415f-ac4d-7fbf5265e676,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-1ed0f421-f307-456d-8867-822a63627b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-be5662c9-0900-4564-875b-e210811c97b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-e05a0bce-c926-47d0-8548-979b46fb9665,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1390736217-172.17.0.13-1595539465196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-0963ad09-4db4-4e87-9211-c07232960980,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-a7431d17-2abc-45bb-a617-b9cfab365858,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-0182944a-80fa-45f6-af3c-2031bee2bea3,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-95eb8e1f-9442-40d5-8fc0-bcaa104ebbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-8b260d67-b1d8-44ee-ba0c-589ebda62ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-971cefee-642d-4923-a3bc-3c5c439122b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-30ca3f31-37b9-4857-a999-21965f4d7016,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-5d9c798d-f170-4d61-8044-29c4b472be92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1390736217-172.17.0.13-1595539465196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-0963ad09-4db4-4e87-9211-c07232960980,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-a7431d17-2abc-45bb-a617-b9cfab365858,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-0182944a-80fa-45f6-af3c-2031bee2bea3,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-95eb8e1f-9442-40d5-8fc0-bcaa104ebbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-8b260d67-b1d8-44ee-ba0c-589ebda62ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-971cefee-642d-4923-a3bc-3c5c439122b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-30ca3f31-37b9-4857-a999-21965f4d7016,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-5d9c798d-f170-4d61-8044-29c4b472be92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12192848-172.17.0.13-1595540230142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36638,DS-2b9b5b00-db18-4b23-a06e-0f6828054658,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-88ddd444-f95f-4464-91d2-a7a7f260b63a,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d55b448b-bad9-42d1-a5d4-b29bfd2a87cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-81db949a-620c-4e55-8cf1-10e385950011,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-20691827-6510-41a5-8fb6-9272b6140085,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-fe6dd87b-b6a2-4da1-b9db-0e4ec37c50ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-fef0b921-da17-4696-9867-e84616bd9513,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-2862ae73-39d5-4afb-b32c-16ec44936271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12192848-172.17.0.13-1595540230142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36638,DS-2b9b5b00-db18-4b23-a06e-0f6828054658,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-88ddd444-f95f-4464-91d2-a7a7f260b63a,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-d55b448b-bad9-42d1-a5d4-b29bfd2a87cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-81db949a-620c-4e55-8cf1-10e385950011,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-20691827-6510-41a5-8fb6-9272b6140085,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-fe6dd87b-b6a2-4da1-b9db-0e4ec37c50ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-fef0b921-da17-4696-9867-e84616bd9513,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-2862ae73-39d5-4afb-b32c-16ec44936271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1445769180-172.17.0.13-1595540387927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36140,DS-bebcaae5-2bbe-4288-9ccc-d66ca645aec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-4c921c1f-2586-4e4e-8012-6de4bd18a81c,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-63562ec4-0904-44db-ab51-fa9dce933391,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-a2c08f1e-58f7-440d-a4f6-ceb05f3c8889,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-e282316a-a0f2-43e7-a772-d72a7e477000,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-4c0df7ed-3a96-4eba-946d-01dd945d906c,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-c7a3a148-7e2c-4054-b486-5adeb79abb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-4adb63e6-28f2-4421-be3d-7eb6070b14fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1445769180-172.17.0.13-1595540387927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36140,DS-bebcaae5-2bbe-4288-9ccc-d66ca645aec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-4c921c1f-2586-4e4e-8012-6de4bd18a81c,DISK], DatanodeInfoWithStorage[127.0.0.1:46523,DS-63562ec4-0904-44db-ab51-fa9dce933391,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-a2c08f1e-58f7-440d-a4f6-ceb05f3c8889,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-e282316a-a0f2-43e7-a772-d72a7e477000,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-4c0df7ed-3a96-4eba-946d-01dd945d906c,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-c7a3a148-7e2c-4054-b486-5adeb79abb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-4adb63e6-28f2-4421-be3d-7eb6070b14fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1150358217-172.17.0.13-1595541041870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44138,DS-86351a0d-07cf-478c-86d3-924304e330a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-1f06c526-fe84-4cd0-b04b-092844ff0c44,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-35c7e22b-02b6-4821-9db7-535db42bfcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-3c30175c-1792-42ba-92c4-18847e4d5651,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-753a550d-2eaa-450c-95ad-47e4b9bcc36b,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-78500a2c-1f84-4a9a-889e-48970142d059,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-f481a6c3-f654-4167-9ed8-c97330f657da,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-016893b5-8edb-46b1-a2e5-421e86a664ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1150358217-172.17.0.13-1595541041870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44138,DS-86351a0d-07cf-478c-86d3-924304e330a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-1f06c526-fe84-4cd0-b04b-092844ff0c44,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-35c7e22b-02b6-4821-9db7-535db42bfcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-3c30175c-1792-42ba-92c4-18847e4d5651,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-753a550d-2eaa-450c-95ad-47e4b9bcc36b,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-78500a2c-1f84-4a9a-889e-48970142d059,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-f481a6c3-f654-4167-9ed8-c97330f657da,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-016893b5-8edb-46b1-a2e5-421e86a664ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817033624-172.17.0.13-1595541191715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42964,DS-f6c14ae8-b8b4-4468-b3d6-d23761169901,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-35ac0941-8d38-4d2c-b952-2fef27782ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-cc2e1dcf-da58-44df-9bb8-03fc5e025020,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-ec724283-c4d0-429f-9626-3290e11d2fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-791796ef-ae74-4a01-be3b-4d380666d659,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-55a665ef-f687-41ab-af31-a41c0341afd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-240c6c4a-25b4-4211-a494-95dce48ef4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-6c18fc44-6d22-427e-b05b-caef4af9d631,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817033624-172.17.0.13-1595541191715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42964,DS-f6c14ae8-b8b4-4468-b3d6-d23761169901,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-35ac0941-8d38-4d2c-b952-2fef27782ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-cc2e1dcf-da58-44df-9bb8-03fc5e025020,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-ec724283-c4d0-429f-9626-3290e11d2fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-791796ef-ae74-4a01-be3b-4d380666d659,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-55a665ef-f687-41ab-af31-a41c0341afd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-240c6c4a-25b4-4211-a494-95dce48ef4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-6c18fc44-6d22-427e-b05b-caef4af9d631,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114816938-172.17.0.13-1595541288371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41590,DS-be8622f6-0327-4ee7-95c3-428b31f960e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-67239a05-e059-42eb-8d85-d3ff6a6cb45b,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-5570dd6a-9134-432f-b4b1-0da5e6616d32,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-553a39e1-4c6d-4536-b102-9f06c34cc319,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-0ad502b8-ccbd-4c69-b803-9754011a799a,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-25380d8f-8a60-4c7c-bab2-6df8c3095e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-8a798755-3290-4598-994c-e838b5f36c78,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-223e9d3b-f44f-4cd0-8dc5-2fb63ef44ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114816938-172.17.0.13-1595541288371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41590,DS-be8622f6-0327-4ee7-95c3-428b31f960e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-67239a05-e059-42eb-8d85-d3ff6a6cb45b,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-5570dd6a-9134-432f-b4b1-0da5e6616d32,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-553a39e1-4c6d-4536-b102-9f06c34cc319,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-0ad502b8-ccbd-4c69-b803-9754011a799a,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-25380d8f-8a60-4c7c-bab2-6df8c3095e84,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-8a798755-3290-4598-994c-e838b5f36c78,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-223e9d3b-f44f-4cd0-8dc5-2fb63ef44ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699978799-172.17.0.13-1595541324787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33018,DS-d8e5ac5d-d2c9-4cbf-96cc-dda7b7d3fcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-89ab974a-a597-4272-836a-1c28c9ec4412,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-d01bc85f-c7f7-4b79-811c-c784ed7acc55,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-5aa3ad76-f936-465a-84c5-63dde4570821,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-56c522d9-d196-4c07-bcb6-3d21f61be929,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-ad6733df-e4ad-4dac-9ed3-eae20b52ffca,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-58a31389-d6e6-4d11-9e95-bfbb90f35fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-8b0ec9a3-e2d3-40c2-87ba-fc8d480a3b60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699978799-172.17.0.13-1595541324787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33018,DS-d8e5ac5d-d2c9-4cbf-96cc-dda7b7d3fcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-89ab974a-a597-4272-836a-1c28c9ec4412,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-d01bc85f-c7f7-4b79-811c-c784ed7acc55,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-5aa3ad76-f936-465a-84c5-63dde4570821,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-56c522d9-d196-4c07-bcb6-3d21f61be929,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-ad6733df-e4ad-4dac-9ed3-eae20b52ffca,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-58a31389-d6e6-4d11-9e95-bfbb90f35fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-8b0ec9a3-e2d3-40c2-87ba-fc8d480a3b60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-309353043-172.17.0.13-1595542500017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44091,DS-a66c29d6-ac91-4510-8172-d08e250a763d,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-0725f583-ae70-4480-b96f-17faff095567,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-4c58e6ba-bab4-4f80-a361-e7d33f91b250,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-7b25a719-1a35-48dc-b758-5ece470ee2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-6ef192ae-f5fb-46e7-9916-b58ca8a6a331,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-ebb64b71-97d9-422b-b15e-4402d0e0e0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-d45ba0b8-50ea-4d3e-bae2-64b683af9c49,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-2c7dedbd-436c-4f85-90c4-e157e97a5bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-309353043-172.17.0.13-1595542500017:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44091,DS-a66c29d6-ac91-4510-8172-d08e250a763d,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-0725f583-ae70-4480-b96f-17faff095567,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-4c58e6ba-bab4-4f80-a361-e7d33f91b250,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-7b25a719-1a35-48dc-b758-5ece470ee2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-6ef192ae-f5fb-46e7-9916-b58ca8a6a331,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-ebb64b71-97d9-422b-b15e-4402d0e0e0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-d45ba0b8-50ea-4d3e-bae2-64b683af9c49,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-2c7dedbd-436c-4f85-90c4-e157e97a5bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131932934-172.17.0.13-1595542757937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35426,DS-af417937-b69b-4b17-ac05-7d5c91176419,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-d535d3ce-3723-4546-be1f-5624d4dadf92,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-8d921799-dac6-47b4-b03c-311b6bafa4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-625a9ba9-39f4-4149-93f8-8a47ffbf79e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-44bc793b-1b9d-4608-baef-fd7c767b1fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-4324bd41-bcb8-4e3a-838c-3747f365ce0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-13916f8c-d731-4fe0-b0b9-faa0ca364da8,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-f9b745d0-6379-4d2c-964d-fff8e39b0ef9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131932934-172.17.0.13-1595542757937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35426,DS-af417937-b69b-4b17-ac05-7d5c91176419,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-d535d3ce-3723-4546-be1f-5624d4dadf92,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-8d921799-dac6-47b4-b03c-311b6bafa4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-625a9ba9-39f4-4149-93f8-8a47ffbf79e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-44bc793b-1b9d-4608-baef-fd7c767b1fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-4324bd41-bcb8-4e3a-838c-3747f365ce0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-13916f8c-d731-4fe0-b0b9-faa0ca364da8,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-f9b745d0-6379-4d2c-964d-fff8e39b0ef9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1813726714-172.17.0.13-1595542984371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37668,DS-85fb10dc-5f12-410e-b27d-9297ad985dad,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-db36848d-c452-4392-be2f-0f81cd124dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-6209ed7e-8173-4f15-9692-6b72624bbac6,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-d11904c5-6032-4959-93d1-abf5a4a81ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-108c1035-f54c-4816-bcb4-370222126f86,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-7d08476a-047d-42cb-9f50-0c4acf71c46e,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-bdb684a1-ad14-44d3-a177-f6d1425999f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-a3a05494-a7d2-4a69-a67a-091eabedd3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1813726714-172.17.0.13-1595542984371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37668,DS-85fb10dc-5f12-410e-b27d-9297ad985dad,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-db36848d-c452-4392-be2f-0f81cd124dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-6209ed7e-8173-4f15-9692-6b72624bbac6,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-d11904c5-6032-4959-93d1-abf5a4a81ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-108c1035-f54c-4816-bcb4-370222126f86,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-7d08476a-047d-42cb-9f50-0c4acf71c46e,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-bdb684a1-ad14-44d3-a177-f6d1425999f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-a3a05494-a7d2-4a69-a67a-091eabedd3dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757687164-172.17.0.13-1595543108204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35570,DS-8f9c98e1-2247-4b13-b9f6-b4ed1381bdad,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-0ca6c021-681d-495f-a191-e0ed358bc7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-225a6307-8e04-47e3-9e85-85b4cc2fcdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-70212442-6e10-4444-86c7-83db1e83939b,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-ff83f692-a739-4602-a115-f54942bb8ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-df771893-b6a1-4d63-8241-7768bfe2598e,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-f97b71c5-5f07-4f05-bcb4-b68d20ad5335,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-024ac089-5647-415d-9519-96fa3c04fa0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757687164-172.17.0.13-1595543108204:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35570,DS-8f9c98e1-2247-4b13-b9f6-b4ed1381bdad,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-0ca6c021-681d-495f-a191-e0ed358bc7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-225a6307-8e04-47e3-9e85-85b4cc2fcdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-70212442-6e10-4444-86c7-83db1e83939b,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-ff83f692-a739-4602-a115-f54942bb8ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-df771893-b6a1-4d63-8241-7768bfe2598e,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-f97b71c5-5f07-4f05-bcb4-b68d20ad5335,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-024ac089-5647-415d-9519-96fa3c04fa0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449552736-172.17.0.13-1595543795439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37302,DS-c7615d74-4980-4ea5-bca8-ecdf9ce3c7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-a89b3752-3201-4615-82e3-034d7334ad85,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-d8216f97-56c9-46db-ae19-83d4c2680c51,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-0c077ddf-8218-4bfa-9c9e-aa9c3c6b0956,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-cfc20154-71c8-4749-9661-eaec7d6e038c,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-92c83757-f47a-4b6f-aa7b-3b5e6fec7912,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-790a8cb0-1a05-4083-8e65-6e6854f8bc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-21a5b67b-adf1-43ed-a3da-9449bdf1afb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449552736-172.17.0.13-1595543795439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37302,DS-c7615d74-4980-4ea5-bca8-ecdf9ce3c7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-a89b3752-3201-4615-82e3-034d7334ad85,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-d8216f97-56c9-46db-ae19-83d4c2680c51,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-0c077ddf-8218-4bfa-9c9e-aa9c3c6b0956,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-cfc20154-71c8-4749-9661-eaec7d6e038c,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-92c83757-f47a-4b6f-aa7b-3b5e6fec7912,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-790a8cb0-1a05-4083-8e65-6e6854f8bc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-21a5b67b-adf1-43ed-a3da-9449bdf1afb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5397
