reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350016296-172.17.0.18-1596036342951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41023,DS-ef05df47-5b65-4d5d-8e4d-d14133486101,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-e9e0c2ad-44d4-4753-add7-b20b946355ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-0b5420a3-4a24-4def-971c-af18f86513b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-0acbdcb0-16ef-4657-b5ab-f5c9005cb77c,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-2a8794d6-ec60-4f26-ae05-03ba7f32384a,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-0347fcfc-98df-4c27-9e79-594130e58d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-ba5548cd-8cc0-48f2-9986-8a43fd0c2b89,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-1b19b453-adb3-42e8-9848-40395e1f42f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350016296-172.17.0.18-1596036342951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41023,DS-ef05df47-5b65-4d5d-8e4d-d14133486101,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-e9e0c2ad-44d4-4753-add7-b20b946355ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-0b5420a3-4a24-4def-971c-af18f86513b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-0acbdcb0-16ef-4657-b5ab-f5c9005cb77c,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-2a8794d6-ec60-4f26-ae05-03ba7f32384a,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-0347fcfc-98df-4c27-9e79-594130e58d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-ba5548cd-8cc0-48f2-9986-8a43fd0c2b89,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-1b19b453-adb3-42e8-9848-40395e1f42f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-786249301-172.17.0.18-1596036962039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34049,DS-72ccb777-a8aa-4f84-bb4c-f5eeee24b7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-a2e04e64-54c6-421a-990e-3eac9b14b5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-c0f92acc-a0a0-415c-aa23-69162208b5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-cb0ac2f5-9553-419e-8828-49413111b152,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-fc56a222-d817-4f6e-a0fc-b756181ffce9,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-9081f9c3-6dc9-46da-9763-3281239b1c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-58ff1904-0283-41ab-913a-33018123e3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-95110735-71e5-4525-9886-adadb3281329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-786249301-172.17.0.18-1596036962039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34049,DS-72ccb777-a8aa-4f84-bb4c-f5eeee24b7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-a2e04e64-54c6-421a-990e-3eac9b14b5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-c0f92acc-a0a0-415c-aa23-69162208b5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-cb0ac2f5-9553-419e-8828-49413111b152,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-fc56a222-d817-4f6e-a0fc-b756181ffce9,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-9081f9c3-6dc9-46da-9763-3281239b1c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-58ff1904-0283-41ab-913a-33018123e3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-95110735-71e5-4525-9886-adadb3281329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305735913-172.17.0.18-1596037113182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45484,DS-a3ef6b1a-fc6d-4ce4-be0d-35b3d4adbf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-18ba6714-3697-4948-aec2-bf69abd6b653,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-1c540d67-a452-4618-be3e-5b8d3d811b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-675f742e-b6b1-44ce-a9bb-02a4307dd243,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-765a6ce5-fc56-4410-92a2-d8f7d773fb72,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-e5d9993a-76ce-4746-9d72-87fa53c9b6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-2fa367bb-aa2b-4cfb-85c0-e653cad96e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-221816ad-2acc-411c-b0fd-fa7279746b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305735913-172.17.0.18-1596037113182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45484,DS-a3ef6b1a-fc6d-4ce4-be0d-35b3d4adbf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-18ba6714-3697-4948-aec2-bf69abd6b653,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-1c540d67-a452-4618-be3e-5b8d3d811b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-675f742e-b6b1-44ce-a9bb-02a4307dd243,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-765a6ce5-fc56-4410-92a2-d8f7d773fb72,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-e5d9993a-76ce-4746-9d72-87fa53c9b6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-2fa367bb-aa2b-4cfb-85c0-e653cad96e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-221816ad-2acc-411c-b0fd-fa7279746b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491444198-172.17.0.18-1596037395944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45926,DS-d2df7747-190d-4288-9c5f-5f94e7c30664,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-8be28ade-ac18-4346-be92-5a8fd351edfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-d5460e6f-f730-4f9d-bfd3-f1f695958430,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-d097ec46-8101-49e7-9b67-88a8aee38612,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-4da5f642-c77e-4ed6-8b56-a942b91b41a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-b8441117-eacb-4d21-ae81-5d5ffd933ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-6f70e9ee-1b55-4caf-a544-d6e12df49f20,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-d839ed35-d46c-4497-aa28-dfcc119a96cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491444198-172.17.0.18-1596037395944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45926,DS-d2df7747-190d-4288-9c5f-5f94e7c30664,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-8be28ade-ac18-4346-be92-5a8fd351edfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-d5460e6f-f730-4f9d-bfd3-f1f695958430,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-d097ec46-8101-49e7-9b67-88a8aee38612,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-4da5f642-c77e-4ed6-8b56-a942b91b41a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-b8441117-eacb-4d21-ae81-5d5ffd933ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-6f70e9ee-1b55-4caf-a544-d6e12df49f20,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-d839ed35-d46c-4497-aa28-dfcc119a96cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750945991-172.17.0.18-1596037475996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42544,DS-8d0d24e4-5448-4393-9e8b-77000408411f,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-4d392134-1f3e-40f2-8037-2318e3ab165f,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-08a1a1b9-dc57-42c1-b549-34dc2837f109,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-3302d2e7-7548-433a-99d3-a122a0587020,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-04518033-65d2-42a9-9f69-5d89ed01f53a,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-5a2fbadb-4cfe-403c-bc11-204357c2a317,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-54452723-36fb-4a6d-8037-f0277a64bf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-0fadaf44-975a-4201-9a11-caf8ccff0c6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750945991-172.17.0.18-1596037475996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42544,DS-8d0d24e4-5448-4393-9e8b-77000408411f,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-4d392134-1f3e-40f2-8037-2318e3ab165f,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-08a1a1b9-dc57-42c1-b549-34dc2837f109,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-3302d2e7-7548-433a-99d3-a122a0587020,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-04518033-65d2-42a9-9f69-5d89ed01f53a,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-5a2fbadb-4cfe-403c-bc11-204357c2a317,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-54452723-36fb-4a6d-8037-f0277a64bf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-0fadaf44-975a-4201-9a11-caf8ccff0c6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212466414-172.17.0.18-1596037562841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38459,DS-eb3c2e11-dde4-41a2-bc61-f6c9b317603b,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-50e4e880-9e55-49be-90d9-34f3ef1827b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-b10ae09f-b348-4f18-84a3-34c212238620,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-5f2793c1-c6b3-46de-92a5-ee1fb22992ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-2e131fa3-2378-451c-a4c4-cfe1c2a2a347,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-dc0286d7-e363-4c92-83b2-5ca47f953f30,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-b2b6b0b2-f087-40b1-88ee-5c0f5e1513de,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-335ff600-9a73-42a4-ab0a-92c7d499ef3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212466414-172.17.0.18-1596037562841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38459,DS-eb3c2e11-dde4-41a2-bc61-f6c9b317603b,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-50e4e880-9e55-49be-90d9-34f3ef1827b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-b10ae09f-b348-4f18-84a3-34c212238620,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-5f2793c1-c6b3-46de-92a5-ee1fb22992ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-2e131fa3-2378-451c-a4c4-cfe1c2a2a347,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-dc0286d7-e363-4c92-83b2-5ca47f953f30,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-b2b6b0b2-f087-40b1-88ee-5c0f5e1513de,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-335ff600-9a73-42a4-ab0a-92c7d499ef3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100817312-172.17.0.18-1596037883465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35819,DS-42bf0413-c7d1-4c05-92d9-bc02dbd7572c,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-0216f2ec-822a-4e1d-ba24-ed352323148a,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-4b26d277-cff4-484a-8ec9-a1c293a5ed21,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-70e663b3-296b-4ee3-8827-1e591d1d763c,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-3370139f-7df6-4293-8936-dbcecd240f22,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-417b6b1d-1d05-486a-8552-fae956f657f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-2852ffd8-de17-4952-a0e9-3c208ad5bb64,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-2ed38373-aa67-42c8-85aa-e99229903779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100817312-172.17.0.18-1596037883465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35819,DS-42bf0413-c7d1-4c05-92d9-bc02dbd7572c,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-0216f2ec-822a-4e1d-ba24-ed352323148a,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-4b26d277-cff4-484a-8ec9-a1c293a5ed21,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-70e663b3-296b-4ee3-8827-1e591d1d763c,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-3370139f-7df6-4293-8936-dbcecd240f22,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-417b6b1d-1d05-486a-8552-fae956f657f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-2852ffd8-de17-4952-a0e9-3c208ad5bb64,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-2ed38373-aa67-42c8-85aa-e99229903779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-53278971-172.17.0.18-1596038088090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-38b0480b-0e0b-4fc9-8660-30e4d22f445b,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-c78e4dce-4cdd-4041-8449-e3d281947c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-c59fab21-aa14-4f7b-b117-03bbd93378f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-e45e3af2-c9d9-490d-b3f2-432fde1ce9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-adfbbfdb-8e1b-4eb4-a9bd-334446c3045a,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-a0f2aeb1-56fe-451e-bf62-f4678d079e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-42f0bad7-760b-4bae-8dd5-374dc208d724,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-a66a183a-fbe2-4850-bf49-293d33739559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-53278971-172.17.0.18-1596038088090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-38b0480b-0e0b-4fc9-8660-30e4d22f445b,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-c78e4dce-4cdd-4041-8449-e3d281947c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-c59fab21-aa14-4f7b-b117-03bbd93378f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-e45e3af2-c9d9-490d-b3f2-432fde1ce9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-adfbbfdb-8e1b-4eb4-a9bd-334446c3045a,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-a0f2aeb1-56fe-451e-bf62-f4678d079e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-42f0bad7-760b-4bae-8dd5-374dc208d724,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-a66a183a-fbe2-4850-bf49-293d33739559,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671558487-172.17.0.18-1596038603572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38767,DS-62cc302e-f074-4c0e-9803-b720158107e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-a251894b-5081-43ee-95b5-963584533d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-2dc963bc-a11e-4e8d-b25b-d1702044f76c,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-bde07ea0-1dd6-42bc-8122-a6a159c7e544,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-dd63baa1-e5bc-4c26-bb0f-684ad0d88b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-4587e064-89be-4259-9008-0757014368e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-1dcff15f-a81d-4555-bdd3-5ecb9d6aea21,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-ea269935-1f2f-4025-9d79-2ae5e6966f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1671558487-172.17.0.18-1596038603572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38767,DS-62cc302e-f074-4c0e-9803-b720158107e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-a251894b-5081-43ee-95b5-963584533d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-2dc963bc-a11e-4e8d-b25b-d1702044f76c,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-bde07ea0-1dd6-42bc-8122-a6a159c7e544,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-dd63baa1-e5bc-4c26-bb0f-684ad0d88b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-4587e064-89be-4259-9008-0757014368e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-1dcff15f-a81d-4555-bdd3-5ecb9d6aea21,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-ea269935-1f2f-4025-9d79-2ae5e6966f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529212949-172.17.0.18-1596038776405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39475,DS-6c10a773-8fe5-4978-b63e-7d37ac4ca918,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-3fc89ea3-8df1-49cc-9abe-bf842486baa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-1fb48bc5-a482-453e-87ab-24c1d603f327,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-0f3a8017-29e5-4e9e-aba9-f63876e6d898,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-f5f6960a-48f7-4998-819b-5cbedd2844fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-11cc2f9e-14b1-4138-ad27-27a080bcc649,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-ae346517-f4d3-445b-b399-7756d17acf39,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-b055c5bb-9860-4bd2-987b-590503ebaeea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529212949-172.17.0.18-1596038776405:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39475,DS-6c10a773-8fe5-4978-b63e-7d37ac4ca918,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-3fc89ea3-8df1-49cc-9abe-bf842486baa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-1fb48bc5-a482-453e-87ab-24c1d603f327,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-0f3a8017-29e5-4e9e-aba9-f63876e6d898,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-f5f6960a-48f7-4998-819b-5cbedd2844fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-11cc2f9e-14b1-4138-ad27-27a080bcc649,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-ae346517-f4d3-445b-b399-7756d17acf39,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-b055c5bb-9860-4bd2-987b-590503ebaeea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1550364180-172.17.0.18-1596039125455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-6caeae93-928b-425c-8682-b1cc1e99894f,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-153faf73-ed2f-4ff8-a5eb-8702e53c7ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-0f2c8c49-d4ed-48cc-b4b8-57dbb7ceaffe,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-7b129e8f-5d8d-4491-ae39-66c12900acb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-263a47cd-9793-4ac5-86b9-d9a91c49f671,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-e560e957-03b0-4cac-9b68-dc2833ca81ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-f96d9f6d-aaa2-45b0-99f7-3da82c8f4121,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-780c3e6b-0ec8-4afa-b01e-4c310dedcb10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1550364180-172.17.0.18-1596039125455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-6caeae93-928b-425c-8682-b1cc1e99894f,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-153faf73-ed2f-4ff8-a5eb-8702e53c7ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-0f2c8c49-d4ed-48cc-b4b8-57dbb7ceaffe,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-7b129e8f-5d8d-4491-ae39-66c12900acb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-263a47cd-9793-4ac5-86b9-d9a91c49f671,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-e560e957-03b0-4cac-9b68-dc2833ca81ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-f96d9f6d-aaa2-45b0-99f7-3da82c8f4121,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-780c3e6b-0ec8-4afa-b01e-4c310dedcb10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1844646300-172.17.0.18-1596039222462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-626b3264-f4fc-4602-9a35-2ca780108b88,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-f59c78fc-218b-48d8-955c-7bed46bf2816,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-96817a8b-1984-41f0-8989-2a68162a6c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-52ddc05c-f67f-4dac-9d48-e653e057ce03,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-1b310e0b-123d-4047-abfb-ce79a4bee855,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-e883815b-7e82-419f-96f2-ea5b25d94a63,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-7fb60abb-dc08-4441-9452-296c67af0ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-1c09e0fa-eaa2-4195-a5cc-63b91ce2a1ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1844646300-172.17.0.18-1596039222462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43667,DS-626b3264-f4fc-4602-9a35-2ca780108b88,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-f59c78fc-218b-48d8-955c-7bed46bf2816,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-96817a8b-1984-41f0-8989-2a68162a6c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-52ddc05c-f67f-4dac-9d48-e653e057ce03,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-1b310e0b-123d-4047-abfb-ce79a4bee855,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-e883815b-7e82-419f-96f2-ea5b25d94a63,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-7fb60abb-dc08-4441-9452-296c67af0ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-1c09e0fa-eaa2-4195-a5cc-63b91ce2a1ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458775375-172.17.0.18-1596040532711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39911,DS-ba6cbe63-7cda-4fba-abc8-64d0de2a89bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-1b735eb4-7530-449e-b516-0179e82997a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-c7aa889f-b926-46f8-9497-76b157692edb,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-6579101f-f7a3-4d13-99db-01ab5111f8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-c01db9ad-3d85-439e-8def-2ae183545561,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-c53c7537-32b5-40c3-8010-e225ce5d8c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-8d4f0986-e093-412d-a381-47ab9d0c0518,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-8806f767-b446-4bec-a6e3-255adffa540a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458775375-172.17.0.18-1596040532711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39911,DS-ba6cbe63-7cda-4fba-abc8-64d0de2a89bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-1b735eb4-7530-449e-b516-0179e82997a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-c7aa889f-b926-46f8-9497-76b157692edb,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-6579101f-f7a3-4d13-99db-01ab5111f8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-c01db9ad-3d85-439e-8def-2ae183545561,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-c53c7537-32b5-40c3-8010-e225ce5d8c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-8d4f0986-e093-412d-a381-47ab9d0c0518,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-8806f767-b446-4bec-a6e3-255adffa540a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220227971-172.17.0.18-1596040700751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33637,DS-33f0e15e-174c-41a8-89c2-09590687e70b,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-ade57185-ca7b-4ef6-a383-48cc9d369d78,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-bd36fda0-10fe-4083-bd1a-e61678e50b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-1b2517a4-ea12-4a0c-91e9-465e69d5b9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-f3ca72a9-1d07-49ac-8407-df9013d83a55,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-6abf0ccc-bd99-4bf9-a13e-3aee4196bac0,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-eb2c88b8-8cb2-467e-8bb1-b4e743c76d84,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-3fd4d23f-15c1-4dee-b2db-7b2870befbcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220227971-172.17.0.18-1596040700751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33637,DS-33f0e15e-174c-41a8-89c2-09590687e70b,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-ade57185-ca7b-4ef6-a383-48cc9d369d78,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-bd36fda0-10fe-4083-bd1a-e61678e50b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-1b2517a4-ea12-4a0c-91e9-465e69d5b9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-f3ca72a9-1d07-49ac-8407-df9013d83a55,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-6abf0ccc-bd99-4bf9-a13e-3aee4196bac0,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-eb2c88b8-8cb2-467e-8bb1-b4e743c76d84,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-3fd4d23f-15c1-4dee-b2db-7b2870befbcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-242210064-172.17.0.18-1596041502530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32849,DS-b9e35c2e-83c7-4996-974f-a2be4912f302,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-4c14a871-c49f-48d7-a9ca-4698d26d451d,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-18b2ecb5-b59d-45f7-9253-f111db7078db,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-8972da62-7572-4989-984d-ef501ecea040,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-1a18a710-cad6-4a49-a8d5-4610717f22e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-32e4424d-f0eb-4275-9063-2a14a6b2ac78,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-7761e6b6-9aea-4bbf-bd16-c1f0f564e377,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-dea18528-bdb8-4b4e-bfb4-0aa99e1605d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-242210064-172.17.0.18-1596041502530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32849,DS-b9e35c2e-83c7-4996-974f-a2be4912f302,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-4c14a871-c49f-48d7-a9ca-4698d26d451d,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-18b2ecb5-b59d-45f7-9253-f111db7078db,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-8972da62-7572-4989-984d-ef501ecea040,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-1a18a710-cad6-4a49-a8d5-4610717f22e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-32e4424d-f0eb-4275-9063-2a14a6b2ac78,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-7761e6b6-9aea-4bbf-bd16-c1f0f564e377,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-dea18528-bdb8-4b4e-bfb4-0aa99e1605d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72410688-172.17.0.18-1596041752873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36501,DS-20f6bd7b-191a-40a9-a41e-284b87b5a099,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-4b49b7f6-e294-4f8c-88f7-1da6b11b5e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-d858f97e-5f97-40c3-9d59-7d63ea2c6a89,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-66e378d7-57b7-4d72-aee2-2c6d9a01d206,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-75f5d069-3961-40d9-89e8-0385fd57c1db,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-589e9fd0-1845-4927-91d3-a01687224ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-7caeb673-a6ea-4bca-b6a8-dcc1399cd83e,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-bb17e993-e2e1-4cae-a875-f4628f2252ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72410688-172.17.0.18-1596041752873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36501,DS-20f6bd7b-191a-40a9-a41e-284b87b5a099,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-4b49b7f6-e294-4f8c-88f7-1da6b11b5e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-d858f97e-5f97-40c3-9d59-7d63ea2c6a89,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-66e378d7-57b7-4d72-aee2-2c6d9a01d206,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-75f5d069-3961-40d9-89e8-0385fd57c1db,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-589e9fd0-1845-4927-91d3-a01687224ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-7caeb673-a6ea-4bca-b6a8-dcc1399cd83e,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-bb17e993-e2e1-4cae-a875-f4628f2252ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760162481-172.17.0.18-1596041895273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33733,DS-64867111-dd03-42dc-8065-3c3c3db4312f,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-e7871372-f39d-4814-9225-de9999bb705f,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-fe008815-bd64-4516-8d0b-b082393b9f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-1364c9a9-aeb5-4291-ac82-79219b4e4cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-0875b094-749e-4e6c-a20d-a36df2330f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-f282e7f0-9d2c-4a9b-820a-170ff39df5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-58059f9d-a5a0-46a5-b1b8-ee997c3ea649,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-e5aa07ce-3af0-458a-a8c5-debcf63c57e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760162481-172.17.0.18-1596041895273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33733,DS-64867111-dd03-42dc-8065-3c3c3db4312f,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-e7871372-f39d-4814-9225-de9999bb705f,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-fe008815-bd64-4516-8d0b-b082393b9f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-1364c9a9-aeb5-4291-ac82-79219b4e4cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-0875b094-749e-4e6c-a20d-a36df2330f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-f282e7f0-9d2c-4a9b-820a-170ff39df5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-58059f9d-a5a0-46a5-b1b8-ee997c3ea649,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-e5aa07ce-3af0-458a-a8c5-debcf63c57e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-360646355-172.17.0.18-1596041976038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42221,DS-d5a6f591-855a-4b13-bc30-6e05fc78163c,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-52312acb-4492-4944-af5c-d4f5dbea935d,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-69736932-b650-46b4-ad79-af7da19ccd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-1ac2639a-4c04-4ca9-af13-009b75da2a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-9e14e1d5-129b-4b6b-9ed3-8ba294bf4519,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-5deb35c0-e30f-4a9f-9770-edcc97a69970,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-b387eebc-6c71-44e6-9cce-fb4963a51648,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-bce2fdce-d377-419e-9887-2a1cef955ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-360646355-172.17.0.18-1596041976038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42221,DS-d5a6f591-855a-4b13-bc30-6e05fc78163c,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-52312acb-4492-4944-af5c-d4f5dbea935d,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-69736932-b650-46b4-ad79-af7da19ccd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-1ac2639a-4c04-4ca9-af13-009b75da2a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-9e14e1d5-129b-4b6b-9ed3-8ba294bf4519,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-5deb35c0-e30f-4a9f-9770-edcc97a69970,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-b387eebc-6c71-44e6-9cce-fb4963a51648,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-bce2fdce-d377-419e-9887-2a1cef955ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6380
