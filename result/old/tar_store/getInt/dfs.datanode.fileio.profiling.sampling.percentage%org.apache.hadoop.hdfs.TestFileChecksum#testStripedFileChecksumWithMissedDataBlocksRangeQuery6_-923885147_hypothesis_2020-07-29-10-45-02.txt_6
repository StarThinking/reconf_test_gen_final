reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536792470-172.17.0.19-1596019624706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44116,DS-00f12587-4d4e-4307-8fc9-5eb5f0d49588,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-ae43c611-4039-404f-a3ef-8cd5b9dacd08,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-2df71618-f53b-48ed-86e8-ade922da7007,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-2c9a93fd-a835-4a6a-9029-3cab8a701ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-7c18d6b8-da65-4111-afd3-aa4d6cf51152,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-8e7ae44e-647a-48f7-bdb5-584296b73a21,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-a65783d5-104d-460a-b905-adac9081023d,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-3ad750b4-484b-4eb0-b10a-be5bfa27e5a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536792470-172.17.0.19-1596019624706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44116,DS-00f12587-4d4e-4307-8fc9-5eb5f0d49588,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-ae43c611-4039-404f-a3ef-8cd5b9dacd08,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-2df71618-f53b-48ed-86e8-ade922da7007,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-2c9a93fd-a835-4a6a-9029-3cab8a701ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-7c18d6b8-da65-4111-afd3-aa4d6cf51152,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-8e7ae44e-647a-48f7-bdb5-584296b73a21,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-a65783d5-104d-460a-b905-adac9081023d,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-3ad750b4-484b-4eb0-b10a-be5bfa27e5a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146921825-172.17.0.19-1596020020527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42223,DS-6fb4d373-ed79-4ae2-ad42-486ef3ca5c06,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-c55101c2-19f3-4176-92b2-5b799479afe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-67a3e14d-93e9-46ce-9e42-42105b3cec33,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-020f4759-bf90-418d-8080-11122e4b7b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-9260ff3c-70fd-4911-81f7-7d2737d4d50e,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-95f9e4ec-02d8-4aab-8a46-9ccc60e4232c,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-75d112fb-36f3-4a00-9735-38f3231802bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-fbc98223-cf6c-4d59-8cbb-6c52d1a98827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146921825-172.17.0.19-1596020020527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42223,DS-6fb4d373-ed79-4ae2-ad42-486ef3ca5c06,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-c55101c2-19f3-4176-92b2-5b799479afe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-67a3e14d-93e9-46ce-9e42-42105b3cec33,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-020f4759-bf90-418d-8080-11122e4b7b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-9260ff3c-70fd-4911-81f7-7d2737d4d50e,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-95f9e4ec-02d8-4aab-8a46-9ccc60e4232c,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-75d112fb-36f3-4a00-9735-38f3231802bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-fbc98223-cf6c-4d59-8cbb-6c52d1a98827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18579383-172.17.0.19-1596020098542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35179,DS-8362edcf-3ce3-4fc2-93b9-17cedb1dd6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-8080ba8d-ba3f-4e91-8481-c204a38ec113,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-4bb30bd8-b3f0-490e-961e-8d76d4ec9000,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-a0fc4abb-5f65-4998-a456-0c44c98c9144,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-42936649-da0d-4211-ac41-20fc12a36137,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-f51470f0-260a-40c8-a21a-871b78a30cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-077c4253-1983-4c0f-9c20-19985f379942,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-b6dad3bc-25f4-4883-aa76-0a68481155f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18579383-172.17.0.19-1596020098542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35179,DS-8362edcf-3ce3-4fc2-93b9-17cedb1dd6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-8080ba8d-ba3f-4e91-8481-c204a38ec113,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-4bb30bd8-b3f0-490e-961e-8d76d4ec9000,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-a0fc4abb-5f65-4998-a456-0c44c98c9144,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-42936649-da0d-4211-ac41-20fc12a36137,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-f51470f0-260a-40c8-a21a-871b78a30cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-077c4253-1983-4c0f-9c20-19985f379942,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-b6dad3bc-25f4-4883-aa76-0a68481155f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630885248-172.17.0.19-1596020223960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39750,DS-44e20551-63ae-4e2d-acf8-5923d689e76d,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-6eb784f1-4264-4b8a-be83-f55f4b2932dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-4e95962e-a071-4eed-b706-fefda4340eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-dd822d8c-3435-448d-8c57-2a69b587c369,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-5b428058-3e60-4361-a46e-71a115f71f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-0cbc5927-2920-4882-8f0d-e4659ff1e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-50880cb2-38a4-4d0d-bdf5-fb531b93647c,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-59d40aad-d444-4532-97b8-4b24c0cb55fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630885248-172.17.0.19-1596020223960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39750,DS-44e20551-63ae-4e2d-acf8-5923d689e76d,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-6eb784f1-4264-4b8a-be83-f55f4b2932dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-4e95962e-a071-4eed-b706-fefda4340eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-dd822d8c-3435-448d-8c57-2a69b587c369,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-5b428058-3e60-4361-a46e-71a115f71f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-0cbc5927-2920-4882-8f0d-e4659ff1e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-50880cb2-38a4-4d0d-bdf5-fb531b93647c,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-59d40aad-d444-4532-97b8-4b24c0cb55fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100740334-172.17.0.19-1596020347678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45375,DS-d8c4ecdb-f33b-4a40-aed6-147f9f573c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-1164b614-d87d-4ed6-9d23-ae5f2191f90c,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-0ffe3f05-ed04-420c-8150-00b8a2a2c647,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-66833afd-2e10-456c-a329-32b08782a987,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-90c480bd-ef21-49e6-987d-82aecdc72ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-37abd581-e948-4942-8340-8c09fe97bff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-b89e90bc-debb-4f81-8bc0-2fa61fd11396,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-4c471f5b-a422-4208-b911-e83740fade21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100740334-172.17.0.19-1596020347678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45375,DS-d8c4ecdb-f33b-4a40-aed6-147f9f573c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-1164b614-d87d-4ed6-9d23-ae5f2191f90c,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-0ffe3f05-ed04-420c-8150-00b8a2a2c647,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-66833afd-2e10-456c-a329-32b08782a987,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-90c480bd-ef21-49e6-987d-82aecdc72ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-37abd581-e948-4942-8340-8c09fe97bff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-b89e90bc-debb-4f81-8bc0-2fa61fd11396,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-4c471f5b-a422-4208-b911-e83740fade21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138701419-172.17.0.19-1596020607853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35280,DS-368e88a3-6825-4cce-bf38-0637ca95e8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-806058f5-c50a-4b0f-b5f6-c1bc7663486a,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-b4f938cb-170d-49cf-867e-e7595d2308cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-1603ca4a-9dcd-4ab2-9175-3da973554af0,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-07538276-77a2-4410-8266-194d2f43babc,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-b282147a-280b-47bd-8f86-6b60752b89b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-7bc01a8d-2854-4e78-bb9f-7171a610e2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-6764ad6a-6985-4dc5-ad48-4b67122b5f05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138701419-172.17.0.19-1596020607853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35280,DS-368e88a3-6825-4cce-bf38-0637ca95e8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-806058f5-c50a-4b0f-b5f6-c1bc7663486a,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-b4f938cb-170d-49cf-867e-e7595d2308cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-1603ca4a-9dcd-4ab2-9175-3da973554af0,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-07538276-77a2-4410-8266-194d2f43babc,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-b282147a-280b-47bd-8f86-6b60752b89b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-7bc01a8d-2854-4e78-bb9f-7171a610e2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-6764ad6a-6985-4dc5-ad48-4b67122b5f05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502243250-172.17.0.19-1596021114401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43236,DS-530b1d96-d42d-4d67-9e71-15b5cffc98a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-6bc2ff28-0b29-474e-a861-0b5824a05eab,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-383a3328-2d80-4763-9079-3cb93c16e82a,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-fa3b8c8c-074a-42b3-ba3c-dc080bc6260e,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-d32c303c-c003-431a-b8b8-3cb77a00ef78,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-4b4e0ed9-f9cf-4089-a479-de511820c1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-b93a3a5f-52f7-4978-94e3-6577b9f5b4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-a9d93868-f92c-4a63-b682-ebf5835470a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502243250-172.17.0.19-1596021114401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43236,DS-530b1d96-d42d-4d67-9e71-15b5cffc98a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-6bc2ff28-0b29-474e-a861-0b5824a05eab,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-383a3328-2d80-4763-9079-3cb93c16e82a,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-fa3b8c8c-074a-42b3-ba3c-dc080bc6260e,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-d32c303c-c003-431a-b8b8-3cb77a00ef78,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-4b4e0ed9-f9cf-4089-a479-de511820c1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-b93a3a5f-52f7-4978-94e3-6577b9f5b4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-a9d93868-f92c-4a63-b682-ebf5835470a6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054606154-172.17.0.19-1596021155750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-8409fd7d-6ca4-45a6-a3d4-6ea9a47754e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-ce4fc487-17b3-4481-8a5a-abe974098a99,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-7bf2aa8c-3e57-41b4-93cf-d4f1733d48f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-c72337d2-52e8-48cc-9f4d-11a984d97873,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-2881d277-9a9b-43b0-adf4-7b2a5d3c1f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-eefd77dc-2f7b-4aa7-b094-ab9f8bc7de56,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-85e7c7ec-823e-486b-8d49-f79a14739723,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-04954a17-6692-46ea-a129-dae9bd37153b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054606154-172.17.0.19-1596021155750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-8409fd7d-6ca4-45a6-a3d4-6ea9a47754e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-ce4fc487-17b3-4481-8a5a-abe974098a99,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-7bf2aa8c-3e57-41b4-93cf-d4f1733d48f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-c72337d2-52e8-48cc-9f4d-11a984d97873,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-2881d277-9a9b-43b0-adf4-7b2a5d3c1f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-eefd77dc-2f7b-4aa7-b094-ab9f8bc7de56,DISK], DatanodeInfoWithStorage[127.0.0.1:38842,DS-85e7c7ec-823e-486b-8d49-f79a14739723,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-04954a17-6692-46ea-a129-dae9bd37153b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246119544-172.17.0.19-1596021197488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45214,DS-1b42f19a-aa5a-45db-823c-b9c6bd606270,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-caf7f906-ad04-4629-b879-e3021a726128,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-59727db0-2593-4441-b764-5b92d1eed92b,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-a074fe5e-66ee-44c0-bb27-f124e6f215d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-a3a57aef-f8bd-49b2-971e-c3280a138cef,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-b2110757-24b5-4717-bfaf-e79b4edb5be6,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-88b6f35f-a4fe-4868-8ac2-31a7376947fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-882ccc01-09d2-431e-b35d-a0577a2f9642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246119544-172.17.0.19-1596021197488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45214,DS-1b42f19a-aa5a-45db-823c-b9c6bd606270,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-caf7f906-ad04-4629-b879-e3021a726128,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-59727db0-2593-4441-b764-5b92d1eed92b,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-a074fe5e-66ee-44c0-bb27-f124e6f215d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-a3a57aef-f8bd-49b2-971e-c3280a138cef,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-b2110757-24b5-4717-bfaf-e79b4edb5be6,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-88b6f35f-a4fe-4868-8ac2-31a7376947fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-882ccc01-09d2-431e-b35d-a0577a2f9642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270542036-172.17.0.19-1596021350087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45590,DS-95220e82-7fd8-40ef-8e48-04990b7cf458,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-860b1aa8-3b1a-4b8e-868b-d96b7eb9e156,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-fe00d343-988b-41ff-bbd3-d7fd39f18bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-a16f2e7f-cf69-4521-be2c-25764310ff98,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-31e02b0f-022c-4115-a9e7-f12642ee54bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-2ff7011e-f2a4-406d-b64c-82265f047b50,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-38da8db1-900a-48f2-92c8-bb53e8f11f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-44a9e20b-b216-40d5-9eeb-f5c4d3ef22eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270542036-172.17.0.19-1596021350087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45590,DS-95220e82-7fd8-40ef-8e48-04990b7cf458,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-860b1aa8-3b1a-4b8e-868b-d96b7eb9e156,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-fe00d343-988b-41ff-bbd3-d7fd39f18bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-a16f2e7f-cf69-4521-be2c-25764310ff98,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-31e02b0f-022c-4115-a9e7-f12642ee54bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-2ff7011e-f2a4-406d-b64c-82265f047b50,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-38da8db1-900a-48f2-92c8-bb53e8f11f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-44a9e20b-b216-40d5-9eeb-f5c4d3ef22eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586867319-172.17.0.19-1596021428233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44741,DS-acaba5a5-f15b-4fcc-b388-ebac0013602c,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-8ef4d552-aa0f-4df8-96d4-ac7b57572246,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-43cda911-92c3-4129-8b6b-78031cf4de04,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-9ec2ee86-eaad-4fa8-9e6c-263420f3166c,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-124a8cd2-9864-48d8-8ab0-b7e120288c03,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-81dadf4a-ce65-4b09-aece-33d564dd018f,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-f3dd5dca-20bc-4964-9504-a0158d7a2623,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-2abcbf33-aa60-4dde-ae01-743063ca61ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586867319-172.17.0.19-1596021428233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44741,DS-acaba5a5-f15b-4fcc-b388-ebac0013602c,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-8ef4d552-aa0f-4df8-96d4-ac7b57572246,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-43cda911-92c3-4129-8b6b-78031cf4de04,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-9ec2ee86-eaad-4fa8-9e6c-263420f3166c,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-124a8cd2-9864-48d8-8ab0-b7e120288c03,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-81dadf4a-ce65-4b09-aece-33d564dd018f,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-f3dd5dca-20bc-4964-9504-a0158d7a2623,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-2abcbf33-aa60-4dde-ae01-743063ca61ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838321996-172.17.0.19-1596021467359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41901,DS-bb9eb2a3-7cd7-4659-92bf-e0d53dc38060,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-afefffad-eb97-41be-83ad-a2cf9432903d,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-fda82778-5ed3-46ea-b151-4bc35e789899,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-bf14e4b9-229b-4241-b3c0-db1d4e547cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-e865b534-3c4c-4870-b9d5-0d04aa2eeac6,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-163e05aa-bf0f-4c29-9754-10629d801271,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-0ce61ce1-639a-4bcf-9f95-8c63c728bc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-b41099f6-c8b8-4143-bdcc-677c1515bc44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-838321996-172.17.0.19-1596021467359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41901,DS-bb9eb2a3-7cd7-4659-92bf-e0d53dc38060,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-afefffad-eb97-41be-83ad-a2cf9432903d,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-fda82778-5ed3-46ea-b151-4bc35e789899,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-bf14e4b9-229b-4241-b3c0-db1d4e547cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-e865b534-3c4c-4870-b9d5-0d04aa2eeac6,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-163e05aa-bf0f-4c29-9754-10629d801271,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-0ce61ce1-639a-4bcf-9f95-8c63c728bc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-b41099f6-c8b8-4143-bdcc-677c1515bc44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140698301-172.17.0.19-1596021711228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41193,DS-cfd3dfc3-ea48-439a-bcd9-52842ccc2fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-0ff5396a-78ce-489b-83d1-07124c7fcec3,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-d2735067-5979-48cd-ad90-dd21acc2c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-8479e400-f805-46ce-b703-428256e4b0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-d57aa8bc-2d7b-4c31-8a2e-e4e5dba2f391,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-f039818b-c23f-4fab-bf3a-bf0155386afe,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-ce3c3328-f8fd-488e-b466-3bc5c1ff79b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-e7828c34-f63c-4952-bcfd-fd57f5ba31df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140698301-172.17.0.19-1596021711228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41193,DS-cfd3dfc3-ea48-439a-bcd9-52842ccc2fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-0ff5396a-78ce-489b-83d1-07124c7fcec3,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-d2735067-5979-48cd-ad90-dd21acc2c30f,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-8479e400-f805-46ce-b703-428256e4b0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-d57aa8bc-2d7b-4c31-8a2e-e4e5dba2f391,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-f039818b-c23f-4fab-bf3a-bf0155386afe,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-ce3c3328-f8fd-488e-b466-3bc5c1ff79b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-e7828c34-f63c-4952-bcfd-fd57f5ba31df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311407931-172.17.0.19-1596022201740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37048,DS-c17375f0-d1bb-4773-84b3-ee3c58175014,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-6c8f8e03-b587-4496-9b2f-682ed003c293,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-7ed71735-fe59-4cbc-b154-777443ac068d,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-fa4a06f0-5c7a-4b4a-9582-8382ccc8048f,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-7aaf9ad1-3b66-453c-9071-79a03da99c60,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-3104d546-1b23-4851-8d4e-087f1e447ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-76ef7c10-4217-4a9c-818a-d5fe4839638d,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-ceaf6885-c559-4a5a-900f-bcb1d8bc792b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311407931-172.17.0.19-1596022201740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37048,DS-c17375f0-d1bb-4773-84b3-ee3c58175014,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-6c8f8e03-b587-4496-9b2f-682ed003c293,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-7ed71735-fe59-4cbc-b154-777443ac068d,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-fa4a06f0-5c7a-4b4a-9582-8382ccc8048f,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-7aaf9ad1-3b66-453c-9071-79a03da99c60,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-3104d546-1b23-4851-8d4e-087f1e447ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-76ef7c10-4217-4a9c-818a-d5fe4839638d,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-ceaf6885-c559-4a5a-900f-bcb1d8bc792b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781768135-172.17.0.19-1596022323533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38762,DS-94a1c64a-6bbf-4967-b95f-e2a1e0ff636b,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-d04c5a89-cff3-4fd1-aa7d-723403a196e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-6a716bd9-9b4f-4822-a4a5-62c6d1294ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-a6901e8b-e496-4d8b-a866-479019c355cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-111c4374-092c-4641-a92b-d00e90905617,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-768ef7ce-de28-4508-aab5-08d89432b306,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-0a40d494-2b5c-44b7-b5ab-afb1bf84619c,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-9de635f6-443c-440b-ace5-dcdc3f3e75de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781768135-172.17.0.19-1596022323533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38762,DS-94a1c64a-6bbf-4967-b95f-e2a1e0ff636b,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-d04c5a89-cff3-4fd1-aa7d-723403a196e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-6a716bd9-9b4f-4822-a4a5-62c6d1294ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-a6901e8b-e496-4d8b-a866-479019c355cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-111c4374-092c-4641-a92b-d00e90905617,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-768ef7ce-de28-4508-aab5-08d89432b306,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-0a40d494-2b5c-44b7-b5ab-afb1bf84619c,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-9de635f6-443c-440b-ace5-dcdc3f3e75de,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546093583-172.17.0.19-1596022400800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-61219f6b-de78-4d3e-ad20-8c47bde5e2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-f66a7282-09c2-42c8-97e3-432ce1842cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-dc517055-65bf-46e5-bbd9-a07f7030914d,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-a73013d0-4234-44c6-a777-3ee6061db7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-7a8ae6e5-057c-413c-a3b5-b9df0440d36c,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-2811502d-fdef-4a43-9629-041dc4196cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-b34b6f24-01de-42f6-8f49-3edfc2a07714,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-b0fd6154-6623-4afe-bf73-5b29f7d38ecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546093583-172.17.0.19-1596022400800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-61219f6b-de78-4d3e-ad20-8c47bde5e2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-f66a7282-09c2-42c8-97e3-432ce1842cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-dc517055-65bf-46e5-bbd9-a07f7030914d,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-a73013d0-4234-44c6-a777-3ee6061db7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-7a8ae6e5-057c-413c-a3b5-b9df0440d36c,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-2811502d-fdef-4a43-9629-041dc4196cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-b34b6f24-01de-42f6-8f49-3edfc2a07714,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-b0fd6154-6623-4afe-bf73-5b29f7d38ecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190981064-172.17.0.19-1596022907973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40312,DS-3e4ea326-1a70-4a32-8a00-72d432ae25a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-16be1eb4-b487-4bb5-925c-8ba3fe00d2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-b2ee9260-4cb7-4171-a4d4-8932377b041f,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-9dd7dbad-189c-4baa-9c8b-e5023a554384,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-baac393e-5251-46f8-b393-13bc9f750fce,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-1c4658a4-263e-46bd-acc6-f3e6d48e337c,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-66fc2868-f4e8-4ea3-a0f1-897b27c33e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-85ffb139-96ad-494b-8f2a-cdb3fc745795,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190981064-172.17.0.19-1596022907973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40312,DS-3e4ea326-1a70-4a32-8a00-72d432ae25a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-16be1eb4-b487-4bb5-925c-8ba3fe00d2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-b2ee9260-4cb7-4171-a4d4-8932377b041f,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-9dd7dbad-189c-4baa-9c8b-e5023a554384,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-baac393e-5251-46f8-b393-13bc9f750fce,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-1c4658a4-263e-46bd-acc6-f3e6d48e337c,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-66fc2868-f4e8-4ea3-a0f1-897b27c33e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-85ffb139-96ad-494b-8f2a-cdb3fc745795,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280995626-172.17.0.19-1596022948328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38332,DS-78f1502e-5aa3-4f20-9421-0cc0de0f4765,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-5a775030-8d99-4334-88ef-80a938915db0,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-9bf35937-8dea-4c27-8e66-fe0ae112852d,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-7f091165-44ab-49d6-952a-0acd8ddcb5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-e9274be9-b1cf-456c-ba9f-800b1649ccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-107692a7-945b-4119-a283-3db263f7ca09,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-8aceb635-6461-48c6-b353-07dec832e78b,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-1878e136-b5e6-408c-8f7b-073b4652651f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280995626-172.17.0.19-1596022948328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38332,DS-78f1502e-5aa3-4f20-9421-0cc0de0f4765,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-5a775030-8d99-4334-88ef-80a938915db0,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-9bf35937-8dea-4c27-8e66-fe0ae112852d,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-7f091165-44ab-49d6-952a-0acd8ddcb5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-e9274be9-b1cf-456c-ba9f-800b1649ccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-107692a7-945b-4119-a283-3db263f7ca09,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-8aceb635-6461-48c6-b353-07dec832e78b,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-1878e136-b5e6-408c-8f7b-073b4652651f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596796687-172.17.0.19-1596023141448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39628,DS-2849e404-d82b-4734-a164-2da141b8258c,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-d3aa3a1d-470e-4e74-83d5-fa71e19d1257,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-eb968364-9af4-4b58-9e40-66917c6d386a,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-68e03027-2036-48ec-944a-b17f0203abe8,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-0342ea1c-16f6-465a-855b-343165d661f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-8cecc27a-5922-4c08-9669-6adbc079f02e,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-c5b4c98a-d8c2-46c1-b2e9-ef255d64c2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-eda43979-934f-408a-84f3-31a3383ccb80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596796687-172.17.0.19-1596023141448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39628,DS-2849e404-d82b-4734-a164-2da141b8258c,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-d3aa3a1d-470e-4e74-83d5-fa71e19d1257,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-eb968364-9af4-4b58-9e40-66917c6d386a,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-68e03027-2036-48ec-944a-b17f0203abe8,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-0342ea1c-16f6-465a-855b-343165d661f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-8cecc27a-5922-4c08-9669-6adbc079f02e,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-c5b4c98a-d8c2-46c1-b2e9-ef255d64c2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-eda43979-934f-408a-84f3-31a3383ccb80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649166541-172.17.0.19-1596023180100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41612,DS-0619e01b-d034-4fa4-ba14-24b115225399,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-68137725-7633-485b-9710-4b7328afb512,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-64185a60-138a-4db1-b881-cdec1ffbb247,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-be094369-d22c-4160-a102-4b62988eca3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-45441455-ba44-4bef-9ee6-eb3fbdb49da1,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-8687b74b-6d3b-450f-8bb7-f169c8b2b091,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-88e146b0-b52f-434b-a1d3-8653e69e17c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-49cf0066-b125-4329-892d-d77f402def72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649166541-172.17.0.19-1596023180100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41612,DS-0619e01b-d034-4fa4-ba14-24b115225399,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-68137725-7633-485b-9710-4b7328afb512,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-64185a60-138a-4db1-b881-cdec1ffbb247,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-be094369-d22c-4160-a102-4b62988eca3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-45441455-ba44-4bef-9ee6-eb3fbdb49da1,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-8687b74b-6d3b-450f-8bb7-f169c8b2b091,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-88e146b0-b52f-434b-a1d3-8653e69e17c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-49cf0066-b125-4329-892d-d77f402def72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804981829-172.17.0.19-1596023363585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40145,DS-314443d6-f803-4e2f-a366-eef17f78484d,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-b4696daf-400a-4eb7-bdb3-7707f0b30f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-28deada2-5adc-4a3d-9d5e-084422d0662e,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-2e1faef2-405e-407a-84ba-f8c41540dad8,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-aed380a5-1008-4cd6-8ea0-ec34b0218a55,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-35201416-a7ce-4eaf-8ef5-cf2d61e0cc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-c1a7b3a1-ab16-4c3c-802e-f99cd7e35851,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-bcb65e98-f517-4813-bc8f-33e8c9cf94a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804981829-172.17.0.19-1596023363585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40145,DS-314443d6-f803-4e2f-a366-eef17f78484d,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-b4696daf-400a-4eb7-bdb3-7707f0b30f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-28deada2-5adc-4a3d-9d5e-084422d0662e,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-2e1faef2-405e-407a-84ba-f8c41540dad8,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-aed380a5-1008-4cd6-8ea0-ec34b0218a55,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-35201416-a7ce-4eaf-8ef5-cf2d61e0cc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-c1a7b3a1-ab16-4c3c-802e-f99cd7e35851,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-bcb65e98-f517-4813-bc8f-33e8c9cf94a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18382899-172.17.0.19-1596023441030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33237,DS-eb5c118e-bc2c-47a2-8388-f69930e06f92,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-978b3102-2074-4029-8332-8e175b8c4c59,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-369745a2-4afe-44c2-87cb-8f17d6ff7d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-c6af7da6-49aa-405a-b448-320faba70071,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-d0a19e14-e782-4954-aafd-7c3b7786c0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-a1ff0f3c-f16b-494d-ba00-4aa7f460ca67,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-158ce32d-cee4-47b0-aee6-1967caae73f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-34d6ac15-6c10-4aff-be46-ce7ce687c7be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18382899-172.17.0.19-1596023441030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33237,DS-eb5c118e-bc2c-47a2-8388-f69930e06f92,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-978b3102-2074-4029-8332-8e175b8c4c59,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-369745a2-4afe-44c2-87cb-8f17d6ff7d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37302,DS-c6af7da6-49aa-405a-b448-320faba70071,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-d0a19e14-e782-4954-aafd-7c3b7786c0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-a1ff0f3c-f16b-494d-ba00-4aa7f460ca67,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-158ce32d-cee4-47b0-aee6-1967caae73f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-34d6ac15-6c10-4aff-be46-ce7ce687c7be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807202148-172.17.0.19-1596023473537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36583,DS-edcbced0-0f65-4e6d-94b2-75f9bef3b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-c76d59b5-e982-4453-ab3c-2e51f395589f,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-469954d8-6da2-4ccd-a065-e3fd3178d7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-e5f92088-76f0-491a-aeb3-002e755cb4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-96baecdd-9442-4485-b6f2-5e0784c7653c,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-820cf702-c1f0-4fdd-9672-8148cfb872d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-13f3cf26-4842-425d-b714-64862894384b,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-aa7ecd1f-e2ed-47d1-bb29-d929ffaa34ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807202148-172.17.0.19-1596023473537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36583,DS-edcbced0-0f65-4e6d-94b2-75f9bef3b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-c76d59b5-e982-4453-ab3c-2e51f395589f,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-469954d8-6da2-4ccd-a065-e3fd3178d7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-e5f92088-76f0-491a-aeb3-002e755cb4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-96baecdd-9442-4485-b6f2-5e0784c7653c,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-820cf702-c1f0-4fdd-9672-8148cfb872d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-13f3cf26-4842-425d-b714-64862894384b,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-aa7ecd1f-e2ed-47d1-bb29-d929ffaa34ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036798978-172.17.0.19-1596023705797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38436,DS-8b086625-66e9-4b15-bb54-d85cdc131c91,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-d4cb6b64-8e88-4dbb-938b-eccc9f4ad886,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-426f6f6c-6e26-4cbb-8c7a-3a1b9d4cecc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-5e1150f9-b722-47ee-b9c5-d1677e5fb6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-3333c251-302d-4133-afe1-3d0957d539a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-a01bc8df-805f-4069-a0c6-0a707a9b0509,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-940087e1-920d-4017-8070-93d94d3803be,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-9fc89567-66ed-490a-ae3d-0be0e4b9b80f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036798978-172.17.0.19-1596023705797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38436,DS-8b086625-66e9-4b15-bb54-d85cdc131c91,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-d4cb6b64-8e88-4dbb-938b-eccc9f4ad886,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-426f6f6c-6e26-4cbb-8c7a-3a1b9d4cecc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-5e1150f9-b722-47ee-b9c5-d1677e5fb6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-3333c251-302d-4133-afe1-3d0957d539a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-a01bc8df-805f-4069-a0c6-0a707a9b0509,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-940087e1-920d-4017-8070-93d94d3803be,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-9fc89567-66ed-490a-ae3d-0be0e4b9b80f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848795506-172.17.0.19-1596023810674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37895,DS-d9f6f115-49a8-434f-af27-7b903c88a1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-226a4ae4-1414-4030-8e06-ab6e58873944,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-dd4da2cb-84df-48e6-a690-e0a64f096db7,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-709df1ee-9758-402b-913c-dd6d4d0b6edb,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-c4abe5f1-7dc9-48f2-b8c8-d3dc516b603b,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-ef36e98c-1f87-4750-9c04-5d2b924eb773,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-da2ffd27-10cd-49b1-bfc9-8266ad430e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-98389a27-295d-40ce-b8e8-7059f5034030,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848795506-172.17.0.19-1596023810674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37895,DS-d9f6f115-49a8-434f-af27-7b903c88a1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-226a4ae4-1414-4030-8e06-ab6e58873944,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-dd4da2cb-84df-48e6-a690-e0a64f096db7,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-709df1ee-9758-402b-913c-dd6d4d0b6edb,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-c4abe5f1-7dc9-48f2-b8c8-d3dc516b603b,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-ef36e98c-1f87-4750-9c04-5d2b924eb773,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-da2ffd27-10cd-49b1-bfc9-8266ad430e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-98389a27-295d-40ce-b8e8-7059f5034030,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156491057-172.17.0.19-1596024111171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41185,DS-d4954713-dc42-4d25-af16-1052b4e92832,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-3c1fd2bf-a285-4f38-8d1f-8e147050ae7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-747c9844-b69e-47f1-819a-e692e8836035,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-25acbf71-6d51-4067-9329-0f2bc0b27015,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-9987249a-120e-478c-ae1a-c99b41115a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-5ab3afd6-2e54-4c38-845c-1c840bb70056,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-46445e8c-1668-4061-aa0e-dd88df849b89,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-e56d5028-a764-4ab4-9ab4-528ef123e473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156491057-172.17.0.19-1596024111171:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41185,DS-d4954713-dc42-4d25-af16-1052b4e92832,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-3c1fd2bf-a285-4f38-8d1f-8e147050ae7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-747c9844-b69e-47f1-819a-e692e8836035,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-25acbf71-6d51-4067-9329-0f2bc0b27015,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-9987249a-120e-478c-ae1a-c99b41115a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-5ab3afd6-2e54-4c38-845c-1c840bb70056,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-46445e8c-1668-4061-aa0e-dd88df849b89,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-e56d5028-a764-4ab4-9ab4-528ef123e473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629452545-172.17.0.19-1596024146761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37005,DS-9f6ac4ee-8da5-4cab-b2ec-083689b1b4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-a9e66350-a9fc-4d58-97b2-79768d8e723e,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-855c5187-4253-49e8-8641-a5ca526c1b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-27b829d6-a000-45ee-92e8-71e0b5a2c03f,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-69eac50c-5f8a-4d11-9575-280ed8ece613,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-1580ee5d-9dc6-4d8e-82f7-b01fccbc13e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-8ea4dc03-015a-4116-8227-3cbfd6991a36,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-ba0e8f59-8f58-49fc-88f0-41ec5cba8519,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629452545-172.17.0.19-1596024146761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37005,DS-9f6ac4ee-8da5-4cab-b2ec-083689b1b4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-a9e66350-a9fc-4d58-97b2-79768d8e723e,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-855c5187-4253-49e8-8641-a5ca526c1b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-27b829d6-a000-45ee-92e8-71e0b5a2c03f,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-69eac50c-5f8a-4d11-9575-280ed8ece613,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-1580ee5d-9dc6-4d8e-82f7-b01fccbc13e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-8ea4dc03-015a-4116-8227-3cbfd6991a36,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-ba0e8f59-8f58-49fc-88f0-41ec5cba8519,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691188532-172.17.0.19-1596024484485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38268,DS-bb148c6c-347f-455a-980c-ccdac2da0542,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-f11099b6-b1c7-479a-9f50-9ebf5c7a1cad,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-a3ad2162-e369-4fe9-bb04-7d746505674b,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-3a4add9a-2c00-4702-9b38-390b8e810adb,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-063eb4bc-56ec-4bba-987c-b8ffac957a70,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-88584a6f-b393-4661-a690-2be4f0a8f6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-15fd19af-1e84-494a-a871-527b0c8da5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-1c7ee8ee-3b6c-4acd-b5f3-ca5686784ed0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691188532-172.17.0.19-1596024484485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38268,DS-bb148c6c-347f-455a-980c-ccdac2da0542,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-f11099b6-b1c7-479a-9f50-9ebf5c7a1cad,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-a3ad2162-e369-4fe9-bb04-7d746505674b,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-3a4add9a-2c00-4702-9b38-390b8e810adb,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-063eb4bc-56ec-4bba-987c-b8ffac957a70,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-88584a6f-b393-4661-a690-2be4f0a8f6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-15fd19af-1e84-494a-a871-527b0c8da5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-1c7ee8ee-3b6c-4acd-b5f3-ca5686784ed0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-890631008-172.17.0.19-1596024793134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36879,DS-302f1cd9-ebf8-4ac1-85c1-f751959bd86b,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-bcb14e3a-a554-43b6-9d80-a34ec828639d,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-4cfd9d2e-57fc-4326-8d91-919c2212a36a,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-339dfa2c-ff39-4f4c-84e9-5bb96cbfc13d,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-9e18c17b-97f7-45a5-892c-54964401866e,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-0effb067-bc7c-4bdc-becc-71e0205d94eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-77577f3a-f32c-46c8-a297-e1b4b05cbf11,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-9f66e47b-87ae-4000-ad12-be282bed94af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-890631008-172.17.0.19-1596024793134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36879,DS-302f1cd9-ebf8-4ac1-85c1-f751959bd86b,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-bcb14e3a-a554-43b6-9d80-a34ec828639d,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-4cfd9d2e-57fc-4326-8d91-919c2212a36a,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-339dfa2c-ff39-4f4c-84e9-5bb96cbfc13d,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-9e18c17b-97f7-45a5-892c-54964401866e,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-0effb067-bc7c-4bdc-becc-71e0205d94eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-77577f3a-f32c-46c8-a297-e1b4b05cbf11,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-9f66e47b-87ae-4000-ad12-be282bed94af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130337469-172.17.0.19-1596024985416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43382,DS-0d4fbba6-89f0-4647-933e-ab8a52966166,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-c70efb00-f027-46d6-9720-6d8c81c3d73d,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-3dae133e-7930-469f-970b-1fdb3f833e03,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-5347f8ef-82e2-41f1-b60a-5597e044c2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-cd169933-72a8-414e-a893-838a28f666dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-b22b76d3-c89a-4ace-a595-930adfd0bc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-4aef8195-73ca-42b6-bca2-ac8cda0e12d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-0558e82a-730a-49df-a803-255c8ccf1cd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130337469-172.17.0.19-1596024985416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43382,DS-0d4fbba6-89f0-4647-933e-ab8a52966166,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-c70efb00-f027-46d6-9720-6d8c81c3d73d,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-3dae133e-7930-469f-970b-1fdb3f833e03,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-5347f8ef-82e2-41f1-b60a-5597e044c2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-cd169933-72a8-414e-a893-838a28f666dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-b22b76d3-c89a-4ace-a595-930adfd0bc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-4aef8195-73ca-42b6-bca2-ac8cda0e12d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-0558e82a-730a-49df-a803-255c8ccf1cd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: might be true error
Total execution time in seconds : 5745
