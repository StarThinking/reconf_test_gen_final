reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069524835-172.17.0.5-1595856972655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46485,DS-dd7aac2c-25c5-43e8-986c-1870e9a88e45,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-4ad49808-d953-4869-ad81-b0f49914bb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-9a7fa632-0939-42a9-81de-5bf13dafbf36,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-10395e63-ce8d-41d8-88aa-0fef3e93cf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-04704618-441b-4c37-a763-34d741b62a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-bd05ae27-0f27-46e7-85ce-89dce3a05f78,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-22cbddbc-7e7d-4ff7-96fe-c3d88ac46616,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-16cfe579-e9db-4954-8b2a-ec4c38716ff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069524835-172.17.0.5-1595856972655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46485,DS-dd7aac2c-25c5-43e8-986c-1870e9a88e45,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-4ad49808-d953-4869-ad81-b0f49914bb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-9a7fa632-0939-42a9-81de-5bf13dafbf36,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-10395e63-ce8d-41d8-88aa-0fef3e93cf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-04704618-441b-4c37-a763-34d741b62a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-bd05ae27-0f27-46e7-85ce-89dce3a05f78,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-22cbddbc-7e7d-4ff7-96fe-c3d88ac46616,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-16cfe579-e9db-4954-8b2a-ec4c38716ff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731675303-172.17.0.5-1595857319470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39334,DS-75f97c29-eea7-4dab-abf4-53a5d83b0729,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-f3448d60-be9d-43b0-9da1-1da49d33315f,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-eb2fd24e-f781-4013-a908-4364f75861f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-40f65ee2-0d62-46e7-9a99-7a3a8ff7d964,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-87100a80-c911-4289-8aa8-def8e718b437,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-b5b05d44-c593-49fa-b5a1-837c452f196e,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-91467c56-68d9-4af7-a690-e999f84439b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-3923618c-b7b7-4a61-9a06-82304f1aea58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731675303-172.17.0.5-1595857319470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39334,DS-75f97c29-eea7-4dab-abf4-53a5d83b0729,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-f3448d60-be9d-43b0-9da1-1da49d33315f,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-eb2fd24e-f781-4013-a908-4364f75861f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-40f65ee2-0d62-46e7-9a99-7a3a8ff7d964,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-87100a80-c911-4289-8aa8-def8e718b437,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-b5b05d44-c593-49fa-b5a1-837c452f196e,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-91467c56-68d9-4af7-a690-e999f84439b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-3923618c-b7b7-4a61-9a06-82304f1aea58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1388658703-172.17.0.5-1595857492603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34383,DS-e2c82934-ed27-48fe-b475-5b33aa71cdab,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-5771cb6d-0624-4dae-aa07-1f5d58be0d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-a6bc8026-0551-4d3a-91b1-7cd4e6b46ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-5b848deb-cd85-44d8-a816-2c7edba574b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-06f94f00-e224-430c-89b4-95802feb02c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-c41e669e-3e8f-41fc-863d-a8c87a4f15c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-452fe507-8c24-48bb-b10f-981942864287,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-e918444d-3eaf-411f-b9e8-eb234ecb0276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1388658703-172.17.0.5-1595857492603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34383,DS-e2c82934-ed27-48fe-b475-5b33aa71cdab,DISK], DatanodeInfoWithStorage[127.0.0.1:45021,DS-5771cb6d-0624-4dae-aa07-1f5d58be0d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-a6bc8026-0551-4d3a-91b1-7cd4e6b46ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-5b848deb-cd85-44d8-a816-2c7edba574b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-06f94f00-e224-430c-89b4-95802feb02c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-c41e669e-3e8f-41fc-863d-a8c87a4f15c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-452fe507-8c24-48bb-b10f-981942864287,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-e918444d-3eaf-411f-b9e8-eb234ecb0276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-210127624-172.17.0.5-1595857899804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36298,DS-a98d6663-cee8-4681-8eae-47a25b6828cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-61204b60-d824-4370-b0c5-26c9570ea318,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-a6a72409-a815-4f34-a5a0-302941e01197,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-2e9f9045-0014-4a2e-8040-121cc48427c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-55ba6feb-2342-4b7c-a85c-f3a7dc146616,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-e609ad87-935c-49c1-8f1f-821bea80f8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-c37d3792-c387-48e1-8a6c-15b3e11ad1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-29187347-f49d-4eee-b8cc-ba8725141c39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-210127624-172.17.0.5-1595857899804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36298,DS-a98d6663-cee8-4681-8eae-47a25b6828cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-61204b60-d824-4370-b0c5-26c9570ea318,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-a6a72409-a815-4f34-a5a0-302941e01197,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-2e9f9045-0014-4a2e-8040-121cc48427c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-55ba6feb-2342-4b7c-a85c-f3a7dc146616,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-e609ad87-935c-49c1-8f1f-821bea80f8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-c37d3792-c387-48e1-8a6c-15b3e11ad1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37954,DS-29187347-f49d-4eee-b8cc-ba8725141c39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615927303-172.17.0.5-1595858103060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36796,DS-a367ea48-daaf-4a33-babe-4079ae2b97d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-37e0bb3e-5ce7-47ef-bf1a-adf8a0988f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-ba556222-0aa2-4447-89bd-bee6b5bb52fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-b4071e7e-fe6a-42f8-a5b1-88801b9a7c94,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-8cbda7c4-5316-4987-a565-a039f6950c63,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-ce3d983e-6f0b-4f9a-ab8a-998235645d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-4e9e42d5-4232-42f3-b376-1a898ca273a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-5404aada-ad35-4186-9b50-e3621376bd71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615927303-172.17.0.5-1595858103060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36796,DS-a367ea48-daaf-4a33-babe-4079ae2b97d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-37e0bb3e-5ce7-47ef-bf1a-adf8a0988f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-ba556222-0aa2-4447-89bd-bee6b5bb52fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39181,DS-b4071e7e-fe6a-42f8-a5b1-88801b9a7c94,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-8cbda7c4-5316-4987-a565-a039f6950c63,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-ce3d983e-6f0b-4f9a-ab8a-998235645d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-4e9e42d5-4232-42f3-b376-1a898ca273a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-5404aada-ad35-4186-9b50-e3621376bd71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109920313-172.17.0.5-1595858138184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34319,DS-cb71129a-38c8-4abc-8181-5f5a37656e61,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-f58621ba-458b-4dfb-808c-879c3fc97b27,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-a89dbf82-1c64-4ac6-87d3-57595e5f5cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-946bf18a-a866-47d1-95ba-0b39c3ffe99b,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-26045690-5385-4cea-bdb1-6da8d27a39bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-96c5c70b-59e5-41df-af3a-48f98ca6e863,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-e01ebe22-059d-4572-a46e-444b7fa05c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-fce859ad-4bb7-4534-a0c7-c8ea54844210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109920313-172.17.0.5-1595858138184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34319,DS-cb71129a-38c8-4abc-8181-5f5a37656e61,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-f58621ba-458b-4dfb-808c-879c3fc97b27,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-a89dbf82-1c64-4ac6-87d3-57595e5f5cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-946bf18a-a866-47d1-95ba-0b39c3ffe99b,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-26045690-5385-4cea-bdb1-6da8d27a39bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-96c5c70b-59e5-41df-af3a-48f98ca6e863,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-e01ebe22-059d-4572-a46e-444b7fa05c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-fce859ad-4bb7-4534-a0c7-c8ea54844210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537589877-172.17.0.5-1595858562889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37349,DS-2d814ebc-3443-4787-943c-12d553d9cdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-a52eaa19-f255-444f-8f72-998ab1aeccda,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-51bc1b16-c4f1-4ad3-83f7-1122e482e33a,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-72af1dab-c62f-40cf-84d6-d77739a097b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-95d21ab3-78ba-49b9-ab95-e9dd0489b1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-a0153ba8-1e6c-48fa-83ec-217b05d32b97,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-93e6122f-7d9c-42c0-8418-5a96a01d7c44,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-32683b2f-e502-42e7-87ab-051f3416f724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537589877-172.17.0.5-1595858562889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37349,DS-2d814ebc-3443-4787-943c-12d553d9cdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-a52eaa19-f255-444f-8f72-998ab1aeccda,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-51bc1b16-c4f1-4ad3-83f7-1122e482e33a,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-72af1dab-c62f-40cf-84d6-d77739a097b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-95d21ab3-78ba-49b9-ab95-e9dd0489b1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-a0153ba8-1e6c-48fa-83ec-217b05d32b97,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-93e6122f-7d9c-42c0-8418-5a96a01d7c44,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-32683b2f-e502-42e7-87ab-051f3416f724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829941148-172.17.0.5-1595858802462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35315,DS-f4f80773-ed39-42ce-97a6-8dae1108fc22,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-e40ed47d-5897-462c-837e-02fb94d46f48,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-5fb2d6ca-be81-4d1c-815c-b374834359a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-b0c982e6-11cc-40ae-8fed-d7d01327690d,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-87feba6d-6027-43f6-9542-147005f41d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-43c27727-8b28-453a-99f5-f5588ba3ae7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-a68e48fd-d595-4baa-9c98-5905bd47f047,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-9cd057d4-fa8d-40dd-8679-dc432bf2ea35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829941148-172.17.0.5-1595858802462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35315,DS-f4f80773-ed39-42ce-97a6-8dae1108fc22,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-e40ed47d-5897-462c-837e-02fb94d46f48,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-5fb2d6ca-be81-4d1c-815c-b374834359a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-b0c982e6-11cc-40ae-8fed-d7d01327690d,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-87feba6d-6027-43f6-9542-147005f41d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-43c27727-8b28-453a-99f5-f5588ba3ae7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-a68e48fd-d595-4baa-9c98-5905bd47f047,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-9cd057d4-fa8d-40dd-8679-dc432bf2ea35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780523404-172.17.0.5-1595859789045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33898,DS-d26ae1a1-61c8-4b0e-9f90-b40bef2996f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-65d4165c-5742-45c7-9678-021cb9134897,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-45d3b8a0-1830-4770-a17b-36d3ff32aa26,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-f2ee0fa1-a74d-4113-8eb1-7e32ee707060,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-ffee4fff-55e5-4326-8e89-58335da92096,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-2cf75952-0984-4aa6-9c48-2114a357ca27,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-d0756843-f268-4b8b-b41a-e5fcda3cae57,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-d4658536-497a-43e4-a00d-f2406bb19e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-780523404-172.17.0.5-1595859789045:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33898,DS-d26ae1a1-61c8-4b0e-9f90-b40bef2996f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-65d4165c-5742-45c7-9678-021cb9134897,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-45d3b8a0-1830-4770-a17b-36d3ff32aa26,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-f2ee0fa1-a74d-4113-8eb1-7e32ee707060,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-ffee4fff-55e5-4326-8e89-58335da92096,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-2cf75952-0984-4aa6-9c48-2114a357ca27,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-d0756843-f268-4b8b-b41a-e5fcda3cae57,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-d4658536-497a-43e4-a00d-f2406bb19e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497963850-172.17.0.5-1595859820485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42587,DS-65425942-30ee-4568-bfb0-99bb4fec51c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-e9addc6a-3084-487a-a5db-fa69e9e77ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-4b78fbfa-1755-45d0-b866-f53f8a431e27,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-50ce1aaa-b0ba-48bc-88e8-22e4fc960a42,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-1fc2f60b-c1ef-4a7c-9b47-990731abde8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-fa38d9e5-3e36-47ed-97c4-ba44324289e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-b9f7edc6-8d1b-43c9-bd10-4c23e4e38052,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-cd3dfa08-5823-49fe-ad13-a4302036ebf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497963850-172.17.0.5-1595859820485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42587,DS-65425942-30ee-4568-bfb0-99bb4fec51c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-e9addc6a-3084-487a-a5db-fa69e9e77ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-4b78fbfa-1755-45d0-b866-f53f8a431e27,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-50ce1aaa-b0ba-48bc-88e8-22e4fc960a42,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-1fc2f60b-c1ef-4a7c-9b47-990731abde8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-fa38d9e5-3e36-47ed-97c4-ba44324289e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-b9f7edc6-8d1b-43c9-bd10-4c23e4e38052,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-cd3dfa08-5823-49fe-ad13-a4302036ebf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104401141-172.17.0.5-1595860057110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39151,DS-31deaa9b-1d0a-42e6-bc86-4cb7310fcb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-cf0a6d7d-febe-4f04-b8e9-918c841d5791,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-2d3f4a08-dc82-4441-88e0-bc0b90343dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-f5606ae1-c7d3-42c8-92a7-f60272b04d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-38a24739-a9b0-4197-9ebf-393ab82b8d01,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-60df84fc-1f6c-4360-8f24-7da93ab6ba0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-8fb26bcd-08ad-4081-8489-34f82cdd3e96,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-8bacd46d-60f4-4c23-9a64-e13f6fb8be1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104401141-172.17.0.5-1595860057110:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39151,DS-31deaa9b-1d0a-42e6-bc86-4cb7310fcb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-cf0a6d7d-febe-4f04-b8e9-918c841d5791,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-2d3f4a08-dc82-4441-88e0-bc0b90343dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-f5606ae1-c7d3-42c8-92a7-f60272b04d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-38a24739-a9b0-4197-9ebf-393ab82b8d01,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-60df84fc-1f6c-4360-8f24-7da93ab6ba0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-8fb26bcd-08ad-4081-8489-34f82cdd3e96,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-8bacd46d-60f4-4c23-9a64-e13f6fb8be1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564470160-172.17.0.5-1595860421398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36332,DS-b45f05d4-1e4b-49f0-82a3-e47c7c64d88a,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-bfbd9d08-c469-41bf-ba60-ac8df2b05292,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-7aab1c8a-eb75-4571-a63c-a87623e60e66,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-0e5afb3c-9f6c-4405-ac8f-85b81266c8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-386f90b7-7e16-42fa-a433-0d98fe0ac238,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-e888dfee-92fc-4376-b686-c6de0da30df0,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-84975b20-760e-4ea3-964c-6498dee51059,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-c6930971-25a3-44fe-9d6d-6785729ff67e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564470160-172.17.0.5-1595860421398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36332,DS-b45f05d4-1e4b-49f0-82a3-e47c7c64d88a,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-bfbd9d08-c469-41bf-ba60-ac8df2b05292,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-7aab1c8a-eb75-4571-a63c-a87623e60e66,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-0e5afb3c-9f6c-4405-ac8f-85b81266c8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-386f90b7-7e16-42fa-a433-0d98fe0ac238,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-e888dfee-92fc-4376-b686-c6de0da30df0,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-84975b20-760e-4ea3-964c-6498dee51059,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-c6930971-25a3-44fe-9d6d-6785729ff67e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1932914305-172.17.0.5-1595860495626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46334,DS-92bfee89-00e7-498a-965b-64f1320fa826,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-4e3afc92-d290-4ddb-b091-df1471899ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-c3f299b1-3ff2-4d59-a197-38f9adf9c68c,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-62eab95a-7558-446e-965d-bd4f4eeeddf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-f15540c0-5ba2-443f-a126-b57a6bc41856,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-3326de7a-b6d8-4fae-abb7-8ff7339eaf13,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-1487f318-9a3f-43e2-9371-d5ff5ef6bdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-aaa5171c-d4d4-437f-8080-d6e9f1f85c9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1932914305-172.17.0.5-1595860495626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46334,DS-92bfee89-00e7-498a-965b-64f1320fa826,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-4e3afc92-d290-4ddb-b091-df1471899ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-c3f299b1-3ff2-4d59-a197-38f9adf9c68c,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-62eab95a-7558-446e-965d-bd4f4eeeddf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-f15540c0-5ba2-443f-a126-b57a6bc41856,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-3326de7a-b6d8-4fae-abb7-8ff7339eaf13,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-1487f318-9a3f-43e2-9371-d5ff5ef6bdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-aaa5171c-d4d4-437f-8080-d6e9f1f85c9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129328572-172.17.0.5-1595861380359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46641,DS-8409eac8-6be7-42d7-81f7-207a2dbd6985,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-43191e7e-c745-456c-8034-ea0d5151a9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-9bc44fa3-c6be-4f4f-8257-c588a4367524,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-f42b5c17-afaa-449d-afc7-451641219dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-6b89f7fc-1a65-49e4-bb5b-da5ac03c04a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-efef58d4-f7fa-4983-9d11-bcb745dff734,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-c9669e53-71a4-48b5-ae44-eab5b5e815e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-31c6cc38-fc79-46dd-b3e7-590c380ff4d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129328572-172.17.0.5-1595861380359:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46641,DS-8409eac8-6be7-42d7-81f7-207a2dbd6985,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-43191e7e-c745-456c-8034-ea0d5151a9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-9bc44fa3-c6be-4f4f-8257-c588a4367524,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-f42b5c17-afaa-449d-afc7-451641219dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-6b89f7fc-1a65-49e4-bb5b-da5ac03c04a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-efef58d4-f7fa-4983-9d11-bcb745dff734,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-c9669e53-71a4-48b5-ae44-eab5b5e815e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-31c6cc38-fc79-46dd-b3e7-590c380ff4d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1790083707-172.17.0.5-1595861627900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46083,DS-e90c52cd-b973-4bc5-84b8-f160238d80fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-f824a809-a28c-4e94-ad87-d9ef889b9cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-c2cdee77-30bb-428e-a9f4-603a89fb90a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-1df1cccf-c980-47f8-9382-ec6815977245,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-92516e40-fa8e-4c4e-8382-d3d07780c428,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-2d317b87-4486-4041-a165-34b85d428b40,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-681fd850-0bd5-4937-b320-7f40869b82f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-24ec7c70-95c5-49d5-9c90-1ce032c3536a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1790083707-172.17.0.5-1595861627900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46083,DS-e90c52cd-b973-4bc5-84b8-f160238d80fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-f824a809-a28c-4e94-ad87-d9ef889b9cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-c2cdee77-30bb-428e-a9f4-603a89fb90a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-1df1cccf-c980-47f8-9382-ec6815977245,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-92516e40-fa8e-4c4e-8382-d3d07780c428,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-2d317b87-4486-4041-a165-34b85d428b40,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-681fd850-0bd5-4937-b320-7f40869b82f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-24ec7c70-95c5-49d5-9c90-1ce032c3536a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 268435456
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297974078-172.17.0.5-1595861664004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44683,DS-9da57e23-a7c2-401f-b9b9-523b5e5fc0af,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-78b60128-cd43-4321-8b07-c1dc13694cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-a0ee5b59-a7ce-4fd3-8ae1-1a71a5f7e614,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-1c919333-ded6-40e6-9798-0128af062321,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-85da4619-0200-4a9d-a1af-ff84ca0bf7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-c9a1c17b-d78e-4b0b-9a3f-42009e933b25,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-6fe10771-ecb2-48aa-8a60-516e1152bd09,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-36eb584d-e935-46f2-a321-913771fca1a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1297974078-172.17.0.5-1595861664004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44683,DS-9da57e23-a7c2-401f-b9b9-523b5e5fc0af,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-78b60128-cd43-4321-8b07-c1dc13694cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-a0ee5b59-a7ce-4fd3-8ae1-1a71a5f7e614,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-1c919333-ded6-40e6-9798-0128af062321,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-85da4619-0200-4a9d-a1af-ff84ca0bf7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-c9a1c17b-d78e-4b0b-9a3f-42009e933b25,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-6fe10771-ecb2-48aa-8a60-516e1152bd09,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-36eb584d-e935-46f2-a321-913771fca1a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5179
