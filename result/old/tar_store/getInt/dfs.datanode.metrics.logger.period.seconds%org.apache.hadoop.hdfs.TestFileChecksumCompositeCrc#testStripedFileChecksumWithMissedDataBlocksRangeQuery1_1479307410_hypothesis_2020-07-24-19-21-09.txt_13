reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80270814-172.17.0.9-1595618484326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37377,DS-dd169843-72d7-4913-8aa7-578e2f7b7418,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-3d504d80-e25d-44df-aae8-6d608f7fde9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-779dc47d-bd22-4816-b6b3-9e0bbcaf9ece,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-1630c3c4-2d0c-4887-9aa2-2a1ff640d36c,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-5222a864-576d-455a-a9e1-2d288abef760,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-6440e03c-dafd-45e1-9fbb-e6afcc918fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-3ecb94a1-bed5-4ff0-8ce3-e0e32977ef6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-88d2336c-0c9d-4338-bce4-10373350db13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80270814-172.17.0.9-1595618484326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37377,DS-dd169843-72d7-4913-8aa7-578e2f7b7418,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-3d504d80-e25d-44df-aae8-6d608f7fde9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-779dc47d-bd22-4816-b6b3-9e0bbcaf9ece,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-1630c3c4-2d0c-4887-9aa2-2a1ff640d36c,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-5222a864-576d-455a-a9e1-2d288abef760,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-6440e03c-dafd-45e1-9fbb-e6afcc918fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-3ecb94a1-bed5-4ff0-8ce3-e0e32977ef6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-88d2336c-0c9d-4338-bce4-10373350db13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968003429-172.17.0.9-1595618552742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45317,DS-7ea1bfdc-5f6a-47c5-b405-2f82bffcb6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-c958009d-5b5b-4103-b4dd-2aa61e095077,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-e8ae5639-0c98-41b7-9bf4-448585fe606e,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-8cf4cd76-c155-4088-98c8-bfd987bd9da1,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-fa406254-f795-4532-a3e7-9d1641f0ba9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-72c68ce7-d86d-43ed-a446-4adcc0b03983,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-862a9192-0728-4f67-a40b-3045cf31583d,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-6ef1b03b-56c6-4756-af6e-f9b777f6343d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968003429-172.17.0.9-1595618552742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45317,DS-7ea1bfdc-5f6a-47c5-b405-2f82bffcb6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-c958009d-5b5b-4103-b4dd-2aa61e095077,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-e8ae5639-0c98-41b7-9bf4-448585fe606e,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-8cf4cd76-c155-4088-98c8-bfd987bd9da1,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-fa406254-f795-4532-a3e7-9d1641f0ba9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-72c68ce7-d86d-43ed-a446-4adcc0b03983,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-862a9192-0728-4f67-a40b-3045cf31583d,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-6ef1b03b-56c6-4756-af6e-f9b777f6343d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114573521-172.17.0.9-1595618892937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33624,DS-772fd6ff-08ef-4c15-8ad5-57a39b7c3c29,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-a607a243-2db2-4263-8867-9f9a6a9cfae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-445d0652-1311-47b9-b60f-44c4f82c1efb,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-43d31795-9a49-4764-b445-bc528dad6df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-4911f763-be11-4b90-bc40-fd567dbcf49e,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-8d51ee22-7060-4766-be19-15fff23b35a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-63d39c46-77f4-4548-a551-961bf3437dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-b67a7aae-727b-453f-8f69-db3c90563f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114573521-172.17.0.9-1595618892937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33624,DS-772fd6ff-08ef-4c15-8ad5-57a39b7c3c29,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-a607a243-2db2-4263-8867-9f9a6a9cfae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-445d0652-1311-47b9-b60f-44c4f82c1efb,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-43d31795-9a49-4764-b445-bc528dad6df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-4911f763-be11-4b90-bc40-fd567dbcf49e,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-8d51ee22-7060-4766-be19-15fff23b35a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-63d39c46-77f4-4548-a551-961bf3437dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-b67a7aae-727b-453f-8f69-db3c90563f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383530234-172.17.0.9-1595618962226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38129,DS-2245ddb8-e113-4a59-818c-fa2c9e4db8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-540366d0-5e89-44ef-a7e0-b4f7dae3058c,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-8e8d8fcd-9e6d-43a5-9d1a-1d9397dfe9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-86319ceb-9481-48e2-9c41-6dc718d96029,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-628ab515-f923-4e12-a743-6df0aa4fea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-7132db42-4625-4404-8230-f0cfbc514d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-fb1d1a81-111a-4bfa-a5ab-ede3baad844e,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-65e27d0d-b440-479d-ab79-0d5094dc57ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383530234-172.17.0.9-1595618962226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38129,DS-2245ddb8-e113-4a59-818c-fa2c9e4db8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-540366d0-5e89-44ef-a7e0-b4f7dae3058c,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-8e8d8fcd-9e6d-43a5-9d1a-1d9397dfe9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-86319ceb-9481-48e2-9c41-6dc718d96029,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-628ab515-f923-4e12-a743-6df0aa4fea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-7132db42-4625-4404-8230-f0cfbc514d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-fb1d1a81-111a-4bfa-a5ab-ede3baad844e,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-65e27d0d-b440-479d-ab79-0d5094dc57ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598488486-172.17.0.9-1595619197200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38525,DS-ab35c751-0c43-4089-b93e-5dd7d44ec64e,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-1866504d-f35e-424b-a582-b0e2afedf135,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-bb9166ed-d0de-4c68-8a62-c10d8c2e84dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-3717be6e-b835-4273-b7a4-1dff0ad84345,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-eedf0511-8874-46d5-acce-9475441f06d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-70bf8fcd-6878-4b70-b915-28cf7cc9b72b,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-c5088e82-dadd-43df-a0a7-0372441f5147,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-9aef1b4d-a455-4953-89c2-d66f52db672e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598488486-172.17.0.9-1595619197200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38525,DS-ab35c751-0c43-4089-b93e-5dd7d44ec64e,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-1866504d-f35e-424b-a582-b0e2afedf135,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-bb9166ed-d0de-4c68-8a62-c10d8c2e84dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-3717be6e-b835-4273-b7a4-1dff0ad84345,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-eedf0511-8874-46d5-acce-9475441f06d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-70bf8fcd-6878-4b70-b915-28cf7cc9b72b,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-c5088e82-dadd-43df-a0a7-0372441f5147,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-9aef1b4d-a455-4953-89c2-d66f52db672e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781753560-172.17.0.9-1595619371495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35593,DS-c5950e61-417d-48df-b99d-4d0fdb322cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-659268b8-480f-4d4d-9826-a764c9f60852,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-d78aede1-d784-4403-ab1e-b1fd1ff2df6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-baef64d8-2059-4012-99b5-de0ccde3298e,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-4ff6c40f-4645-4757-83b1-e4cdea51364a,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-9fe0fe4a-0576-4f6e-8a18-1ec8244ed58f,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-e4a2701a-d486-469f-9f5d-6ef38e465b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-03083655-5b71-427d-b364-0535d33628af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781753560-172.17.0.9-1595619371495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35593,DS-c5950e61-417d-48df-b99d-4d0fdb322cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-659268b8-480f-4d4d-9826-a764c9f60852,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-d78aede1-d784-4403-ab1e-b1fd1ff2df6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-baef64d8-2059-4012-99b5-de0ccde3298e,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-4ff6c40f-4645-4757-83b1-e4cdea51364a,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-9fe0fe4a-0576-4f6e-8a18-1ec8244ed58f,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-e4a2701a-d486-469f-9f5d-6ef38e465b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-03083655-5b71-427d-b364-0535d33628af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178341654-172.17.0.9-1595619406746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34718,DS-66571650-df09-4087-b003-c87fa280d1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-806e1b9a-f5bc-4854-975e-797c2da52f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-6244f802-cde9-4e85-bf2b-45f296e4ac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-10d8af0c-937c-4fe3-9cf2-99af287f9b21,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-e0e2199c-a17c-4921-a0bb-039c1588fcba,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-e7aaa4e7-d3e8-4739-92b5-cfdfce160f35,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-a0225547-2847-4245-bd39-c2af2eff53c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-7f4eb170-ae7c-4264-ae76-51b135593c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178341654-172.17.0.9-1595619406746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34718,DS-66571650-df09-4087-b003-c87fa280d1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-806e1b9a-f5bc-4854-975e-797c2da52f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-6244f802-cde9-4e85-bf2b-45f296e4ac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-10d8af0c-937c-4fe3-9cf2-99af287f9b21,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-e0e2199c-a17c-4921-a0bb-039c1588fcba,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-e7aaa4e7-d3e8-4739-92b5-cfdfce160f35,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-a0225547-2847-4245-bd39-c2af2eff53c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-7f4eb170-ae7c-4264-ae76-51b135593c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964863760-172.17.0.9-1595619518146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39009,DS-f1971318-5453-49f5-92c5-d4bbc78a5179,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-cc59f43c-fedc-4316-87a1-a96146909126,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-40ceab38-3a54-4f05-8b2a-702acb3fe391,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-7aa36b6a-c109-46d7-b389-b24f4ece53e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-e7ac1766-9d3a-4b09-a1e1-61f6dfddd9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-61e16cfa-2165-4f41-baae-54d0f35d6924,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-edb5dd5f-43d6-4f02-9f56-eb5b9aad962f,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-67a15ee5-20b8-46da-92b2-3c3fdb5613e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964863760-172.17.0.9-1595619518146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39009,DS-f1971318-5453-49f5-92c5-d4bbc78a5179,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-cc59f43c-fedc-4316-87a1-a96146909126,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-40ceab38-3a54-4f05-8b2a-702acb3fe391,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-7aa36b6a-c109-46d7-b389-b24f4ece53e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-e7ac1766-9d3a-4b09-a1e1-61f6dfddd9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-61e16cfa-2165-4f41-baae-54d0f35d6924,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-edb5dd5f-43d6-4f02-9f56-eb5b9aad962f,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-67a15ee5-20b8-46da-92b2-3c3fdb5613e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683056268-172.17.0.9-1595619548289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38006,DS-7e02c3a2-4c39-4316-9a69-9d81793efc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-df5e61b2-7b76-4903-8c32-a7342fd9dce2,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-8d32fb5e-038b-46b4-9f01-e6ba576ddebf,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-1ede59f0-b439-45c3-99e3-0c327f93a2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-d897582b-dd22-4020-812a-6313250fb9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-cca080af-78cf-4acf-8724-2eb581522c49,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-52c24016-c5b1-4ec0-94a1-6d50a6d7f4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-d2bf9910-d7e5-4fe9-bb54-de705a1f222e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683056268-172.17.0.9-1595619548289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38006,DS-7e02c3a2-4c39-4316-9a69-9d81793efc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-df5e61b2-7b76-4903-8c32-a7342fd9dce2,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-8d32fb5e-038b-46b4-9f01-e6ba576ddebf,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-1ede59f0-b439-45c3-99e3-0c327f93a2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-d897582b-dd22-4020-812a-6313250fb9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-cca080af-78cf-4acf-8724-2eb581522c49,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-52c24016-c5b1-4ec0-94a1-6d50a6d7f4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-d2bf9910-d7e5-4fe9-bb54-de705a1f222e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855551353-172.17.0.9-1595619851521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39329,DS-ec1fb9ae-cdce-4ca8-b2b5-022feb0e7927,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-eb516c6a-f478-481f-b22c-ae96fff22ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-b90198b5-f6e6-499a-8439-6546f5a079d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-d376a405-85a1-469c-b974-5043c09d5e81,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-6393d5c4-62cf-46ca-832b-9f9a05fd832a,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-05a13a5f-0d18-46c3-9819-f95e4f2a5ede,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-b6fe6a9b-dde1-4ce8-a662-54d97ed3f21d,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-4e7623c8-c0b9-478c-85b6-f0830660f274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855551353-172.17.0.9-1595619851521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39329,DS-ec1fb9ae-cdce-4ca8-b2b5-022feb0e7927,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-eb516c6a-f478-481f-b22c-ae96fff22ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-b90198b5-f6e6-499a-8439-6546f5a079d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-d376a405-85a1-469c-b974-5043c09d5e81,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-6393d5c4-62cf-46ca-832b-9f9a05fd832a,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-05a13a5f-0d18-46c3-9819-f95e4f2a5ede,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-b6fe6a9b-dde1-4ce8-a662-54d97ed3f21d,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-4e7623c8-c0b9-478c-85b6-f0830660f274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186674033-172.17.0.9-1595619931476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33950,DS-655582cd-fc58-4d24-95a5-c132718b6bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-21c335b0-babd-461a-9c11-a749e86aa347,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-753a8d2a-ec7d-4583-a25e-46e3d1a2b0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-d3fa9d6d-77bf-4716-80c0-d4f59ab890c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-f93c2b23-3441-47e0-a197-df9909e62a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-4d76303d-3947-4c33-bf89-39ef6ad66c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-170851e1-b846-41cb-9086-91db32829afb,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-b0510c4d-e078-4edb-a2c8-025d3eb21d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186674033-172.17.0.9-1595619931476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33950,DS-655582cd-fc58-4d24-95a5-c132718b6bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-21c335b0-babd-461a-9c11-a749e86aa347,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-753a8d2a-ec7d-4583-a25e-46e3d1a2b0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-d3fa9d6d-77bf-4716-80c0-d4f59ab890c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-f93c2b23-3441-47e0-a197-df9909e62a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-4d76303d-3947-4c33-bf89-39ef6ad66c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-170851e1-b846-41cb-9086-91db32829afb,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-b0510c4d-e078-4edb-a2c8-025d3eb21d11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670480962-172.17.0.9-1595620314406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44815,DS-933edb21-62d0-47bf-87a0-6679228fa463,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-fce27eea-e96a-48a3-8ea4-9d6360ee28d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-b131a4e4-b7fc-4a29-bb09-6e35770b05d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-2c084a9e-eac2-4af7-a669-11c2a32dc07d,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-a6b39fd8-cf08-4c8a-b0ef-0731e0f82d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-fb40f5ba-88ad-4b83-9947-b670ad89cc84,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-f3c99191-a823-4e36-b475-41c1cec672b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-7c56814d-a184-42ee-80ad-64ce2f82ccba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670480962-172.17.0.9-1595620314406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44815,DS-933edb21-62d0-47bf-87a0-6679228fa463,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-fce27eea-e96a-48a3-8ea4-9d6360ee28d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-b131a4e4-b7fc-4a29-bb09-6e35770b05d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-2c084a9e-eac2-4af7-a669-11c2a32dc07d,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-a6b39fd8-cf08-4c8a-b0ef-0731e0f82d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-fb40f5ba-88ad-4b83-9947-b670ad89cc84,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-f3c99191-a823-4e36-b475-41c1cec672b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-7c56814d-a184-42ee-80ad-64ce2f82ccba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501826826-172.17.0.9-1595620742639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39628,DS-231cc5ac-1f2e-42a2-b4e7-90ed779fcfde,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-53bd3a32-61f7-49ca-a3ce-4d0110db07f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-ed456f12-dc11-4ad0-ba2e-912d8d12d794,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-916ebcb5-edf3-43ff-b6b8-bce947056b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-0d6b2d42-7ada-4778-91e2-dbed24fb2f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-efecb2c7-b33c-4273-a05b-908ec987b3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-c3bb9666-799b-478b-8d90-166b1aed75a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-7177fbdf-87e4-4d72-9b82-d9798b5a68bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501826826-172.17.0.9-1595620742639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39628,DS-231cc5ac-1f2e-42a2-b4e7-90ed779fcfde,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-53bd3a32-61f7-49ca-a3ce-4d0110db07f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-ed456f12-dc11-4ad0-ba2e-912d8d12d794,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-916ebcb5-edf3-43ff-b6b8-bce947056b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-0d6b2d42-7ada-4778-91e2-dbed24fb2f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-efecb2c7-b33c-4273-a05b-908ec987b3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-c3bb9666-799b-478b-8d90-166b1aed75a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-7177fbdf-87e4-4d72-9b82-d9798b5a68bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791037450-172.17.0.9-1595620802248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-ffadea2f-f63f-447d-a3c8-86315e6e2f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-9b16de61-a282-4dbe-b485-0ad5e171eeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-985ca01c-8b27-4642-aa74-ba68f8c7554b,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-d6eca677-8d79-44da-9584-de0d2e2dfabf,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-9662ec69-50cc-4a27-96a5-d348600483b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-0fe1f80f-8468-4170-9dc6-603494fc90ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-c954e506-346e-4274-986c-d6971a483856,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-a9856702-3d53-4a6e-b7f3-8cd53f3f38e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791037450-172.17.0.9-1595620802248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-ffadea2f-f63f-447d-a3c8-86315e6e2f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-9b16de61-a282-4dbe-b485-0ad5e171eeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-985ca01c-8b27-4642-aa74-ba68f8c7554b,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-d6eca677-8d79-44da-9584-de0d2e2dfabf,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-9662ec69-50cc-4a27-96a5-d348600483b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-0fe1f80f-8468-4170-9dc6-603494fc90ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-c954e506-346e-4274-986c-d6971a483856,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-a9856702-3d53-4a6e-b7f3-8cd53f3f38e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352266872-172.17.0.9-1595621282389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38666,DS-f0fc588d-b392-4bb3-a6e6-1212698134bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-c736107a-3d16-4919-bf5f-cedc40d51e09,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-39d1609b-6e24-45a6-822b-4c1a32bdc622,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-2b8f1356-edeb-4482-ae05-6bbb04d71ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-02869b05-f878-49ed-b8b3-df5e8f4cef81,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-1266008a-60a0-4512-9823-99382f84e139,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-11222751-d2d0-4a6b-843e-266435038bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-c467a534-f947-4d3d-9505-bae72974ab41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352266872-172.17.0.9-1595621282389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38666,DS-f0fc588d-b392-4bb3-a6e6-1212698134bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40766,DS-c736107a-3d16-4919-bf5f-cedc40d51e09,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-39d1609b-6e24-45a6-822b-4c1a32bdc622,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-2b8f1356-edeb-4482-ae05-6bbb04d71ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-02869b05-f878-49ed-b8b3-df5e8f4cef81,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-1266008a-60a0-4512-9823-99382f84e139,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-11222751-d2d0-4a6b-843e-266435038bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-c467a534-f947-4d3d-9505-bae72974ab41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255912650-172.17.0.9-1595621413583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-fe7423fb-b011-4c6d-872d-db4901b9e5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-5054f70f-024c-4b0f-96a5-c8f27cabbb68,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-fa6c058a-7210-4f49-bb20-ff4324511b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-45ae1e00-ce11-469b-acdb-8d58803d9e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-54929407-7378-4382-8dbc-39e007f3ae85,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-20da123c-dfa7-4f83-9496-f41c0f3b1447,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-d9689a83-63f7-4c1b-85b3-f4e416453ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-abb17af0-9c1b-4ac6-82f2-b5e3c2744ef9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255912650-172.17.0.9-1595621413583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44607,DS-fe7423fb-b011-4c6d-872d-db4901b9e5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-5054f70f-024c-4b0f-96a5-c8f27cabbb68,DISK], DatanodeInfoWithStorage[127.0.0.1:45026,DS-fa6c058a-7210-4f49-bb20-ff4324511b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-45ae1e00-ce11-469b-acdb-8d58803d9e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-54929407-7378-4382-8dbc-39e007f3ae85,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-20da123c-dfa7-4f83-9496-f41c0f3b1447,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-d9689a83-63f7-4c1b-85b3-f4e416453ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-abb17af0-9c1b-4ac6-82f2-b5e3c2744ef9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444579745-172.17.0.9-1595621505845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46116,DS-ea4d6942-dd61-4a6a-8dff-807e04894a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-73a8737d-b5e7-4091-8a29-63aa670053fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-82d4e25b-bd89-425a-a9b4-2bd99f2276a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-c9d75b08-bb11-4285-8520-6116268acf28,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-53b18083-f77a-4984-bcc7-4e8c8493941f,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-b1866cae-d24a-4cf1-93e4-e3e42b70f6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-35f36e6a-8032-40d3-8665-0431b7be02c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-52e24d80-7153-4cbe-a7e7-e6544d464e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444579745-172.17.0.9-1595621505845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46116,DS-ea4d6942-dd61-4a6a-8dff-807e04894a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-73a8737d-b5e7-4091-8a29-63aa670053fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-82d4e25b-bd89-425a-a9b4-2bd99f2276a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-c9d75b08-bb11-4285-8520-6116268acf28,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-53b18083-f77a-4984-bcc7-4e8c8493941f,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-b1866cae-d24a-4cf1-93e4-e3e42b70f6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-35f36e6a-8032-40d3-8665-0431b7be02c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-52e24d80-7153-4cbe-a7e7-e6544d464e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286075085-172.17.0.9-1595621572336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41451,DS-3b806569-6a68-4722-89fb-f45e15375c67,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-54c9974f-cd05-4fc7-bccb-7f09d78d92d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-5edd0cff-0d2b-46ac-91bc-622e8eca2ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-fc232907-9abc-4906-9105-3e6ca92a89c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-13900b78-f6e9-4eca-a6ef-ca6ac1d8e443,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-344017a0-f4a6-4950-8366-c2c21459c0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-6f1d3cbf-dd9e-4aa1-bd60-44d4b5f4a595,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-e250d207-1d20-464a-9b70-56d9721e6540,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286075085-172.17.0.9-1595621572336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41451,DS-3b806569-6a68-4722-89fb-f45e15375c67,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-54c9974f-cd05-4fc7-bccb-7f09d78d92d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-5edd0cff-0d2b-46ac-91bc-622e8eca2ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-fc232907-9abc-4906-9105-3e6ca92a89c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-13900b78-f6e9-4eca-a6ef-ca6ac1d8e443,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-344017a0-f4a6-4950-8366-c2c21459c0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-6f1d3cbf-dd9e-4aa1-bd60-44d4b5f4a595,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-e250d207-1d20-464a-9b70-56d9721e6540,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468786867-172.17.0.9-1595622047940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40159,DS-44a1ff7c-a53c-411f-a8c1-d17738b1aafa,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-78006712-d854-4af0-880c-d75b29ae77a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-33a70d17-d660-4c4a-81c8-67e65b281698,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-db040f52-76c8-442c-91b0-91e8d9119d68,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-c4db6e96-5bc9-4119-a697-ea7d79e7c58c,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-c1ac951c-cdb3-418f-bbf7-b98c434d8562,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-7c9400f8-fb65-4509-80b0-49de8fe08f26,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-3153ec19-d026-4c70-ac2f-2d5f86972620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-468786867-172.17.0.9-1595622047940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40159,DS-44a1ff7c-a53c-411f-a8c1-d17738b1aafa,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-78006712-d854-4af0-880c-d75b29ae77a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-33a70d17-d660-4c4a-81c8-67e65b281698,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-db040f52-76c8-442c-91b0-91e8d9119d68,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-c4db6e96-5bc9-4119-a697-ea7d79e7c58c,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-c1ac951c-cdb3-418f-bbf7-b98c434d8562,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-7c9400f8-fb65-4509-80b0-49de8fe08f26,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-3153ec19-d026-4c70-ac2f-2d5f86972620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899919961-172.17.0.9-1595622245150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40532,DS-d5e8cef3-fd0b-4915-8018-f990d36c73a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-38757027-8b21-4423-b981-6c8a93dd9140,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-b470eb6d-f86b-4cee-9310-ecfecdd3b734,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-1f409968-e0d8-4f4d-ab84-209e9aecb0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-202c9183-dc89-41cc-b3e7-a841a57e6203,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-2ae90a1d-c52d-4fb3-8e2d-feadf4b35926,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-ec867ff4-16b0-4abb-9793-c8cae9e008a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-5e0cb0ee-80bb-4ad7-b591-fb989b7a224a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899919961-172.17.0.9-1595622245150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40532,DS-d5e8cef3-fd0b-4915-8018-f990d36c73a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-38757027-8b21-4423-b981-6c8a93dd9140,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-b470eb6d-f86b-4cee-9310-ecfecdd3b734,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-1f409968-e0d8-4f4d-ab84-209e9aecb0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-202c9183-dc89-41cc-b3e7-a841a57e6203,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-2ae90a1d-c52d-4fb3-8e2d-feadf4b35926,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-ec867ff4-16b0-4abb-9793-c8cae9e008a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-5e0cb0ee-80bb-4ad7-b591-fb989b7a224a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629742497-172.17.0.9-1595622467822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34189,DS-e906fd5e-08bc-46fc-992a-31fad3994e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-b4be113f-d621-4357-ac69-b3ae4bbb543f,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-b0cf2b98-1303-40ce-823e-99f11d16d5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-842c3ea0-86fe-4be7-adf2-03df92fcfe14,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-075a2e20-c6b4-4449-9be9-89334c514141,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-2fd91740-125b-4ae1-8474-cfae9ca70ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-6c44b07d-8a4c-4b78-b1b2-177b2ffe4ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-c2aab6a4-f0d1-4cd1-90b3-f63ca4b3b4ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629742497-172.17.0.9-1595622467822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34189,DS-e906fd5e-08bc-46fc-992a-31fad3994e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-b4be113f-d621-4357-ac69-b3ae4bbb543f,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-b0cf2b98-1303-40ce-823e-99f11d16d5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-842c3ea0-86fe-4be7-adf2-03df92fcfe14,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-075a2e20-c6b4-4449-9be9-89334c514141,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-2fd91740-125b-4ae1-8474-cfae9ca70ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-6c44b07d-8a4c-4b78-b1b2-177b2ffe4ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-c2aab6a4-f0d1-4cd1-90b3-f63ca4b3b4ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473843370-172.17.0.9-1595622681401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39850,DS-3673e6bd-8a3c-4251-b0a4-b7df43380e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-a86c733e-5434-4f48-9376-22c64c418134,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-81e961c9-4a30-4a56-8e17-fdbbf77beafa,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-dbcbf00f-ed6a-49df-af12-3aa129f213db,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-43bc56f5-c8ab-4da0-acb6-b1b5fbd2b69b,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-dab1c20a-9eb6-402d-9fc3-00b7e8487b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-7d4fe84d-9951-46cd-a251-36f23f55c6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-829ddc6a-ee64-4258-ab7a-8dac9782dece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473843370-172.17.0.9-1595622681401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39850,DS-3673e6bd-8a3c-4251-b0a4-b7df43380e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-a86c733e-5434-4f48-9376-22c64c418134,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-81e961c9-4a30-4a56-8e17-fdbbf77beafa,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-dbcbf00f-ed6a-49df-af12-3aa129f213db,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-43bc56f5-c8ab-4da0-acb6-b1b5fbd2b69b,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-dab1c20a-9eb6-402d-9fc3-00b7e8487b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-7d4fe84d-9951-46cd-a251-36f23f55c6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-829ddc6a-ee64-4258-ab7a-8dac9782dece,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995257126-172.17.0.9-1595622863216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44463,DS-d9486741-c17e-48a1-bf45-a9fee9a24610,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-99c9ecde-01e1-41af-b70e-aa1be46ebe83,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-a948d412-070f-4eb0-800e-36e24237092b,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-df87aa23-5fa3-4398-a2e0-a46f166e8649,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-5934b027-fd54-4268-af46-03d076d06672,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-7819a273-ef48-43f4-9275-56c3d3da8e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-a5e40527-7e10-461f-802e-911e0f41b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-bacb77b6-8a70-4a38-bde9-3415e2415d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995257126-172.17.0.9-1595622863216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44463,DS-d9486741-c17e-48a1-bf45-a9fee9a24610,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-99c9ecde-01e1-41af-b70e-aa1be46ebe83,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-a948d412-070f-4eb0-800e-36e24237092b,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-df87aa23-5fa3-4398-a2e0-a46f166e8649,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-5934b027-fd54-4268-af46-03d076d06672,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-7819a273-ef48-43f4-9275-56c3d3da8e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-a5e40527-7e10-461f-802e-911e0f41b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-bacb77b6-8a70-4a38-bde9-3415e2415d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531016872-172.17.0.9-1595622973124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41220,DS-34a25e36-58ea-48fe-bf6f-1e8a7edcf54d,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-4b4d1d1f-e031-4340-9a73-d70acf963bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-bffee6bd-ce35-40c5-b963-7d4f8208619c,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-a2529a5d-f732-42f4-bc40-388eb1fe2979,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-874111a9-66e7-4499-9bed-b87e9b5e7a75,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-b1d43554-c2b1-4aaf-ad7e-13edaf5e8686,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-396cec5b-604f-405b-9ed8-c827c7c89fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-76113a84-7c08-4bb7-b135-283d51273655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531016872-172.17.0.9-1595622973124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41220,DS-34a25e36-58ea-48fe-bf6f-1e8a7edcf54d,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-4b4d1d1f-e031-4340-9a73-d70acf963bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-bffee6bd-ce35-40c5-b963-7d4f8208619c,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-a2529a5d-f732-42f4-bc40-388eb1fe2979,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-874111a9-66e7-4499-9bed-b87e9b5e7a75,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-b1d43554-c2b1-4aaf-ad7e-13edaf5e8686,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-396cec5b-604f-405b-9ed8-c827c7c89fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-76113a84-7c08-4bb7-b135-283d51273655,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1677936667-172.17.0.9-1595623200562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34556,DS-943de0ff-0288-4797-8902-c4aebb1a26f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-078ed940-fdf7-4740-8ece-4e0ed271f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-66f84872-0011-45ba-a666-9d6441f304b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-cdb23fce-c7ad-4c42-815d-9536b4a36271,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-d29d47bf-cc67-484a-8068-66be8d7de363,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-1f37a8b7-a06c-4d6d-9f0e-850e79914e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-2f041445-7be8-45c9-8d8f-67547f3c238a,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-3923dddb-d02a-41a5-99f2-785b97af11b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1677936667-172.17.0.9-1595623200562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34556,DS-943de0ff-0288-4797-8902-c4aebb1a26f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-078ed940-fdf7-4740-8ece-4e0ed271f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-66f84872-0011-45ba-a666-9d6441f304b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34338,DS-cdb23fce-c7ad-4c42-815d-9536b4a36271,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-d29d47bf-cc67-484a-8068-66be8d7de363,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-1f37a8b7-a06c-4d6d-9f0e-850e79914e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-2f041445-7be8-45c9-8d8f-67547f3c238a,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-3923dddb-d02a-41a5-99f2-785b97af11b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67095687-172.17.0.9-1595623239083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36536,DS-7e35415e-1c24-4d86-95ee-b8084a53504a,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-a1d3e158-0854-407f-bb43-fe3f407b1efb,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-71d875f8-6969-4845-a847-2d0d3f1d339e,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-43892422-3308-42ba-a326-2774dc7da771,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-ac379718-b24d-4a18-aedb-a92ef3bf8389,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-9c896f29-5b92-4730-bdfa-c505bf88c44e,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-8e88aecf-c715-4654-9b1e-62796c6ffab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-ce4a8017-e7a6-4015-a3ef-a71b66a9c52b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67095687-172.17.0.9-1595623239083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36536,DS-7e35415e-1c24-4d86-95ee-b8084a53504a,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-a1d3e158-0854-407f-bb43-fe3f407b1efb,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-71d875f8-6969-4845-a847-2d0d3f1d339e,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-43892422-3308-42ba-a326-2774dc7da771,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-ac379718-b24d-4a18-aedb-a92ef3bf8389,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-9c896f29-5b92-4730-bdfa-c505bf88c44e,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-8e88aecf-c715-4654-9b1e-62796c6ffab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-ce4a8017-e7a6-4015-a3ef-a71b66a9c52b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926977259-172.17.0.9-1595623347397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45084,DS-c4594018-b2cb-4f66-b7f0-ed4425b6f23e,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-ae2d9efd-72a2-4081-8598-1d93f0014587,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-8556b317-81cc-4e62-b1f2-6b3f968d6776,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-0156afc1-09de-48a2-a633-e336e7939b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-134216a6-b7f4-4b96-abfc-60a4b12e5c72,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-38235ae2-2bcd-436c-a4ba-5ff87de1b2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-6c6cd023-2a62-41a6-9b47-b5b9a2380c10,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-ac40ec48-107c-4982-bf6d-199a528ea0d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926977259-172.17.0.9-1595623347397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45084,DS-c4594018-b2cb-4f66-b7f0-ed4425b6f23e,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-ae2d9efd-72a2-4081-8598-1d93f0014587,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-8556b317-81cc-4e62-b1f2-6b3f968d6776,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-0156afc1-09de-48a2-a633-e336e7939b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-134216a6-b7f4-4b96-abfc-60a4b12e5c72,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-38235ae2-2bcd-436c-a4ba-5ff87de1b2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-6c6cd023-2a62-41a6-9b47-b5b9a2380c10,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-ac40ec48-107c-4982-bf6d-199a528ea0d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95936459-172.17.0.9-1595623570387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39825,DS-0946390f-11f9-4c85-a529-ea86928b4687,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-a3bc199d-59b9-4404-9b0f-77361566e808,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-0874220f-1952-4fdf-b8e4-9b42fa4ac6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-dd6128ff-df80-4ecf-9185-3b6a41caf628,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-7f2bc949-697e-4a83-99cc-cc921ef06b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-8de401a4-2f2f-4f00-97f3-472dca95629d,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-e4667201-4086-4e55-91f0-fc520c1e604a,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-c79764b6-38be-43c3-b898-fe6883313174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95936459-172.17.0.9-1595623570387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39825,DS-0946390f-11f9-4c85-a529-ea86928b4687,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-a3bc199d-59b9-4404-9b0f-77361566e808,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-0874220f-1952-4fdf-b8e4-9b42fa4ac6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-dd6128ff-df80-4ecf-9185-3b6a41caf628,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-7f2bc949-697e-4a83-99cc-cc921ef06b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-8de401a4-2f2f-4f00-97f3-472dca95629d,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-e4667201-4086-4e55-91f0-fc520c1e604a,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-c79764b6-38be-43c3-b898-fe6883313174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5275
