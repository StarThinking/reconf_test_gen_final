reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785876633-172.17.0.17-1595612904003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40332,DS-100dda81-86fc-4a9e-b924-d0562edc6ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-242a50e3-0b0c-4551-b68b-c49c15855ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-deef81ad-7e41-4c20-a095-e4dde14e2de4,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-8b9f9959-b62e-4607-b34e-21663aee4872,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-f8aa0885-1cb6-4ac3-8317-85f3ac189af4,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-4495da9e-a8c7-44f9-a84c-a8d6f2b714ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-fad2db8b-a713-4662-b036-1e488942f1df,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-49f1ddeb-1e32-4a1a-b3a4-27021dc09e05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785876633-172.17.0.17-1595612904003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40332,DS-100dda81-86fc-4a9e-b924-d0562edc6ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-242a50e3-0b0c-4551-b68b-c49c15855ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-deef81ad-7e41-4c20-a095-e4dde14e2de4,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-8b9f9959-b62e-4607-b34e-21663aee4872,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-f8aa0885-1cb6-4ac3-8317-85f3ac189af4,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-4495da9e-a8c7-44f9-a84c-a8d6f2b714ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-fad2db8b-a713-4662-b036-1e488942f1df,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-49f1ddeb-1e32-4a1a-b3a4-27021dc09e05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103117609-172.17.0.17-1595612946247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35243,DS-1fc05679-85b1-4edc-aa31-c903fab9be5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-98aaf364-cfb2-4925-bd09-10ef1f056f01,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-fb5b89b4-7c62-4de5-a030-b38e18dc8f05,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-a3c757ec-ce89-4b85-89f3-59ccd5215d74,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-10d5c9da-2cae-4ab9-a254-7bc935884909,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-52a71785-192c-427c-96d6-2fe81c9e54eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-e0fd18d5-04ff-4284-a8d3-e5e050d8b548,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-66de41b5-89c0-4fef-8aee-0ebff5210621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103117609-172.17.0.17-1595612946247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35243,DS-1fc05679-85b1-4edc-aa31-c903fab9be5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-98aaf364-cfb2-4925-bd09-10ef1f056f01,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-fb5b89b4-7c62-4de5-a030-b38e18dc8f05,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-a3c757ec-ce89-4b85-89f3-59ccd5215d74,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-10d5c9da-2cae-4ab9-a254-7bc935884909,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-52a71785-192c-427c-96d6-2fe81c9e54eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-e0fd18d5-04ff-4284-a8d3-e5e050d8b548,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-66de41b5-89c0-4fef-8aee-0ebff5210621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341607765-172.17.0.17-1595613333799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43570,DS-7af47efd-377a-45df-901d-e6e30b624fec,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-6ac74551-1bb0-4aa9-9266-5f991821ae43,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-8b57e912-ae87-4d2d-b382-e0760d3d9685,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-8f36a173-3cce-4bc5-9448-edc4c217b6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-ce30b72f-1ffa-4978-9d09-545111f3d142,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-40c5d7be-c602-4b50-957e-dd5140779e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-9bda06b5-213d-4276-9250-241fe7fbccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-8e3d2d27-80d4-440b-abde-aeaad6100eb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341607765-172.17.0.17-1595613333799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43570,DS-7af47efd-377a-45df-901d-e6e30b624fec,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-6ac74551-1bb0-4aa9-9266-5f991821ae43,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-8b57e912-ae87-4d2d-b382-e0760d3d9685,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-8f36a173-3cce-4bc5-9448-edc4c217b6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-ce30b72f-1ffa-4978-9d09-545111f3d142,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-40c5d7be-c602-4b50-957e-dd5140779e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-9bda06b5-213d-4276-9250-241fe7fbccb6,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-8e3d2d27-80d4-440b-abde-aeaad6100eb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537377418-172.17.0.17-1595613436973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44171,DS-2922249b-e579-43c7-9827-0329ce793209,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-ff89d6cc-691f-4783-ba11-38a7cc9c1f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-79b057a7-810d-4b19-9f58-2e612860a540,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-cd2499f0-baf3-4b58-8fdb-870a7b83cc79,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-883044f9-3b8d-4538-b417-f9ce51fb0ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-4e7aae8a-bcb1-4def-b20b-6a7416ffdf50,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-eca045ce-4331-4f72-9c80-5f09320956d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-6689c710-ad7a-45e8-b950-5286cd3e3255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537377418-172.17.0.17-1595613436973:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44171,DS-2922249b-e579-43c7-9827-0329ce793209,DISK], DatanodeInfoWithStorage[127.0.0.1:40300,DS-ff89d6cc-691f-4783-ba11-38a7cc9c1f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-79b057a7-810d-4b19-9f58-2e612860a540,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-cd2499f0-baf3-4b58-8fdb-870a7b83cc79,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-883044f9-3b8d-4538-b417-f9ce51fb0ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-4e7aae8a-bcb1-4def-b20b-6a7416ffdf50,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-eca045ce-4331-4f72-9c80-5f09320956d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-6689c710-ad7a-45e8-b950-5286cd3e3255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145519236-172.17.0.17-1595613550131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42710,DS-1db29742-eda4-46fc-ac5c-25f80e760dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-f50d8ecc-80e7-49e4-bb0b-bb022ba7162f,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-2760aa27-5d32-4446-a825-c3647af42278,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-f9b85802-b7de-4463-a6c7-b786426b5b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-480ad0c0-5e19-4b36-b951-cbcfcc269ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-09327780-4fc8-400b-baad-fb72f258b9df,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-5a321d35-de40-4cc6-aa12-5c860d7f2880,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-31dba4f7-ac0a-4d8a-ae3f-3e8b5203d6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145519236-172.17.0.17-1595613550131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42710,DS-1db29742-eda4-46fc-ac5c-25f80e760dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-f50d8ecc-80e7-49e4-bb0b-bb022ba7162f,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-2760aa27-5d32-4446-a825-c3647af42278,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-f9b85802-b7de-4463-a6c7-b786426b5b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-480ad0c0-5e19-4b36-b951-cbcfcc269ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-09327780-4fc8-400b-baad-fb72f258b9df,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-5a321d35-de40-4cc6-aa12-5c860d7f2880,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-31dba4f7-ac0a-4d8a-ae3f-3e8b5203d6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945678456-172.17.0.17-1595613896673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34617,DS-ad260531-e8ae-4c52-b5d5-b14a75257605,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-3e4b727b-a3f7-4426-a33f-0473c3423ede,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-7201125f-84bd-43c5-8a70-d1b033cb5325,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-6be17d31-f67e-4b14-a174-a9a5ab762316,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-be75dfca-ede0-4ae6-b4c8-3d217a39aa02,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-8746cbf8-f44d-4138-af58-1f8c0303e6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-8b99bd83-df3e-4d4a-a3ee-30cae6038a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-0839a6d2-aab1-4928-96d7-ba2afb8b499f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945678456-172.17.0.17-1595613896673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34617,DS-ad260531-e8ae-4c52-b5d5-b14a75257605,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-3e4b727b-a3f7-4426-a33f-0473c3423ede,DISK], DatanodeInfoWithStorage[127.0.0.1:46173,DS-7201125f-84bd-43c5-8a70-d1b033cb5325,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-6be17d31-f67e-4b14-a174-a9a5ab762316,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-be75dfca-ede0-4ae6-b4c8-3d217a39aa02,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-8746cbf8-f44d-4138-af58-1f8c0303e6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-8b99bd83-df3e-4d4a-a3ee-30cae6038a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-0839a6d2-aab1-4928-96d7-ba2afb8b499f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-144123384-172.17.0.17-1595614070794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35737,DS-91255c06-1563-4248-8e41-02fef4eda324,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-bf68e2f9-0d4e-4cde-96b1-1b11988f9198,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-134cf03b-fb68-402a-9cf9-9ca57c874ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-93c434c6-826f-4d88-8521-ac06d0b61c63,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-b7234d42-11e5-4851-8797-3172ed19f6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-1c3f3cf3-940c-4b8f-b917-6099166d5d67,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-fbbe607c-6832-4359-9a71-c8460b1f73a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-ce9e221c-4d5d-4813-ab7c-e1235be400ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-144123384-172.17.0.17-1595614070794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35737,DS-91255c06-1563-4248-8e41-02fef4eda324,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-bf68e2f9-0d4e-4cde-96b1-1b11988f9198,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-134cf03b-fb68-402a-9cf9-9ca57c874ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-93c434c6-826f-4d88-8521-ac06d0b61c63,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-b7234d42-11e5-4851-8797-3172ed19f6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-1c3f3cf3-940c-4b8f-b917-6099166d5d67,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-fbbe607c-6832-4359-9a71-c8460b1f73a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-ce9e221c-4d5d-4813-ab7c-e1235be400ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961005331-172.17.0.17-1595614717379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40862,DS-3576ab90-b853-4f51-8dd9-552454bd166f,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-5efaa965-ee64-4b8e-8b75-8e1484c681b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-612eeb62-f568-49aa-991b-01111a4893e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-b3f27e5f-897f-419d-a124-a444aea56f89,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-fa9cb7e8-e60e-48b2-a649-46e112ae5f41,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-e3a59abd-5476-4cec-8547-0940ab7bb0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-f0c90339-2dd6-41fb-a5ac-b824683eb831,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-073fa4c8-dcde-448f-b2bb-d805e55c8517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-961005331-172.17.0.17-1595614717379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40862,DS-3576ab90-b853-4f51-8dd9-552454bd166f,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-5efaa965-ee64-4b8e-8b75-8e1484c681b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-612eeb62-f568-49aa-991b-01111a4893e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-b3f27e5f-897f-419d-a124-a444aea56f89,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-fa9cb7e8-e60e-48b2-a649-46e112ae5f41,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-e3a59abd-5476-4cec-8547-0940ab7bb0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-f0c90339-2dd6-41fb-a5ac-b824683eb831,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-073fa4c8-dcde-448f-b2bb-d805e55c8517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941408084-172.17.0.17-1595614794016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43731,DS-9f2a488b-f7b5-4976-9678-493190180134,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-881d21b0-9b22-4927-9cca-efe9cb8aa023,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-87f56ebe-4844-4d82-83d1-6476ddc067c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-009f0877-da5b-4ff0-b0d7-e9a0dff389dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-ff95ee96-ffd4-481e-9668-edc5605b0496,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-d1d8d305-3627-4f30-bbb1-717f18522a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-8968f06c-f2dc-4969-8ddb-d03b6ec1c2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-97bb3b9d-e987-49e2-a11f-5219eda5cb2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941408084-172.17.0.17-1595614794016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43731,DS-9f2a488b-f7b5-4976-9678-493190180134,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-881d21b0-9b22-4927-9cca-efe9cb8aa023,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-87f56ebe-4844-4d82-83d1-6476ddc067c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-009f0877-da5b-4ff0-b0d7-e9a0dff389dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-ff95ee96-ffd4-481e-9668-edc5605b0496,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-d1d8d305-3627-4f30-bbb1-717f18522a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-8968f06c-f2dc-4969-8ddb-d03b6ec1c2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-97bb3b9d-e987-49e2-a11f-5219eda5cb2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793248314-172.17.0.17-1595615157060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41258,DS-ded72a46-f52e-40c3-92d2-49005e0e3326,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-a9c1219b-4202-439e-a12b-2339379062ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-08d401ac-842a-48b8-babc-09219c5ab276,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-71db7951-81ff-4eec-ac53-d94c6139bf95,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-4cc41a00-05c7-40c7-af1b-c3baf1471b69,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-f9d7ce4f-157f-4c95-a90b-c784f33143a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-22d522c5-eff3-4f50-8c4d-83bcaaee8148,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-38105e41-59ed-4d0c-b6e5-170fe4867b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793248314-172.17.0.17-1595615157060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41258,DS-ded72a46-f52e-40c3-92d2-49005e0e3326,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-a9c1219b-4202-439e-a12b-2339379062ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-08d401ac-842a-48b8-babc-09219c5ab276,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-71db7951-81ff-4eec-ac53-d94c6139bf95,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-4cc41a00-05c7-40c7-af1b-c3baf1471b69,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-f9d7ce4f-157f-4c95-a90b-c784f33143a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-22d522c5-eff3-4f50-8c4d-83bcaaee8148,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-38105e41-59ed-4d0c-b6e5-170fe4867b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590690820-172.17.0.17-1595615896013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40011,DS-8c10897e-906c-403a-93da-f857f16b2d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-fb42296f-6cb1-4b3a-90ed-c0fed58abd81,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-34d8f29c-f840-4aef-948c-6a34b76fcaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-b90802db-aba3-46ce-8311-6d16ba7b52cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-d9c7cb19-f8ad-4219-942b-848bb536a6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-e2d4c878-a578-4fc2-aa14-146915009afe,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-e5d93716-08da-46ce-a6cc-e813344c031d,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-9606083d-87ba-41b8-a6d3-5d31ed51ec6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590690820-172.17.0.17-1595615896013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40011,DS-8c10897e-906c-403a-93da-f857f16b2d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-fb42296f-6cb1-4b3a-90ed-c0fed58abd81,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-34d8f29c-f840-4aef-948c-6a34b76fcaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-b90802db-aba3-46ce-8311-6d16ba7b52cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-d9c7cb19-f8ad-4219-942b-848bb536a6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-e2d4c878-a578-4fc2-aa14-146915009afe,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-e5d93716-08da-46ce-a6cc-e813344c031d,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-9606083d-87ba-41b8-a6d3-5d31ed51ec6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45040586-172.17.0.17-1595616404315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44820,DS-91a9a44d-b9ee-45ca-9c5b-9549e6553481,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-ab2c9648-bbe0-48a9-929a-da35679f5af6,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-60e0ca25-b69f-4e87-8156-945d9abe44df,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-337bf942-7c5c-4510-be76-c0e153428f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-b83954c7-cfac-4c86-8d42-2731de4227de,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-a01ecd64-38ee-4a6d-9362-d26bce252635,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-365aacf5-0dac-44c7-a8b7-a8b60f8e2908,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-16340c0c-f502-42e0-925a-904095c114d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45040586-172.17.0.17-1595616404315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44820,DS-91a9a44d-b9ee-45ca-9c5b-9549e6553481,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-ab2c9648-bbe0-48a9-929a-da35679f5af6,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-60e0ca25-b69f-4e87-8156-945d9abe44df,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-337bf942-7c5c-4510-be76-c0e153428f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-b83954c7-cfac-4c86-8d42-2731de4227de,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-a01ecd64-38ee-4a6d-9362-d26bce252635,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-365aacf5-0dac-44c7-a8b7-a8b60f8e2908,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-16340c0c-f502-42e0-925a-904095c114d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453840199-172.17.0.17-1595616473529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42921,DS-644e43c9-0b31-4e5b-b095-9230470c65c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-a78e6e46-2c63-4caa-969e-6b280d9bf697,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-729dd28d-ed6d-4ce2-9ca4-2801812fe730,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-909a295c-1b04-4740-b8f1-daa50819e40f,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-249f5ec1-ca1b-4ff3-97fa-33aad971962d,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-806a96ed-c68a-4cd9-85a1-d689a3c153eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-43fe83c7-7514-4a7c-8492-68ae289e5d48,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-87b16bd1-7865-4a9a-9777-0657c5945594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453840199-172.17.0.17-1595616473529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42921,DS-644e43c9-0b31-4e5b-b095-9230470c65c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-a78e6e46-2c63-4caa-969e-6b280d9bf697,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-729dd28d-ed6d-4ce2-9ca4-2801812fe730,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-909a295c-1b04-4740-b8f1-daa50819e40f,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-249f5ec1-ca1b-4ff3-97fa-33aad971962d,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-806a96ed-c68a-4cd9-85a1-d689a3c153eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-43fe83c7-7514-4a7c-8492-68ae289e5d48,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-87b16bd1-7865-4a9a-9777-0657c5945594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342733385-172.17.0.17-1595617484477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34174,DS-649a6009-8d9c-49dd-8251-011941ad442b,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-29501b6c-60e8-4ca3-9daa-d249cf434da2,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-5ec67b70-5503-45e8-8163-c66d457015f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-1c5ce9ff-4939-418c-8525-7f76665a2da0,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-9015c727-4467-49e2-9977-df9f90b43de2,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-fed77cc1-3c1d-4308-b863-e34b2aae848e,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-00b64766-c6d2-4572-8312-c8809b1dc458,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-f21c8a03-b356-455c-85bc-f7991ec037d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342733385-172.17.0.17-1595617484477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34174,DS-649a6009-8d9c-49dd-8251-011941ad442b,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-29501b6c-60e8-4ca3-9daa-d249cf434da2,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-5ec67b70-5503-45e8-8163-c66d457015f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-1c5ce9ff-4939-418c-8525-7f76665a2da0,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-9015c727-4467-49e2-9977-df9f90b43de2,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-fed77cc1-3c1d-4308-b863-e34b2aae848e,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-00b64766-c6d2-4572-8312-c8809b1dc458,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-f21c8a03-b356-455c-85bc-f7991ec037d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979627200-172.17.0.17-1595617880621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-0744f7bc-19dd-420c-9dad-24a57b5e53b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-c3f18776-9f02-4c64-907b-50f85107f768,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-1d7fde70-5a55-46ec-b641-9beefba5fbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-fa366797-8f68-4cc6-b62c-7d7f6e51c77b,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-e8cb7e0d-83de-436a-9599-f8766cb0becb,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-d2689fa7-bd93-4b8a-b668-372bee914950,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-e8ab2d3d-ab4b-40d3-b796-da4134282abc,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-2cc6b1ed-f865-4f39-aaf1-fca2a2f6e97d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979627200-172.17.0.17-1595617880621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-0744f7bc-19dd-420c-9dad-24a57b5e53b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-c3f18776-9f02-4c64-907b-50f85107f768,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-1d7fde70-5a55-46ec-b641-9beefba5fbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-fa366797-8f68-4cc6-b62c-7d7f6e51c77b,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-e8cb7e0d-83de-436a-9599-f8766cb0becb,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-d2689fa7-bd93-4b8a-b668-372bee914950,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-e8ab2d3d-ab4b-40d3-b796-da4134282abc,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-2cc6b1ed-f865-4f39-aaf1-fca2a2f6e97d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5331
