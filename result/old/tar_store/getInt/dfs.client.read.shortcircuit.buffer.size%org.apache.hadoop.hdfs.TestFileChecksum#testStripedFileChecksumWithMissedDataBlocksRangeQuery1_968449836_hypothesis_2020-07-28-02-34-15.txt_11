reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046920151-172.17.0.12-1595904655379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46841,DS-534baa85-5ec0-4aea-b5d9-c39b04fe4361,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-5840d14b-b012-49ad-a598-2e57e4ef85de,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-90791d66-a9f8-4fbe-bd8b-591ab735bd45,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-3fc77e20-972f-4a12-afaf-b21f56655e40,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-876339a2-6a5c-40ca-a023-17f15e0bc1da,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-aa59c774-d75f-4d42-9324-f5212c4abfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-019802a8-3c95-46ad-8241-2465a04c0d78,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-afeb6785-6076-4e0c-8a3f-ee9296286e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046920151-172.17.0.12-1595904655379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46841,DS-534baa85-5ec0-4aea-b5d9-c39b04fe4361,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-5840d14b-b012-49ad-a598-2e57e4ef85de,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-90791d66-a9f8-4fbe-bd8b-591ab735bd45,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-3fc77e20-972f-4a12-afaf-b21f56655e40,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-876339a2-6a5c-40ca-a023-17f15e0bc1da,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-aa59c774-d75f-4d42-9324-f5212c4abfc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-019802a8-3c95-46ad-8241-2465a04c0d78,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-afeb6785-6076-4e0c-8a3f-ee9296286e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75177140-172.17.0.12-1595905065444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36847,DS-92a118ad-5eb7-46df-aee2-1809561cf215,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-ce17c93d-3acc-415b-b04d-727f0309ca54,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-b1a5b8e8-eebc-4712-b9cf-e074b1dd5d79,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-ca4f74d7-2765-4b6c-af5a-9e21f9ce8b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-70bc2cde-3595-4c43-8ee2-53b7e75ad648,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-5240da42-b2cc-41de-b0ef-009ab2a86a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-1f7d6761-74a5-443e-afde-fb0caebe7737,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-d9b65077-995d-4266-969a-648e9e9a7946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75177140-172.17.0.12-1595905065444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36847,DS-92a118ad-5eb7-46df-aee2-1809561cf215,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-ce17c93d-3acc-415b-b04d-727f0309ca54,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-b1a5b8e8-eebc-4712-b9cf-e074b1dd5d79,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-ca4f74d7-2765-4b6c-af5a-9e21f9ce8b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-70bc2cde-3595-4c43-8ee2-53b7e75ad648,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-5240da42-b2cc-41de-b0ef-009ab2a86a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-1f7d6761-74a5-443e-afde-fb0caebe7737,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-d9b65077-995d-4266-969a-648e9e9a7946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786907818-172.17.0.12-1595905585049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46617,DS-72b9b4a2-234d-4286-af69-f9f187c6e3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-66df7e43-9672-4b8c-bbdb-29885ee3eb20,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-b6070d7d-dc01-42b0-9206-9d744ccfa000,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-9c277b2e-2031-43bf-9740-e793d7323f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-066b3059-9a20-43eb-b427-a74e815a33db,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-6b5de8f4-8147-4616-916a-0a308f72c5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-85c62d55-a091-4ebc-9332-02e6e4ec3b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-fa86ecbb-2c7d-4920-857a-5905a51dbe12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786907818-172.17.0.12-1595905585049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46617,DS-72b9b4a2-234d-4286-af69-f9f187c6e3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-66df7e43-9672-4b8c-bbdb-29885ee3eb20,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-b6070d7d-dc01-42b0-9206-9d744ccfa000,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-9c277b2e-2031-43bf-9740-e793d7323f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-066b3059-9a20-43eb-b427-a74e815a33db,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-6b5de8f4-8147-4616-916a-0a308f72c5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-85c62d55-a091-4ebc-9332-02e6e4ec3b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-fa86ecbb-2c7d-4920-857a-5905a51dbe12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103797423-172.17.0.12-1595907615775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33784,DS-25b5356d-cc56-4496-a739-35ef37c10dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-10d00039-6981-4bc2-9821-dee5c2bb39da,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-48da6080-9584-4658-be91-8220d4a742dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-a4536d9c-b769-40c9-9c89-e0ff9150b9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-072f4183-90ac-4aec-af43-7fb9ad6d9561,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-8e18b2cf-e3ca-4f79-8edb-5d6b01a1abf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-ebeaa95f-fbc7-45c4-b041-714a354566cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-d7f9f312-d54a-4582-a2cc-b333811f97e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103797423-172.17.0.12-1595907615775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33784,DS-25b5356d-cc56-4496-a739-35ef37c10dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-10d00039-6981-4bc2-9821-dee5c2bb39da,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-48da6080-9584-4658-be91-8220d4a742dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-a4536d9c-b769-40c9-9c89-e0ff9150b9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44993,DS-072f4183-90ac-4aec-af43-7fb9ad6d9561,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-8e18b2cf-e3ca-4f79-8edb-5d6b01a1abf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-ebeaa95f-fbc7-45c4-b041-714a354566cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-d7f9f312-d54a-4582-a2cc-b333811f97e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917979283-172.17.0.12-1595907807391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-38cf778f-be76-4c3a-9ced-4b0498b4bfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-0ae3e9b0-4af1-4c4a-bf77-47bcb8c92432,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-269abc4d-c39f-41fe-a570-62855ca440d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-faa3f44a-bb97-416c-ba22-6d7185afcab5,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-12b43584-f16e-40e6-8bfe-832488998f16,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-4ea7dc85-0288-4239-a4ab-f3994718e99f,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-c231b86d-bee7-4b61-8155-56e34e762d85,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-3ab6af90-a582-4917-b0c7-77bdbf1cfd57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917979283-172.17.0.12-1595907807391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37909,DS-38cf778f-be76-4c3a-9ced-4b0498b4bfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-0ae3e9b0-4af1-4c4a-bf77-47bcb8c92432,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-269abc4d-c39f-41fe-a570-62855ca440d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-faa3f44a-bb97-416c-ba22-6d7185afcab5,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-12b43584-f16e-40e6-8bfe-832488998f16,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-4ea7dc85-0288-4239-a4ab-f3994718e99f,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-c231b86d-bee7-4b61-8155-56e34e762d85,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-3ab6af90-a582-4917-b0c7-77bdbf1cfd57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212057473-172.17.0.12-1595908323737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46578,DS-d3ffed77-d147-428a-975b-0b794c1c50db,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-bab33841-9769-468a-9797-bdea0587a295,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-c2d474c5-220c-44a4-aebb-b7471c452381,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-e41bcabd-9e50-4ec9-8107-467d23e3f194,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-c3689b7e-e5c8-4010-bc91-0cb0eb5506bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-75bc0c82-ce6b-43fc-be6c-5c72c4ce7899,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-f4ffbf6c-2061-4ed7-907e-7dd6139e6be2,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-0d18be19-4505-499f-b6ab-6d77dd740c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212057473-172.17.0.12-1595908323737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46578,DS-d3ffed77-d147-428a-975b-0b794c1c50db,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-bab33841-9769-468a-9797-bdea0587a295,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-c2d474c5-220c-44a4-aebb-b7471c452381,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-e41bcabd-9e50-4ec9-8107-467d23e3f194,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-c3689b7e-e5c8-4010-bc91-0cb0eb5506bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-75bc0c82-ce6b-43fc-be6c-5c72c4ce7899,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-f4ffbf6c-2061-4ed7-907e-7dd6139e6be2,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-0d18be19-4505-499f-b6ab-6d77dd740c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267023482-172.17.0.12-1595908609597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33975,DS-b694d027-46e9-4ed2-a805-f55dffad505f,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-aa0ce51a-3da8-4c77-bf39-75d8b8563ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-0072b980-21c6-470e-bbdd-b825370486d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-d0f94c1f-00fc-4ce6-bcb0-c94d5e4c3a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-a5ac4316-1e47-4e27-9b9c-984047c319ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-705b22ac-b87b-4c33-9260-5d0149453283,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-7a555457-16e1-4267-9f8e-7c445c26657f,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-305b538b-59e0-4b25-9b26-a276d28b66c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267023482-172.17.0.12-1595908609597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33975,DS-b694d027-46e9-4ed2-a805-f55dffad505f,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-aa0ce51a-3da8-4c77-bf39-75d8b8563ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-0072b980-21c6-470e-bbdd-b825370486d7,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-d0f94c1f-00fc-4ce6-bcb0-c94d5e4c3a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-a5ac4316-1e47-4e27-9b9c-984047c319ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-705b22ac-b87b-4c33-9260-5d0149453283,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-7a555457-16e1-4267-9f8e-7c445c26657f,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-305b538b-59e0-4b25-9b26-a276d28b66c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075008575-172.17.0.12-1595908649876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37514,DS-6a1fdfc0-5504-4d76-aa4b-e381620ba597,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-de5980a0-58ed-4206-b389-7a4d9738e819,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-dafe4ecc-e2a7-4b27-841b-621d07771e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-1d779613-1fdc-4c92-aca0-7d740e501572,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-a7a070dd-9379-4563-91fd-7fadfc3c4bac,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-75c0445d-18fd-475c-b72f-9e307aa2fcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-d99584c0-bf70-43c6-a2df-893f2cc82c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-c68eb794-97ec-4ed1-8928-91df8c50b845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075008575-172.17.0.12-1595908649876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37514,DS-6a1fdfc0-5504-4d76-aa4b-e381620ba597,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-de5980a0-58ed-4206-b389-7a4d9738e819,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-dafe4ecc-e2a7-4b27-841b-621d07771e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-1d779613-1fdc-4c92-aca0-7d740e501572,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-a7a070dd-9379-4563-91fd-7fadfc3c4bac,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-75c0445d-18fd-475c-b72f-9e307aa2fcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-d99584c0-bf70-43c6-a2df-893f2cc82c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-c68eb794-97ec-4ed1-8928-91df8c50b845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856277928-172.17.0.12-1595909205800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40067,DS-1c469c8a-b2ca-449a-8d7b-af3efeaec4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-f7638ac8-f4f1-4a07-9398-0cadac389e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-69fe76fa-5181-4b77-9b7a-b06c0f6e7f92,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-0faa71ff-bdc7-4efc-a082-60b829b7feec,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-4ab8faff-5124-42fa-8b13-ae7e41ede897,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-8d553e40-66d7-4113-92c4-0447d0f8e904,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-95a121ec-b1b3-4bb8-9537-e8cdf47ab486,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-e280f1b8-af20-419e-b422-02b9d455bd5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856277928-172.17.0.12-1595909205800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40067,DS-1c469c8a-b2ca-449a-8d7b-af3efeaec4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-f7638ac8-f4f1-4a07-9398-0cadac389e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-69fe76fa-5181-4b77-9b7a-b06c0f6e7f92,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-0faa71ff-bdc7-4efc-a082-60b829b7feec,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-4ab8faff-5124-42fa-8b13-ae7e41ede897,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-8d553e40-66d7-4113-92c4-0447d0f8e904,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-95a121ec-b1b3-4bb8-9537-e8cdf47ab486,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-e280f1b8-af20-419e-b422-02b9d455bd5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434537398-172.17.0.12-1595909877619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34012,DS-a091af47-ce18-4907-aba2-facef3431074,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-8ef6ae34-9d44-4630-8c1f-cf56072cc40d,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-7c78a58d-a491-44c6-af17-9f9bc1d64a51,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-39c2db38-63ed-4b65-bea3-1b15f42f4d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-b28802d2-2397-4563-a988-842e7e4b38c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-1ca9f4aa-588c-474e-8f12-23a7fe4c308e,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-959fed4b-7b99-4e47-a5fe-4ed79aeec651,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-1a8e0b33-c384-4991-91eb-850e6f2962a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434537398-172.17.0.12-1595909877619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34012,DS-a091af47-ce18-4907-aba2-facef3431074,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-8ef6ae34-9d44-4630-8c1f-cf56072cc40d,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-7c78a58d-a491-44c6-af17-9f9bc1d64a51,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-39c2db38-63ed-4b65-bea3-1b15f42f4d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-b28802d2-2397-4563-a988-842e7e4b38c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-1ca9f4aa-588c-474e-8f12-23a7fe4c308e,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-959fed4b-7b99-4e47-a5fe-4ed79aeec651,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-1a8e0b33-c384-4991-91eb-850e6f2962a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4765314-172.17.0.12-1595910139436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41951,DS-9e284575-d4a2-4ca2-9e52-a90cda930872,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-be4f8e1d-542e-4a76-b9fc-ee8e7a4a63fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-e384e0aa-945d-48cb-ac00-ceae3ee57b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-c4dc6e9b-51d3-42e5-a4d6-cdda51b26f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-017f4bea-26b7-482a-b745-5938d87f5efd,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-e1bb8a57-4d39-4167-b5b2-ccdedc5a2c45,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-52bd5de5-b1ba-4b6f-91e1-d6bc541acfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-2c3c1038-b6cf-4248-83d7-42ad8b931ba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4765314-172.17.0.12-1595910139436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41951,DS-9e284575-d4a2-4ca2-9e52-a90cda930872,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-be4f8e1d-542e-4a76-b9fc-ee8e7a4a63fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-e384e0aa-945d-48cb-ac00-ceae3ee57b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-c4dc6e9b-51d3-42e5-a4d6-cdda51b26f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-017f4bea-26b7-482a-b745-5938d87f5efd,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-e1bb8a57-4d39-4167-b5b2-ccdedc5a2c45,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-52bd5de5-b1ba-4b6f-91e1-d6bc541acfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-2c3c1038-b6cf-4248-83d7-42ad8b931ba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719144237-172.17.0.12-1595910386781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41061,DS-f44b19af-b891-4cb9-8104-6c36150f8ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-6fe4df70-7e1f-4487-868f-6062dd96dada,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-4bee3a9d-9c3a-4fcb-801b-0fc904bb965a,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-5efa9370-1b97-4242-b9cc-a973407e469e,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-55b34e42-f19d-4da5-a9ff-fb6e3f709d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-a2ef819e-0189-46ef-af92-1ca7c55cdc05,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-6761d61d-1e65-47e4-ba01-753d6be0bd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-4457fdbe-df6d-4be5-ab04-41447ad3a4b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719144237-172.17.0.12-1595910386781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41061,DS-f44b19af-b891-4cb9-8104-6c36150f8ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-6fe4df70-7e1f-4487-868f-6062dd96dada,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-4bee3a9d-9c3a-4fcb-801b-0fc904bb965a,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-5efa9370-1b97-4242-b9cc-a973407e469e,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-55b34e42-f19d-4da5-a9ff-fb6e3f709d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-a2ef819e-0189-46ef-af92-1ca7c55cdc05,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-6761d61d-1e65-47e4-ba01-753d6be0bd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-4457fdbe-df6d-4be5-ab04-41447ad3a4b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6759
