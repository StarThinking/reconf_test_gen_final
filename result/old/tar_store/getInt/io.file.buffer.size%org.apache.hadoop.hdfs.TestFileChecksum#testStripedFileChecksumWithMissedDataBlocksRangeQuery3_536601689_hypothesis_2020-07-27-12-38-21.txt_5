reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-540225026-172.17.0.8-1595853555652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-80f6d293-c1cb-4804-aa57-3921799b4455,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-1e89d67b-7c16-4cef-bc73-a1391035c02f,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-ec533bc2-395f-4b94-839d-6142e0cbb49a,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-e6441804-6d85-4d8c-9e17-d5c4f5f46c19,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-4d668630-1b97-473f-b500-ffe8bb19be20,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-50822e30-4e4c-4cef-87b9-fadb1bafadc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-9db59d5c-7d32-47f0-93d4-d81380bc2e91,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-262f2f13-c522-4cb3-8533-6b2b68eb2e4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-540225026-172.17.0.8-1595853555652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-80f6d293-c1cb-4804-aa57-3921799b4455,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-1e89d67b-7c16-4cef-bc73-a1391035c02f,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-ec533bc2-395f-4b94-839d-6142e0cbb49a,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-e6441804-6d85-4d8c-9e17-d5c4f5f46c19,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-4d668630-1b97-473f-b500-ffe8bb19be20,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-50822e30-4e4c-4cef-87b9-fadb1bafadc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-9db59d5c-7d32-47f0-93d4-d81380bc2e91,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-262f2f13-c522-4cb3-8533-6b2b68eb2e4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502398480-172.17.0.8-1595853968671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46601,DS-b9b11f8e-a8e9-4aa4-929a-cc9f5a794a37,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-7dedd9ae-b087-4389-a6d8-a593eebaa3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-f5c1b01c-9828-4bb8-96c6-c9bb8c53e0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-996252d5-dea6-457a-89cb-ca1633a2ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-3ac511d6-6a95-4b18-964b-7fda846ad9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-3d14b85e-2463-4537-82c3-5fe89d7e3920,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-8a294856-18ce-41e1-b589-5090e80bf776,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-31d446f2-d3fe-412f-a1ba-70ce0c2d81db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502398480-172.17.0.8-1595853968671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46601,DS-b9b11f8e-a8e9-4aa4-929a-cc9f5a794a37,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-7dedd9ae-b087-4389-a6d8-a593eebaa3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-f5c1b01c-9828-4bb8-96c6-c9bb8c53e0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-996252d5-dea6-457a-89cb-ca1633a2ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-3ac511d6-6a95-4b18-964b-7fda846ad9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-3d14b85e-2463-4537-82c3-5fe89d7e3920,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-8a294856-18ce-41e1-b589-5090e80bf776,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-31d446f2-d3fe-412f-a1ba-70ce0c2d81db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256257160-172.17.0.8-1595854079363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34100,DS-764c593b-87a7-491e-a71b-15c2f8ba48bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-b9414c82-ea9e-43bd-9311-0597066fbce6,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-1fa9ab84-a27a-4ef8-ba87-a2e44240266f,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-01c70f36-da44-4ceb-a7bc-2333a24a63ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-b5f1c331-ecea-46c8-ae20-4ab80709fec7,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-0f63a493-5af2-4b9f-b3f8-e6ead0af0868,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-f173b4d1-8e16-467d-a103-0919c4f0fa42,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-8f40661b-9552-4de4-b972-ccb49a0ee941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256257160-172.17.0.8-1595854079363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34100,DS-764c593b-87a7-491e-a71b-15c2f8ba48bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-b9414c82-ea9e-43bd-9311-0597066fbce6,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-1fa9ab84-a27a-4ef8-ba87-a2e44240266f,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-01c70f36-da44-4ceb-a7bc-2333a24a63ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-b5f1c331-ecea-46c8-ae20-4ab80709fec7,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-0f63a493-5af2-4b9f-b3f8-e6ead0af0868,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-f173b4d1-8e16-467d-a103-0919c4f0fa42,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-8f40661b-9552-4de4-b972-ccb49a0ee941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117103798-172.17.0.8-1595854729486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43489,DS-9db1d271-a7a2-4c62-bb8a-8d1107e3a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-988fc3a4-59f6-476a-b358-aec175fe3607,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-d98d1248-0a68-4938-a214-efa8dadfa6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-5fdf3677-5312-412f-bde9-cc26390e14f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-d50fb872-b61b-4245-9aa9-d063d09857fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-7d7d4251-b184-4de1-ac09-0f557124b2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-0e4458b1-e9a3-47e9-9c41-1cee693d8d45,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-d3239e48-9d6c-456c-8a87-bde062d36dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117103798-172.17.0.8-1595854729486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43489,DS-9db1d271-a7a2-4c62-bb8a-8d1107e3a1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-988fc3a4-59f6-476a-b358-aec175fe3607,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-d98d1248-0a68-4938-a214-efa8dadfa6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-5fdf3677-5312-412f-bde9-cc26390e14f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-d50fb872-b61b-4245-9aa9-d063d09857fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-7d7d4251-b184-4de1-ac09-0f557124b2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-0e4458b1-e9a3-47e9-9c41-1cee693d8d45,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-d3239e48-9d6c-456c-8a87-bde062d36dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058598590-172.17.0.8-1595854992470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41700,DS-f43c6a02-7d0c-44bc-a38e-3afdb3041f38,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-38666ad5-5fe3-4a14-b0d3-fbb6a0da6991,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-8a5e680f-9eda-4c0a-8338-5bfe6022daee,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-fcb07c48-6f01-426f-8aff-1ac4c54033c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-c04c5fe0-c9f1-4941-8035-203541453b40,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-688bb620-55c7-4ac7-9b0a-6a5836c2290f,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-258971cb-8343-4b01-8f87-8ed865826e45,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-8ad91806-b71b-45c1-be4c-c7fed145b44e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058598590-172.17.0.8-1595854992470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41700,DS-f43c6a02-7d0c-44bc-a38e-3afdb3041f38,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-38666ad5-5fe3-4a14-b0d3-fbb6a0da6991,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-8a5e680f-9eda-4c0a-8338-5bfe6022daee,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-fcb07c48-6f01-426f-8aff-1ac4c54033c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-c04c5fe0-c9f1-4941-8035-203541453b40,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-688bb620-55c7-4ac7-9b0a-6a5836c2290f,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-258971cb-8343-4b01-8f87-8ed865826e45,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-8ad91806-b71b-45c1-be4c-c7fed145b44e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816745277-172.17.0.8-1595855418834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42272,DS-c0e78624-ff60-42a4-ae8e-e0ce909b627a,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-7dbe852f-6a50-4a8d-a2ed-5ea78a72cf08,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-3d00a516-d7fa-44e6-9f19-91eab9be21cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-34c620ce-748a-4ab5-85b7-d748aded4d81,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-95a31f89-cdc3-4271-9d9b-d11b94195176,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-5df7993c-9ff8-464a-9113-4261f5243eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-c6980257-aae3-450b-b2a0-4ed375fc0b29,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-fdda218e-0188-431b-900a-7a09af36185e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816745277-172.17.0.8-1595855418834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42272,DS-c0e78624-ff60-42a4-ae8e-e0ce909b627a,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-7dbe852f-6a50-4a8d-a2ed-5ea78a72cf08,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-3d00a516-d7fa-44e6-9f19-91eab9be21cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-34c620ce-748a-4ab5-85b7-d748aded4d81,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-95a31f89-cdc3-4271-9d9b-d11b94195176,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-5df7993c-9ff8-464a-9113-4261f5243eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-c6980257-aae3-450b-b2a0-4ed375fc0b29,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-fdda218e-0188-431b-900a-7a09af36185e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056453467-172.17.0.8-1595855805394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44362,DS-920ae8f3-ed9d-4012-af39-877597214434,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-5178fa3b-44ba-4998-8c45-1ef6c7304578,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-52db760e-3ec3-450a-a9b9-ac20ba16e75b,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-43eb7be1-bf05-4675-9f5e-f7e389ec0a00,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-3352d038-0be2-4e1c-bad6-ad47535974c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-9d6a9098-d99d-45bd-9d26-e4b8ce35c0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-4c0ff846-0dcd-43f6-b7cc-4f372ba43098,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-a7c5ec85-597a-48d5-8eb6-e3afd82e8711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056453467-172.17.0.8-1595855805394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44362,DS-920ae8f3-ed9d-4012-af39-877597214434,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-5178fa3b-44ba-4998-8c45-1ef6c7304578,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-52db760e-3ec3-450a-a9b9-ac20ba16e75b,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-43eb7be1-bf05-4675-9f5e-f7e389ec0a00,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-3352d038-0be2-4e1c-bad6-ad47535974c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-9d6a9098-d99d-45bd-9d26-e4b8ce35c0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-4c0ff846-0dcd-43f6-b7cc-4f372ba43098,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-a7c5ec85-597a-48d5-8eb6-e3afd82e8711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34409615-172.17.0.8-1595855844128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46401,DS-f324f14d-4b02-423f-9c1e-f310c71fb4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-1068113a-9be7-4a55-9fe0-36d1e370ca15,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-6cfab8b7-70f8-4c1f-8f13-6952f7d5d136,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-7f259ca2-b2a1-401b-9eb3-245c8854e0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-d0754d53-744e-44f7-89be-b31bf254b4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-02b03e1c-4360-464d-858d-b14bbdcf07fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-d6787c28-9345-4fbd-89a2-9182f3eb80f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-6aafb014-b1aa-4492-bae7-fa7f4bf1fe8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34409615-172.17.0.8-1595855844128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46401,DS-f324f14d-4b02-423f-9c1e-f310c71fb4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-1068113a-9be7-4a55-9fe0-36d1e370ca15,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-6cfab8b7-70f8-4c1f-8f13-6952f7d5d136,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-7f259ca2-b2a1-401b-9eb3-245c8854e0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-d0754d53-744e-44f7-89be-b31bf254b4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-02b03e1c-4360-464d-858d-b14bbdcf07fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-d6787c28-9345-4fbd-89a2-9182f3eb80f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-6aafb014-b1aa-4492-bae7-fa7f4bf1fe8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426384236-172.17.0.8-1595855950627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39580,DS-30ec2c8f-9ea1-45a1-b595-e22b4dd5d550,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-e19690d3-02f2-45cc-a76a-821fdc39c7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-e6ecbf62-c26a-4cf5-94b6-b732120d8574,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-f8e2f5b8-a445-4f46-8d0f-4d8bf2683fef,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-78bbb474-ecad-43a5-b6c3-994b84e131d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-48dbb6d1-4977-4e6f-8c1f-7b7694a0e745,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-2bd7fe67-4b1f-42e9-a7aa-398122876f46,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-743469ba-783e-4a21-992b-97da9374e265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426384236-172.17.0.8-1595855950627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39580,DS-30ec2c8f-9ea1-45a1-b595-e22b4dd5d550,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-e19690d3-02f2-45cc-a76a-821fdc39c7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-e6ecbf62-c26a-4cf5-94b6-b732120d8574,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-f8e2f5b8-a445-4f46-8d0f-4d8bf2683fef,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-78bbb474-ecad-43a5-b6c3-994b84e131d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-48dbb6d1-4977-4e6f-8c1f-7b7694a0e745,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-2bd7fe67-4b1f-42e9-a7aa-398122876f46,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-743469ba-783e-4a21-992b-97da9374e265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332604873-172.17.0.8-1595856284399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42937,DS-65ac51ad-2533-4fa1-a30c-630699a0e764,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-0f53c2c0-d351-489c-bdbf-1985714d01b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-67359983-b636-437c-9ba3-6c9e5013c2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-498272db-b26e-4bf5-947c-5910dfd48692,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-d32e5b91-6228-4a10-bb7e-d047ce6dee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-de3ce375-b9c7-4dfa-b43a-522b843507d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-b9ed7ccc-01e3-4f3c-9781-1a43d34de433,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-4731dc22-8c91-4619-a044-14a4a696e720,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332604873-172.17.0.8-1595856284399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42937,DS-65ac51ad-2533-4fa1-a30c-630699a0e764,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-0f53c2c0-d351-489c-bdbf-1985714d01b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-67359983-b636-437c-9ba3-6c9e5013c2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-498272db-b26e-4bf5-947c-5910dfd48692,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-d32e5b91-6228-4a10-bb7e-d047ce6dee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-de3ce375-b9c7-4dfa-b43a-522b843507d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-b9ed7ccc-01e3-4f3c-9781-1a43d34de433,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-4731dc22-8c91-4619-a044-14a4a696e720,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827338904-172.17.0.8-1595856419991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43304,DS-58cb4404-513d-499c-ad71-876fe13541b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-124d168b-e1b3-4096-a0ae-9ce326764b01,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-7c9a743b-1925-46f2-9268-2cd68280dfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-a58a6ec5-85ac-45ab-8589-8035abf927e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-74a4853a-35fb-464c-83c4-7c3b5ce695b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-4551be10-500d-4993-a772-4fcad92e9173,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-27ebe767-c841-41e5-9f7d-e66c7200687d,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-72a52f8e-aba5-4b0a-94a9-f963d92125ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827338904-172.17.0.8-1595856419991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43304,DS-58cb4404-513d-499c-ad71-876fe13541b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-124d168b-e1b3-4096-a0ae-9ce326764b01,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-7c9a743b-1925-46f2-9268-2cd68280dfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-a58a6ec5-85ac-45ab-8589-8035abf927e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-74a4853a-35fb-464c-83c4-7c3b5ce695b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-4551be10-500d-4993-a772-4fcad92e9173,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-27ebe767-c841-41e5-9f7d-e66c7200687d,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-72a52f8e-aba5-4b0a-94a9-f963d92125ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003517707-172.17.0.8-1595856920723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38302,DS-bf442f1d-843d-4b37-a039-2c3d3364a70e,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-6e3b2121-4126-4b19-925c-ebb3a73819de,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-d1f94cb8-cf85-479a-8476-954728a7b89e,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-be3820a4-d7e7-46d6-841e-fca088ae2c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-b718728e-13a0-4192-872d-7f5e223a748c,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-e8e4fe49-b182-4e15-a760-6479f36fe034,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-b7024bc3-bfb0-483d-9106-a25a767c1134,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-3363676f-4126-4a7c-b5a8-613f18c9e166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003517707-172.17.0.8-1595856920723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38302,DS-bf442f1d-843d-4b37-a039-2c3d3364a70e,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-6e3b2121-4126-4b19-925c-ebb3a73819de,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-d1f94cb8-cf85-479a-8476-954728a7b89e,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-be3820a4-d7e7-46d6-841e-fca088ae2c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-b718728e-13a0-4192-872d-7f5e223a748c,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-e8e4fe49-b182-4e15-a760-6479f36fe034,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-b7024bc3-bfb0-483d-9106-a25a767c1134,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-3363676f-4126-4a7c-b5a8-613f18c9e166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853125009-172.17.0.8-1595858103964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36822,DS-d06673fa-ed06-4247-bb9a-a67f231f23fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-7256186d-0fdc-45f6-961e-2878982ac1be,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-083c56eb-84e9-421f-8cd0-8f7e5d0f2be1,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-68034d72-960d-4abf-8f72-c73b2587bd25,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-637e4e8b-c0db-4962-b29d-05234efbffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-0be5bbce-12b9-40bc-b2f7-d75f8815cfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-2986512d-0e53-4f88-b42b-49c90e468891,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-253a4e59-7762-42df-8f33-84183d04c4fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853125009-172.17.0.8-1595858103964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36822,DS-d06673fa-ed06-4247-bb9a-a67f231f23fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-7256186d-0fdc-45f6-961e-2878982ac1be,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-083c56eb-84e9-421f-8cd0-8f7e5d0f2be1,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-68034d72-960d-4abf-8f72-c73b2587bd25,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-637e4e8b-c0db-4962-b29d-05234efbffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-0be5bbce-12b9-40bc-b2f7-d75f8815cfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-2986512d-0e53-4f88-b42b-49c90e468891,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-253a4e59-7762-42df-8f33-84183d04c4fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567283937-172.17.0.8-1595858593320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43519,DS-fd0a5016-74b9-406a-91c6-8ad484254908,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-abb75758-1541-45cb-9632-55fd3ef35aca,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-cc414c25-6f79-47e6-88c2-dd08d65cb0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-3814e55e-792b-4a78-8879-65bacc1ea75b,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-3d16b3ca-4a35-4b45-8a16-34c40ee20a90,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-f0ff9935-b801-491b-9c3d-fd72d88871c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-265a6930-21b4-46de-988f-f2167514d224,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-39af8d00-22ef-4561-b4e5-1b03f86b3ffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567283937-172.17.0.8-1595858593320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43519,DS-fd0a5016-74b9-406a-91c6-8ad484254908,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-abb75758-1541-45cb-9632-55fd3ef35aca,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-cc414c25-6f79-47e6-88c2-dd08d65cb0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-3814e55e-792b-4a78-8879-65bacc1ea75b,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-3d16b3ca-4a35-4b45-8a16-34c40ee20a90,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-f0ff9935-b801-491b-9c3d-fd72d88871c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-265a6930-21b4-46de-988f-f2167514d224,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-39af8d00-22ef-4561-b4e5-1b03f86b3ffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369341329-172.17.0.8-1595858662906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37689,DS-093e2f78-6b4c-4721-bc60-6a62ab8ea6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-f33cc8db-bd4e-4834-ae03-3123cedd5287,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-fbb2acd0-c2a5-4368-a1f6-632861d80035,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-1ed2c6b4-ad8c-41f9-adf7-3298c61bf95a,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-50dfaead-8a59-4752-8bf9-f0f4419a7700,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-7267e3f3-0ed8-40b1-9532-abc6f41577e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-d8963117-b03c-4f3d-b1fa-89ab6121f7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-c322d047-864e-48aa-9f89-92f3f926dbde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369341329-172.17.0.8-1595858662906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37689,DS-093e2f78-6b4c-4721-bc60-6a62ab8ea6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-f33cc8db-bd4e-4834-ae03-3123cedd5287,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-fbb2acd0-c2a5-4368-a1f6-632861d80035,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-1ed2c6b4-ad8c-41f9-adf7-3298c61bf95a,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-50dfaead-8a59-4752-8bf9-f0f4419a7700,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-7267e3f3-0ed8-40b1-9532-abc6f41577e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-d8963117-b03c-4f3d-b1fa-89ab6121f7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-c322d047-864e-48aa-9f89-92f3f926dbde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956751759-172.17.0.8-1595858783768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36350,DS-c899bf6a-30c4-4538-8308-8231f159a574,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-c0dc2276-3ac5-4ead-853b-aaad4e44012d,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-df7857e5-7b94-402a-b7af-602800328f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-a9b9437c-e9a4-44cb-b8b4-c5d92ea4130f,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-c8ab0351-0e95-4a77-8a2a-92282bf21d69,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-aa6a4596-ca5c-495e-b96f-2201fa733734,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-09be33de-82ba-4e06-a2c0-236593c7c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-bef0d11a-e983-474f-b08c-78aebbc8fe51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956751759-172.17.0.8-1595858783768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36350,DS-c899bf6a-30c4-4538-8308-8231f159a574,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-c0dc2276-3ac5-4ead-853b-aaad4e44012d,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-df7857e5-7b94-402a-b7af-602800328f77,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-a9b9437c-e9a4-44cb-b8b4-c5d92ea4130f,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-c8ab0351-0e95-4a77-8a2a-92282bf21d69,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-aa6a4596-ca5c-495e-b96f-2201fa733734,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-09be33de-82ba-4e06-a2c0-236593c7c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-bef0d11a-e983-474f-b08c-78aebbc8fe51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5411
