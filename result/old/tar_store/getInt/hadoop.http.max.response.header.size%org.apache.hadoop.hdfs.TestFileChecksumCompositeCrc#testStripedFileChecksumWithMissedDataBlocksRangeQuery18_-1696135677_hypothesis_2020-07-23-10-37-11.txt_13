reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-383955846-172.17.0.6-1595500654095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34745,DS-69b4c028-7e16-4e3d-baa3-599cea31706a,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-a8090e5d-8156-4835-b840-d19638c2ec76,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-2ee50eba-4fbd-49f1-b3ff-6db58c486b66,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-49e8f65f-10a0-457f-ade0-f8a722539aef,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-633f19bd-d8e7-49f8-ba68-910184c31218,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-15e9a2b4-28d2-4e5e-a580-f6684ae59ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-92ab6fb0-5fd9-4a4e-bc05-9a3d4c852c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-4f41ab11-6498-42b7-a4ac-d5320a94793e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-383955846-172.17.0.6-1595500654095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34745,DS-69b4c028-7e16-4e3d-baa3-599cea31706a,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-a8090e5d-8156-4835-b840-d19638c2ec76,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-2ee50eba-4fbd-49f1-b3ff-6db58c486b66,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-49e8f65f-10a0-457f-ade0-f8a722539aef,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-633f19bd-d8e7-49f8-ba68-910184c31218,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-15e9a2b4-28d2-4e5e-a580-f6684ae59ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-92ab6fb0-5fd9-4a4e-bc05-9a3d4c852c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-4f41ab11-6498-42b7-a4ac-d5320a94793e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377973039-172.17.0.6-1595500954912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46615,DS-de1475fc-aae7-4360-90da-ea4e01e8ff14,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-197d6a99-9cad-49f8-8c01-8722d271e118,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-9b5c7f08-ec5c-415b-9aa1-837b4d37f7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-b8dba537-3520-40f7-8361-3607e0318fda,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-700a6217-a5a1-4f03-a89d-dd185b616a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-ee274663-55cc-4a4b-86af-0f3ac0a8db97,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-5217eca3-9ee6-47b3-8dd9-a96f4b617ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-19662b56-c5a8-4a9f-88b3-08fe4a32dd6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377973039-172.17.0.6-1595500954912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46615,DS-de1475fc-aae7-4360-90da-ea4e01e8ff14,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-197d6a99-9cad-49f8-8c01-8722d271e118,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-9b5c7f08-ec5c-415b-9aa1-837b4d37f7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-b8dba537-3520-40f7-8361-3607e0318fda,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-700a6217-a5a1-4f03-a89d-dd185b616a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-ee274663-55cc-4a4b-86af-0f3ac0a8db97,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-5217eca3-9ee6-47b3-8dd9-a96f4b617ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-19662b56-c5a8-4a9f-88b3-08fe4a32dd6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477263211-172.17.0.6-1595501012196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33249,DS-9edb1160-7eff-4d79-9384-98788f0fe5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-67e634ac-80fe-4486-860c-ac29eb6946f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-c0db069c-9f9b-48f4-a91d-ba12dca9203d,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-85ba8030-65c7-421b-972e-9d6c041e1655,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-93ed6e6f-1353-4d59-9e2f-fb1e78cc2096,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-484b2d53-0d5a-422b-a406-31eb837f2fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-faba31bd-cba7-4cf1-8005-ee7aa2f620e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-95dba8d5-c9ed-413e-82c6-7cb0e542aaaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477263211-172.17.0.6-1595501012196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33249,DS-9edb1160-7eff-4d79-9384-98788f0fe5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-67e634ac-80fe-4486-860c-ac29eb6946f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-c0db069c-9f9b-48f4-a91d-ba12dca9203d,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-85ba8030-65c7-421b-972e-9d6c041e1655,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-93ed6e6f-1353-4d59-9e2f-fb1e78cc2096,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-484b2d53-0d5a-422b-a406-31eb837f2fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-faba31bd-cba7-4cf1-8005-ee7aa2f620e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-95dba8d5-c9ed-413e-82c6-7cb0e542aaaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547010602-172.17.0.6-1595501280147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36349,DS-99127ce4-d34f-4fdd-9d9a-680eb47787ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-b30b9a22-56b1-467b-b9e2-0da27e9c5027,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-92a5e8cb-8bd8-461d-8845-ffa218d91df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-e59f4cd2-d5e0-4024-99e5-dee5094da197,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-1b3b78fb-ad84-4275-b302-e9eefa180e36,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-c7a980f5-67b8-4d5c-bf31-8a72d57df676,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-298a8be4-e472-407c-8225-004b4dce237b,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-0b358756-5f99-4229-a889-241243020dd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547010602-172.17.0.6-1595501280147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36349,DS-99127ce4-d34f-4fdd-9d9a-680eb47787ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-b30b9a22-56b1-467b-b9e2-0da27e9c5027,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-92a5e8cb-8bd8-461d-8845-ffa218d91df8,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-e59f4cd2-d5e0-4024-99e5-dee5094da197,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-1b3b78fb-ad84-4275-b302-e9eefa180e36,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-c7a980f5-67b8-4d5c-bf31-8a72d57df676,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-298a8be4-e472-407c-8225-004b4dce237b,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-0b358756-5f99-4229-a889-241243020dd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873266426-172.17.0.6-1595501479397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38442,DS-ce3730fa-df21-476a-be7c-128ce3f5e9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-9040bf78-4f4a-42d8-ba85-d670cacb7a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-5afaa57d-1d2b-43bb-ba89-f4904e767a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-387b94a9-05e9-42c2-85ce-48a6d596206e,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-9d539cb8-a5fa-439a-8409-90719296f2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-28468c31-a8bf-4f5d-b98f-3d0a27d988c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-67c7efd1-0518-4f75-b72d-3864556d4d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-71efe051-aa9c-4eca-b35c-11992eca4b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873266426-172.17.0.6-1595501479397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38442,DS-ce3730fa-df21-476a-be7c-128ce3f5e9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-9040bf78-4f4a-42d8-ba85-d670cacb7a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-5afaa57d-1d2b-43bb-ba89-f4904e767a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-387b94a9-05e9-42c2-85ce-48a6d596206e,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-9d539cb8-a5fa-439a-8409-90719296f2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-28468c31-a8bf-4f5d-b98f-3d0a27d988c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-67c7efd1-0518-4f75-b72d-3864556d4d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-71efe051-aa9c-4eca-b35c-11992eca4b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722298622-172.17.0.6-1595502298263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46254,DS-0cb450db-e2e2-499d-9c76-7d5d9e193646,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-4e18700d-56bf-4f63-994c-26a716caa6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-90102ed0-2c8a-4de6-887e-430920bf4656,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-d9295339-57be-4037-a28d-8869b7e491a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-e29b1e2a-526e-4ca5-8e01-e3a8a922af26,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-d7f296ba-1c49-45fa-aefc-15359c82b568,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-074b1bad-54c2-4825-b043-ef317b96fe82,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-71be9079-93e8-4d8b-87dc-0b600ab9abb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722298622-172.17.0.6-1595502298263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46254,DS-0cb450db-e2e2-499d-9c76-7d5d9e193646,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-4e18700d-56bf-4f63-994c-26a716caa6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-90102ed0-2c8a-4de6-887e-430920bf4656,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-d9295339-57be-4037-a28d-8869b7e491a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-e29b1e2a-526e-4ca5-8e01-e3a8a922af26,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-d7f296ba-1c49-45fa-aefc-15359c82b568,DISK], DatanodeInfoWithStorage[127.0.0.1:38529,DS-074b1bad-54c2-4825-b043-ef317b96fe82,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-71be9079-93e8-4d8b-87dc-0b600ab9abb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301781652-172.17.0.6-1595502351745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37170,DS-c2ede7b5-7563-498e-83e0-968668e97783,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-00799759-d2ca-4373-b9b8-14b4fe2cf3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-a84b464b-31ee-4e86-acd4-40ba5eaae025,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-652ca875-d298-4a7b-be0b-59cf4ab01ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-f8a5c5ed-7abc-4958-9ea3-8a829d090a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-d031f0ac-5144-45a2-aff5-5952a5592e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-e99ce951-bacd-40ac-8aa0-46e2f6f4313d,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-0b15926b-4417-4102-8bba-03f14fa70b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301781652-172.17.0.6-1595502351745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37170,DS-c2ede7b5-7563-498e-83e0-968668e97783,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-00799759-d2ca-4373-b9b8-14b4fe2cf3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-a84b464b-31ee-4e86-acd4-40ba5eaae025,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-652ca875-d298-4a7b-be0b-59cf4ab01ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-f8a5c5ed-7abc-4958-9ea3-8a829d090a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-d031f0ac-5144-45a2-aff5-5952a5592e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-e99ce951-bacd-40ac-8aa0-46e2f6f4313d,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-0b15926b-4417-4102-8bba-03f14fa70b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211013572-172.17.0.6-1595502435492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35229,DS-af031bcf-ade0-40c7-87e1-01e9bb6d220c,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-309920e7-097a-4a5e-89f1-b23e81ca4ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-511d63ac-05e1-40f1-88cc-7c8ecac41bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-42edbc7f-0ad5-48c1-98d0-9c432b313cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-b76f9d49-78ca-45dd-8699-9c4dc5f9cc01,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-c4326772-94a4-4d3f-9200-4209ac5698cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-1d98ec0d-2e92-41f3-bd61-485bb7cb79ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-f206cd5a-da24-4707-a861-7f0cec9d0546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211013572-172.17.0.6-1595502435492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35229,DS-af031bcf-ade0-40c7-87e1-01e9bb6d220c,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-309920e7-097a-4a5e-89f1-b23e81ca4ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-511d63ac-05e1-40f1-88cc-7c8ecac41bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-42edbc7f-0ad5-48c1-98d0-9c432b313cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-b76f9d49-78ca-45dd-8699-9c4dc5f9cc01,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-c4326772-94a4-4d3f-9200-4209ac5698cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-1d98ec0d-2e92-41f3-bd61-485bb7cb79ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-f206cd5a-da24-4707-a861-7f0cec9d0546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728368888-172.17.0.6-1595502608152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46062,DS-3fa68f3b-2269-47c0-a235-180e15f377f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-76c18148-2834-457c-9de4-4c5148b5b20a,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-4a3e5a28-22aa-4ce4-92f3-1b0af856c9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-c5cc0506-6ae5-4220-84c5-1cec48782053,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-2795580b-8f96-416b-9848-3a5f09f42a61,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-4519d54a-117e-434c-bf6c-b16a0da58aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-bb45859a-4649-492f-8333-0d5fd4ed6936,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-58e8da62-0b0e-48c9-b07f-94f40b175d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728368888-172.17.0.6-1595502608152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46062,DS-3fa68f3b-2269-47c0-a235-180e15f377f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-76c18148-2834-457c-9de4-4c5148b5b20a,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-4a3e5a28-22aa-4ce4-92f3-1b0af856c9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-c5cc0506-6ae5-4220-84c5-1cec48782053,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-2795580b-8f96-416b-9848-3a5f09f42a61,DISK], DatanodeInfoWithStorage[127.0.0.1:38949,DS-4519d54a-117e-434c-bf6c-b16a0da58aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-bb45859a-4649-492f-8333-0d5fd4ed6936,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-58e8da62-0b0e-48c9-b07f-94f40b175d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453516221-172.17.0.6-1595503315809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43533,DS-fe259b56-e72d-4300-a56f-6f4e564f6528,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-ad16f65d-7043-439d-8b01-8c268a7fe59e,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-374454f0-cbe1-48b6-a9fa-ecaf2c9367ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-0135b86e-88a3-4016-9b20-ca49d659086c,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-512d0978-330b-4d79-b711-f80c25284220,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-4a853acc-28f6-4aca-8978-03b55065683d,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-8a80e0f9-c469-40d1-b95b-c2ce2005f1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-a481304f-02f9-46c3-9a4e-cc92bd390a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453516221-172.17.0.6-1595503315809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43533,DS-fe259b56-e72d-4300-a56f-6f4e564f6528,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-ad16f65d-7043-439d-8b01-8c268a7fe59e,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-374454f0-cbe1-48b6-a9fa-ecaf2c9367ff,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-0135b86e-88a3-4016-9b20-ca49d659086c,DISK], DatanodeInfoWithStorage[127.0.0.1:33367,DS-512d0978-330b-4d79-b711-f80c25284220,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-4a853acc-28f6-4aca-8978-03b55065683d,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-8a80e0f9-c469-40d1-b95b-c2ce2005f1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-a481304f-02f9-46c3-9a4e-cc92bd390a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156355274-172.17.0.6-1595503411649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42983,DS-6601c377-d696-49b8-aa15-590598acbffa,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-d02b42dd-e97d-4cb5-be53-87769165def9,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-110e8303-33d7-416b-9b97-2761070c7728,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-835463cb-8728-4f65-aade-0d337fa59c55,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-3bcceb02-c088-4cfc-b7fa-a4ef756aa098,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-2801725e-4ab9-4708-ab35-b2623a39f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-2e6864c8-e7bf-4682-bee3-583a7501f9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-6a4f9a80-c43b-44f6-a496-2a1ede4c6835,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156355274-172.17.0.6-1595503411649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42983,DS-6601c377-d696-49b8-aa15-590598acbffa,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-d02b42dd-e97d-4cb5-be53-87769165def9,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-110e8303-33d7-416b-9b97-2761070c7728,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-835463cb-8728-4f65-aade-0d337fa59c55,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-3bcceb02-c088-4cfc-b7fa-a4ef756aa098,DISK], DatanodeInfoWithStorage[127.0.0.1:34981,DS-2801725e-4ab9-4708-ab35-b2623a39f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-2e6864c8-e7bf-4682-bee3-583a7501f9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-6a4f9a80-c43b-44f6-a496-2a1ede4c6835,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032820284-172.17.0.6-1595504367741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46489,DS-95474df9-3ec7-4e3a-985d-59ba17cec297,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-b4fded46-1c2e-4d89-8b2a-dfc3b7e05934,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-8a04905a-a42d-451d-96ad-32991d4ea796,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-ff484f0a-acb9-4c72-b84a-7afb9a971b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-601e4546-0261-430e-9dce-8954c33e04b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-b6edec9b-66a3-497d-bce7-d558cbf48398,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-aed21b6e-c42e-4d93-a285-a068062b9b28,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-632ba832-690a-4f21-af6e-149ad93469ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032820284-172.17.0.6-1595504367741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46489,DS-95474df9-3ec7-4e3a-985d-59ba17cec297,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-b4fded46-1c2e-4d89-8b2a-dfc3b7e05934,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-8a04905a-a42d-451d-96ad-32991d4ea796,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-ff484f0a-acb9-4c72-b84a-7afb9a971b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44849,DS-601e4546-0261-430e-9dce-8954c33e04b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-b6edec9b-66a3-497d-bce7-d558cbf48398,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-aed21b6e-c42e-4d93-a285-a068062b9b28,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-632ba832-690a-4f21-af6e-149ad93469ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531283843-172.17.0.6-1595504555964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35296,DS-824f56a7-d46c-43e0-8115-b1e594cb0783,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-9b2495ab-dd43-4c2e-993b-09e843156e94,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-5e87e55b-f855-408b-8f6e-f8aad5f56cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-59d59ec9-8dbb-435f-9dda-34eeebea16cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-695a3b53-2ad1-4e2e-8364-471b22bedc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-6edc04df-da52-4458-b96c-804e7dc848cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-923f6db4-7a55-4494-883d-6e21b0940b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-aabbbafc-6454-417f-92fe-05f3e93badda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531283843-172.17.0.6-1595504555964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35296,DS-824f56a7-d46c-43e0-8115-b1e594cb0783,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-9b2495ab-dd43-4c2e-993b-09e843156e94,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-5e87e55b-f855-408b-8f6e-f8aad5f56cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-59d59ec9-8dbb-435f-9dda-34eeebea16cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-695a3b53-2ad1-4e2e-8364-471b22bedc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-6edc04df-da52-4458-b96c-804e7dc848cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-923f6db4-7a55-4494-883d-6e21b0940b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-aabbbafc-6454-417f-92fe-05f3e93badda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449239153-172.17.0.6-1595504883306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35743,DS-1dff630b-e677-45ef-a376-5804b62d6515,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-0bce1aaa-919d-497a-92bc-9d837632be46,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-f45aca0c-2218-429e-a294-3420f69d8843,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-4c580959-a25c-4c1b-aa57-ea9ef42c81a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-288f4184-8b49-41d7-942c-d8ffbc85243b,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-d8837d65-6d57-4a47-bce3-9abda4cd47af,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-104c0096-1e80-4d0b-a368-ef1ea9de6f10,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-43519173-ccbe-4c31-98b8-7eb901cf1202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449239153-172.17.0.6-1595504883306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35743,DS-1dff630b-e677-45ef-a376-5804b62d6515,DISK], DatanodeInfoWithStorage[127.0.0.1:43045,DS-0bce1aaa-919d-497a-92bc-9d837632be46,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-f45aca0c-2218-429e-a294-3420f69d8843,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-4c580959-a25c-4c1b-aa57-ea9ef42c81a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-288f4184-8b49-41d7-942c-d8ffbc85243b,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-d8837d65-6d57-4a47-bce3-9abda4cd47af,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-104c0096-1e80-4d0b-a368-ef1ea9de6f10,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-43519173-ccbe-4c31-98b8-7eb901cf1202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81376960-172.17.0.6-1595506311439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39827,DS-ff517f40-f304-4d5c-af90-1491aec31c45,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-0da19636-ad75-48e3-b7f8-0bf1a6935184,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-927828d1-1981-4bb8-bc08-56da2b11a5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-6e30c675-90a2-4818-a624-939e9199465d,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-d2842b32-6dc7-40a5-aa2b-956f6d3cc283,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-84ce0b2d-3d85-4dfd-9e46-ae31c548faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-c3bf6ff9-7310-46f6-8291-84586886811a,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-49433898-34f7-4853-846e-62aab2a1209d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81376960-172.17.0.6-1595506311439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39827,DS-ff517f40-f304-4d5c-af90-1491aec31c45,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-0da19636-ad75-48e3-b7f8-0bf1a6935184,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-927828d1-1981-4bb8-bc08-56da2b11a5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-6e30c675-90a2-4818-a624-939e9199465d,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-d2842b32-6dc7-40a5-aa2b-956f6d3cc283,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-84ce0b2d-3d85-4dfd-9e46-ae31c548faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-c3bf6ff9-7310-46f6-8291-84586886811a,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-49433898-34f7-4853-846e-62aab2a1209d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360130579-172.17.0.6-1595507354313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37615,DS-7901d3ce-a912-4733-a005-7b1dc2d1c7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-abfc4369-f48d-44c9-ba7e-48926388cd57,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-79136ebd-8b1e-4259-b374-b886f6d928ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-60001f77-a5c5-4acf-8fad-19bd8850e97f,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-56dccece-f441-4729-9c5b-e34ac4ff09ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-a1a54b8a-596a-4238-96a9-ff566562c4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-b08d2e34-e55d-4bd7-9394-04b9722c09b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-d64701df-fa45-4d64-a790-911601ddec56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1360130579-172.17.0.6-1595507354313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37615,DS-7901d3ce-a912-4733-a005-7b1dc2d1c7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-abfc4369-f48d-44c9-ba7e-48926388cd57,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-79136ebd-8b1e-4259-b374-b886f6d928ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-60001f77-a5c5-4acf-8fad-19bd8850e97f,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-56dccece-f441-4729-9c5b-e34ac4ff09ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-a1a54b8a-596a-4238-96a9-ff566562c4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-b08d2e34-e55d-4bd7-9394-04b9722c09b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-d64701df-fa45-4d64-a790-911601ddec56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6925
