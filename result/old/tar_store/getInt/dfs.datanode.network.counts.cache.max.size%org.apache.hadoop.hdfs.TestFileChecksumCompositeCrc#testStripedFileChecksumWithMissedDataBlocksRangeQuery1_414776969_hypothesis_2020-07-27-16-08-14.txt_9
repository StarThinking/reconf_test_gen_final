reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084173763-172.17.0.18-1595866284082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37822,DS-d8d7f36d-af78-40b8-82c9-eb5c78bfe72c,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-b64fe81c-c81c-4e06-95b3-93f0bdc4034c,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-65b44d81-9495-4d0c-9429-3cee5ad3e3da,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-aee7bd25-39b1-40c8-ac5f-fa2c491a1389,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-0732fa1f-fbdb-4629-b814-a3b943a9cf05,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-3cc6b9fd-e1dc-424f-a168-3651fde60fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-81786bed-803f-40d3-afc8-d51d8b108b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-b2bfde31-e643-4df6-9f87-5e9dbb0cf44b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084173763-172.17.0.18-1595866284082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37822,DS-d8d7f36d-af78-40b8-82c9-eb5c78bfe72c,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-b64fe81c-c81c-4e06-95b3-93f0bdc4034c,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-65b44d81-9495-4d0c-9429-3cee5ad3e3da,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-aee7bd25-39b1-40c8-ac5f-fa2c491a1389,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-0732fa1f-fbdb-4629-b814-a3b943a9cf05,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-3cc6b9fd-e1dc-424f-a168-3651fde60fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-81786bed-803f-40d3-afc8-d51d8b108b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-b2bfde31-e643-4df6-9f87-5e9dbb0cf44b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581624439-172.17.0.18-1595866359900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42568,DS-1c251727-0bc7-401f-912e-485469d65375,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-152bedf5-a12b-49fd-ae51-5cc9dd9797b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-9a9fb4a2-a6b8-4560-be35-714ea2f9b772,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-b7316ae7-8911-4f36-8740-7ff5faa3fbee,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-5b0e2155-1f59-4034-b32a-3de996517ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-f2778291-8185-425f-8d43-c05f68a5a180,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-bb86fce1-245c-47d8-82f2-bfddb0f61bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-106084b8-56bf-46b8-bb84-5e679f8bd6ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581624439-172.17.0.18-1595866359900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42568,DS-1c251727-0bc7-401f-912e-485469d65375,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-152bedf5-a12b-49fd-ae51-5cc9dd9797b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-9a9fb4a2-a6b8-4560-be35-714ea2f9b772,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-b7316ae7-8911-4f36-8740-7ff5faa3fbee,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-5b0e2155-1f59-4034-b32a-3de996517ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-f2778291-8185-425f-8d43-c05f68a5a180,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-bb86fce1-245c-47d8-82f2-bfddb0f61bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-106084b8-56bf-46b8-bb84-5e679f8bd6ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824537675-172.17.0.18-1595866552919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41887,DS-1e43aa8e-a461-418e-b31a-7d3bae10993a,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-b60a0181-1073-4102-a6e1-3e13774d815e,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-33436b53-6f98-4e78-a7de-4f47fa07f179,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-6f913cad-c5a7-4c47-bc98-b695cb57a5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-27365295-d1a0-4f76-8c38-a04c16fed814,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-168ed661-6e1d-4c42-a536-4ae9c7ec0429,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-e8a8720f-d317-4167-8676-81c7258f73e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-d1370abb-8035-49fa-ad86-c77ca0a3f505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1824537675-172.17.0.18-1595866552919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41887,DS-1e43aa8e-a461-418e-b31a-7d3bae10993a,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-b60a0181-1073-4102-a6e1-3e13774d815e,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-33436b53-6f98-4e78-a7de-4f47fa07f179,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-6f913cad-c5a7-4c47-bc98-b695cb57a5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-27365295-d1a0-4f76-8c38-a04c16fed814,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-168ed661-6e1d-4c42-a536-4ae9c7ec0429,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-e8a8720f-d317-4167-8676-81c7258f73e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-d1370abb-8035-49fa-ad86-c77ca0a3f505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921517795-172.17.0.18-1595866924780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45854,DS-68e35cde-2f1e-429b-8cab-f59fa6e71c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-2b094257-027a-4be5-933b-9baa2122ab2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-3ea02414-c119-442c-b983-a07e260e15bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-6baa4bcb-aabc-4a4e-8a7c-2b7961218a12,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-2ba4aeec-229a-4ea3-bfe6-9290d9e44b03,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-bec44121-421a-4b09-a9dd-e8a7023c76bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-e0ef40d9-de37-4558-a6e3-02f5fa4dc032,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-e165a24c-ffa7-4b44-98df-2a34a3e964b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921517795-172.17.0.18-1595866924780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45854,DS-68e35cde-2f1e-429b-8cab-f59fa6e71c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-2b094257-027a-4be5-933b-9baa2122ab2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-3ea02414-c119-442c-b983-a07e260e15bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-6baa4bcb-aabc-4a4e-8a7c-2b7961218a12,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-2ba4aeec-229a-4ea3-bfe6-9290d9e44b03,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-bec44121-421a-4b09-a9dd-e8a7023c76bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-e0ef40d9-de37-4558-a6e3-02f5fa4dc032,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-e165a24c-ffa7-4b44-98df-2a34a3e964b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483884682-172.17.0.18-1595867178297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34125,DS-444beaf8-af9c-4b50-8d68-7e7464d71038,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-43126df4-6949-447b-b146-ac5706233d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-1f674676-043f-4a3d-b048-80cdb82fd258,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-0655783e-9b30-4a26-9af3-bd526713145f,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-d52deae3-5025-443c-937c-5c844b475c84,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-8f7ae9e7-7f81-4b88-baf0-cfb4eb8fd228,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-15dd3d71-439b-473f-92ab-da45f02e6062,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-8c44eee5-a0a6-4a55-a7a9-28f010152862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483884682-172.17.0.18-1595867178297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34125,DS-444beaf8-af9c-4b50-8d68-7e7464d71038,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-43126df4-6949-447b-b146-ac5706233d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-1f674676-043f-4a3d-b048-80cdb82fd258,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-0655783e-9b30-4a26-9af3-bd526713145f,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-d52deae3-5025-443c-937c-5c844b475c84,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-8f7ae9e7-7f81-4b88-baf0-cfb4eb8fd228,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-15dd3d71-439b-473f-92ab-da45f02e6062,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-8c44eee5-a0a6-4a55-a7a9-28f010152862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941953500-172.17.0.18-1595867942841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40994,DS-0562f0f9-940b-4dcb-919d-356e37d5b2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-c4eb4962-0335-4f24-9549-14c93bf40270,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-7d57e962-f31d-42a3-bb5a-c232014e22bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-248de837-b098-46aa-9621-fde330da3b23,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-e731eda0-6095-428e-85f6-cdaf0807b359,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-75da6422-665b-493d-8985-5a52010a3355,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-ad62b3d2-5405-4ee2-8fe0-872a3be1b4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-66e5096e-1583-423b-87b3-ed60527ce899,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941953500-172.17.0.18-1595867942841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40994,DS-0562f0f9-940b-4dcb-919d-356e37d5b2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-c4eb4962-0335-4f24-9549-14c93bf40270,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-7d57e962-f31d-42a3-bb5a-c232014e22bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-248de837-b098-46aa-9621-fde330da3b23,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-e731eda0-6095-428e-85f6-cdaf0807b359,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-75da6422-665b-493d-8985-5a52010a3355,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-ad62b3d2-5405-4ee2-8fe0-872a3be1b4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-66e5096e-1583-423b-87b3-ed60527ce899,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431789348-172.17.0.18-1595868189327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41635,DS-95e842c0-dcd6-44c8-a26a-8f8a983d7f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-016b6c83-3fef-4ab0-b74a-0be1f264dd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-ea18a5f4-2903-4229-880a-8b924225bfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-ddc97da0-629c-4ade-b1e2-63ac98d80585,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-5e044cb5-cede-4d6c-aee2-d7adc788850c,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-7f8d81e7-5eb3-47bc-a45b-0f4ba6f3b984,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-f350e485-45b8-4e51-9de9-b028780ff64a,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-452d011e-2b41-4d0c-abf1-5c7f491c3cfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431789348-172.17.0.18-1595868189327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41635,DS-95e842c0-dcd6-44c8-a26a-8f8a983d7f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-016b6c83-3fef-4ab0-b74a-0be1f264dd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-ea18a5f4-2903-4229-880a-8b924225bfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-ddc97da0-629c-4ade-b1e2-63ac98d80585,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-5e044cb5-cede-4d6c-aee2-d7adc788850c,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-7f8d81e7-5eb3-47bc-a45b-0f4ba6f3b984,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-f350e485-45b8-4e51-9de9-b028780ff64a,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-452d011e-2b41-4d0c-abf1-5c7f491c3cfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593426826-172.17.0.18-1595868562245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40197,DS-b31ab8af-91e6-44fb-a333-b1e8e9f2dfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-3d08514e-812e-41c1-b35d-b080fbb7e8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-4ae968fd-fbb9-43da-9327-9c7b68598833,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-80cc2128-71c1-483b-be97-71bc4b6f3954,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-fb0fdb16-b502-4025-9923-5c093a256180,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-0f30ea36-cd61-4542-8398-16cfbde455d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-be1eb724-076e-4536-92b4-ddb99af49319,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-8ac1e183-bd30-4d26-b08d-ef8c5e521cf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593426826-172.17.0.18-1595868562245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40197,DS-b31ab8af-91e6-44fb-a333-b1e8e9f2dfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-3d08514e-812e-41c1-b35d-b080fbb7e8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-4ae968fd-fbb9-43da-9327-9c7b68598833,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-80cc2128-71c1-483b-be97-71bc4b6f3954,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-fb0fdb16-b502-4025-9923-5c093a256180,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-0f30ea36-cd61-4542-8398-16cfbde455d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-be1eb724-076e-4536-92b4-ddb99af49319,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-8ac1e183-bd30-4d26-b08d-ef8c5e521cf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879736974-172.17.0.18-1595868778015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40379,DS-81016e44-777c-4a8f-9ddf-f05d7422bb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-83a83876-2813-475c-96fd-4abb1bbb3dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-552879bb-bc2a-45c2-8531-8b293382c6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-ba27cc43-b652-41d7-9a97-ef5bc26e6c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-8b59a56f-6522-4623-a5a7-ce069477cb33,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-cecd544d-45ff-4196-9e77-0e021d25570c,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-ae9a8cb4-9d67-4609-95f7-a74e8ea67908,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-fad49dfe-be68-446c-98e2-9a90981fc89a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-879736974-172.17.0.18-1595868778015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40379,DS-81016e44-777c-4a8f-9ddf-f05d7422bb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-83a83876-2813-475c-96fd-4abb1bbb3dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-552879bb-bc2a-45c2-8531-8b293382c6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-ba27cc43-b652-41d7-9a97-ef5bc26e6c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-8b59a56f-6522-4623-a5a7-ce069477cb33,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-cecd544d-45ff-4196-9e77-0e021d25570c,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-ae9a8cb4-9d67-4609-95f7-a74e8ea67908,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-fad49dfe-be68-446c-98e2-9a90981fc89a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647654725-172.17.0.18-1595868951562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38572,DS-51a43d8e-e2af-40bc-8677-aadd3e82ba1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-da460a1a-a651-4336-86d6-dd52cc6f1263,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-fe141d63-f363-4252-ac0a-57a8a74174f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-aed60a3f-a00c-41bb-a18a-879ed8509616,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-b94a412d-a755-4984-b043-ad82a2177928,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-9df104a0-bcfe-43c9-9dae-4d9cbd65fd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-6301d901-7e20-4a50-ba6e-ecb6e17db192,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-25f44a1b-7c7e-42e6-b432-0cde60eecd4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647654725-172.17.0.18-1595868951562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38572,DS-51a43d8e-e2af-40bc-8677-aadd3e82ba1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-da460a1a-a651-4336-86d6-dd52cc6f1263,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-fe141d63-f363-4252-ac0a-57a8a74174f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-aed60a3f-a00c-41bb-a18a-879ed8509616,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-b94a412d-a755-4984-b043-ad82a2177928,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-9df104a0-bcfe-43c9-9dae-4d9cbd65fd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-6301d901-7e20-4a50-ba6e-ecb6e17db192,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-25f44a1b-7c7e-42e6-b432-0cde60eecd4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550653529-172.17.0.18-1595869278655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46628,DS-b777558a-b187-40d2-a13c-8a3fdf96e254,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-c1299ca9-8db4-41fd-98be-a3c7e266e35f,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-1bae3458-ecc6-4aab-b999-c432722d4997,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-5ebe1bcd-21a5-4060-a94f-2efbf915ae44,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-3f4e3801-800f-46bd-8f0e-85602fbac7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-b9a812d3-9aca-4799-bcce-54811e9af157,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-9243d72f-40a2-431b-88d0-c1fddba449d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-ccb89b0c-df37-4b36-8f48-a44d192d6305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550653529-172.17.0.18-1595869278655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46628,DS-b777558a-b187-40d2-a13c-8a3fdf96e254,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-c1299ca9-8db4-41fd-98be-a3c7e266e35f,DISK], DatanodeInfoWithStorage[127.0.0.1:42805,DS-1bae3458-ecc6-4aab-b999-c432722d4997,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-5ebe1bcd-21a5-4060-a94f-2efbf915ae44,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-3f4e3801-800f-46bd-8f0e-85602fbac7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-b9a812d3-9aca-4799-bcce-54811e9af157,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-9243d72f-40a2-431b-88d0-c1fddba449d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-ccb89b0c-df37-4b36-8f48-a44d192d6305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382566421-172.17.0.18-1595869522229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33268,DS-a1a8d6d5-905f-4f9c-bae5-de5b5f2a6879,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-d8d2ee68-10c8-431f-9f65-47bf66d72a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-61c9efe4-545c-476b-ba19-2c89131e29cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-c7cec423-d053-4287-8d6d-818d97424a14,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-77f1a574-3a03-406e-b701-f89d8eae7549,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-70708068-ff9a-4d78-867e-08f6dbab6c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-27b4b39b-26d9-4bfd-936f-4de9804957f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-d666cd3b-d372-4a10-aeff-65c12bb0489c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382566421-172.17.0.18-1595869522229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33268,DS-a1a8d6d5-905f-4f9c-bae5-de5b5f2a6879,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-d8d2ee68-10c8-431f-9f65-47bf66d72a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-61c9efe4-545c-476b-ba19-2c89131e29cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-c7cec423-d053-4287-8d6d-818d97424a14,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-77f1a574-3a03-406e-b701-f89d8eae7549,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-70708068-ff9a-4d78-867e-08f6dbab6c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-27b4b39b-26d9-4bfd-936f-4de9804957f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-d666cd3b-d372-4a10-aeff-65c12bb0489c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518231887-172.17.0.18-1595869598217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46778,DS-2b52d13a-076a-4eba-89ec-dcf0d8628c65,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-59884336-0cdf-4903-9834-857f900381c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-5257bd25-739c-4d98-8e0e-0adea5d2380a,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-5b29db25-9403-4ebb-b452-5b9475f6b79f,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-b35fae47-f523-4570-90de-df14b8c335f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-8e07ec6f-3e31-4472-8579-ea0378c1b7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-b1e59123-5c0d-4932-826d-5dc7e8e1bd52,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-75b6945f-e7eb-4368-b1dd-ad55f1966d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518231887-172.17.0.18-1595869598217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46778,DS-2b52d13a-076a-4eba-89ec-dcf0d8628c65,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-59884336-0cdf-4903-9834-857f900381c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-5257bd25-739c-4d98-8e0e-0adea5d2380a,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-5b29db25-9403-4ebb-b452-5b9475f6b79f,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-b35fae47-f523-4570-90de-df14b8c335f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40831,DS-8e07ec6f-3e31-4472-8579-ea0378c1b7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-b1e59123-5c0d-4932-826d-5dc7e8e1bd52,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-75b6945f-e7eb-4368-b1dd-ad55f1966d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261637544-172.17.0.18-1595869946757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42831,DS-17a23451-10d9-45f8-a025-918e44147c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-9a2afe2b-a803-4f0f-8c4e-4e26a0ef8053,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-651f36b7-84be-466e-8d4f-d173f55ba310,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-59e6eb19-c497-4509-8c0f-a1f7019523af,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-319ead70-f55c-4bec-aeea-7abbbbd20a72,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-134f0848-cc9c-4d8f-9079-00c257249a42,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-928b9810-affa-45e7-84ac-608488dae5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-2344f398-02aa-4e12-a176-28dede4a9daa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261637544-172.17.0.18-1595869946757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42831,DS-17a23451-10d9-45f8-a025-918e44147c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-9a2afe2b-a803-4f0f-8c4e-4e26a0ef8053,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-651f36b7-84be-466e-8d4f-d173f55ba310,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-59e6eb19-c497-4509-8c0f-a1f7019523af,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-319ead70-f55c-4bec-aeea-7abbbbd20a72,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-134f0848-cc9c-4d8f-9079-00c257249a42,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-928b9810-affa-45e7-84ac-608488dae5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-2344f398-02aa-4e12-a176-28dede4a9daa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572861683-172.17.0.18-1595870167203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40452,DS-a9538737-8d7a-4843-b4e6-bb8cbff5d7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-8e480e9b-5d8a-4ac4-928f-4689c3cc0dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-6c2315cc-aa74-4689-ae44-f93405d908ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-d1883cdf-abec-4c68-95fa-fa2f2e4c28d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-e6732318-c09d-4f9b-8713-977d944c9994,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-ab0d3bab-e18e-48de-9c5c-baa071d475d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-f68e25da-3113-4121-a0b1-ffa9b66ae65b,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-ce4bbdbc-15c1-40fb-8531-6f00f00d2fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572861683-172.17.0.18-1595870167203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40452,DS-a9538737-8d7a-4843-b4e6-bb8cbff5d7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-8e480e9b-5d8a-4ac4-928f-4689c3cc0dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-6c2315cc-aa74-4689-ae44-f93405d908ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-d1883cdf-abec-4c68-95fa-fa2f2e4c28d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-e6732318-c09d-4f9b-8713-977d944c9994,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-ab0d3bab-e18e-48de-9c5c-baa071d475d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-f68e25da-3113-4121-a0b1-ffa9b66ae65b,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-ce4bbdbc-15c1-40fb-8531-6f00f00d2fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554873751-172.17.0.18-1595870548474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43150,DS-6af8b54d-bdf2-49d6-9d98-003d38ec43f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-cc8f3247-b2aa-4571-99d4-fb4f82077815,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-d95bda2d-178b-4eab-b89c-38fb650298d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-cd420580-a4da-4659-aa7c-365f06568719,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-32f73154-7974-4511-8e87-8b9163be40a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-9192dc57-ecd3-4e57-80a7-e9611e3dec57,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-2e71f5b7-cada-46f9-8c8f-57d558c8b59d,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-cb3e7b0f-7086-4860-aa07-5604666b8542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554873751-172.17.0.18-1595870548474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43150,DS-6af8b54d-bdf2-49d6-9d98-003d38ec43f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-cc8f3247-b2aa-4571-99d4-fb4f82077815,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-d95bda2d-178b-4eab-b89c-38fb650298d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-cd420580-a4da-4659-aa7c-365f06568719,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-32f73154-7974-4511-8e87-8b9163be40a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-9192dc57-ecd3-4e57-80a7-e9611e3dec57,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-2e71f5b7-cada-46f9-8c8f-57d558c8b59d,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-cb3e7b0f-7086-4860-aa07-5604666b8542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936689522-172.17.0.18-1595870588500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38713,DS-462c5339-bb6a-4335-a74a-968614718841,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-d3b51cd3-91f8-4086-b237-6921343614a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-c4c992b8-33df-47d1-8f00-ddbd468f4fff,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-a65221f2-35f3-4bb2-9c9a-f1e153e34215,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-ea5c5d5e-f51c-4ffb-a377-cebac6df6221,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-bd6b068a-df6c-4d1d-9663-0bdc50be9103,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-a54961c7-dd29-409d-a126-9bfac6851456,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-2359282c-8c14-4ec8-8c59-5b7eba8bb3cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936689522-172.17.0.18-1595870588500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38713,DS-462c5339-bb6a-4335-a74a-968614718841,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-d3b51cd3-91f8-4086-b237-6921343614a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-c4c992b8-33df-47d1-8f00-ddbd468f4fff,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-a65221f2-35f3-4bb2-9c9a-f1e153e34215,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-ea5c5d5e-f51c-4ffb-a377-cebac6df6221,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-bd6b068a-df6c-4d1d-9663-0bdc50be9103,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-a54961c7-dd29-409d-a126-9bfac6851456,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-2359282c-8c14-4ec8-8c59-5b7eba8bb3cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923228743-172.17.0.18-1595870872558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45127,DS-41700bb1-42b9-475f-accf-0d0e9e135152,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-7e4975a6-d478-4876-9e76-c1fd181942b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-fe5908b0-e93a-44d9-91ff-e9fbebcb9145,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-56f77237-9336-4bdc-945f-b75b421a5e12,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-c03fbba8-101d-4030-b36e-fac67be8f66d,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-ae4fc6f6-5e24-458d-b6c5-6d32945f1f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-020f1934-87f6-4814-977b-663563b901eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-9a841713-5616-411d-9833-49ff6895f13c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923228743-172.17.0.18-1595870872558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45127,DS-41700bb1-42b9-475f-accf-0d0e9e135152,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-7e4975a6-d478-4876-9e76-c1fd181942b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-fe5908b0-e93a-44d9-91ff-e9fbebcb9145,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-56f77237-9336-4bdc-945f-b75b421a5e12,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-c03fbba8-101d-4030-b36e-fac67be8f66d,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-ae4fc6f6-5e24-458d-b6c5-6d32945f1f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-020f1934-87f6-4814-977b-663563b901eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-9a841713-5616-411d-9833-49ff6895f13c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520186946-172.17.0.18-1595870945154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39261,DS-dc09b7d9-91ae-4c66-a2c8-16f835510037,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-7df1ccc7-95ce-42bb-9287-6bd0eff97fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-af61512d-91e4-4add-bdd8-11c28332b561,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-3b61c4f1-3355-4cf3-b1c6-d77993736717,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-2217c3cf-c2b6-4627-97c5-c2f749b4465a,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-65f8882d-ab45-4f29-b16d-d08882d2c971,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-cbe0d9d1-2465-42a6-8f05-08d321efadb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-446c925e-9f83-47f5-8864-ec48eced4915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520186946-172.17.0.18-1595870945154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39261,DS-dc09b7d9-91ae-4c66-a2c8-16f835510037,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-7df1ccc7-95ce-42bb-9287-6bd0eff97fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-af61512d-91e4-4add-bdd8-11c28332b561,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-3b61c4f1-3355-4cf3-b1c6-d77993736717,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-2217c3cf-c2b6-4627-97c5-c2f749b4465a,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-65f8882d-ab45-4f29-b16d-d08882d2c971,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-cbe0d9d1-2465-42a6-8f05-08d321efadb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-446c925e-9f83-47f5-8864-ec48eced4915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008692816-172.17.0.18-1595871056164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34459,DS-4f2904c9-9c54-4f6c-a5f9-6009ca1f38c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-e6a54b46-b782-47a0-9224-979d1c702a38,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-4fb9177e-bf10-451d-99cc-e123d4a1e9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-d5bee260-ad00-4c1e-8f6f-3202744f6e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-37bdf1bc-94e2-45b3-88d2-711c86f67614,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-1858bc8d-b586-4afb-b1a6-19b0cf03152f,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-df27efa4-8f8f-4ab3-912d-271ee8bf2301,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-c7184321-ec22-4134-a379-f7199e9038b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008692816-172.17.0.18-1595871056164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34459,DS-4f2904c9-9c54-4f6c-a5f9-6009ca1f38c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-e6a54b46-b782-47a0-9224-979d1c702a38,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-4fb9177e-bf10-451d-99cc-e123d4a1e9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-d5bee260-ad00-4c1e-8f6f-3202744f6e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-37bdf1bc-94e2-45b3-88d2-711c86f67614,DISK], DatanodeInfoWithStorage[127.0.0.1:44132,DS-1858bc8d-b586-4afb-b1a6-19b0cf03152f,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-df27efa4-8f8f-4ab3-912d-271ee8bf2301,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-c7184321-ec22-4134-a379-f7199e9038b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 1
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081226606-172.17.0.18-1595871379650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34011,DS-1a66690d-1e4c-441e-b721-fda4576c0386,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-7a2c8e30-819f-46d2-9933-81247e3a77e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-b559b46b-c22f-46bc-a1cf-d4245a8dd335,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-7adae7b2-c9a4-4ca9-a899-5d6d24041c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-88578887-887e-47d3-984f-c56f63618f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-5f129f16-be8c-4845-9d95-8bf4644a4c42,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-76b4c924-1624-4746-9345-ed3fed6e259e,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-13694857-2a3c-487b-9334-67fb06b2837d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081226606-172.17.0.18-1595871379650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34011,DS-1a66690d-1e4c-441e-b721-fda4576c0386,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-7a2c8e30-819f-46d2-9933-81247e3a77e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-b559b46b-c22f-46bc-a1cf-d4245a8dd335,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-7adae7b2-c9a4-4ca9-a899-5d6d24041c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-88578887-887e-47d3-984f-c56f63618f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-5f129f16-be8c-4845-9d95-8bf4644a4c42,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-76b4c924-1624-4746-9345-ed3fed6e259e,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-13694857-2a3c-487b-9334-67fb06b2837d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5531
