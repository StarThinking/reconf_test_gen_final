reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266594579-172.17.0.10-1595571594857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42242,DS-c252c9dd-6717-4727-9526-cf0fa4841834,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-9efcc101-e86d-42b8-a659-46a0dd57970f,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-a55db6c2-7e62-49a6-be32-f21d2300ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-2ba1b199-3cdc-4fc0-80fa-e7e6227f2648,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-c43f2bff-e834-4e48-bf0f-3f4efe6b28f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-3fc15a27-6f54-4da3-ac01-1fd7cb69c253,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-e6fb3d9f-a28c-4dbb-941b-7cc631513992,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-b8eb4223-8cf2-431d-97f0-40a9544c5acb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266594579-172.17.0.10-1595571594857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42242,DS-c252c9dd-6717-4727-9526-cf0fa4841834,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-9efcc101-e86d-42b8-a659-46a0dd57970f,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-a55db6c2-7e62-49a6-be32-f21d2300ecfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-2ba1b199-3cdc-4fc0-80fa-e7e6227f2648,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-c43f2bff-e834-4e48-bf0f-3f4efe6b28f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-3fc15a27-6f54-4da3-ac01-1fd7cb69c253,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-e6fb3d9f-a28c-4dbb-941b-7cc631513992,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-b8eb4223-8cf2-431d-97f0-40a9544c5acb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428324500-172.17.0.10-1595572317825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46185,DS-b86147c8-9670-4363-b313-5997537190fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-d63be8ca-3518-4b41-884e-1e950eb0c630,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-4bc850eb-10c6-4d98-9515-4e58a239c9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-a06b0d0f-1978-4f80-b776-cad71a4f3d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-79fa563c-336c-415a-9c12-0826c74e134e,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-aeda008f-dea2-4387-bb59-3db57dbaf6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-3212c1f2-249a-411b-aa91-5f77feb62faf,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-08aa4de2-9bbf-406d-b3ce-e55498bf9128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428324500-172.17.0.10-1595572317825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46185,DS-b86147c8-9670-4363-b313-5997537190fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-d63be8ca-3518-4b41-884e-1e950eb0c630,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-4bc850eb-10c6-4d98-9515-4e58a239c9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-a06b0d0f-1978-4f80-b776-cad71a4f3d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-79fa563c-336c-415a-9c12-0826c74e134e,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-aeda008f-dea2-4387-bb59-3db57dbaf6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-3212c1f2-249a-411b-aa91-5f77feb62faf,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-08aa4de2-9bbf-406d-b3ce-e55498bf9128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806290007-172.17.0.10-1595572997077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42607,DS-d72ada15-8465-40ae-9edb-7292d795b57d,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-e63f5717-394d-45bb-bc28-d7e383fc125f,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-2e78725d-a7ed-463a-8c12-114af0e69dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-39665afa-7e4d-483f-a90c-76f3558de0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-b5745319-3de7-4769-858e-c19ca650aaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-e133b3b3-84e0-4d73-9d25-8feed40805fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-6b8bdd92-8c70-4358-b861-0c6424e569ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-e9412db6-1758-4e23-87ab-05451da303fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-806290007-172.17.0.10-1595572997077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42607,DS-d72ada15-8465-40ae-9edb-7292d795b57d,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-e63f5717-394d-45bb-bc28-d7e383fc125f,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-2e78725d-a7ed-463a-8c12-114af0e69dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34006,DS-39665afa-7e4d-483f-a90c-76f3558de0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-b5745319-3de7-4769-858e-c19ca650aaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-e133b3b3-84e0-4d73-9d25-8feed40805fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-6b8bdd92-8c70-4358-b861-0c6424e569ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-e9412db6-1758-4e23-87ab-05451da303fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-215818582-172.17.0.10-1595573067249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39224,DS-a54715e5-84d2-4f55-a6e8-41b83b1dfed9,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-9118c5f0-c453-4cf4-8a0f-4aba739a9035,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-d3ce8c0c-9116-4796-9793-67fbacce7a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-e6411bdb-518b-4bca-9a56-b46f378b8cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-e854b561-8a3f-4b2d-8d2c-a72ffb0b5ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-d070ff55-e24f-4337-9d08-deb1fe0ddf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-773bb72a-fbee-475b-81b8-b9e3a87db29c,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-e876efae-ee39-43c3-9604-2837305dfa56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-215818582-172.17.0.10-1595573067249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39224,DS-a54715e5-84d2-4f55-a6e8-41b83b1dfed9,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-9118c5f0-c453-4cf4-8a0f-4aba739a9035,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-d3ce8c0c-9116-4796-9793-67fbacce7a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-e6411bdb-518b-4bca-9a56-b46f378b8cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-e854b561-8a3f-4b2d-8d2c-a72ffb0b5ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-d070ff55-e24f-4337-9d08-deb1fe0ddf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-773bb72a-fbee-475b-81b8-b9e3a87db29c,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-e876efae-ee39-43c3-9604-2837305dfa56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143998445-172.17.0.10-1595573104107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37134,DS-605b6c24-9b24-46f2-9b5f-8fea1702b436,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-3187a9b6-089a-4a61-b317-d577596cc807,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-5d36bafa-f300-453f-9e4c-76430df19dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-70856133-f5eb-44b3-8b96-cce219937f75,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-7c4be3d5-251e-4648-b2f4-41cd2e993525,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-b3a6abca-2b72-482b-8a94-88194e45501e,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-b55f4397-50bd-4c1a-8cce-bd3ecec7b0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-ae335cae-42fe-4767-92bb-3d0524eb0413,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143998445-172.17.0.10-1595573104107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37134,DS-605b6c24-9b24-46f2-9b5f-8fea1702b436,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-3187a9b6-089a-4a61-b317-d577596cc807,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-5d36bafa-f300-453f-9e4c-76430df19dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-70856133-f5eb-44b3-8b96-cce219937f75,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-7c4be3d5-251e-4648-b2f4-41cd2e993525,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-b3a6abca-2b72-482b-8a94-88194e45501e,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-b55f4397-50bd-4c1a-8cce-bd3ecec7b0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-ae335cae-42fe-4767-92bb-3d0524eb0413,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468776051-172.17.0.10-1595573412755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41566,DS-aebb02a2-8c55-4095-a71b-6a005b740443,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-9bbc2d63-a9d2-4861-a2f2-9254f4f6eb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-dc810833-8a34-433e-bd7d-586da7d333aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-b7180abf-ba54-49fb-acc3-8b98e5841d86,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-7d32a5c3-564b-462c-9252-80fa0b8eff72,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-9b0f32fe-7c32-4e9d-b7b9-9ce8069efaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-67aa53ad-5e46-43f5-bec4-cff1e2b34e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-26c31b85-cbd1-4a88-9034-7c7898c8829c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468776051-172.17.0.10-1595573412755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41566,DS-aebb02a2-8c55-4095-a71b-6a005b740443,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-9bbc2d63-a9d2-4861-a2f2-9254f4f6eb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-dc810833-8a34-433e-bd7d-586da7d333aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-b7180abf-ba54-49fb-acc3-8b98e5841d86,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-7d32a5c3-564b-462c-9252-80fa0b8eff72,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-9b0f32fe-7c32-4e9d-b7b9-9ce8069efaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-67aa53ad-5e46-43f5-bec4-cff1e2b34e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-26c31b85-cbd1-4a88-9034-7c7898c8829c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851837797-172.17.0.10-1595573708954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-d2a5dedf-41c3-4dae-aa1e-d3ab18845d58,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-d5c37e7a-86be-49e3-9dd6-9897a34a7b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-37415d1c-9897-42aa-a9b4-de86a835cec4,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-fcbe6afc-dd4e-4ef4-bc01-7ac3168b3c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-50715533-2ddf-414c-a30f-8933a905d7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-1aab08c3-20f7-4d88-922c-cb2a923a1036,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-c886dbf8-6ada-4087-ad6f-f98969cb4d37,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-41650846-fd3f-4736-b496-ee4ab8ac34f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851837797-172.17.0.10-1595573708954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-d2a5dedf-41c3-4dae-aa1e-d3ab18845d58,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-d5c37e7a-86be-49e3-9dd6-9897a34a7b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-37415d1c-9897-42aa-a9b4-de86a835cec4,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-fcbe6afc-dd4e-4ef4-bc01-7ac3168b3c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-50715533-2ddf-414c-a30f-8933a905d7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-1aab08c3-20f7-4d88-922c-cb2a923a1036,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-c886dbf8-6ada-4087-ad6f-f98969cb4d37,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-41650846-fd3f-4736-b496-ee4ab8ac34f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048160691-172.17.0.10-1595573816331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46654,DS-4a75df80-8c4a-431a-9124-8a04273d2716,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-f1ee27b0-82ec-4ae4-998c-45c712a8886b,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-1bcbd57c-8e95-4680-a040-012f29312780,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-b251a118-36f6-4a66-ae5a-e82c9cc66be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-565251d3-538f-4521-941b-7c796cc9fcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-c84f04f6-31b9-4123-b648-2704628d6a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-9fac7284-ef1f-4cb5-9c14-f8f324c2db53,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-dfc1bd1e-4544-4407-8990-4da04b8b186c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048160691-172.17.0.10-1595573816331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46654,DS-4a75df80-8c4a-431a-9124-8a04273d2716,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-f1ee27b0-82ec-4ae4-998c-45c712a8886b,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-1bcbd57c-8e95-4680-a040-012f29312780,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-b251a118-36f6-4a66-ae5a-e82c9cc66be7,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-565251d3-538f-4521-941b-7c796cc9fcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-c84f04f6-31b9-4123-b648-2704628d6a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-9fac7284-ef1f-4cb5-9c14-f8f324c2db53,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-dfc1bd1e-4544-4407-8990-4da04b8b186c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281221283-172.17.0.10-1595574643070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40176,DS-059c010f-8d30-49de-9959-c661a2854017,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-17904789-29de-4697-ba29-32a9f45a6df2,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-c9bd6813-caa3-492d-8992-76929a3a9081,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-96fbe8f4-bc48-43e4-bc55-448dd86836cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-fe44ba3d-a829-4bce-a776-aa6bab63b296,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-e0daee5f-914e-4073-8243-6bbb0ceb0894,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-a3351fbc-7989-4b1c-9188-1ddd5ddd9851,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-c7b4af17-4ba6-4461-b990-f78b661370ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281221283-172.17.0.10-1595574643070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40176,DS-059c010f-8d30-49de-9959-c661a2854017,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-17904789-29de-4697-ba29-32a9f45a6df2,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-c9bd6813-caa3-492d-8992-76929a3a9081,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-96fbe8f4-bc48-43e4-bc55-448dd86836cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-fe44ba3d-a829-4bce-a776-aa6bab63b296,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-e0daee5f-914e-4073-8243-6bbb0ceb0894,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-a3351fbc-7989-4b1c-9188-1ddd5ddd9851,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-c7b4af17-4ba6-4461-b990-f78b661370ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611872847-172.17.0.10-1595574674536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45224,DS-bf24d64b-89ed-4fa0-95e7-5ac204b93f91,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-a1eebb49-cd8a-4645-a1ef-0a972badfd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-8dc9d965-0537-4155-96d3-c5041ec4cd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-51f94ae1-341b-4c94-918b-a87befe0e1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-dc2ad113-71df-4bb8-a0d9-348e50b30ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-795e5553-891a-4ec4-9739-b8053ae3135b,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-07ee974d-e546-429b-8cb7-790a325fb198,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-eea28eaa-4b8c-4bf6-91f6-b7283f70221d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611872847-172.17.0.10-1595574674536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45224,DS-bf24d64b-89ed-4fa0-95e7-5ac204b93f91,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-a1eebb49-cd8a-4645-a1ef-0a972badfd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-8dc9d965-0537-4155-96d3-c5041ec4cd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-51f94ae1-341b-4c94-918b-a87befe0e1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-dc2ad113-71df-4bb8-a0d9-348e50b30ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-795e5553-891a-4ec4-9739-b8053ae3135b,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-07ee974d-e546-429b-8cb7-790a325fb198,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-eea28eaa-4b8c-4bf6-91f6-b7283f70221d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290247815-172.17.0.10-1595575225035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43185,DS-4b44095d-4682-4ea7-b934-ae583e369ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-0195e3c5-7b91-43d9-91a1-d5d4746e02a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-b5edb7d4-566a-4a3b-874d-9b6997dcddf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-23b5f4fa-f13d-43f9-be89-0e67de771b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-5395f02c-52f6-448b-8fb0-c3f862495421,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-403565c9-5f20-4aec-a219-370fcb40668c,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-8f8f6045-1033-4e0e-8b98-133213b1ae76,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-006a7291-9703-41aa-bb09-225119619b15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290247815-172.17.0.10-1595575225035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43185,DS-4b44095d-4682-4ea7-b934-ae583e369ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-0195e3c5-7b91-43d9-91a1-d5d4746e02a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-b5edb7d4-566a-4a3b-874d-9b6997dcddf3,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-23b5f4fa-f13d-43f9-be89-0e67de771b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-5395f02c-52f6-448b-8fb0-c3f862495421,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-403565c9-5f20-4aec-a219-370fcb40668c,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-8f8f6045-1033-4e0e-8b98-133213b1ae76,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-006a7291-9703-41aa-bb09-225119619b15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571027691-172.17.0.10-1595575261382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33562,DS-ae7b7db0-262e-47de-873e-0ac5c40cb009,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-3e822136-97fe-4ced-b844-85af9c48cea5,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-618ceb0f-62fd-45a1-96bb-37e2cc449327,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-c9120784-8c02-45a0-b03d-d414f7770f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-c27ed53d-283b-4f0d-b0ce-60e350e21026,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-4ac54875-3c91-470b-969d-eb1c8506309e,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-75ad51f9-f0a9-4b2b-b349-afd47081dc45,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-18b9dc0b-2a3b-45ee-9952-e5cb8088aed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1571027691-172.17.0.10-1595575261382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33562,DS-ae7b7db0-262e-47de-873e-0ac5c40cb009,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-3e822136-97fe-4ced-b844-85af9c48cea5,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-618ceb0f-62fd-45a1-96bb-37e2cc449327,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-c9120784-8c02-45a0-b03d-d414f7770f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-c27ed53d-283b-4f0d-b0ce-60e350e21026,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-4ac54875-3c91-470b-969d-eb1c8506309e,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-75ad51f9-f0a9-4b2b-b349-afd47081dc45,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-18b9dc0b-2a3b-45ee-9952-e5cb8088aed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642856772-172.17.0.10-1595575399205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44714,DS-fb456314-a283-4175-810b-ab7e8090a798,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-42e82954-267b-4a45-9151-c48c58b101db,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-6e6ac324-14f0-4313-9d46-34fccc829be2,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-58afd4cb-a486-4241-8b22-b679dd66b04c,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-e7de42bf-2f7c-43c3-8876-413759eaa49a,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-6e10c31b-af94-4766-8610-cd93a8fe49d0,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-5bb9b780-2615-44f7-8c24-f1816a16e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-b1ca5cf9-8789-4601-92b7-f60bc1fbee51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642856772-172.17.0.10-1595575399205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44714,DS-fb456314-a283-4175-810b-ab7e8090a798,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-42e82954-267b-4a45-9151-c48c58b101db,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-6e6ac324-14f0-4313-9d46-34fccc829be2,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-58afd4cb-a486-4241-8b22-b679dd66b04c,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-e7de42bf-2f7c-43c3-8876-413759eaa49a,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-6e10c31b-af94-4766-8610-cd93a8fe49d0,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-5bb9b780-2615-44f7-8c24-f1816a16e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-b1ca5cf9-8789-4601-92b7-f60bc1fbee51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042449719-172.17.0.10-1595575659505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39991,DS-8971c9eb-ba9b-49b4-8156-d94d8f52a90d,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-f4f867e2-e36a-459e-b767-d1abf644650b,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-27bd97dc-d165-4608-9776-c29dd6e650c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-b857cf96-fdf0-43ae-9364-7d9d45606dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-6eaa52b2-765d-4d4c-b30d-fc46c8795f11,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-4371f59f-7714-4005-b28a-ca03089644d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-e2721b67-285e-4092-84e3-589152dbc652,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-7abcc4fa-d117-471a-aa14-6d4d27315bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1042449719-172.17.0.10-1595575659505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39991,DS-8971c9eb-ba9b-49b4-8156-d94d8f52a90d,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-f4f867e2-e36a-459e-b767-d1abf644650b,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-27bd97dc-d165-4608-9776-c29dd6e650c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-b857cf96-fdf0-43ae-9364-7d9d45606dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-6eaa52b2-765d-4d4c-b30d-fc46c8795f11,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-4371f59f-7714-4005-b28a-ca03089644d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-e2721b67-285e-4092-84e3-589152dbc652,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-7abcc4fa-d117-471a-aa14-6d4d27315bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61343102-172.17.0.10-1595575723216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37241,DS-6b48d1b9-8069-44a3-9db6-ba51f71d7e12,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-9e4a8099-9bea-4d71-9bad-6a6a41938f77,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-4219785d-4a40-4be2-9ae7-fa486eb8fde8,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-c8ca23de-ce6f-4310-a1db-185305d409db,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-fa080807-f51f-44c5-b476-e35bce108135,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-daf7b466-6c97-4c8b-a48b-14c258302d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-4c3fb4c0-42f5-4f89-8739-d44aea50966b,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-36c678b7-918b-45f5-be41-e8599ab8cfe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61343102-172.17.0.10-1595575723216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37241,DS-6b48d1b9-8069-44a3-9db6-ba51f71d7e12,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-9e4a8099-9bea-4d71-9bad-6a6a41938f77,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-4219785d-4a40-4be2-9ae7-fa486eb8fde8,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-c8ca23de-ce6f-4310-a1db-185305d409db,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-fa080807-f51f-44c5-b476-e35bce108135,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-daf7b466-6c97-4c8b-a48b-14c258302d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-4c3fb4c0-42f5-4f89-8739-d44aea50966b,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-36c678b7-918b-45f5-be41-e8599ab8cfe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785888781-172.17.0.10-1595575879119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38509,DS-7fcbc9aa-6de2-4e86-9b3f-6712f4eac85f,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-24a1ac24-a92a-4e34-90da-1b1bfb0ba123,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-ec4ea185-584c-40f3-a9e2-b4033cc449fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-259e795b-5791-4d75-ae6e-ac4597614dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-ad69e57d-71b0-4705-90f4-c9bfe1e16801,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-990208ac-0155-4e37-9ff0-75c7224e478c,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-db8c3fcf-7258-49e2-a987-63ec23a39ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-a3975a48-d641-4377-aba9-f0e658058908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1785888781-172.17.0.10-1595575879119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38509,DS-7fcbc9aa-6de2-4e86-9b3f-6712f4eac85f,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-24a1ac24-a92a-4e34-90da-1b1bfb0ba123,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-ec4ea185-584c-40f3-a9e2-b4033cc449fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-259e795b-5791-4d75-ae6e-ac4597614dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-ad69e57d-71b0-4705-90f4-c9bfe1e16801,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-990208ac-0155-4e37-9ff0-75c7224e478c,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-db8c3fcf-7258-49e2-a987-63ec23a39ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-a3975a48-d641-4377-aba9-f0e658058908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-34900690-172.17.0.10-1595575974438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35281,DS-5fb3b220-5b16-4e9a-a5d8-3c14a782f882,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-8958e1c2-0990-47c0-8e12-d105d7470e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-d14a3de5-4571-4e0e-94db-7d44fa11cc57,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-9747cfab-2505-44ff-acc1-ba3e6e66338d,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-f47b4035-9a38-48b6-b82d-01c4cb2ace5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-a081e469-0566-4995-946d-dcdbb40f60c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-af25954c-d8f9-42e2-923a-f8a86b1f6a29,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-8b4e5460-9396-4a57-8f6a-c3db7df7e29d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-34900690-172.17.0.10-1595575974438:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35281,DS-5fb3b220-5b16-4e9a-a5d8-3c14a782f882,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-8958e1c2-0990-47c0-8e12-d105d7470e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-d14a3de5-4571-4e0e-94db-7d44fa11cc57,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-9747cfab-2505-44ff-acc1-ba3e6e66338d,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-f47b4035-9a38-48b6-b82d-01c4cb2ace5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-a081e469-0566-4995-946d-dcdbb40f60c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-af25954c-d8f9-42e2-923a-f8a86b1f6a29,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-8b4e5460-9396-4a57-8f6a-c3db7df7e29d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140518793-172.17.0.10-1595576077193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41821,DS-623696ac-0828-431f-99db-e40a0db570c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-ca4ef97f-8e0d-4822-a28a-e85e39bd91a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-df72dd2f-38dc-45e4-a8e8-442f6dbfa6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-29ac49b3-56ff-497b-825b-c53a7a44e8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-c8dfb714-949b-4569-8ece-e9c2a8e87d58,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-64a85182-b6c7-4c42-8b75-d564995f12e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-2418f5cf-49b7-4525-8b32-25f6a2b779c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-36d2b2ea-5001-4b96-a0cb-c6a052c9887c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140518793-172.17.0.10-1595576077193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41821,DS-623696ac-0828-431f-99db-e40a0db570c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-ca4ef97f-8e0d-4822-a28a-e85e39bd91a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-df72dd2f-38dc-45e4-a8e8-442f6dbfa6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-29ac49b3-56ff-497b-825b-c53a7a44e8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-c8dfb714-949b-4569-8ece-e9c2a8e87d58,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-64a85182-b6c7-4c42-8b75-d564995f12e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-2418f5cf-49b7-4525-8b32-25f6a2b779c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-36d2b2ea-5001-4b96-a0cb-c6a052c9887c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-122738229-172.17.0.10-1595576110967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45717,DS-0ecf6e2e-838b-4768-8b93-a505a538f3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-6067c96d-09d0-4af2-be2e-9ef74d2d2197,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-9b5e6901-d28e-47ec-b573-89da20c29b16,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-4bb407ab-b602-4588-822e-9a25dbaf9779,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-06a1af11-cb4d-45cd-80bc-05649ea6b999,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-edddcb0c-881f-4a3b-8570-7f744cab67b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-78fd5b7b-b536-4aa6-9d8a-75653488f08b,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-8db7acf1-df92-4b4c-b9d8-a3534cfa900b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-122738229-172.17.0.10-1595576110967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45717,DS-0ecf6e2e-838b-4768-8b93-a505a538f3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-6067c96d-09d0-4af2-be2e-9ef74d2d2197,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-9b5e6901-d28e-47ec-b573-89da20c29b16,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-4bb407ab-b602-4588-822e-9a25dbaf9779,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-06a1af11-cb4d-45cd-80bc-05649ea6b999,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-edddcb0c-881f-4a3b-8570-7f744cab67b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-78fd5b7b-b536-4aa6-9d8a-75653488f08b,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-8db7acf1-df92-4b4c-b9d8-a3534cfa900b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.retry.interval
component: hdfs:DataNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1107074004-172.17.0.10-1595576269650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42093,DS-ee3814f9-6d19-4169-ae8b-e861ab9c52d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-b501d7c7-426a-4cae-bdf0-552758940620,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-52168c2f-8e2d-4da2-bc9b-aa1ce37ff39b,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-620cda50-3bab-4746-a046-43f39781925e,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-3828fb28-36fa-468d-8b80-4597038f9845,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-aa5af8bd-d7f8-4a2a-95f4-3a1a84145e94,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-5cb02312-de7f-4719-944c-0b26d960d396,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-379ca471-ee55-4271-94ac-6a1986fc37f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1107074004-172.17.0.10-1595576269650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42093,DS-ee3814f9-6d19-4169-ae8b-e861ab9c52d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-b501d7c7-426a-4cae-bdf0-552758940620,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-52168c2f-8e2d-4da2-bc9b-aa1ce37ff39b,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-620cda50-3bab-4746-a046-43f39781925e,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-3828fb28-36fa-468d-8b80-4597038f9845,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-aa5af8bd-d7f8-4a2a-95f4-3a1a84145e94,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-5cb02312-de7f-4719-944c-0b26d960d396,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-379ca471-ee55-4271-94ac-6a1986fc37f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5057
