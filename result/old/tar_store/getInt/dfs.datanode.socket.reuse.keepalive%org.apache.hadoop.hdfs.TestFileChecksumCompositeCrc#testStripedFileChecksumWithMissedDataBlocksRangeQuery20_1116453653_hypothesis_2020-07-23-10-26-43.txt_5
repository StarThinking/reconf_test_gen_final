reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972376028-172.17.0.12-1595500018820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46568,DS-5277bba1-3fee-47ff-ae21-e0437bdf3bef,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-2b7b4896-8f0c-4649-bcd2-0e1ba6ece626,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-c0197c15-c3c5-4e06-8664-4966c9bbc435,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-2e2c32b7-7394-4777-9163-8e46925b9503,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-218f7150-5e72-42b2-9f52-214aca453d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-6cf039b2-24b7-47f4-bf16-79327464f943,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-169d4105-f376-421a-b291-dae151f5c1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-98e5d10f-754f-4e46-8af4-613ece53a6d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972376028-172.17.0.12-1595500018820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46568,DS-5277bba1-3fee-47ff-ae21-e0437bdf3bef,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-2b7b4896-8f0c-4649-bcd2-0e1ba6ece626,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-c0197c15-c3c5-4e06-8664-4966c9bbc435,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-2e2c32b7-7394-4777-9163-8e46925b9503,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-218f7150-5e72-42b2-9f52-214aca453d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-6cf039b2-24b7-47f4-bf16-79327464f943,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-169d4105-f376-421a-b291-dae151f5c1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-98e5d10f-754f-4e46-8af4-613ece53a6d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197673791-172.17.0.12-1595500169751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45806,DS-871c9a1f-dc93-4172-9002-668bb31a3d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-1af4c622-fd67-40d9-ac81-7bce6909e393,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-18338dc3-9c1a-4572-9ad2-3e7d05bb3fca,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-f50d0c8c-d9a4-444b-aeb9-a2b7d5fda386,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-0ab4af2d-97ba-4c5d-8798-2685b1a1afc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-09d7903c-2ab0-4836-9d31-ebb2aa9edbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-8fc3c3d3-c709-4be4-8538-f7935afd60bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-92813ed1-453e-4dd5-b4d8-741d4a85dd99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197673791-172.17.0.12-1595500169751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45806,DS-871c9a1f-dc93-4172-9002-668bb31a3d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-1af4c622-fd67-40d9-ac81-7bce6909e393,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-18338dc3-9c1a-4572-9ad2-3e7d05bb3fca,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-f50d0c8c-d9a4-444b-aeb9-a2b7d5fda386,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-0ab4af2d-97ba-4c5d-8798-2685b1a1afc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-09d7903c-2ab0-4836-9d31-ebb2aa9edbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-8fc3c3d3-c709-4be4-8538-f7935afd60bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-92813ed1-453e-4dd5-b4d8-741d4a85dd99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1561848740-172.17.0.12-1595500587060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41800,DS-5b73b96e-486a-42fd-983b-016fd3244dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-1b608865-e262-4e3d-96d8-bfea6ebf4df1,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-ede1e648-aa09-4b22-a136-65dbe4104a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-1e7061ea-7d87-4f0b-8262-d2cd1ddbf0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-e1a7f568-8ceb-4c87-bdec-736c1f03e6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-3443ba41-3ed5-4a72-b4b7-ded9558eedae,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-a211921d-556a-4fb4-8014-d0a1164a09a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-7aabb8cb-af44-4afd-a208-6abe3cceddc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1561848740-172.17.0.12-1595500587060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41800,DS-5b73b96e-486a-42fd-983b-016fd3244dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-1b608865-e262-4e3d-96d8-bfea6ebf4df1,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-ede1e648-aa09-4b22-a136-65dbe4104a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-1e7061ea-7d87-4f0b-8262-d2cd1ddbf0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-e1a7f568-8ceb-4c87-bdec-736c1f03e6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-3443ba41-3ed5-4a72-b4b7-ded9558eedae,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-a211921d-556a-4fb4-8014-d0a1164a09a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-7aabb8cb-af44-4afd-a208-6abe3cceddc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142175453-172.17.0.12-1595500848534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38272,DS-f01f2097-12b8-4442-9589-828027327e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-bb2238ba-a8bf-4365-b4a5-a0393479ae94,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-50f2b0aa-c993-46b5-9c68-68fb2458f03c,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-cd07bdeb-a548-4fdc-bcfa-001027d2e846,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-c829209c-b197-48b8-aa0e-0a4da39e0a95,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-f5e56da4-867b-459f-acac-a1b5a8afda5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-35e7f166-e117-4cb2-9b18-8322b382932e,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-cde76b1d-b347-4385-af4a-1d69c8b49057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2142175453-172.17.0.12-1595500848534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38272,DS-f01f2097-12b8-4442-9589-828027327e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-bb2238ba-a8bf-4365-b4a5-a0393479ae94,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-50f2b0aa-c993-46b5-9c68-68fb2458f03c,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-cd07bdeb-a548-4fdc-bcfa-001027d2e846,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-c829209c-b197-48b8-aa0e-0a4da39e0a95,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-f5e56da4-867b-459f-acac-a1b5a8afda5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-35e7f166-e117-4cb2-9b18-8322b382932e,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-cde76b1d-b347-4385-af4a-1d69c8b49057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428724011-172.17.0.12-1595501003195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37021,DS-226600be-7023-4fd3-968b-2de24839f839,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-1c147a32-c684-48cd-be0a-548c0a008920,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-03cb31e3-be6e-4fd9-a7e4-4e531af80e92,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-0c0bb7fb-776a-4f65-9bdb-91f9f540c6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-4af2887d-80de-46bb-9719-f0022899546d,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-3ff94f4d-fbd2-4054-8f00-8ba16988db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-781ad8c4-d42b-47ce-9cea-9f217bc24775,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-4b2a477f-ce3e-41ed-ac10-17e9c31f7e08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428724011-172.17.0.12-1595501003195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37021,DS-226600be-7023-4fd3-968b-2de24839f839,DISK], DatanodeInfoWithStorage[127.0.0.1:37189,DS-1c147a32-c684-48cd-be0a-548c0a008920,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-03cb31e3-be6e-4fd9-a7e4-4e531af80e92,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-0c0bb7fb-776a-4f65-9bdb-91f9f540c6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-4af2887d-80de-46bb-9719-f0022899546d,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-3ff94f4d-fbd2-4054-8f00-8ba16988db6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-781ad8c4-d42b-47ce-9cea-9f217bc24775,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-4b2a477f-ce3e-41ed-ac10-17e9c31f7e08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1331003097-172.17.0.12-1595501303243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43903,DS-1fe31195-fe38-482a-bde7-36f753a29024,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-a9ae0de1-8c4e-41ce-826e-e87236afc980,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-d056d980-f241-45f6-9092-e815caf402fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-a2bf7ef6-9b30-46f9-b0ee-da1d49042139,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-ec990841-27a9-44b5-b604-4e5c15f8fee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-956fdb35-61f0-409a-b882-db7128f02aec,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-b8ee7d1e-2aca-46af-81f5-552623666b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-acf6be25-c9ef-40ff-85e4-8e09eccafe84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1331003097-172.17.0.12-1595501303243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43903,DS-1fe31195-fe38-482a-bde7-36f753a29024,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-a9ae0de1-8c4e-41ce-826e-e87236afc980,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-d056d980-f241-45f6-9092-e815caf402fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-a2bf7ef6-9b30-46f9-b0ee-da1d49042139,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-ec990841-27a9-44b5-b604-4e5c15f8fee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-956fdb35-61f0-409a-b882-db7128f02aec,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-b8ee7d1e-2aca-46af-81f5-552623666b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-acf6be25-c9ef-40ff-85e4-8e09eccafe84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2035238708-172.17.0.12-1595501380941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32800,DS-f18999a0-a5bf-4a52-82d6-60185643e9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-0c513688-699a-47ee-ab3a-ea6c8d5c5c56,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-4df08776-fc8a-47c2-9249-9e9c5a09146c,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-92e132f8-1589-492d-9eaa-1151fa1c6e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-111d6da0-42e1-4360-87ab-955cc65b031c,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-7153a09e-ac03-4b29-b9fe-8f0052742adc,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-cdd77498-d0c1-4a25-b8a6-f353ecbe40ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-e7d33b5f-ada5-449a-87ee-be87c4d130f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2035238708-172.17.0.12-1595501380941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32800,DS-f18999a0-a5bf-4a52-82d6-60185643e9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-0c513688-699a-47ee-ab3a-ea6c8d5c5c56,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-4df08776-fc8a-47c2-9249-9e9c5a09146c,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-92e132f8-1589-492d-9eaa-1151fa1c6e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-111d6da0-42e1-4360-87ab-955cc65b031c,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-7153a09e-ac03-4b29-b9fe-8f0052742adc,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-cdd77498-d0c1-4a25-b8a6-f353ecbe40ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-e7d33b5f-ada5-449a-87ee-be87c4d130f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601060292-172.17.0.12-1595501638316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35265,DS-6005148d-ec01-4032-afae-5cdd8bc80d44,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-9e606591-65df-4349-80ad-cb3ae581b56c,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-069c5131-dc16-4abe-824a-509e96f4adf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-4600a58c-bb7d-4164-a870-8d8b689645cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-129fa5b4-71e4-4663-b9cb-562e16586265,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-29537d2f-3bb1-405b-ae86-14865be27faa,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-e44d4dab-6ab4-43d7-959e-f57dea0e1185,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-fac54823-7874-4569-8db2-3c272daa967b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601060292-172.17.0.12-1595501638316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35265,DS-6005148d-ec01-4032-afae-5cdd8bc80d44,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-9e606591-65df-4349-80ad-cb3ae581b56c,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-069c5131-dc16-4abe-824a-509e96f4adf4,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-4600a58c-bb7d-4164-a870-8d8b689645cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-129fa5b4-71e4-4663-b9cb-562e16586265,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-29537d2f-3bb1-405b-ae86-14865be27faa,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-e44d4dab-6ab4-43d7-959e-f57dea0e1185,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-fac54823-7874-4569-8db2-3c272daa967b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454309328-172.17.0.12-1595502324896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43058,DS-90fed6bd-2146-4c9e-ac74-1cb09df050a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-7f44d1c5-5ef0-4205-934f-52226e15d072,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-324b179a-4ffe-4231-92fe-22a45afedfee,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-6ac3db1d-e83d-4690-bed0-2f314148a116,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-2503a9f1-61a2-42e9-a69a-36bbdafbc430,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-78e7133f-f380-43e7-8b10-a6320cfffbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-449e6985-2568-43af-9197-32c4244cdb81,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-660efa25-7bd6-4296-a871-96889c1a20fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454309328-172.17.0.12-1595502324896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43058,DS-90fed6bd-2146-4c9e-ac74-1cb09df050a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-7f44d1c5-5ef0-4205-934f-52226e15d072,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-324b179a-4ffe-4231-92fe-22a45afedfee,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-6ac3db1d-e83d-4690-bed0-2f314148a116,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-2503a9f1-61a2-42e9-a69a-36bbdafbc430,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-78e7133f-f380-43e7-8b10-a6320cfffbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-449e6985-2568-43af-9197-32c4244cdb81,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-660efa25-7bd6-4296-a871-96889c1a20fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-333600207-172.17.0.12-1595502834705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39392,DS-9455fc4a-5822-45e4-a29c-8439a8227cba,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-aa3fb42f-54d2-4598-901a-c95228e682fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-fadd5371-a4c9-42d9-8a0c-08488f1efaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-f85c5590-a5c9-43ea-a645-7949190081e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-202399af-8e91-479a-8de5-59cc659faf71,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-3b44b382-866b-42f3-a08e-1f385c272225,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-975f1b81-d3b7-4677-a8f9-8b8e3a53aa09,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-69c7c054-df43-44f8-9f76-d73059ddcf09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-333600207-172.17.0.12-1595502834705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39392,DS-9455fc4a-5822-45e4-a29c-8439a8227cba,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-aa3fb42f-54d2-4598-901a-c95228e682fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-fadd5371-a4c9-42d9-8a0c-08488f1efaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-f85c5590-a5c9-43ea-a645-7949190081e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-202399af-8e91-479a-8de5-59cc659faf71,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-3b44b382-866b-42f3-a08e-1f385c272225,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-975f1b81-d3b7-4677-a8f9-8b8e3a53aa09,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-69c7c054-df43-44f8-9f76-d73059ddcf09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009723224-172.17.0.12-1595503117032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34540,DS-4ecdb4bf-7d5d-4c6b-9012-04ad349d82f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-7b71ebaa-6eab-4b36-9aba-76515c7315da,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-5687e2c9-361a-4788-b26d-fe345223fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-121ee9bd-744c-4aa7-88cd-136b421fefee,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-9193e4e5-e8ae-4ae1-abe3-bec960dd15ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-20df5011-9f1a-4a14-aba9-cc177c9d4caf,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-004ecfce-8f09-4cfd-86e7-0a973bc0250c,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-86b24876-5bdd-40c2-a8c6-966cfbf48744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2009723224-172.17.0.12-1595503117032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34540,DS-4ecdb4bf-7d5d-4c6b-9012-04ad349d82f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-7b71ebaa-6eab-4b36-9aba-76515c7315da,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-5687e2c9-361a-4788-b26d-fe345223fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-121ee9bd-744c-4aa7-88cd-136b421fefee,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-9193e4e5-e8ae-4ae1-abe3-bec960dd15ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-20df5011-9f1a-4a14-aba9-cc177c9d4caf,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-004ecfce-8f09-4cfd-86e7-0a973bc0250c,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-86b24876-5bdd-40c2-a8c6-966cfbf48744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160267112-172.17.0.12-1595503187277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34279,DS-b5a5c40a-aefd-4123-bab1-84fd51cf5a46,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-94b7ca1a-d59f-4bdb-a1f1-1779625f7b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-ec0fdbed-3a58-42d3-bfb2-ae45be6e22f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-b1f9c50d-8d3b-4c6c-9260-0d54c53695e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-57dcc923-efa6-4a08-830f-0adfe8b55db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-66e2f6a1-1c87-4d65-b34f-1602abd8a944,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-98f3083b-be6f-44b2-8293-0360d02c736c,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-aa87ae82-f15a-41e8-830e-74d6a760834c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1160267112-172.17.0.12-1595503187277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34279,DS-b5a5c40a-aefd-4123-bab1-84fd51cf5a46,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-94b7ca1a-d59f-4bdb-a1f1-1779625f7b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-ec0fdbed-3a58-42d3-bfb2-ae45be6e22f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-b1f9c50d-8d3b-4c6c-9260-0d54c53695e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-57dcc923-efa6-4a08-830f-0adfe8b55db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-66e2f6a1-1c87-4d65-b34f-1602abd8a944,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-98f3083b-be6f-44b2-8293-0360d02c736c,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-aa87ae82-f15a-41e8-830e-74d6a760834c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487578685-172.17.0.12-1595503296124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43263,DS-62a522b4-bc65-44fd-bd0e-cf140a689d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-de080e20-e5ec-498c-8427-fb0450299870,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-4d58d3cd-7cea-49f5-b266-d197d8191876,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-86e2b602-4505-4c80-a78f-95ae52e677bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-9b1c995d-c839-4b55-9a9e-a82703ba98ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-105aec5d-d4fa-4b41-b56d-e86a8804a340,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-c757eb7c-b13e-4b02-923e-9ebc4f17f547,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-d0ab63ee-cb7d-4b54-b0f5-df703b4400d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487578685-172.17.0.12-1595503296124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43263,DS-62a522b4-bc65-44fd-bd0e-cf140a689d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-de080e20-e5ec-498c-8427-fb0450299870,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-4d58d3cd-7cea-49f5-b266-d197d8191876,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-86e2b602-4505-4c80-a78f-95ae52e677bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-9b1c995d-c839-4b55-9a9e-a82703ba98ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-105aec5d-d4fa-4b41-b56d-e86a8804a340,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-c757eb7c-b13e-4b02-923e-9ebc4f17f547,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-d0ab63ee-cb7d-4b54-b0f5-df703b4400d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220339249-172.17.0.12-1595503410396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46101,DS-8c92089b-e743-4dd6-b207-eac9345c50c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-ce6bf6f8-d6cc-4c59-b2ea-efd04c84dd06,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-d36479b4-5041-4648-89c1-70c7a354f361,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-cf3a5e32-c172-4e0c-a71e-169fca45a531,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-b37f57fc-f706-4ba2-bc62-5ad695228bac,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-756c8e69-d140-4530-b3b1-cd0915ff40d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-d467e6dc-13ed-457e-945e-82056098b09c,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-c2b7d570-b45f-4c64-a943-2dcbf3d98c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220339249-172.17.0.12-1595503410396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46101,DS-8c92089b-e743-4dd6-b207-eac9345c50c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-ce6bf6f8-d6cc-4c59-b2ea-efd04c84dd06,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-d36479b4-5041-4648-89c1-70c7a354f361,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-cf3a5e32-c172-4e0c-a71e-169fca45a531,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-b37f57fc-f706-4ba2-bc62-5ad695228bac,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-756c8e69-d140-4530-b3b1-cd0915ff40d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-d467e6dc-13ed-457e-945e-82056098b09c,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-c2b7d570-b45f-4c64-a943-2dcbf3d98c34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703833393-172.17.0.12-1595503555767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34472,DS-2f3c7b9f-99d0-4a44-afd6-4c09e2472367,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-d2c80a92-6bb3-40fd-9bca-b9445aee48b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-b97e1234-23a7-408d-b683-7e5e57835abf,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-69ba2f01-5182-4176-a561-996f942dee5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-8f892874-d38f-4f73-9e20-78c6d2e57df5,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-b83a41c3-4359-4134-8087-694c6fd77764,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-1dd0a80c-819c-4c36-9365-5f43e538300e,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-9855b56b-61a1-46a1-97e4-42d7f01790f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703833393-172.17.0.12-1595503555767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34472,DS-2f3c7b9f-99d0-4a44-afd6-4c09e2472367,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-d2c80a92-6bb3-40fd-9bca-b9445aee48b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-b97e1234-23a7-408d-b683-7e5e57835abf,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-69ba2f01-5182-4176-a561-996f942dee5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-8f892874-d38f-4f73-9e20-78c6d2e57df5,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-b83a41c3-4359-4134-8087-694c6fd77764,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-1dd0a80c-819c-4c36-9365-5f43e538300e,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-9855b56b-61a1-46a1-97e4-42d7f01790f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616913954-172.17.0.12-1595504055085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37237,DS-d4445810-4f11-4d0c-bef6-bfb38028fa50,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-72faf463-73d8-458f-a55f-8ee19206009c,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-3eb74405-600b-4130-8bd6-c334e7abc776,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-24bcb44a-eb40-424c-832b-419523a6b83c,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-d2fd2756-3c9e-4ca7-8ac8-b8888078dc82,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-a8a8c4cc-ebb2-4ea1-9d33-6ae261516dca,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-9efbe089-e2c4-426e-9b21-2e9401f4b32c,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-f5898c40-01ec-4aaf-b708-2d4aa64e22cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-616913954-172.17.0.12-1595504055085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37237,DS-d4445810-4f11-4d0c-bef6-bfb38028fa50,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-72faf463-73d8-458f-a55f-8ee19206009c,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-3eb74405-600b-4130-8bd6-c334e7abc776,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-24bcb44a-eb40-424c-832b-419523a6b83c,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-d2fd2756-3c9e-4ca7-8ac8-b8888078dc82,DISK], DatanodeInfoWithStorage[127.0.0.1:42187,DS-a8a8c4cc-ebb2-4ea1-9d33-6ae261516dca,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-9efbe089-e2c4-426e-9b21-2e9401f4b32c,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-f5898c40-01ec-4aaf-b708-2d4aa64e22cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599722676-172.17.0.12-1595505050986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46273,DS-54228c47-dbcb-4b4d-b4ff-f9865fc5fe1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-c5a94d22-c21b-4458-bd58-aa785f58c4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-bf6aeca1-c120-46e5-bc14-a35cac109c46,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-a1083756-b0ce-45a4-8d0d-6508455411a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-0f720c1f-5a82-45ee-9dba-d3418518a931,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-14c029cd-e8bd-49c6-b012-eee55ff6a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-9f1e25c3-68e3-4ea4-a72f-639130125d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-3013182b-8e87-4033-be47-dcbc1a4971f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599722676-172.17.0.12-1595505050986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46273,DS-54228c47-dbcb-4b4d-b4ff-f9865fc5fe1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-c5a94d22-c21b-4458-bd58-aa785f58c4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-bf6aeca1-c120-46e5-bc14-a35cac109c46,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-a1083756-b0ce-45a4-8d0d-6508455411a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-0f720c1f-5a82-45ee-9dba-d3418518a931,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-14c029cd-e8bd-49c6-b012-eee55ff6a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-9f1e25c3-68e3-4ea4-a72f-639130125d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-3013182b-8e87-4033-be47-dcbc1a4971f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686501696-172.17.0.12-1595505222219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44690,DS-560c9f5a-069d-443c-b095-e08ba2d12f05,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-e665e05e-5c2f-4736-b4e6-6b4df9b09606,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-25f6fc32-9a19-4c71-a954-c04774e5cd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-cd1ee090-e886-4844-8e85-deba6501ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-7b6985e9-9708-4201-8d78-60724f66b73b,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-d61bb2fd-9cc6-498b-9e7c-22fddd20fd74,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-edc998d1-66ac-4d18-8a97-9543b74ecf70,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-10e9a3db-cfdf-4ca8-9228-03df77780c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686501696-172.17.0.12-1595505222219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44690,DS-560c9f5a-069d-443c-b095-e08ba2d12f05,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-e665e05e-5c2f-4736-b4e6-6b4df9b09606,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-25f6fc32-9a19-4c71-a954-c04774e5cd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-cd1ee090-e886-4844-8e85-deba6501ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-7b6985e9-9708-4201-8d78-60724f66b73b,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-d61bb2fd-9cc6-498b-9e7c-22fddd20fd74,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-edc998d1-66ac-4d18-8a97-9543b74ecf70,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-10e9a3db-cfdf-4ca8-9228-03df77780c03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1099586751-172.17.0.12-1595505476057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35464,DS-33e14d6b-65cb-4d50-a18f-0a73a52a0067,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-aa726709-80ae-44ba-a0e1-0d2c80be95b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-74dabac9-4c38-4d90-9c25-c0a180f4673a,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-a02ba6af-22bc-40c5-ae5c-c4b8ca28aa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-0b7a1d8d-735a-4c11-8fce-674c5c32ffd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-2d6b1323-7c08-4589-83d2-3ed8206e63fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-5f851fa0-1559-426f-8ec5-e6e2b6f4d83a,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-78bd7f46-8305-4b21-bf59-4f4cf5532a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1099586751-172.17.0.12-1595505476057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35464,DS-33e14d6b-65cb-4d50-a18f-0a73a52a0067,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-aa726709-80ae-44ba-a0e1-0d2c80be95b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-74dabac9-4c38-4d90-9c25-c0a180f4673a,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-a02ba6af-22bc-40c5-ae5c-c4b8ca28aa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-0b7a1d8d-735a-4c11-8fce-674c5c32ffd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-2d6b1323-7c08-4589-83d2-3ed8206e63fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-5f851fa0-1559-426f-8ec5-e6e2b6f4d83a,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-78bd7f46-8305-4b21-bf59-4f4cf5532a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812779759-172.17.0.12-1595505514686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38507,DS-82be4daf-fe94-406b-9835-8f5ce77ce7be,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-5169cc8d-9628-4e37-a758-f7acd26005b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-2dbea263-0e3b-4046-b3f7-88f6bcb001a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-a7bd7bba-3ee3-45b2-8a59-9213c41188ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-e170344a-6755-4f9e-9c7d-9cdcd0614269,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-fb333c75-2a26-472f-98ea-8185f316ac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-d5a34fe6-a2e7-4447-8e4d-c1fd4b8aef29,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-bc9f269a-9a8d-4f39-b541-08a1debd552f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812779759-172.17.0.12-1595505514686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38507,DS-82be4daf-fe94-406b-9835-8f5ce77ce7be,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-5169cc8d-9628-4e37-a758-f7acd26005b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-2dbea263-0e3b-4046-b3f7-88f6bcb001a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-a7bd7bba-3ee3-45b2-8a59-9213c41188ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-e170344a-6755-4f9e-9c7d-9cdcd0614269,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-fb333c75-2a26-472f-98ea-8185f316ac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-d5a34fe6-a2e7-4447-8e4d-c1fd4b8aef29,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-bc9f269a-9a8d-4f39-b541-08a1debd552f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5535
