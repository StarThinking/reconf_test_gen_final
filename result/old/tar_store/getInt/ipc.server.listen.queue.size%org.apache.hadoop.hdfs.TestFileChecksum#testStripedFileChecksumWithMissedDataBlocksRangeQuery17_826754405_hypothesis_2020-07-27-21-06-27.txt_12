reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134566098-172.17.0.6-1595884397724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37525,DS-b9fb6974-7234-4d46-ac71-a211e7b387c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-1f8319a5-e6aa-4c08-9e5e-2fe5712c20b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-938756b1-37fe-4879-9285-2da720be698e,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-fc11c5b8-b6a7-41f1-adbf-c0c388fe9cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-756db692-6972-4033-9f7c-034cd4667c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-c8f7b669-b06f-40a1-8fab-e9816a27ff81,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-09fcdd41-a5bb-4d90-aaee-5e7e5d4b5288,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-1dc5e282-77db-4969-a0fc-fee9606509c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134566098-172.17.0.6-1595884397724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37525,DS-b9fb6974-7234-4d46-ac71-a211e7b387c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-1f8319a5-e6aa-4c08-9e5e-2fe5712c20b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-938756b1-37fe-4879-9285-2da720be698e,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-fc11c5b8-b6a7-41f1-adbf-c0c388fe9cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-756db692-6972-4033-9f7c-034cd4667c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-c8f7b669-b06f-40a1-8fab-e9816a27ff81,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-09fcdd41-a5bb-4d90-aaee-5e7e5d4b5288,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-1dc5e282-77db-4969-a0fc-fee9606509c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141240410-172.17.0.6-1595884723716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41930,DS-9fac616c-ddb5-497b-bd25-6105440ae600,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-e3d31825-193d-4430-906c-6f797030373d,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-2d8a1ebe-0cea-4636-885d-7df62e93a8df,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-800f3bf9-debf-416a-ae8f-f5e3d6318f45,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-7dd70813-4dd5-498a-8bc5-1d501f6119bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-65d89abb-3347-4250-a95b-01e78e73606b,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-0d0c3403-30db-469b-9762-5cffec64679f,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-11bc9cd0-bc8f-46c0-9d49-1cc2488859bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2141240410-172.17.0.6-1595884723716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41930,DS-9fac616c-ddb5-497b-bd25-6105440ae600,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-e3d31825-193d-4430-906c-6f797030373d,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-2d8a1ebe-0cea-4636-885d-7df62e93a8df,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-800f3bf9-debf-416a-ae8f-f5e3d6318f45,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-7dd70813-4dd5-498a-8bc5-1d501f6119bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-65d89abb-3347-4250-a95b-01e78e73606b,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-0d0c3403-30db-469b-9762-5cffec64679f,DISK], DatanodeInfoWithStorage[127.0.0.1:34182,DS-11bc9cd0-bc8f-46c0-9d49-1cc2488859bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374743260-172.17.0.6-1595884860527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34750,DS-d7aad370-8dab-4837-982f-f907ee4af982,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-c2706845-a56b-4a15-874c-c55136da5ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-3c89b083-8ab1-4375-8d46-f3411a993d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-5c4e4a7b-bb64-4d6e-82c6-3b2af52b76c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-5de25fc0-f580-4f84-a8e5-233ef1a555a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-4fc97bbb-71a7-4550-944a-3713bbb5e3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-990a425a-59a3-48f8-9b61-e98846e66b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-dc79e047-8224-4edb-ad7f-579755469301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374743260-172.17.0.6-1595884860527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34750,DS-d7aad370-8dab-4837-982f-f907ee4af982,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-c2706845-a56b-4a15-874c-c55136da5ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-3c89b083-8ab1-4375-8d46-f3411a993d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-5c4e4a7b-bb64-4d6e-82c6-3b2af52b76c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-5de25fc0-f580-4f84-a8e5-233ef1a555a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-4fc97bbb-71a7-4550-944a-3713bbb5e3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-990a425a-59a3-48f8-9b61-e98846e66b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-dc79e047-8224-4edb-ad7f-579755469301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958083774-172.17.0.6-1595885259447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39888,DS-4c682227-0744-44c5-8ab8-5de58715f03d,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-2a1ad95a-6a38-4de0-ba22-0a8ad79b0b39,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-88731b1a-1604-46e3-ad58-22ffb4d977c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-ded59df7-74c1-4759-905d-71af45685303,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-8afac4e9-6274-434d-96d7-34f15fc68583,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-3b290283-82a7-4cf3-8588-a1ca6991f3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-2758627a-bb7c-4a05-8e15-1827a6854555,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-b9782ca4-42b4-43ad-b4b6-8b4142636a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958083774-172.17.0.6-1595885259447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39888,DS-4c682227-0744-44c5-8ab8-5de58715f03d,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-2a1ad95a-6a38-4de0-ba22-0a8ad79b0b39,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-88731b1a-1604-46e3-ad58-22ffb4d977c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-ded59df7-74c1-4759-905d-71af45685303,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-8afac4e9-6274-434d-96d7-34f15fc68583,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-3b290283-82a7-4cf3-8588-a1ca6991f3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-2758627a-bb7c-4a05-8e15-1827a6854555,DISK], DatanodeInfoWithStorage[127.0.0.1:45306,DS-b9782ca4-42b4-43ad-b4b6-8b4142636a49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091143731-172.17.0.6-1595885331806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41282,DS-ba383151-1d3f-4b79-83b1-25a491de7b91,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-e5bed075-7b12-4153-9cf4-7eece9b1c6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-99c7fc00-5eeb-41c5-821a-e1dbafef7326,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-9ac6c272-e154-41cf-856d-5eae5536c795,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-eae4dc21-b641-476f-ac0f-91ecac28ec58,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-ff420380-b971-47e1-afd5-cc257afc7712,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-95c52806-a91f-465e-9ed5-17ab3d9fad1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-64c70f76-3f9c-4ad3-b602-c5a9d6c81fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091143731-172.17.0.6-1595885331806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41282,DS-ba383151-1d3f-4b79-83b1-25a491de7b91,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-e5bed075-7b12-4153-9cf4-7eece9b1c6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-99c7fc00-5eeb-41c5-821a-e1dbafef7326,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-9ac6c272-e154-41cf-856d-5eae5536c795,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-eae4dc21-b641-476f-ac0f-91ecac28ec58,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-ff420380-b971-47e1-afd5-cc257afc7712,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-95c52806-a91f-465e-9ed5-17ab3d9fad1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-64c70f76-3f9c-4ad3-b602-c5a9d6c81fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988476769-172.17.0.6-1595886646542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45223,DS-d69eb7c5-1cd5-4079-a40d-806608d93024,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-0da5f0df-f5a9-4cf5-8b72-98b5c16af38a,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-4949be46-53bb-42d7-8853-7e8f093c5ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-25c40804-a6ae-46dd-85ad-1e1f49d5271d,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-0747e201-5bf6-4a18-a2de-d0b657009efc,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-081175cf-9a6d-41c4-ab99-31ecce7c9db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-a3d8662b-e366-41d4-aaac-3361ecda67cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-831542a7-8c2b-4b3f-9b74-670f043eca86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988476769-172.17.0.6-1595886646542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45223,DS-d69eb7c5-1cd5-4079-a40d-806608d93024,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-0da5f0df-f5a9-4cf5-8b72-98b5c16af38a,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-4949be46-53bb-42d7-8853-7e8f093c5ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-25c40804-a6ae-46dd-85ad-1e1f49d5271d,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-0747e201-5bf6-4a18-a2de-d0b657009efc,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-081175cf-9a6d-41c4-ab99-31ecce7c9db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-a3d8662b-e366-41d4-aaac-3361ecda67cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-831542a7-8c2b-4b3f-9b74-670f043eca86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162184821-172.17.0.6-1595886899725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34257,DS-b9d08bcb-8a6f-4018-a800-877350d8ea72,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-08b1c1c2-cdfd-4b0c-914f-2954e9d17a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-96c2e95c-9960-4546-b4ec-2799b9346e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-208b616f-544b-4ec2-a670-aeb0b4ec2043,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-36a6a885-0ef7-43eb-864f-a780831167b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-baae3322-faaa-4665-a4ff-8594840949f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-d427c797-7d56-4cb3-8b0a-67a661bef78a,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-f556ea28-fe04-4cdc-a38e-d77e8071bac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162184821-172.17.0.6-1595886899725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34257,DS-b9d08bcb-8a6f-4018-a800-877350d8ea72,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-08b1c1c2-cdfd-4b0c-914f-2954e9d17a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-96c2e95c-9960-4546-b4ec-2799b9346e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-208b616f-544b-4ec2-a670-aeb0b4ec2043,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-36a6a885-0ef7-43eb-864f-a780831167b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-baae3322-faaa-4665-a4ff-8594840949f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-d427c797-7d56-4cb3-8b0a-67a661bef78a,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-f556ea28-fe04-4cdc-a38e-d77e8071bac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332759330-172.17.0.6-1595887111013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33340,DS-e2e5a729-6d76-452d-a29c-bcacd9a7dfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-9efdfc47-d418-4d30-bd8c-253290d4a7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-de39dfa2-502f-43c3-980d-8f939fa4879f,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-2a8fa8ff-0d20-45cc-926e-80f3b1f3e1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-f9a1afeb-3d22-45c9-98b0-5b3d50d35a83,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-c6dbcfda-8708-4548-afd8-6d3bda7e95a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-80f46f4b-af75-4202-bec2-2320aaaf2e68,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-632a24a6-6236-4433-af52-7eaa816bc897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332759330-172.17.0.6-1595887111013:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33340,DS-e2e5a729-6d76-452d-a29c-bcacd9a7dfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-9efdfc47-d418-4d30-bd8c-253290d4a7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-de39dfa2-502f-43c3-980d-8f939fa4879f,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-2a8fa8ff-0d20-45cc-926e-80f3b1f3e1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-f9a1afeb-3d22-45c9-98b0-5b3d50d35a83,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-c6dbcfda-8708-4548-afd8-6d3bda7e95a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-80f46f4b-af75-4202-bec2-2320aaaf2e68,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-632a24a6-6236-4433-af52-7eaa816bc897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085198422-172.17.0.6-1595887999745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45598,DS-136b4c12-60c5-4180-bd2d-a8b5d8369f95,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-65e75f28-8253-4c94-b146-91cc8d115500,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-0582259e-145f-49e4-8ee1-2f1e303eac34,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-12812936-b6bd-4f88-87e5-9f608a08dfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-41b7765f-763e-4267-a42c-0c77a72409e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-f3fd8417-7ab4-4140-b1eb-72a6bc202985,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-8d05cfae-81b1-4a83-8a35-0b63da57d142,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-09df7577-13f3-4cfb-97e5-8c232d59e791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085198422-172.17.0.6-1595887999745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45598,DS-136b4c12-60c5-4180-bd2d-a8b5d8369f95,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-65e75f28-8253-4c94-b146-91cc8d115500,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-0582259e-145f-49e4-8ee1-2f1e303eac34,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-12812936-b6bd-4f88-87e5-9f608a08dfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-41b7765f-763e-4267-a42c-0c77a72409e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-f3fd8417-7ab4-4140-b1eb-72a6bc202985,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-8d05cfae-81b1-4a83-8a35-0b63da57d142,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-09df7577-13f3-4cfb-97e5-8c232d59e791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-664493840-172.17.0.6-1595888142263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46728,DS-1f649cfe-1734-4786-93af-ef7f33527121,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-563ef404-6a5f-4ec0-ab77-3f0f3a4a4988,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-4d8d964d-cc87-413b-a043-0996d2408c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-95867b9d-945f-4ebe-8c70-7f4c1e168716,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-b9d76a04-c6b7-49d9-b273-b4bf23d250b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-eef640a2-b192-416d-a6ec-79506570b1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-18f41e5b-59cc-4e53-a822-97e62c1f6995,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-a3d78248-85b2-4f77-9e60-cec945e33a35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-664493840-172.17.0.6-1595888142263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46728,DS-1f649cfe-1734-4786-93af-ef7f33527121,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-563ef404-6a5f-4ec0-ab77-3f0f3a4a4988,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-4d8d964d-cc87-413b-a043-0996d2408c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-95867b9d-945f-4ebe-8c70-7f4c1e168716,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-b9d76a04-c6b7-49d9-b273-b4bf23d250b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-eef640a2-b192-416d-a6ec-79506570b1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-18f41e5b-59cc-4e53-a822-97e62c1f6995,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-a3d78248-85b2-4f77-9e60-cec945e33a35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456282525-172.17.0.6-1595888502217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37488,DS-a54c54fd-a65f-400c-a239-9a2d27cba805,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-2a367917-4ee2-4d49-affa-dbb2f3ae229c,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-523395a5-e2e5-4fdc-b912-a402c6667ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-5b8e5dbc-877e-4dd4-9d2c-b200ef7c1a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-4ede6383-e269-4461-8cde-b289ac3850a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-99749016-9970-4de9-be41-80a67edac804,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-a45b24ce-11e9-4752-9630-c31ec764755a,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-3f9779e9-7fff-416f-a689-94950b5e612b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456282525-172.17.0.6-1595888502217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37488,DS-a54c54fd-a65f-400c-a239-9a2d27cba805,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-2a367917-4ee2-4d49-affa-dbb2f3ae229c,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-523395a5-e2e5-4fdc-b912-a402c6667ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-5b8e5dbc-877e-4dd4-9d2c-b200ef7c1a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-4ede6383-e269-4461-8cde-b289ac3850a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-99749016-9970-4de9-be41-80a67edac804,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-a45b24ce-11e9-4752-9630-c31ec764755a,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-3f9779e9-7fff-416f-a689-94950b5e612b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 16384
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-412701892-172.17.0.6-1595888681275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40126,DS-652f3453-9ba3-415c-b2de-2dcc63f43d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-86e91dd8-b9ff-4afd-a5ac-fc62a7ade054,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-437e6dad-e240-429e-95e2-d6c8984ef2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-71715953-6765-4662-83ad-ef804f6d610f,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-a707c550-b5d3-4f54-bf42-1c209eba6608,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-7ac3dc74-53a6-4f48-9520-85068b6279e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-4281a3f1-68e1-4126-9f85-fb636fb3bdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-687276e9-ece3-4c77-906c-173721e9eb57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-412701892-172.17.0.6-1595888681275:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40126,DS-652f3453-9ba3-415c-b2de-2dcc63f43d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-86e91dd8-b9ff-4afd-a5ac-fc62a7ade054,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-437e6dad-e240-429e-95e2-d6c8984ef2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-71715953-6765-4662-83ad-ef804f6d610f,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-a707c550-b5d3-4f54-bf42-1c209eba6608,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-7ac3dc74-53a6-4f48-9520-85068b6279e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-4281a3f1-68e1-4126-9f85-fb636fb3bdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-687276e9-ece3-4c77-906c-173721e9eb57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5316
