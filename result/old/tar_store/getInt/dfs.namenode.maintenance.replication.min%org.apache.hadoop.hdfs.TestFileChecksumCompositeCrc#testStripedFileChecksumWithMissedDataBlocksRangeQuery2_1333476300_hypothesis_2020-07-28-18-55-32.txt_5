reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211639737-172.17.0.21-1595962660484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36167,DS-f6916984-e58a-436a-91bc-de6f4f1093b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-4b6805b2-1baa-4f5a-b496-74ce8c4f36ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-56b8c5d5-e31c-45ff-9675-025f0feefc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-80620ddc-150a-4f0b-9932-a151cccf08ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-fac4186f-a3f6-4b2e-b8ba-3ff669103ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-1c56cadb-7b95-4053-94a5-f2845ffe1980,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-7a9938e1-a694-43cf-9649-b43a2cec114f,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-93dbe52f-9c3c-473e-a327-f5358092137e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211639737-172.17.0.21-1595962660484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36167,DS-f6916984-e58a-436a-91bc-de6f4f1093b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-4b6805b2-1baa-4f5a-b496-74ce8c4f36ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-56b8c5d5-e31c-45ff-9675-025f0feefc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-80620ddc-150a-4f0b-9932-a151cccf08ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-fac4186f-a3f6-4b2e-b8ba-3ff669103ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-1c56cadb-7b95-4053-94a5-f2845ffe1980,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-7a9938e1-a694-43cf-9649-b43a2cec114f,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-93dbe52f-9c3c-473e-a327-f5358092137e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265056652-172.17.0.21-1595963321147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44552,DS-75d66393-bc3f-4553-8987-6ff1de3df9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-ef7868d7-60ff-4269-b04b-1043247bdc92,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-ab17b871-9ef7-43db-b6a2-56f486f3da2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-8b958ed5-b694-4fba-90c1-c8309f80af58,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-97ad982f-6583-433e-b951-898ba66ff6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-01971a12-ae6e-465b-9680-da66ec5a4bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-f68b914e-5edc-404c-b097-eeb978ff27b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-bd8a1d2f-b5bc-47db-afa6-d8c3d86bcb7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1265056652-172.17.0.21-1595963321147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44552,DS-75d66393-bc3f-4553-8987-6ff1de3df9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-ef7868d7-60ff-4269-b04b-1043247bdc92,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-ab17b871-9ef7-43db-b6a2-56f486f3da2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-8b958ed5-b694-4fba-90c1-c8309f80af58,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-97ad982f-6583-433e-b951-898ba66ff6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-01971a12-ae6e-465b-9680-da66ec5a4bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-f68b914e-5edc-404c-b097-eeb978ff27b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-bd8a1d2f-b5bc-47db-afa6-d8c3d86bcb7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765178792-172.17.0.21-1595963516210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33575,DS-00a50d9e-c245-42cd-9c07-cbb0ded77fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-d206e8bc-ffc1-4b81-b0ae-11bc0cfa88fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-752c91f4-8f5a-403b-914e-ef8d8df3a202,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-6770cd13-09ef-4f45-a901-15ac560cc55e,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-05bc9fe7-551d-4a6c-893d-166eba1df379,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-268dd4b5-1703-4408-b1bf-0c6732dadea9,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-3bda8f5d-9cba-4ec9-b44a-519469687f97,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-59484406-6e0e-419d-9d90-45923bcafc29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765178792-172.17.0.21-1595963516210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33575,DS-00a50d9e-c245-42cd-9c07-cbb0ded77fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-d206e8bc-ffc1-4b81-b0ae-11bc0cfa88fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-752c91f4-8f5a-403b-914e-ef8d8df3a202,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-6770cd13-09ef-4f45-a901-15ac560cc55e,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-05bc9fe7-551d-4a6c-893d-166eba1df379,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-268dd4b5-1703-4408-b1bf-0c6732dadea9,DISK], DatanodeInfoWithStorage[127.0.0.1:41987,DS-3bda8f5d-9cba-4ec9-b44a-519469687f97,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-59484406-6e0e-419d-9d90-45923bcafc29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978024678-172.17.0.21-1595963701139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37172,DS-f345d6a4-2194-4d92-8f89-39cf9395bbba,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-153d2f95-68a1-4e65-a1cd-a55553e40bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-eb9023f2-8d5e-4909-8077-02a96a63eb25,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-e6a68aeb-c7fb-408d-9068-82485e8c600f,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-66a0f8af-be75-4fd0-b91c-d97b5f457672,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-5d4c1efd-5ab4-4f40-a34d-a77c71802bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-ab5a5431-ff45-4687-80de-fad03aec2c79,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-774f1acc-3758-488c-b851-1fe940693f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978024678-172.17.0.21-1595963701139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37172,DS-f345d6a4-2194-4d92-8f89-39cf9395bbba,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-153d2f95-68a1-4e65-a1cd-a55553e40bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-eb9023f2-8d5e-4909-8077-02a96a63eb25,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-e6a68aeb-c7fb-408d-9068-82485e8c600f,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-66a0f8af-be75-4fd0-b91c-d97b5f457672,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-5d4c1efd-5ab4-4f40-a34d-a77c71802bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-ab5a5431-ff45-4687-80de-fad03aec2c79,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-774f1acc-3758-488c-b851-1fe940693f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69383645-172.17.0.21-1595963779034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41284,DS-d9af0a46-2feb-45ed-89ab-dc1d0a503528,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-4656fafd-13c5-4ea8-a2ad-dbe6da6ed340,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-14230271-203e-450c-a0ef-55f92765c834,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-b71e988f-5c73-4622-9220-f463fac8d0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-cfc0f1e0-0b63-40d8-a2fb-26f03d644e97,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-25e15da3-1435-4c71-9f6c-c82b007c2a95,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-ea5204f6-462b-4ccb-bf1a-92d72840ed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-de5f1409-e2eb-48f1-b456-6c65674d75ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69383645-172.17.0.21-1595963779034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41284,DS-d9af0a46-2feb-45ed-89ab-dc1d0a503528,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-4656fafd-13c5-4ea8-a2ad-dbe6da6ed340,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-14230271-203e-450c-a0ef-55f92765c834,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-b71e988f-5c73-4622-9220-f463fac8d0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-cfc0f1e0-0b63-40d8-a2fb-26f03d644e97,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-25e15da3-1435-4c71-9f6c-c82b007c2a95,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-ea5204f6-462b-4ccb-bf1a-92d72840ed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-de5f1409-e2eb-48f1-b456-6c65674d75ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659510077-172.17.0.21-1595963888934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40674,DS-cc7a371c-3700-4547-9886-035e641e08c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-676ba0d6-f572-45a5-b84f-d8aa566b7845,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-18a73164-a522-48f3-ae61-971b63c2723f,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-4cc473da-37ab-400a-849c-f84b9f3f2d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-e82b4bf9-a776-4205-9412-a20e7c6025c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-7249a6d3-1f10-4b21-833d-9fcd19146deb,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-300b8c52-4880-4f90-beaf-5d90f1b2b585,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-5917434b-bbbc-4a13-b07b-22509d1ace95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659510077-172.17.0.21-1595963888934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40674,DS-cc7a371c-3700-4547-9886-035e641e08c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-676ba0d6-f572-45a5-b84f-d8aa566b7845,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-18a73164-a522-48f3-ae61-971b63c2723f,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-4cc473da-37ab-400a-849c-f84b9f3f2d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-e82b4bf9-a776-4205-9412-a20e7c6025c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-7249a6d3-1f10-4b21-833d-9fcd19146deb,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-300b8c52-4880-4f90-beaf-5d90f1b2b585,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-5917434b-bbbc-4a13-b07b-22509d1ace95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789328888-172.17.0.21-1595964053677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37201,DS-23f4a0ff-f705-4747-b306-a1d430c15b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-81e15e03-bc3c-4316-9467-a9cef4cac12e,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-f7f62f43-20f8-437c-ac35-9341703e5859,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-eadd20ff-937e-4930-9d68-19ae6f76974b,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-6a784560-3b4e-4336-a5ff-c788611b62a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-326aa801-f043-44c7-86cd-97e433d78667,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-47d79c2e-06af-47b4-849b-726963d52f86,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-61007e22-1811-4bef-8951-80d67c48c749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789328888-172.17.0.21-1595964053677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37201,DS-23f4a0ff-f705-4747-b306-a1d430c15b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-81e15e03-bc3c-4316-9467-a9cef4cac12e,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-f7f62f43-20f8-437c-ac35-9341703e5859,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-eadd20ff-937e-4930-9d68-19ae6f76974b,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-6a784560-3b4e-4336-a5ff-c788611b62a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-326aa801-f043-44c7-86cd-97e433d78667,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-47d79c2e-06af-47b4-849b-726963d52f86,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-61007e22-1811-4bef-8951-80d67c48c749,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129709655-172.17.0.21-1595964239211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32951,DS-6342c123-c792-4e7a-881b-0d3134572e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-70ddbd46-33ea-4457-9e37-3bbb475136c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-a7990d92-8414-4a09-a2c4-24e61b9f04b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-6b0ebeaf-dd79-4683-be0f-e0bffb6b8589,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-569b0a12-bb08-47ad-a290-fa2fff879c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-4d214337-c299-443a-a05c-82a788e98f01,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-1608074e-59cf-4f26-8d95-998ca174a6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-c95f4562-518e-427c-866a-3b7c77d8d68f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129709655-172.17.0.21-1595964239211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32951,DS-6342c123-c792-4e7a-881b-0d3134572e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-70ddbd46-33ea-4457-9e37-3bbb475136c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-a7990d92-8414-4a09-a2c4-24e61b9f04b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-6b0ebeaf-dd79-4683-be0f-e0bffb6b8589,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-569b0a12-bb08-47ad-a290-fa2fff879c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-4d214337-c299-443a-a05c-82a788e98f01,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-1608074e-59cf-4f26-8d95-998ca174a6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-c95f4562-518e-427c-866a-3b7c77d8d68f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119235823-172.17.0.21-1595964393484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43581,DS-ae7e576e-d950-4881-803d-47946cecef4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-14c265f6-19e1-491e-8e65-2b57e4cb8894,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-3519ed9d-b3dc-4627-9170-77f31d3cac17,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-0ad2535f-09a5-4adc-8a4a-2f3423ce191b,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-2a6f7441-c383-492b-869d-8ad6f55a2916,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-34a85930-143a-44c4-84a2-b0b0875f64fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-f92e7663-66c2-483b-b967-365d01199f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-e12ef131-aa52-4509-8358-b5b578dfebea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119235823-172.17.0.21-1595964393484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43581,DS-ae7e576e-d950-4881-803d-47946cecef4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-14c265f6-19e1-491e-8e65-2b57e4cb8894,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-3519ed9d-b3dc-4627-9170-77f31d3cac17,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-0ad2535f-09a5-4adc-8a4a-2f3423ce191b,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-2a6f7441-c383-492b-869d-8ad6f55a2916,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-34a85930-143a-44c4-84a2-b0b0875f64fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-f92e7663-66c2-483b-b967-365d01199f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-e12ef131-aa52-4509-8358-b5b578dfebea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835987409-172.17.0.21-1595964819290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37822,DS-7b1b9f17-73b4-4098-8461-6e6c94db9106,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-24011940-4b06-43b4-b9dd-639706f019bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-e059dc1d-0e01-48c7-b6c2-5d51b3f8f68c,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-5d80dfbf-642e-41bd-9df4-ab66e148d1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-34373bf0-f3e9-4957-bc2f-15b792653508,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-7864b4d7-fade-4891-953d-b905b3522f58,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-fffb3ed1-9ee0-4b12-89c0-44eb6b35612a,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-ca2b8573-b47d-47f6-be75-1a6f28b01e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835987409-172.17.0.21-1595964819290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37822,DS-7b1b9f17-73b4-4098-8461-6e6c94db9106,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-24011940-4b06-43b4-b9dd-639706f019bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-e059dc1d-0e01-48c7-b6c2-5d51b3f8f68c,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-5d80dfbf-642e-41bd-9df4-ab66e148d1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-34373bf0-f3e9-4957-bc2f-15b792653508,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-7864b4d7-fade-4891-953d-b905b3522f58,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-fffb3ed1-9ee0-4b12-89c0-44eb6b35612a,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-ca2b8573-b47d-47f6-be75-1a6f28b01e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594146223-172.17.0.21-1595965989707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41732,DS-e79d9592-8dfc-4e92-8eeb-30d8d1b352e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-42894990-2df1-452c-abec-f89536bf7203,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-8ff6f64f-ef54-4384-874c-cad3df8491c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-5b0d9cfb-afc0-4c26-bcdb-76bda44505c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-78eaf622-80eb-47fd-a82a-346c9f677ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-dad6a08b-48d3-45f7-be0e-89f30ec89b83,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-41c5843c-76e3-45db-831f-f66457ba3f68,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-fef248d6-4402-48e5-835c-56accfd03bad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594146223-172.17.0.21-1595965989707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41732,DS-e79d9592-8dfc-4e92-8eeb-30d8d1b352e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-42894990-2df1-452c-abec-f89536bf7203,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-8ff6f64f-ef54-4384-874c-cad3df8491c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-5b0d9cfb-afc0-4c26-bcdb-76bda44505c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-78eaf622-80eb-47fd-a82a-346c9f677ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-dad6a08b-48d3-45f7-be0e-89f30ec89b83,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-41c5843c-76e3-45db-831f-f66457ba3f68,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-fef248d6-4402-48e5-835c-56accfd03bad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649837510-172.17.0.21-1595966109981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34286,DS-fa3c3495-ae92-4289-b029-e17c3a5cfbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-bbd229a0-a116-4f25-b4eb-3796aa8d7688,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-72cea188-8847-48f2-b2df-6fb447a793b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-82562379-a67e-49a4-8534-fd01a6ca7de3,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-49c81566-2068-40ea-85a5-e1f9d70920e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-651bb91b-23c3-47cf-a1ea-f382a11fdaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-2687fba3-9b24-429f-a873-3c8893899a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-9c8bc0b9-2a63-4415-9874-b9ef91e7a8f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1649837510-172.17.0.21-1595966109981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34286,DS-fa3c3495-ae92-4289-b029-e17c3a5cfbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-bbd229a0-a116-4f25-b4eb-3796aa8d7688,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-72cea188-8847-48f2-b2df-6fb447a793b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-82562379-a67e-49a4-8534-fd01a6ca7de3,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-49c81566-2068-40ea-85a5-e1f9d70920e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-651bb91b-23c3-47cf-a1ea-f382a11fdaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-2687fba3-9b24-429f-a873-3c8893899a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-9c8bc0b9-2a63-4415-9874-b9ef91e7a8f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375974633-172.17.0.21-1595966400717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44945,DS-afb4e028-f7f8-45a5-834c-2fe61756601d,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-ab008a9e-296d-4251-a677-eec237bc1e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-5918bc98-0ad4-4155-b4fa-60c48a98af58,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-c577ee38-2f23-44f5-8b9b-d463dd17d82a,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-779fa100-5753-4dc8-905d-615ebe0d35c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-b897cbae-f222-40e4-8542-1d001d8b6296,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-6a7a4650-998b-4290-8ab6-0f694db234ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-b3c56d79-ff44-4eec-bd2d-e0594276b321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375974633-172.17.0.21-1595966400717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44945,DS-afb4e028-f7f8-45a5-834c-2fe61756601d,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-ab008a9e-296d-4251-a677-eec237bc1e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-5918bc98-0ad4-4155-b4fa-60c48a98af58,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-c577ee38-2f23-44f5-8b9b-d463dd17d82a,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-779fa100-5753-4dc8-905d-615ebe0d35c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-b897cbae-f222-40e4-8542-1d001d8b6296,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-6a7a4650-998b-4290-8ab6-0f694db234ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-b3c56d79-ff44-4eec-bd2d-e0594276b321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239640852-172.17.0.21-1595966781542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-719f0751-6360-402e-aee3-b7b4f3fdc3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-18fc29b6-ae3f-4105-9323-5d8a4ab42039,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-8671cbc7-57d2-4c66-8cd8-a56f34dbdbca,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-045d530a-b8bf-42eb-b251-2baa6f2853f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-02214dd4-0e74-4e5a-84cf-05a913d3d529,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-e8790dc0-6665-49a8-a1a1-0bc1506a0a17,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-30f900e6-80f5-487e-a199-e158361f9b91,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-f556c5e9-e0be-4658-9e09-499804767f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239640852-172.17.0.21-1595966781542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-719f0751-6360-402e-aee3-b7b4f3fdc3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-18fc29b6-ae3f-4105-9323-5d8a4ab42039,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-8671cbc7-57d2-4c66-8cd8-a56f34dbdbca,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-045d530a-b8bf-42eb-b251-2baa6f2853f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-02214dd4-0e74-4e5a-84cf-05a913d3d529,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-e8790dc0-6665-49a8-a1a1-0bc1506a0a17,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-30f900e6-80f5-487e-a199-e158361f9b91,DISK], DatanodeInfoWithStorage[127.0.0.1:46321,DS-f556c5e9-e0be-4658-9e09-499804767f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394118709-172.17.0.21-1595967663102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42528,DS-4686e6c8-bdaf-4c5e-adab-e81490628cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-acb65e11-0b5f-43fb-bfca-f30467950205,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-54bde149-876a-46bf-bf59-be25741cc70d,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-3bacf79d-7dd4-4167-b307-1103f4530e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-38fc2af8-2892-4cbe-bba5-6bd4f69d2d50,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-0c5820e8-2239-4f1a-8014-b910c356d5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-7084a705-4116-435f-8505-9c929105cade,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-d20ef24c-6c39-49f0-8817-91b4154dd56a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394118709-172.17.0.21-1595967663102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42528,DS-4686e6c8-bdaf-4c5e-adab-e81490628cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-acb65e11-0b5f-43fb-bfca-f30467950205,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-54bde149-876a-46bf-bf59-be25741cc70d,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-3bacf79d-7dd4-4167-b307-1103f4530e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-38fc2af8-2892-4cbe-bba5-6bd4f69d2d50,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-0c5820e8-2239-4f1a-8014-b910c356d5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-7084a705-4116-435f-8505-9c929105cade,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-d20ef24c-6c39-49f0-8817-91b4154dd56a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400689641-172.17.0.21-1595967896786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45489,DS-42d06a36-47a7-4089-838d-8dd7acc66299,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-13ce69e0-17a3-40d1-bccf-717375caf798,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-565f02d6-8a87-4411-975e-83e7c84ec299,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-7f5e2a86-c74c-43e4-bf0a-47d543cf648c,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-d66b8a33-b8c5-4483-8bb7-5fb41fbc7ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-240a277f-2a89-4467-ade5-7f71755868ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-6dd320c8-20b9-4208-b777-fbcd9a1ecf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-ac9fe482-5596-4e6b-bef9-c2b802946a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400689641-172.17.0.21-1595967896786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45489,DS-42d06a36-47a7-4089-838d-8dd7acc66299,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-13ce69e0-17a3-40d1-bccf-717375caf798,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-565f02d6-8a87-4411-975e-83e7c84ec299,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-7f5e2a86-c74c-43e4-bf0a-47d543cf648c,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-d66b8a33-b8c5-4483-8bb7-5fb41fbc7ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-240a277f-2a89-4467-ade5-7f71755868ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-6dd320c8-20b9-4208-b777-fbcd9a1ecf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-ac9fe482-5596-4e6b-bef9-c2b802946a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673253868-172.17.0.21-1595968026212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40873,DS-249cda61-3123-4192-bf0b-29ef6e429958,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-cf2b130d-4e99-4d17-a17a-837a605f56c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-70044a32-b2b3-48b4-aba4-f4bd9c34da34,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-5773befb-b6e5-4fee-89d4-c0992ed0cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-6180bb00-8bb1-42df-9bb7-1318f8ad1e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-8e777b8b-5d46-424c-a990-aec6fc4db3da,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-68534898-8578-472a-af79-22483e600ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-c3d98a82-d9fe-4592-a9c9-c0f0585f7c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1673253868-172.17.0.21-1595968026212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40873,DS-249cda61-3123-4192-bf0b-29ef6e429958,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-cf2b130d-4e99-4d17-a17a-837a605f56c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-70044a32-b2b3-48b4-aba4-f4bd9c34da34,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-5773befb-b6e5-4fee-89d4-c0992ed0cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-6180bb00-8bb1-42df-9bb7-1318f8ad1e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-8e777b8b-5d46-424c-a990-aec6fc4db3da,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-68534898-8578-472a-af79-22483e600ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-c3d98a82-d9fe-4592-a9c9-c0f0585f7c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.maintenance.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008835869-172.17.0.21-1595968067178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-8614b966-0b6b-41fa-86af-0b16f5376a96,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-d8de7736-6254-48e7-8735-99e40bfe6c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-3ff178d6-db38-4544-b50c-b2601dfccdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-f11b4c9f-258f-4113-876b-687560d523e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-b01d39d2-bc05-4b69-a7fd-2988e175582f,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-d712d2d9-56cc-4edb-8f26-3778f27428c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-efddfd81-9c67-4a16-a33c-cd6af80768e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-d82459c6-3152-4e46-96b4-e1fbbaebabf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008835869-172.17.0.21-1595968067178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-8614b966-0b6b-41fa-86af-0b16f5376a96,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-d8de7736-6254-48e7-8735-99e40bfe6c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-3ff178d6-db38-4544-b50c-b2601dfccdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-f11b4c9f-258f-4113-876b-687560d523e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-b01d39d2-bc05-4b69-a7fd-2988e175582f,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-d712d2d9-56cc-4edb-8f26-3778f27428c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-efddfd81-9c67-4a16-a33c-cd6af80768e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-d82459c6-3152-4e46-96b4-e1fbbaebabf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5579
