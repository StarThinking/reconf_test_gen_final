reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973119679-172.17.0.7-1595901037211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40844,DS-5df27464-5bdf-4c4e-989a-5f34e698abad,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-356c3251-5818-4ad5-a8e7-a3bde34af508,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-0ba985d3-1300-46f4-87f5-8522134c237f,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-4fc8eb52-a94d-4793-a725-55584cdc7dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-7b8a3a66-382d-4828-83f4-50ad7922720f,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-15543f0c-b512-4b5d-a652-41dd170fb579,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-55ff919a-b624-42ff-8e14-844e2440b0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-03b4403c-26fb-40c0-b8f5-dbbcb6f8b7d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973119679-172.17.0.7-1595901037211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40844,DS-5df27464-5bdf-4c4e-989a-5f34e698abad,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-356c3251-5818-4ad5-a8e7-a3bde34af508,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-0ba985d3-1300-46f4-87f5-8522134c237f,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-4fc8eb52-a94d-4793-a725-55584cdc7dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-7b8a3a66-382d-4828-83f4-50ad7922720f,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-15543f0c-b512-4b5d-a652-41dd170fb579,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-55ff919a-b624-42ff-8e14-844e2440b0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-03b4403c-26fb-40c0-b8f5-dbbcb6f8b7d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607203676-172.17.0.7-1595901414857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39119,DS-da442563-e115-44a4-8c81-a03b302cdec6,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-5f91a2ae-cbff-4e6c-92eb-229d0eccff78,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-8eb126f4-45bf-4fd3-a79d-a990284ee8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-c759b340-00e7-4bd5-82e3-30a793fd2415,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-8fbbff56-54ee-474c-af4c-935f2ae4f5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-388f3d43-364f-46df-9a29-f45d9f96dc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-62cda961-a6c3-4af9-9b5a-8c981faaeb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-63040c6f-6be8-430e-b66e-f762f0e3ce72,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607203676-172.17.0.7-1595901414857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39119,DS-da442563-e115-44a4-8c81-a03b302cdec6,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-5f91a2ae-cbff-4e6c-92eb-229d0eccff78,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-8eb126f4-45bf-4fd3-a79d-a990284ee8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-c759b340-00e7-4bd5-82e3-30a793fd2415,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-8fbbff56-54ee-474c-af4c-935f2ae4f5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-388f3d43-364f-46df-9a29-f45d9f96dc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-62cda961-a6c3-4af9-9b5a-8c981faaeb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41037,DS-63040c6f-6be8-430e-b66e-f762f0e3ce72,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274762895-172.17.0.7-1595901879061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34498,DS-6c16a98f-574f-4fd1-a366-3e8f0e29f6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-0fadbe0a-fc22-414f-92da-56b343ad968c,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-3b9f2384-b35c-43d5-9496-e64dfad20ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-aee60453-dd7e-48d9-af52-96974939a798,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-06337b75-32a8-40dc-9dd0-dff46da2181d,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-e6feb208-56e8-486a-bb12-6fcaed415901,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-8ea3efd5-6761-4c7f-9ec1-29f0f259a96b,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-094dec2f-066c-4209-ae54-3ff2acdc4eee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274762895-172.17.0.7-1595901879061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34498,DS-6c16a98f-574f-4fd1-a366-3e8f0e29f6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-0fadbe0a-fc22-414f-92da-56b343ad968c,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-3b9f2384-b35c-43d5-9496-e64dfad20ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-aee60453-dd7e-48d9-af52-96974939a798,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-06337b75-32a8-40dc-9dd0-dff46da2181d,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-e6feb208-56e8-486a-bb12-6fcaed415901,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-8ea3efd5-6761-4c7f-9ec1-29f0f259a96b,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-094dec2f-066c-4209-ae54-3ff2acdc4eee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609191040-172.17.0.7-1595901954408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42629,DS-bc51e35b-a0a7-427a-b686-2a7cda08de63,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-3afeb57a-d2b1-4e69-9a44-6c82d4ce578c,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-6ef791b4-a636-4ef4-86f6-5f7b0e7e1514,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-ab2b7bdb-7003-4436-b085-be172216dd70,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-a570661d-68f2-4f58-924a-db6392a7d279,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-ab2b3933-57eb-431d-b49d-8a27b8cc8a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-4356ca62-1c62-41c4-919e-1cc89dd89b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-dd064dca-5c4f-4c7e-bdfc-faecc4172006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1609191040-172.17.0.7-1595901954408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42629,DS-bc51e35b-a0a7-427a-b686-2a7cda08de63,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-3afeb57a-d2b1-4e69-9a44-6c82d4ce578c,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-6ef791b4-a636-4ef4-86f6-5f7b0e7e1514,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-ab2b7bdb-7003-4436-b085-be172216dd70,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-a570661d-68f2-4f58-924a-db6392a7d279,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-ab2b3933-57eb-431d-b49d-8a27b8cc8a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38417,DS-4356ca62-1c62-41c4-919e-1cc89dd89b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-dd064dca-5c4f-4c7e-bdfc-faecc4172006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453333556-172.17.0.7-1595901991689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37100,DS-92bc8318-2ad0-4aa4-88e2-4ec623a65983,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-b4dc67dc-fd0c-4f1b-b700-7e3f1a90fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-1465815c-030e-4dff-8c73-bc756c28dc05,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-68721352-6821-45bf-aa15-2d94a40f3a83,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-34e7374c-3ead-4f50-bd2e-749d7c170047,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-2cf0982f-508a-4aa3-aaf1-bbdea08a2621,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-cb768867-5327-4549-8745-90ca2058cca8,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-8f9fceb5-4060-414e-870e-c2a9566b1991,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453333556-172.17.0.7-1595901991689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37100,DS-92bc8318-2ad0-4aa4-88e2-4ec623a65983,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-b4dc67dc-fd0c-4f1b-b700-7e3f1a90fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-1465815c-030e-4dff-8c73-bc756c28dc05,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-68721352-6821-45bf-aa15-2d94a40f3a83,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-34e7374c-3ead-4f50-bd2e-749d7c170047,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-2cf0982f-508a-4aa3-aaf1-bbdea08a2621,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-cb768867-5327-4549-8745-90ca2058cca8,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-8f9fceb5-4060-414e-870e-c2a9566b1991,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496016961-172.17.0.7-1595902026259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34274,DS-7d281806-b97e-40fc-868e-11945c4f2f63,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-6321cd48-5ed0-49bc-b1f2-1c063c983f08,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-38b1b0ab-7f98-4025-a007-2bcb8a95dd79,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-c77f6440-7feb-4fd6-9983-06286e811798,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-7827d8f1-24cc-4ced-b4f2-b2c8b729c88b,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-f3495d45-5e1d-4e6e-8b81-c3594f3fbbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-80a959fa-f340-464e-931c-6e89a615c3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-2acf87c5-d72a-4729-b4a4-05a868b9c110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496016961-172.17.0.7-1595902026259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34274,DS-7d281806-b97e-40fc-868e-11945c4f2f63,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-6321cd48-5ed0-49bc-b1f2-1c063c983f08,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-38b1b0ab-7f98-4025-a007-2bcb8a95dd79,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-c77f6440-7feb-4fd6-9983-06286e811798,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-7827d8f1-24cc-4ced-b4f2-b2c8b729c88b,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-f3495d45-5e1d-4e6e-8b81-c3594f3fbbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-80a959fa-f340-464e-931c-6e89a615c3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-2acf87c5-d72a-4729-b4a4-05a868b9c110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348525342-172.17.0.7-1595902170768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44887,DS-7b957847-7269-43ff-97e9-8e9b4316df72,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-94a4edec-1c02-4659-b578-0e03ff5eec9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-bb75f600-2633-4e3e-b36e-06bc0baf4756,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-9f84dab4-6e9b-4c69-9d6a-379bf94617ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-6e8c67c7-e6dc-4e0d-9e39-1850e2cea3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-35e78490-0049-49f0-b7e0-e0701499ef98,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-8289b978-7097-4438-bea7-5ab22b2574b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-c3d38c75-a107-4357-aa5d-f367096068fd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348525342-172.17.0.7-1595902170768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44887,DS-7b957847-7269-43ff-97e9-8e9b4316df72,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-94a4edec-1c02-4659-b578-0e03ff5eec9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-bb75f600-2633-4e3e-b36e-06bc0baf4756,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-9f84dab4-6e9b-4c69-9d6a-379bf94617ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-6e8c67c7-e6dc-4e0d-9e39-1850e2cea3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-35e78490-0049-49f0-b7e0-e0701499ef98,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-8289b978-7097-4438-bea7-5ab22b2574b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-c3d38c75-a107-4357-aa5d-f367096068fd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541691412-172.17.0.7-1595902204360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33931,DS-458c963e-9a9a-4568-a4c5-cf29c5d8e000,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-3adf48b4-d602-4914-9792-fdf0ee0e8ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-fc2360f3-809e-4aba-82ed-9f11a297cecf,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-fb255bc9-b943-4731-b682-d405612f0f60,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-5b3810a5-9ede-42ce-a629-be6be038b2af,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-948e7709-3a5d-4ed1-9868-535a7e6d578c,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-71f491fb-7cd8-4800-bce7-eed221317c96,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-19db38c8-46f0-493e-ad85-363422d4d1e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541691412-172.17.0.7-1595902204360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33931,DS-458c963e-9a9a-4568-a4c5-cf29c5d8e000,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-3adf48b4-d602-4914-9792-fdf0ee0e8ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-fc2360f3-809e-4aba-82ed-9f11a297cecf,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-fb255bc9-b943-4731-b682-d405612f0f60,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-5b3810a5-9ede-42ce-a629-be6be038b2af,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-948e7709-3a5d-4ed1-9868-535a7e6d578c,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-71f491fb-7cd8-4800-bce7-eed221317c96,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-19db38c8-46f0-493e-ad85-363422d4d1e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105156027-172.17.0.7-1595902245621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42190,DS-a86860a5-2845-446a-99ee-9d23d0505a77,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-19043e68-aaff-46c5-bdb4-67782cf7feb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-583a675d-5a2f-44fa-971c-7572e9c101b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-d913f53c-a9d6-4bc4-a976-291057ddb358,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-2631fa72-7aa5-40eb-92e0-02efd0957a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-a9872dc6-ed49-4851-a54e-711920ed8892,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-cfa519a1-2ec7-41f6-a0c4-11758a9c875b,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-0ce7fea0-926d-49a6-840e-48e72af5c162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105156027-172.17.0.7-1595902245621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42190,DS-a86860a5-2845-446a-99ee-9d23d0505a77,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-19043e68-aaff-46c5-bdb4-67782cf7feb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-583a675d-5a2f-44fa-971c-7572e9c101b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-d913f53c-a9d6-4bc4-a976-291057ddb358,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-2631fa72-7aa5-40eb-92e0-02efd0957a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-a9872dc6-ed49-4851-a54e-711920ed8892,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-cfa519a1-2ec7-41f6-a0c4-11758a9c875b,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-0ce7fea0-926d-49a6-840e-48e72af5c162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930157971-172.17.0.7-1595902287465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44243,DS-f0ecfb19-cdd3-4f08-9031-c67f160eb401,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-a845697b-3d50-4313-95be-c0d2d276d26b,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-5267cceb-8770-4b89-89fc-46200ab99657,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-ae5e0c3f-1fa3-4757-b697-ac278030b33a,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-a2fb815e-196c-4749-b56e-8d632a8f5470,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-70e95200-6b08-4223-be7a-b2871737eb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-96523361-d366-447e-a4ea-d1247cb7d660,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-bc0e5f38-5e5d-40a4-a8a6-b94070ac098a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930157971-172.17.0.7-1595902287465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44243,DS-f0ecfb19-cdd3-4f08-9031-c67f160eb401,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-a845697b-3d50-4313-95be-c0d2d276d26b,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-5267cceb-8770-4b89-89fc-46200ab99657,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-ae5e0c3f-1fa3-4757-b697-ac278030b33a,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-a2fb815e-196c-4749-b56e-8d632a8f5470,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-70e95200-6b08-4223-be7a-b2871737eb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-96523361-d366-447e-a4ea-d1247cb7d660,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-bc0e5f38-5e5d-40a4-a8a6-b94070ac098a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800956449-172.17.0.7-1595902399855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44335,DS-ac0dd05b-3f64-4f35-8876-f726ec449def,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-585a3ff5-876b-4ba0-9f80-b5cef1be9877,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-279140b8-86a8-4e7f-9c75-2999df290552,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-5a906026-1de2-4601-b665-9ea87dd48287,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-a28e8157-6433-402f-9818-93d955ef5c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-887a3f95-0154-40ea-b741-922b445b43f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-5e80d160-13dc-4d1a-9bec-1dbb2f044beb,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-6d629955-60af-4853-9d2a-493555421d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800956449-172.17.0.7-1595902399855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44335,DS-ac0dd05b-3f64-4f35-8876-f726ec449def,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-585a3ff5-876b-4ba0-9f80-b5cef1be9877,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-279140b8-86a8-4e7f-9c75-2999df290552,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-5a906026-1de2-4601-b665-9ea87dd48287,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-a28e8157-6433-402f-9818-93d955ef5c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-887a3f95-0154-40ea-b741-922b445b43f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-5e80d160-13dc-4d1a-9bec-1dbb2f044beb,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-6d629955-60af-4853-9d2a-493555421d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383478090-172.17.0.7-1595902601378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35092,DS-d165852d-ffd0-465b-8cd4-0e632cde0b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-a18ff71d-f18a-452b-84f7-0dbb7a585903,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-a60ae03b-302e-41af-806d-4bcc008df022,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-174a1eb0-ea67-4773-b2f9-47bb382a9608,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-523e52ac-4342-48a3-b141-e7baa7736d02,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-c5df32a1-1617-47d2-ae39-161c5adc3230,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-f3c89af3-9ea3-4a88-b1f9-7effb271d7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-55f4c079-42f7-462f-a73a-a7843d0a6b8b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383478090-172.17.0.7-1595902601378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35092,DS-d165852d-ffd0-465b-8cd4-0e632cde0b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-a18ff71d-f18a-452b-84f7-0dbb7a585903,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-a60ae03b-302e-41af-806d-4bcc008df022,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-174a1eb0-ea67-4773-b2f9-47bb382a9608,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-523e52ac-4342-48a3-b141-e7baa7736d02,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-c5df32a1-1617-47d2-ae39-161c5adc3230,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-f3c89af3-9ea3-4a88-b1f9-7effb271d7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-55f4c079-42f7-462f-a73a-a7843d0a6b8b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256382832-172.17.0.7-1595902643084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37714,DS-908cdd6d-d0c7-4d28-84ea-540d80a0e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-930ec219-897c-4ac4-b2bb-8a0fb9666498,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-1f155a20-e365-437d-8435-215e4f792651,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-0747bfb4-0890-4f94-b39b-991b793adcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-85122457-3d07-4594-8aa7-5e57fc09fbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-ca030adb-5d51-460c-8c5d-42151f5a1482,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-92316c7f-1972-41bf-8efa-6fc75fc0d632,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-aa8ebac3-369e-480a-8a80-f96495f2796f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256382832-172.17.0.7-1595902643084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37714,DS-908cdd6d-d0c7-4d28-84ea-540d80a0e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-930ec219-897c-4ac4-b2bb-8a0fb9666498,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-1f155a20-e365-437d-8435-215e4f792651,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-0747bfb4-0890-4f94-b39b-991b793adcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-85122457-3d07-4594-8aa7-5e57fc09fbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-ca030adb-5d51-460c-8c5d-42151f5a1482,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-92316c7f-1972-41bf-8efa-6fc75fc0d632,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-aa8ebac3-369e-480a-8a80-f96495f2796f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549394912-172.17.0.7-1595902792588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45591,DS-c3d0493d-a1c4-43df-bcec-3466647995ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-d75b8146-d15a-49ab-bcf6-3518e0fa5098,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-790b9456-9a92-44a8-b2a4-fb1d02d51f15,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-efbbd953-0bc2-4288-b62b-788a983ba787,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-06018ff3-5779-42fe-bdfc-f3135bdde828,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-4fdc1c04-af7a-4a68-9397-bb9fec3e8879,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-545f2876-bbfe-4738-b825-5554a7204cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-91e37d12-bedc-4665-b8f7-f97b1b209792,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549394912-172.17.0.7-1595902792588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45591,DS-c3d0493d-a1c4-43df-bcec-3466647995ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-d75b8146-d15a-49ab-bcf6-3518e0fa5098,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-790b9456-9a92-44a8-b2a4-fb1d02d51f15,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-efbbd953-0bc2-4288-b62b-788a983ba787,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-06018ff3-5779-42fe-bdfc-f3135bdde828,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-4fdc1c04-af7a-4a68-9397-bb9fec3e8879,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-545f2876-bbfe-4738-b825-5554a7204cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-91e37d12-bedc-4665-b8f7-f97b1b209792,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484856902-172.17.0.7-1595902912562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44741,DS-325a2611-dfd6-4113-b606-6990eb6983a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-9badf3fd-7aef-4dc5-b094-cc2ebf14306b,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-52bd1d69-9b74-45a5-855f-22f736f1febb,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-82bc5776-3231-4fcc-8a20-5c6bb3402da9,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-bafa1fa6-ea6c-4b1e-85ad-732a6cbbc259,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-7f83cbff-b13c-4b2d-a214-4e9323ba422f,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-901d4dd2-7f34-4b6b-837a-c6dbec3738d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-786db7da-eaea-4a90-b354-403063f09d69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484856902-172.17.0.7-1595902912562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44741,DS-325a2611-dfd6-4113-b606-6990eb6983a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-9badf3fd-7aef-4dc5-b094-cc2ebf14306b,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-52bd1d69-9b74-45a5-855f-22f736f1febb,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-82bc5776-3231-4fcc-8a20-5c6bb3402da9,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-bafa1fa6-ea6c-4b1e-85ad-732a6cbbc259,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-7f83cbff-b13c-4b2d-a214-4e9323ba422f,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-901d4dd2-7f34-4b6b-837a-c6dbec3738d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-786db7da-eaea-4a90-b354-403063f09d69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885374119-172.17.0.7-1595902949967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42656,DS-e23cbeba-a254-4a0d-8a50-f64380802389,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-87aa4c89-0d35-4d1b-9d68-a653aae64687,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-742a33e0-4d39-4eb9-874f-4dd17492c2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-024f3832-f66a-4b92-b6ca-1dfb7105862c,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-4f3f9787-4434-40bd-b47c-dd79a9e1e777,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-e2709664-1670-466a-b921-0c4eba4b9920,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-290a144e-f52e-4b5f-9f54-ebddf42c316b,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-ec274c6c-d090-4c93-a231-4ba0e3fe9b06,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885374119-172.17.0.7-1595902949967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42656,DS-e23cbeba-a254-4a0d-8a50-f64380802389,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-87aa4c89-0d35-4d1b-9d68-a653aae64687,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-742a33e0-4d39-4eb9-874f-4dd17492c2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-024f3832-f66a-4b92-b6ca-1dfb7105862c,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-4f3f9787-4434-40bd-b47c-dd79a9e1e777,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-e2709664-1670-466a-b921-0c4eba4b9920,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-290a144e-f52e-4b5f-9f54-ebddf42c316b,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-ec274c6c-d090-4c93-a231-4ba0e3fe9b06,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144168148-172.17.0.7-1595903031128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-fe358852-4c86-4753-9b5a-0e5581c94297,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-e678e302-9140-4565-82f9-d9050ff259e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-c80c402d-15ca-469e-be2f-66ff77424674,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-e42a21e6-07cc-4b62-99d4-693c96fd8c04,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-a042d323-f07c-4caf-91dc-a5f3541283d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-720cc19d-61a3-45a3-9804-44c20ba420e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-9f0e5427-fded-4020-97b2-041711bd34d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-cc6acf87-087f-4e44-8720-347ebd51038b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144168148-172.17.0.7-1595903031128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-fe358852-4c86-4753-9b5a-0e5581c94297,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-e678e302-9140-4565-82f9-d9050ff259e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-c80c402d-15ca-469e-be2f-66ff77424674,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-e42a21e6-07cc-4b62-99d4-693c96fd8c04,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-a042d323-f07c-4caf-91dc-a5f3541283d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-720cc19d-61a3-45a3-9804-44c20ba420e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-9f0e5427-fded-4020-97b2-041711bd34d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-cc6acf87-087f-4e44-8720-347ebd51038b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992208603-172.17.0.7-1595903191936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34760,DS-0537242a-f7f6-4f23-8dfa-11b2dfff8f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-3f2aae49-8409-4b7e-bfde-5afb13b4ef6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-f2001703-67bc-4bf9-8dba-f46b9bbc469d,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-0f3934b8-10bc-40bb-b5b1-40ddeac546d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-c5f9b1d8-a1b7-4028-9366-517ce0f3a231,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-5b9a7537-51f4-4766-8f02-c7589ef25e43,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-08a69dfe-25ca-493f-808a-81bad14dfc87,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-1d245ec2-f060-40f4-931d-fbaf559cdaf1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992208603-172.17.0.7-1595903191936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34760,DS-0537242a-f7f6-4f23-8dfa-11b2dfff8f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-3f2aae49-8409-4b7e-bfde-5afb13b4ef6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-f2001703-67bc-4bf9-8dba-f46b9bbc469d,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-0f3934b8-10bc-40bb-b5b1-40ddeac546d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-c5f9b1d8-a1b7-4028-9366-517ce0f3a231,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-5b9a7537-51f4-4766-8f02-c7589ef25e43,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-08a69dfe-25ca-493f-808a-81bad14dfc87,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-1d245ec2-f060-40f4-931d-fbaf559cdaf1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870858730-172.17.0.7-1595903226176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34831,DS-4b19568b-1ff2-4c8b-9deb-1cb7238e00fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-287ee587-6c71-4217-8752-b5a4f53003b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-7905ca76-2182-4224-8f1a-0fb5bfd93b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-cff74d9e-b864-481d-99d7-e4737474d5df,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-6fe3262b-7f81-4b1a-9f8c-a449ae95e49d,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-6d1f56a8-e2d1-4056-ae63-646f2eff499a,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-bf9e476e-0b4b-4817-a3ed-9d61eaffe414,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-471e58a9-d465-4d2b-9384-7380029cc2e8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870858730-172.17.0.7-1595903226176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34831,DS-4b19568b-1ff2-4c8b-9deb-1cb7238e00fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-287ee587-6c71-4217-8752-b5a4f53003b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-7905ca76-2182-4224-8f1a-0fb5bfd93b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-cff74d9e-b864-481d-99d7-e4737474d5df,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-6fe3262b-7f81-4b1a-9f8c-a449ae95e49d,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-6d1f56a8-e2d1-4056-ae63-646f2eff499a,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-bf9e476e-0b4b-4817-a3ed-9d61eaffe414,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-471e58a9-d465-4d2b-9384-7380029cc2e8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713719228-172.17.0.7-1595903454821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-28c4dc01-61ab-4f53-b5c5-61ab999d1684,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-20cfbfcd-8480-4931-9c21-d4809dba49a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-53f5f8b3-2398-411e-b9e3-ffa92795fec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-835093a2-2cc6-4518-947d-c33bf4e08fad,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-2911e290-6092-422e-b17e-ab7a3cd50ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-1271b399-a9d3-474a-a93a-a28a587c72c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-6de89b35-75b8-469d-ad7d-7537289079d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-b81b7bb0-d13c-48df-a45c-38d1d48ef4a5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713719228-172.17.0.7-1595903454821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-28c4dc01-61ab-4f53-b5c5-61ab999d1684,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-20cfbfcd-8480-4931-9c21-d4809dba49a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-53f5f8b3-2398-411e-b9e3-ffa92795fec3,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-835093a2-2cc6-4518-947d-c33bf4e08fad,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-2911e290-6092-422e-b17e-ab7a3cd50ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-1271b399-a9d3-474a-a93a-a28a587c72c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-6de89b35-75b8-469d-ad7d-7537289079d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40511,DS-b81b7bb0-d13c-48df-a45c-38d1d48ef4a5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530410085-172.17.0.7-1595903602694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35159,DS-acd86deb-7597-4ba0-9863-214a9b3339c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-66693ef4-83a2-431e-bfb9-5202d5c8d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-49b49695-85cd-4b62-9010-dab7f35ae624,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-7a177572-90b8-4f81-9e34-fb3e55073e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-2c476975-4c32-4d65-8d51-18757805a794,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-17f561c3-5898-41dd-a067-e88cb6e0fe24,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-6144e46f-9a56-431a-ba72-061d00386637,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-bdd5ff36-c715-4696-8c86-c099fa74e46f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530410085-172.17.0.7-1595903602694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35159,DS-acd86deb-7597-4ba0-9863-214a9b3339c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-66693ef4-83a2-431e-bfb9-5202d5c8d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-49b49695-85cd-4b62-9010-dab7f35ae624,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-7a177572-90b8-4f81-9e34-fb3e55073e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-2c476975-4c32-4d65-8d51-18757805a794,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-17f561c3-5898-41dd-a067-e88cb6e0fe24,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-6144e46f-9a56-431a-ba72-061d00386637,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-bdd5ff36-c715-4696-8c86-c099fa74e46f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987779796-172.17.0.7-1595903758388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35675,DS-4a035d4c-3efe-4d6b-92b7-c3abd4c6ff92,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-6693b751-d162-4cee-8cdf-eae308bd6a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-3b25abf9-ca95-48b1-9a4c-55dfce9e59c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-507f7fb4-bf71-450e-a3e2-2643942094a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-250a5c27-a1c4-4029-886c-572ce36f58c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-03b3d81c-7c0d-47d8-b7f4-cda0fddde7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-dae2377a-3193-4136-b6a0-0bfdc8798ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-715d4aa4-2972-4614-8e64-273c2ce2d422,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987779796-172.17.0.7-1595903758388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35675,DS-4a035d4c-3efe-4d6b-92b7-c3abd4c6ff92,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-6693b751-d162-4cee-8cdf-eae308bd6a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-3b25abf9-ca95-48b1-9a4c-55dfce9e59c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-507f7fb4-bf71-450e-a3e2-2643942094a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-250a5c27-a1c4-4029-886c-572ce36f58c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-03b3d81c-7c0d-47d8-b7f4-cda0fddde7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-dae2377a-3193-4136-b6a0-0bfdc8798ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-715d4aa4-2972-4614-8e64-273c2ce2d422,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403842608-172.17.0.7-1595903793433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37106,DS-8da253c8-f58f-4fb9-8cfc-4796240624f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-beeefe3b-ef85-4d0f-8f23-2f6b32c9deec,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-d695f38c-4076-4034-b2a9-0628bbefbeab,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-7a79da53-ada9-4aa6-819c-1e24dac0978e,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-ab7648ab-b614-40d8-b3af-722177c182a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-619550af-1d24-42db-8909-edc8070549c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-0a88b40b-807e-47c8-9448-5027cc14c57f,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-5f4343b5-e385-4be1-900e-6d2b35767ca9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403842608-172.17.0.7-1595903793433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37106,DS-8da253c8-f58f-4fb9-8cfc-4796240624f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-beeefe3b-ef85-4d0f-8f23-2f6b32c9deec,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-d695f38c-4076-4034-b2a9-0628bbefbeab,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-7a79da53-ada9-4aa6-819c-1e24dac0978e,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-ab7648ab-b614-40d8-b3af-722177c182a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-619550af-1d24-42db-8909-edc8070549c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-0a88b40b-807e-47c8-9448-5027cc14c57f,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-5f4343b5-e385-4be1-900e-6d2b35767ca9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2125108393-172.17.0.7-1595903901888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44979,DS-4aaf34bc-434a-4df0-93ae-a856f29d839e,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-b4c36498-3fb1-47cc-9ea5-66783fdcde8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-ebc76e71-44ce-4c38-8965-442e03062b03,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-5af7b1e4-8c15-4216-a008-2845f5f48f96,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-55f5b7fd-69e0-4633-a852-1b3f0e3215af,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-ed556610-7138-4a66-9ada-a007e38cffbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-00faa724-d745-47ae-aca6-b6b60cd65c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-53ecb2a4-5f49-463b-bb28-c5fdf25ca7c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2125108393-172.17.0.7-1595903901888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44979,DS-4aaf34bc-434a-4df0-93ae-a856f29d839e,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-b4c36498-3fb1-47cc-9ea5-66783fdcde8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-ebc76e71-44ce-4c38-8965-442e03062b03,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-5af7b1e4-8c15-4216-a008-2845f5f48f96,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-55f5b7fd-69e0-4633-a852-1b3f0e3215af,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-ed556610-7138-4a66-9ada-a007e38cffbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-00faa724-d745-47ae-aca6-b6b60cd65c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-53ecb2a4-5f49-463b-bb28-c5fdf25ca7c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116902566-172.17.0.7-1595903986502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45464,DS-2ef22b9d-f6b6-403e-b6b2-3ff4ef2d37de,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-e3f81524-7c71-4fb3-8b3a-22dc0bf7099d,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-5564b106-5e6a-4d4c-a00d-da002f631d90,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-295bd403-58d0-4735-b1cf-8af4ca660010,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-1fedd3a4-5006-4381-a03b-8edec06eb666,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-dee8cb4e-ad68-44e3-b11b-0388fc8c12aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-a9dfc93f-de48-4fde-a5a2-8b6282263653,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-c1e4426d-4239-4642-a0c1-35f082cd3788,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116902566-172.17.0.7-1595903986502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45464,DS-2ef22b9d-f6b6-403e-b6b2-3ff4ef2d37de,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-e3f81524-7c71-4fb3-8b3a-22dc0bf7099d,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-5564b106-5e6a-4d4c-a00d-da002f631d90,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-295bd403-58d0-4735-b1cf-8af4ca660010,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-1fedd3a4-5006-4381-a03b-8edec06eb666,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-dee8cb4e-ad68-44e3-b11b-0388fc8c12aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-a9dfc93f-de48-4fde-a5a2-8b6282263653,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-c1e4426d-4239-4642-a0c1-35f082cd3788,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537580953-172.17.0.7-1595904022076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38893,DS-88f28556-9bb3-4371-837f-c5a1b133a984,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-a067a15c-5566-44df-af5e-382b4c2a4053,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-0b1d55b1-46be-483c-8fae-7af5ffad433e,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-4e49489e-adf0-4f47-b76f-7e12e80cf6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-3fc9e4d6-d0ac-4272-9a88-c49d0b8aad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-c32fef01-714f-46ae-8347-73aca251680b,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-8238a6e6-579e-4ec0-8026-a76fa870e5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-603a4d70-1a7b-4396-9479-23f5ab557a65,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537580953-172.17.0.7-1595904022076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38893,DS-88f28556-9bb3-4371-837f-c5a1b133a984,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-a067a15c-5566-44df-af5e-382b4c2a4053,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-0b1d55b1-46be-483c-8fae-7af5ffad433e,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-4e49489e-adf0-4f47-b76f-7e12e80cf6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-3fc9e4d6-d0ac-4272-9a88-c49d0b8aad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-c32fef01-714f-46ae-8347-73aca251680b,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-8238a6e6-579e-4ec0-8026-a76fa870e5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-603a4d70-1a7b-4396-9479-23f5ab557a65,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710485314-172.17.0.7-1595904137701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36643,DS-d867a850-7d0d-4c2a-8d93-fbd9ebf9e8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-fd758c3d-29b5-4af5-9f94-dd75732f2bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-3ec2f4ca-38b0-42f0-9bfc-f6efbbbc6f87,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-014af09a-3859-41e0-96e8-12d7d6c68ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-40786e82-f1e8-48fa-90f3-bad970d9e6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-c1316932-8985-4bfb-8c0b-ba832e3b6f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-9a666e75-8cda-4c95-a62c-dbedf954f2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-4043ae9f-6b73-4cd8-9de9-ba3b1d4aad7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710485314-172.17.0.7-1595904137701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36643,DS-d867a850-7d0d-4c2a-8d93-fbd9ebf9e8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-fd758c3d-29b5-4af5-9f94-dd75732f2bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-3ec2f4ca-38b0-42f0-9bfc-f6efbbbc6f87,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-014af09a-3859-41e0-96e8-12d7d6c68ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-40786e82-f1e8-48fa-90f3-bad970d9e6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-c1316932-8985-4bfb-8c0b-ba832e3b6f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-9a666e75-8cda-4c95-a62c-dbedf954f2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-4043ae9f-6b73-4cd8-9de9-ba3b1d4aad7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701419672-172.17.0.7-1595904178807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44688,DS-8e107e08-79f1-419c-afdc-68236f27e260,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-7057c3df-465b-4adb-88fe-38356b3e34d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-f68153f9-dbda-4c7b-83a1-d3bb0e05db26,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-00e7b02f-da25-42f7-955c-1b950537a571,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-b642aecd-b41f-40ee-96c6-2550c7478233,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-8673cd13-b731-4aa7-84d5-b5cd47cd3ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-68f17838-9307-4069-90c1-93b9c5ddbd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-a58d8910-3eca-4b21-9536-7967b9399834,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-701419672-172.17.0.7-1595904178807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44688,DS-8e107e08-79f1-419c-afdc-68236f27e260,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-7057c3df-465b-4adb-88fe-38356b3e34d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-f68153f9-dbda-4c7b-83a1-d3bb0e05db26,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-00e7b02f-da25-42f7-955c-1b950537a571,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-b642aecd-b41f-40ee-96c6-2550c7478233,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-8673cd13-b731-4aa7-84d5-b5cd47cd3ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-68f17838-9307-4069-90c1-93b9c5ddbd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-a58d8910-3eca-4b21-9536-7967b9399834,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153713994-172.17.0.7-1595904251303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37393,DS-7096eaf6-6291-43da-899d-54e62076904b,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-d84712cc-0d2a-4de1-8729-c0eb3d7bd53a,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-e6db412f-19f6-49a3-81f5-a573edd7ac7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-402a2058-18f2-4ae1-b681-23c67dbcc29d,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-c3fea560-1d80-4cc1-aef5-4097e53a8ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-74beeec8-de7f-4fdc-9ffa-a00514ecf992,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-ea5217aa-1770-4757-beb0-069e88ee5ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-6fcabfc9-5a4a-4fd5-a42f-7fb6107d1b33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153713994-172.17.0.7-1595904251303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37393,DS-7096eaf6-6291-43da-899d-54e62076904b,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-d84712cc-0d2a-4de1-8729-c0eb3d7bd53a,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-e6db412f-19f6-49a3-81f5-a573edd7ac7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-402a2058-18f2-4ae1-b681-23c67dbcc29d,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-c3fea560-1d80-4cc1-aef5-4097e53a8ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-74beeec8-de7f-4fdc-9ffa-a00514ecf992,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-ea5217aa-1770-4757-beb0-069e88ee5ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-6fcabfc9-5a4a-4fd5-a42f-7fb6107d1b33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245065195-172.17.0.7-1595904388250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42239,DS-dce02b95-a6ac-46e7-8018-5e9da30a885c,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-77c0c26b-51c6-42a4-94cc-d13b4f0ca826,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-8edd8e9c-2b3f-4e99-b822-229ef4b7bdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-b9601b56-8a88-4294-becf-24a7f441fef0,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-236ea78b-2931-48cb-b408-58885359f055,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-6305981d-9b40-40de-a7c3-d3f61494add6,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-0bfcfedc-f266-4322-824e-22440c017db8,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-521697c6-2f02-4c9c-b6b2-a29f71f1a1cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245065195-172.17.0.7-1595904388250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42239,DS-dce02b95-a6ac-46e7-8018-5e9da30a885c,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-77c0c26b-51c6-42a4-94cc-d13b4f0ca826,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-8edd8e9c-2b3f-4e99-b822-229ef4b7bdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-b9601b56-8a88-4294-becf-24a7f441fef0,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-236ea78b-2931-48cb-b408-58885359f055,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-6305981d-9b40-40de-a7c3-d3f61494add6,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-0bfcfedc-f266-4322-824e-22440c017db8,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-521697c6-2f02-4c9c-b6b2-a29f71f1a1cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635084824-172.17.0.7-1595904894415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37497,DS-76be7dfe-bc81-4fa6-961a-a943a362bd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-c5d951a8-0191-48f0-bd77-813004e75e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-ed86a134-0653-49f2-89fd-7cb7eab1f189,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-fc32a07c-7fe3-45a4-a23f-13e11a8e7990,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-beeb2375-eae4-4aa5-ac53-59aff74bd53d,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-7880ac9b-cf01-4d79-8f31-2cc3c61e2eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-fb94a661-7195-4618-a615-272afd279431,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-57a3876a-b0d7-40ed-91d1-bcb715b88eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635084824-172.17.0.7-1595904894415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37497,DS-76be7dfe-bc81-4fa6-961a-a943a362bd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-c5d951a8-0191-48f0-bd77-813004e75e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-ed86a134-0653-49f2-89fd-7cb7eab1f189,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-fc32a07c-7fe3-45a4-a23f-13e11a8e7990,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-beeb2375-eae4-4aa5-ac53-59aff74bd53d,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-7880ac9b-cf01-4d79-8f31-2cc3c61e2eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-fb94a661-7195-4618-a615-272afd279431,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-57a3876a-b0d7-40ed-91d1-bcb715b88eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477171948-172.17.0.7-1595905010493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37434,DS-83d2ec5b-230e-47a5-b38b-4fa4cf6a46cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-65f9a6b9-b58a-4f15-a651-872d58c03f08,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-cb5548ed-79ac-4622-bbbd-4beaf6d1b55d,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-ce2bd19c-4314-40a2-9e62-388ba18631c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-697614a8-9c42-40f9-a101-e6d72e778789,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-83160a2f-7f6c-4643-aa9c-9448c881dd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-68d6b693-9630-4f1e-acfb-378d3da249a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-c7dde770-9178-4c1a-90ad-d6b06572664b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477171948-172.17.0.7-1595905010493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37434,DS-83d2ec5b-230e-47a5-b38b-4fa4cf6a46cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-65f9a6b9-b58a-4f15-a651-872d58c03f08,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-cb5548ed-79ac-4622-bbbd-4beaf6d1b55d,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-ce2bd19c-4314-40a2-9e62-388ba18631c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-697614a8-9c42-40f9-a101-e6d72e778789,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-83160a2f-7f6c-4643-aa9c-9448c881dd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-68d6b693-9630-4f1e-acfb-378d3da249a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-c7dde770-9178-4c1a-90ad-d6b06572664b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942904013-172.17.0.7-1595905326298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41142,DS-86bae1a1-c738-4d60-b8fd-e1fcf30d4199,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-51dd6311-97b1-4dc1-b8d3-ab47d064c1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-9f601faf-0905-4a44-94f7-6cb1e0a7e124,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-65cd55e7-9e4c-4817-884c-b9903284d30c,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-5e899176-b422-4b41-ba8b-fca9a2247152,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-98a1c112-24bb-401a-bdca-f261e94d581e,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-6107174c-4c26-4259-bf78-030ab713e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-0f54e0bc-1cd1-4826-b76a-8b24ea57de58,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942904013-172.17.0.7-1595905326298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41142,DS-86bae1a1-c738-4d60-b8fd-e1fcf30d4199,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-51dd6311-97b1-4dc1-b8d3-ab47d064c1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-9f601faf-0905-4a44-94f7-6cb1e0a7e124,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-65cd55e7-9e4c-4817-884c-b9903284d30c,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-5e899176-b422-4b41-ba8b-fca9a2247152,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-98a1c112-24bb-401a-bdca-f261e94d581e,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-6107174c-4c26-4259-bf78-030ab713e90b,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-0f54e0bc-1cd1-4826-b76a-8b24ea57de58,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615245214-172.17.0.7-1595905362820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39638,DS-e1011740-067d-4b83-9b7b-047a901c7d66,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-7c9b676b-5a35-49a3-a41a-c0425447fbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-104d4aad-c29f-49b8-9ce8-6da30ccddf12,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-92e28911-af46-4064-bc1e-e00ed402f2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-f7a4adc6-7dbd-4660-93dd-071cd8d1b16a,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-b11d1bde-fab1-4bb4-b9bd-a8dae3bab886,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-25510137-273b-4bc6-baf6-d8fe369f3e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-7da2a09e-75ab-46fe-b9ad-27dfc8d6ed92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615245214-172.17.0.7-1595905362820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39638,DS-e1011740-067d-4b83-9b7b-047a901c7d66,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-7c9b676b-5a35-49a3-a41a-c0425447fbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-104d4aad-c29f-49b8-9ce8-6da30ccddf12,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-92e28911-af46-4064-bc1e-e00ed402f2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-f7a4adc6-7dbd-4660-93dd-071cd8d1b16a,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-b11d1bde-fab1-4bb4-b9bd-a8dae3bab886,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-25510137-273b-4bc6-baf6-d8fe369f3e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-7da2a09e-75ab-46fe-b9ad-27dfc8d6ed92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881768829-172.17.0.7-1595905782295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37605,DS-2ef89652-6b90-4294-9a88-7ba993f152d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-7d5e37c0-b742-4e53-9402-5659c79c52c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-83a87b22-839b-450b-b14d-629bc87276e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-3e5fe0b1-2005-4305-b50a-1164c73763d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-52460351-7fdf-4623-92b8-fe738a2d6ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-dd4adcdf-e710-44e2-8449-5ecb807dcede,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-28474747-49e6-4f3e-8673-6581fbbaf666,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-3cc803e1-cc49-4c4f-847c-4b6fb17c36f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881768829-172.17.0.7-1595905782295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37605,DS-2ef89652-6b90-4294-9a88-7ba993f152d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-7d5e37c0-b742-4e53-9402-5659c79c52c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-83a87b22-839b-450b-b14d-629bc87276e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-3e5fe0b1-2005-4305-b50a-1164c73763d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-52460351-7fdf-4623-92b8-fe738a2d6ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-dd4adcdf-e710-44e2-8449-5ecb807dcede,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-28474747-49e6-4f3e-8673-6581fbbaf666,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-3cc803e1-cc49-4c4f-847c-4b6fb17c36f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571109759-172.17.0.7-1595905921502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34235,DS-081150a3-44d5-4f96-98b7-d0561e93511f,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-d1c39263-6624-4ca0-a452-5965c83097c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-3fd8bb4e-d284-4e35-8922-5d0edecfd815,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-eda3a16f-a181-4970-9559-a2a2a42ba235,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-e1155a6b-565c-4641-8366-b646097766a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-bbb634e9-c1e2-4097-9ea2-26513918ca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-e4b08e7a-e7aa-4f6b-97de-dc3a57cc6c61,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-484b5bd3-aeda-4f26-b83b-e86525c19336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571109759-172.17.0.7-1595905921502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34235,DS-081150a3-44d5-4f96-98b7-d0561e93511f,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-d1c39263-6624-4ca0-a452-5965c83097c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-3fd8bb4e-d284-4e35-8922-5d0edecfd815,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-eda3a16f-a181-4970-9559-a2a2a42ba235,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-e1155a6b-565c-4641-8366-b646097766a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-bbb634e9-c1e2-4097-9ea2-26513918ca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-e4b08e7a-e7aa-4f6b-97de-dc3a57cc6c61,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-484b5bd3-aeda-4f26-b83b-e86525c19336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496079160-172.17.0.7-1595905959910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38663,DS-d2273ad0-00d4-4661-ae8a-ec013decb918,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-4d4daa31-5be7-46c8-be5b-1c262c0055ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-83ef2433-8e54-4ecf-bb1c-e6f6eea8ad53,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-d86f20e7-128e-46e0-ae28-5eab91658b56,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-b19a34e4-b9c5-452a-9595-cd77f2b34c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-54a1928f-4821-4036-a8d1-a66455b27386,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-8a979dbc-230c-46be-b476-1fba039913b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-065ea0f9-60b2-4e3c-a438-f89560996246,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496079160-172.17.0.7-1595905959910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38663,DS-d2273ad0-00d4-4661-ae8a-ec013decb918,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-4d4daa31-5be7-46c8-be5b-1c262c0055ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-83ef2433-8e54-4ecf-bb1c-e6f6eea8ad53,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-d86f20e7-128e-46e0-ae28-5eab91658b56,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-b19a34e4-b9c5-452a-9595-cd77f2b34c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-54a1928f-4821-4036-a8d1-a66455b27386,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-8a979dbc-230c-46be-b476-1fba039913b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-065ea0f9-60b2-4e3c-a438-f89560996246,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 17 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5612
