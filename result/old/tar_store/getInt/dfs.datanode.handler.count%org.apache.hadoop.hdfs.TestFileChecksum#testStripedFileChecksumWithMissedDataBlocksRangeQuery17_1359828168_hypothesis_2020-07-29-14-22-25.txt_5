reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763380263-172.17.0.2-1596032933864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42349,DS-8a0eeaa7-ab9c-4e42-a44b-d48db26ead25,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-372c01ee-d0f3-4cd4-af8e-db102e8396f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-bd3cfa1c-db87-4fb1-b59c-66ee33ce0709,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-d4494a50-20de-4c4c-8acc-72a92a3fdd69,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-0853faa4-c2bd-427c-b991-4a1c945162ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-127f4005-9c8f-4e52-a5fc-d069b74bde22,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-a59b7175-c772-478f-a3de-f960e166ff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-f5705852-255c-4984-a46b-f0dd90f91e03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763380263-172.17.0.2-1596032933864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42349,DS-8a0eeaa7-ab9c-4e42-a44b-d48db26ead25,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-372c01ee-d0f3-4cd4-af8e-db102e8396f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-bd3cfa1c-db87-4fb1-b59c-66ee33ce0709,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-d4494a50-20de-4c4c-8acc-72a92a3fdd69,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-0853faa4-c2bd-427c-b991-4a1c945162ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-127f4005-9c8f-4e52-a5fc-d069b74bde22,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-a59b7175-c772-478f-a3de-f960e166ff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-f5705852-255c-4984-a46b-f0dd90f91e03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146098285-172.17.0.2-1596033111527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46792,DS-3d003fe0-0edf-423d-8b8c-a824ce8325cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-d67169e9-e305-4091-a551-737804fd2de6,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-6ede4ec3-1c0e-4706-b2be-046dfb1f21d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-be97d460-a8e3-467f-8008-5000815b458a,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-13432d9e-add1-43cf-8a78-aad732a7c2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-a120b7f4-746b-47bf-8380-cdb2bb7159c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-9008a750-ef76-479e-be96-44d67bf119a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-d8c07b8c-2ef2-4db6-aecd-2def92488320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146098285-172.17.0.2-1596033111527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46792,DS-3d003fe0-0edf-423d-8b8c-a824ce8325cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-d67169e9-e305-4091-a551-737804fd2de6,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-6ede4ec3-1c0e-4706-b2be-046dfb1f21d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-be97d460-a8e3-467f-8008-5000815b458a,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-13432d9e-add1-43cf-8a78-aad732a7c2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-a120b7f4-746b-47bf-8380-cdb2bb7159c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-9008a750-ef76-479e-be96-44d67bf119a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-d8c07b8c-2ef2-4db6-aecd-2def92488320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59179960-172.17.0.2-1596033292712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41349,DS-c7c415fe-1b0d-47d8-90b3-6de0a4f333c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-3f11215d-a184-4f08-957c-495a47871ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-f97af8b4-e2a7-4e20-a191-f83b17cd09cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-724399f6-f93a-465f-821a-73ccfacff194,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-a4f8d2ed-f1d0-42a6-81af-b5442c7e5174,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-094074e8-11ec-4b8d-b407-51eb13080710,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-900ad1c8-684f-431a-9a95-8894a517558e,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-cd75d2f4-5507-405b-ad92-9d67d5d66807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59179960-172.17.0.2-1596033292712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41349,DS-c7c415fe-1b0d-47d8-90b3-6de0a4f333c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-3f11215d-a184-4f08-957c-495a47871ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-f97af8b4-e2a7-4e20-a191-f83b17cd09cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-724399f6-f93a-465f-821a-73ccfacff194,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-a4f8d2ed-f1d0-42a6-81af-b5442c7e5174,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-094074e8-11ec-4b8d-b407-51eb13080710,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-900ad1c8-684f-431a-9a95-8894a517558e,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-cd75d2f4-5507-405b-ad92-9d67d5d66807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288383733-172.17.0.2-1596033425621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42974,DS-4737345d-bc7a-446f-85e9-3337ba967268,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-748e3d0f-f45c-47e3-bc9f-010bac456d31,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-81b8c211-0157-4c75-b927-aca67ff0bec0,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-1653b89b-734e-4be5-8ac4-4311f9d9393e,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-777699cc-4608-4163-8bfc-428b8bcd0837,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-8c0e4703-c24f-4eba-9a49-d9135ced57d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-a96318f8-1428-4bad-8b47-58b84456c3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-93b999d2-4781-4b3e-a09d-fff3c6dc6ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288383733-172.17.0.2-1596033425621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42974,DS-4737345d-bc7a-446f-85e9-3337ba967268,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-748e3d0f-f45c-47e3-bc9f-010bac456d31,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-81b8c211-0157-4c75-b927-aca67ff0bec0,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-1653b89b-734e-4be5-8ac4-4311f9d9393e,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-777699cc-4608-4163-8bfc-428b8bcd0837,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-8c0e4703-c24f-4eba-9a49-d9135ced57d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-a96318f8-1428-4bad-8b47-58b84456c3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-93b999d2-4781-4b3e-a09d-fff3c6dc6ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978272706-172.17.0.2-1596033538417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33163,DS-65f5fc53-82da-48b5-9935-0562b8aa1e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-a8f727b8-5f05-4011-b698-50fe2e9d7773,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-f73d1613-c2a8-4b70-951b-f0fde9120e86,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-95f81730-c752-463d-abef-3e02cd6bc103,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-18c218dc-d142-4be1-a44c-45a253488265,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-a0db8699-bc97-40db-88fa-57fb83b94fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-90316b60-b629-4e03-af4e-b00ed753d53e,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-14d4d129-18e6-4ac8-bb3f-b46f284218c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978272706-172.17.0.2-1596033538417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33163,DS-65f5fc53-82da-48b5-9935-0562b8aa1e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-a8f727b8-5f05-4011-b698-50fe2e9d7773,DISK], DatanodeInfoWithStorage[127.0.0.1:38721,DS-f73d1613-c2a8-4b70-951b-f0fde9120e86,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-95f81730-c752-463d-abef-3e02cd6bc103,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-18c218dc-d142-4be1-a44c-45a253488265,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-a0db8699-bc97-40db-88fa-57fb83b94fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-90316b60-b629-4e03-af4e-b00ed753d53e,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-14d4d129-18e6-4ac8-bb3f-b46f284218c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-882168068-172.17.0.2-1596033629654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38994,DS-0828a7b5-afa6-4500-affc-526d4d685b77,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-b1bb39e1-a92e-4597-a3cd-05c0cecb0a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-61f84d99-d4e8-4e3c-b83d-c1368c5fe188,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-b898c4fe-0ff6-4368-bca5-f18619d6cba9,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-a46d86dd-6b87-446e-92e3-a67c0fe58f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-62ca646b-878f-432d-80d9-4eac6aa64f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-fa4e0bc6-2900-4eef-8241-0c4871406ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-5174e5a4-aa66-41e5-8adf-054fa3fd1400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-882168068-172.17.0.2-1596033629654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38994,DS-0828a7b5-afa6-4500-affc-526d4d685b77,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-b1bb39e1-a92e-4597-a3cd-05c0cecb0a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-61f84d99-d4e8-4e3c-b83d-c1368c5fe188,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-b898c4fe-0ff6-4368-bca5-f18619d6cba9,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-a46d86dd-6b87-446e-92e3-a67c0fe58f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-62ca646b-878f-432d-80d9-4eac6aa64f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-fa4e0bc6-2900-4eef-8241-0c4871406ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-5174e5a4-aa66-41e5-8adf-054fa3fd1400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320742807-172.17.0.2-1596033897727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33577,DS-debf629c-2105-4b53-99b9-8d62b12580ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-869c85d8-ff36-4888-9e2b-5be84f9ec8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-795141f1-d557-44df-86ba-7f9b9c52b335,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-ef8bf243-572d-4179-8ac8-a7631d9f091e,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-a5b2ea74-6d87-4677-ae55-15e1c16e1051,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-d81f2349-63b6-40d7-8abe-be888b1d5439,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-564cea3e-91d3-403d-9d87-0f2190429003,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-08ab2326-8abc-4a67-99df-2fa6c018f501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1320742807-172.17.0.2-1596033897727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33577,DS-debf629c-2105-4b53-99b9-8d62b12580ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-869c85d8-ff36-4888-9e2b-5be84f9ec8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-795141f1-d557-44df-86ba-7f9b9c52b335,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-ef8bf243-572d-4179-8ac8-a7631d9f091e,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-a5b2ea74-6d87-4677-ae55-15e1c16e1051,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-d81f2349-63b6-40d7-8abe-be888b1d5439,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-564cea3e-91d3-403d-9d87-0f2190429003,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-08ab2326-8abc-4a67-99df-2fa6c018f501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-44276421-172.17.0.2-1596034018291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39352,DS-090db9c2-72f2-4d9e-87c1-9d4ddd4d3acd,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-23938945-f165-4211-bdee-be0d5f0ad44b,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-a57bea9d-01f3-4cbb-87c5-2cb432c4d792,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-ade95032-8ded-4846-875c-60fbce30b4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-403428ac-5dcc-4a53-be50-96adbc657c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-5a704639-a7c2-4bc5-b9c6-ad0903e291f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-1cc3f4c6-c1c5-4513-9619-66cfd336a371,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-08b13717-c968-410c-b702-88ad9ca54ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-44276421-172.17.0.2-1596034018291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39352,DS-090db9c2-72f2-4d9e-87c1-9d4ddd4d3acd,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-23938945-f165-4211-bdee-be0d5f0ad44b,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-a57bea9d-01f3-4cbb-87c5-2cb432c4d792,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-ade95032-8ded-4846-875c-60fbce30b4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-403428ac-5dcc-4a53-be50-96adbc657c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-5a704639-a7c2-4bc5-b9c6-ad0903e291f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-1cc3f4c6-c1c5-4513-9619-66cfd336a371,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-08b13717-c968-410c-b702-88ad9ca54ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021241459-172.17.0.2-1596034829104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32773,DS-2df87e66-28c6-4412-afed-016971cef831,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-98e83b32-81b8-425a-942a-124b07a86f67,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-dada391d-e686-4b15-8b3e-bd6b7c37e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-a2e04297-da3c-435c-b1b8-7526355669c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-fcade078-8490-4ef9-b717-f0cb4a0555cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-d1abbf14-4485-4e93-a5d7-1dfdea27d5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-bd7c6ac8-51f1-46a1-9d6a-63419385df6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-e1b913e7-92c0-4692-a31f-f824ab3d70cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2021241459-172.17.0.2-1596034829104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32773,DS-2df87e66-28c6-4412-afed-016971cef831,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-98e83b32-81b8-425a-942a-124b07a86f67,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-dada391d-e686-4b15-8b3e-bd6b7c37e55f,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-a2e04297-da3c-435c-b1b8-7526355669c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-fcade078-8490-4ef9-b717-f0cb4a0555cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-d1abbf14-4485-4e93-a5d7-1dfdea27d5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-bd7c6ac8-51f1-46a1-9d6a-63419385df6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-e1b913e7-92c0-4692-a31f-f824ab3d70cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710175733-172.17.0.2-1596035664141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44809,DS-afb33df2-a9eb-4347-8d7a-901b81dead1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-6084eecc-84bd-4840-b33a-d4b9a8a7566e,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-1b37d81f-0ac5-40ed-864c-cd471ad2aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-69015a31-53e0-4ae9-9290-11b9e258c65c,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-700e4b65-a2fd-4a21-a630-242e996bd417,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-3d81ca95-348f-4934-8a55-3b214cff08ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-2c4a6f6f-06f5-4744-b3b8-d72e75558e35,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-a920cd5a-f495-4fba-8209-4c75bef176ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710175733-172.17.0.2-1596035664141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44809,DS-afb33df2-a9eb-4347-8d7a-901b81dead1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-6084eecc-84bd-4840-b33a-d4b9a8a7566e,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-1b37d81f-0ac5-40ed-864c-cd471ad2aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-69015a31-53e0-4ae9-9290-11b9e258c65c,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-700e4b65-a2fd-4a21-a630-242e996bd417,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-3d81ca95-348f-4934-8a55-3b214cff08ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-2c4a6f6f-06f5-4744-b3b8-d72e75558e35,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-a920cd5a-f495-4fba-8209-4c75bef176ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825698419-172.17.0.2-1596036274982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41272,DS-c23f90b0-d529-428b-a1f8-4428f7f66c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-13fee563-bc3a-4810-abd7-9fe03453dbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-433c97c3-6827-40c6-86e3-3af250605659,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-87fa139c-8e8e-4113-84fd-3ac6ce57c29b,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-c6d5e4bf-34b1-4dde-a7ee-88f5f46f1b42,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-57d01bf6-a892-4daa-a92e-8c2627b6f91b,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-16f2db12-49ad-4125-b503-f34369ec6d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-fd3ea514-79de-462b-925a-a1cad75f8013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825698419-172.17.0.2-1596036274982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41272,DS-c23f90b0-d529-428b-a1f8-4428f7f66c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-13fee563-bc3a-4810-abd7-9fe03453dbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-433c97c3-6827-40c6-86e3-3af250605659,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-87fa139c-8e8e-4113-84fd-3ac6ce57c29b,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-c6d5e4bf-34b1-4dde-a7ee-88f5f46f1b42,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-57d01bf6-a892-4daa-a92e-8c2627b6f91b,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-16f2db12-49ad-4125-b503-f34369ec6d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-fd3ea514-79de-462b-925a-a1cad75f8013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502506099-172.17.0.2-1596036523205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44758,DS-89f4090f-c05a-43ee-9881-3fdb081d3239,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-3da48402-aeec-45e6-b6f6-6c37b009d73b,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-f45f94c4-bb1f-4f6f-b23e-83667f8d52d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-bd3c6c66-554b-4885-a2c1-e593e45d3985,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-8544dcfd-965a-46af-a598-22e6f112a06c,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-857ef213-ce76-4eeb-b5e4-685ac7b293b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-0c94df87-ba6f-47df-b484-608366c33422,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-d4b82e2f-1588-4560-853b-13b4fcf0c381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1502506099-172.17.0.2-1596036523205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44758,DS-89f4090f-c05a-43ee-9881-3fdb081d3239,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-3da48402-aeec-45e6-b6f6-6c37b009d73b,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-f45f94c4-bb1f-4f6f-b23e-83667f8d52d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-bd3c6c66-554b-4885-a2c1-e593e45d3985,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-8544dcfd-965a-46af-a598-22e6f112a06c,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-857ef213-ce76-4eeb-b5e4-685ac7b293b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-0c94df87-ba6f-47df-b484-608366c33422,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-d4b82e2f-1588-4560-853b-13b4fcf0c381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684157789-172.17.0.2-1596037438779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-69397994-507a-4987-be10-cc4e551da947,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-a21d175f-c9d6-48de-9992-7e6cf1ca6301,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-1d6d5095-74d1-4923-9983-215b69e70cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-779eb570-a369-4128-b36e-4b01897e03b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-5dd87aa7-6995-4571-84af-061feef7993a,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-d583db49-f868-4d39-a98e-853f480a9a18,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-2dae819a-8beb-46df-a69d-4b8ad153896d,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-239a4d34-38e4-456c-9a05-3b05c57ec6cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684157789-172.17.0.2-1596037438779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-69397994-507a-4987-be10-cc4e551da947,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-a21d175f-c9d6-48de-9992-7e6cf1ca6301,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-1d6d5095-74d1-4923-9983-215b69e70cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-779eb570-a369-4128-b36e-4b01897e03b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-5dd87aa7-6995-4571-84af-061feef7993a,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-d583db49-f868-4d39-a98e-853f480a9a18,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-2dae819a-8beb-46df-a69d-4b8ad153896d,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-239a4d34-38e4-456c-9a05-3b05c57ec6cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859520812-172.17.0.2-1596037627585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42293,DS-f34bda01-fadd-448e-8c4b-74dde362fa35,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-54adbc35-ec59-4d20-8ee4-2e00815f93b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-bf1a410d-7232-43f4-8b6e-86eefb1161fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-45e7e0e4-f3b3-4b0d-853f-e3eb40a5b1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-116acf45-ecd5-4e5e-bc81-f8d065154405,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-475fc2a5-d9f6-4e37-8457-191e070291aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-df2f6a09-99bc-4a68-a1bc-76f2f3c5c9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-31c01a3d-f35b-44dc-8974-548157a205a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859520812-172.17.0.2-1596037627585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42293,DS-f34bda01-fadd-448e-8c4b-74dde362fa35,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-54adbc35-ec59-4d20-8ee4-2e00815f93b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-bf1a410d-7232-43f4-8b6e-86eefb1161fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-45e7e0e4-f3b3-4b0d-853f-e3eb40a5b1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-116acf45-ecd5-4e5e-bc81-f8d065154405,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-475fc2a5-d9f6-4e37-8457-191e070291aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-df2f6a09-99bc-4a68-a1bc-76f2f3c5c9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-31c01a3d-f35b-44dc-8974-548157a205a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843191155-172.17.0.2-1596037754816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42639,DS-c65eff23-e091-4b64-8365-a72ca0dc974b,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-d8f0cb20-8a7b-46c2-ad1b-b04411501a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-bc20ed75-48e2-4e99-8a7b-f759a431865d,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-a5b79de3-5ef0-4b6a-9001-ed0cbeed1ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-c95f4760-661e-400a-92fd-744284809b39,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-048480c4-59e1-4c08-9466-940f2c52de1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-155b3e8f-f8db-4e23-b5b3-bbfac3ab9100,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-40208bc6-1ddf-4e8d-ad7c-ae5e0831b417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843191155-172.17.0.2-1596037754816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42639,DS-c65eff23-e091-4b64-8365-a72ca0dc974b,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-d8f0cb20-8a7b-46c2-ad1b-b04411501a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-bc20ed75-48e2-4e99-8a7b-f759a431865d,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-a5b79de3-5ef0-4b6a-9001-ed0cbeed1ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-c95f4760-661e-400a-92fd-744284809b39,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-048480c4-59e1-4c08-9466-940f2c52de1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-155b3e8f-f8db-4e23-b5b3-bbfac3ab9100,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-40208bc6-1ddf-4e8d-ad7c-ae5e0831b417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371168445-172.17.0.2-1596038423424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40043,DS-d11f4f40-1f9f-4dcb-b4b2-3af14f6d9892,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-310ad2d1-6ddf-4644-93a8-66fa731e0710,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-32387cb8-f803-4836-996d-9f25200a2dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-b46e6170-c6ad-4fd7-8a57-951a3952a6db,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-74e88fd5-c5a2-43b8-a961-8d87c112967d,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-c60fd529-d631-4259-9cf9-dc245ac61668,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-3c442fe4-67b2-4dca-bd1d-0f4c2086ba27,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-f5144451-77a2-465a-a542-76d4e987c908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371168445-172.17.0.2-1596038423424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40043,DS-d11f4f40-1f9f-4dcb-b4b2-3af14f6d9892,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-310ad2d1-6ddf-4644-93a8-66fa731e0710,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-32387cb8-f803-4836-996d-9f25200a2dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-b46e6170-c6ad-4fd7-8a57-951a3952a6db,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-74e88fd5-c5a2-43b8-a961-8d87c112967d,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-c60fd529-d631-4259-9cf9-dc245ac61668,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-3c442fe4-67b2-4dca-bd1d-0f4c2086ba27,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-f5144451-77a2-465a-a542-76d4e987c908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26888574-172.17.0.2-1596038837175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44785,DS-636cdedc-2020-4a6a-9720-331e29181221,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-00d05a5a-ba0c-472c-b450-3e27e35c33b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-6160a3b2-c73b-434d-ad7c-baf7b94a6564,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-550bcf52-07cb-4afb-9657-941b726de349,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-d9758997-17ba-48e4-ba41-d5ea28d090cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-5de6a508-6120-4a6a-b4fa-752a2d7760a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-2ef44692-b026-4f39-8090-ddad2e7c02a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-fdf087ca-38b7-4f8d-993f-9e3bb151f0ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26888574-172.17.0.2-1596038837175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44785,DS-636cdedc-2020-4a6a-9720-331e29181221,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-00d05a5a-ba0c-472c-b450-3e27e35c33b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-6160a3b2-c73b-434d-ad7c-baf7b94a6564,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-550bcf52-07cb-4afb-9657-941b726de349,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-d9758997-17ba-48e4-ba41-d5ea28d090cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-5de6a508-6120-4a6a-b4fa-752a2d7760a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-2ef44692-b026-4f39-8090-ddad2e7c02a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-fdf087ca-38b7-4f8d-993f-9e3bb151f0ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6673
