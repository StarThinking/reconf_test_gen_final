reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113086833-172.17.0.13-1596009418305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41633,DS-40310ef5-6802-4c04-83eb-e579e18eb0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-3893a6bc-496b-4057-a5bb-43e68532e6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-e1e3370b-1d60-41a6-8ca7-810a8c75bd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-9b65aaa7-1a8b-4090-b66c-c057912ebbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-57e249a3-cefb-429f-aef1-e1040c13ab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-224cf551-2b62-4598-b10e-8c43bd27e1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-7b784d23-d3a3-4c4d-afb0-8d10565c29ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-6646da18-fe24-491e-87a0-db214b62a2b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1113086833-172.17.0.13-1596009418305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41633,DS-40310ef5-6802-4c04-83eb-e579e18eb0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-3893a6bc-496b-4057-a5bb-43e68532e6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-e1e3370b-1d60-41a6-8ca7-810a8c75bd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-9b65aaa7-1a8b-4090-b66c-c057912ebbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-57e249a3-cefb-429f-aef1-e1040c13ab4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-224cf551-2b62-4598-b10e-8c43bd27e1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-7b784d23-d3a3-4c4d-afb0-8d10565c29ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-6646da18-fe24-491e-87a0-db214b62a2b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495455295-172.17.0.13-1596009487603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33216,DS-2d3fdabf-afef-4e7d-81e7-9aad6911c8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-665821b1-8a41-42e4-af83-1ae39d087ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-4646cbf2-9182-44b3-9317-97639f9593f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-0e0c11cb-d8fd-44bd-8bb5-80973c63dd70,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-0cea79f9-a85b-48f2-9868-08b985aee1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-0786f23c-1b76-49d6-8bea-866c4ca4f79d,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-679052d6-c27f-4203-bbd0-526908f8239d,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-556847b1-2d02-4113-a28e-abc7f8fb2e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495455295-172.17.0.13-1596009487603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33216,DS-2d3fdabf-afef-4e7d-81e7-9aad6911c8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-665821b1-8a41-42e4-af83-1ae39d087ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-4646cbf2-9182-44b3-9317-97639f9593f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-0e0c11cb-d8fd-44bd-8bb5-80973c63dd70,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-0cea79f9-a85b-48f2-9868-08b985aee1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-0786f23c-1b76-49d6-8bea-866c4ca4f79d,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-679052d6-c27f-4203-bbd0-526908f8239d,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-556847b1-2d02-4113-a28e-abc7f8fb2e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123253559-172.17.0.13-1596009639368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43259,DS-2f93c1e0-f9fa-4373-9efd-656978a83e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-a3b5c9eb-99ac-4979-8e5e-3fb6daae864c,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-c75316d9-ecf5-4192-8bd2-ef3bac4d5745,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-706d1f9b-b7d7-472f-a7a0-734d3bc6b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-c38e0a80-00d3-4484-8d97-55330af7beed,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-13fec1ab-7709-456e-a40b-c55dfe0b4e24,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-6f851439-1c24-4233-a6f1-def7d81631b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-06e8f229-bdc5-449d-8d18-7042fe90aa0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123253559-172.17.0.13-1596009639368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43259,DS-2f93c1e0-f9fa-4373-9efd-656978a83e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-a3b5c9eb-99ac-4979-8e5e-3fb6daae864c,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-c75316d9-ecf5-4192-8bd2-ef3bac4d5745,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-706d1f9b-b7d7-472f-a7a0-734d3bc6b4df,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-c38e0a80-00d3-4484-8d97-55330af7beed,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-13fec1ab-7709-456e-a40b-c55dfe0b4e24,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-6f851439-1c24-4233-a6f1-def7d81631b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-06e8f229-bdc5-449d-8d18-7042fe90aa0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010234017-172.17.0.13-1596010644876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37976,DS-a8224b33-e02f-4be3-b9b0-bf8f3991c5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-3d35d312-9372-4802-be01-99a2fc0f1372,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-ad4deb8c-7bae-4b14-8afd-7cfe598dccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-c90e77a2-0fb1-45a1-b3d7-4b8c464d10d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-ad09e969-a95d-4c7f-bb87-86f2ae03fe6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-76dee9c5-4950-4072-b64f-3939c24b984f,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-6376e105-bf8c-4843-9af7-f3a9fc16149b,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-a1224fd0-ac50-4675-b91e-62cf98a472de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010234017-172.17.0.13-1596010644876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37976,DS-a8224b33-e02f-4be3-b9b0-bf8f3991c5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-3d35d312-9372-4802-be01-99a2fc0f1372,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-ad4deb8c-7bae-4b14-8afd-7cfe598dccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-c90e77a2-0fb1-45a1-b3d7-4b8c464d10d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-ad09e969-a95d-4c7f-bb87-86f2ae03fe6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-76dee9c5-4950-4072-b64f-3939c24b984f,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-6376e105-bf8c-4843-9af7-f3a9fc16149b,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-a1224fd0-ac50-4675-b91e-62cf98a472de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-573469626-172.17.0.13-1596011001050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36347,DS-ec2f4fe9-9f60-4e4a-acb0-22beebe3fd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-4aa48aaf-53d5-48f2-b59b-a669ba9cec2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-2e0d33e6-3215-46e7-b37e-70fffb472ded,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-800ba8d9-4b5d-49ef-9ea9-4fea1f624570,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-09525a2b-ba1e-49c4-a0c3-8c22ee184390,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-4c65083d-2723-46f1-8b44-9eb5fcc0b824,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-c0c9193b-2b80-478a-989c-cc73b6c74ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-097b0151-e557-419a-8ea1-0b13275b8f8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-573469626-172.17.0.13-1596011001050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36347,DS-ec2f4fe9-9f60-4e4a-acb0-22beebe3fd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-4aa48aaf-53d5-48f2-b59b-a669ba9cec2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-2e0d33e6-3215-46e7-b37e-70fffb472ded,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-800ba8d9-4b5d-49ef-9ea9-4fea1f624570,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-09525a2b-ba1e-49c4-a0c3-8c22ee184390,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-4c65083d-2723-46f1-8b44-9eb5fcc0b824,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-c0c9193b-2b80-478a-989c-cc73b6c74ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-097b0151-e557-419a-8ea1-0b13275b8f8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128458819-172.17.0.13-1596011435162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40159,DS-687c38d7-bdab-42e8-8e70-3a331a153c94,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-ddc00c03-060d-446b-808d-a5a0a8713f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-ab638c67-2246-4441-b416-b09962fad941,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-af51d835-c295-41d6-a97c-8ce5f77559eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-a96b81f5-367c-4043-bf94-f610c7eebf53,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-0b0f7074-e052-4070-aa28-486e4c00fe91,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-b26fcbfe-d643-4dee-a3d1-d192501f3491,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-86e6d085-808d-41af-b239-8bcec1d16ae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-128458819-172.17.0.13-1596011435162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40159,DS-687c38d7-bdab-42e8-8e70-3a331a153c94,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-ddc00c03-060d-446b-808d-a5a0a8713f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-ab638c67-2246-4441-b416-b09962fad941,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-af51d835-c295-41d6-a97c-8ce5f77559eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-a96b81f5-367c-4043-bf94-f610c7eebf53,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-0b0f7074-e052-4070-aa28-486e4c00fe91,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-b26fcbfe-d643-4dee-a3d1-d192501f3491,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-86e6d085-808d-41af-b239-8bcec1d16ae9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622564818-172.17.0.13-1596011589719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43188,DS-64e5b3ab-c154-44f8-8f83-26cb10ab246c,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-925e65ed-4c64-46ce-97e9-ec2218019d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-24f4ab8a-85cf-439a-b260-67ae8750fa64,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-aad9112f-db8c-444a-919d-6eb204a3f9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-b1a6ad38-619c-4621-b91d-94fa34845cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-61cdf17c-be10-4a10-a507-009797400aec,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-144cbaa7-ae82-4259-8ca8-94094b699f36,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-8fea7577-3d3d-40b9-be32-5472b5166787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622564818-172.17.0.13-1596011589719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43188,DS-64e5b3ab-c154-44f8-8f83-26cb10ab246c,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-925e65ed-4c64-46ce-97e9-ec2218019d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-24f4ab8a-85cf-439a-b260-67ae8750fa64,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-aad9112f-db8c-444a-919d-6eb204a3f9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-b1a6ad38-619c-4621-b91d-94fa34845cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-61cdf17c-be10-4a10-a507-009797400aec,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-144cbaa7-ae82-4259-8ca8-94094b699f36,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-8fea7577-3d3d-40b9-be32-5472b5166787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448710441-172.17.0.13-1596012153255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-e719aaf7-4192-4629-9b50-5574fec56abc,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-b73e9ab7-4c5b-4f65-8e3c-797de648a47b,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-f0e2db35-b314-436c-ba9d-e0bb5446293f,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-72c960ad-7d3a-4a55-92fa-d648d4732372,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-0da08319-ab82-4faa-8e2f-4a6be84009e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-7ab7746c-5759-4532-9a3a-b82d1c0b0486,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-1bc9da2b-30dd-473d-bb59-d1b5f25e6e04,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-53000769-f1db-46cd-ba98-a04b34ef9167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448710441-172.17.0.13-1596012153255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-e719aaf7-4192-4629-9b50-5574fec56abc,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-b73e9ab7-4c5b-4f65-8e3c-797de648a47b,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-f0e2db35-b314-436c-ba9d-e0bb5446293f,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-72c960ad-7d3a-4a55-92fa-d648d4732372,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-0da08319-ab82-4faa-8e2f-4a6be84009e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-7ab7746c-5759-4532-9a3a-b82d1c0b0486,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-1bc9da2b-30dd-473d-bb59-d1b5f25e6e04,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-53000769-f1db-46cd-ba98-a04b34ef9167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317450209-172.17.0.13-1596012361309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38140,DS-c0b293d4-63bf-4a80-82ec-388c99ad4e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-d53dc195-ef26-4c9a-8032-9df3d48ab49e,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-9bdb351b-0347-422c-8159-001946b01ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-cc886da3-73cb-4d00-94dc-b4cda66af79d,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-10714db2-54fd-45a7-9e0b-ec2793ca7012,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-9e79dfb1-9345-4f85-a140-7b25994b8674,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-9e0a72b8-12bb-4495-9e48-72fa80046c56,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-f9602613-0930-48cc-a7c4-e9c52ed3feb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317450209-172.17.0.13-1596012361309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38140,DS-c0b293d4-63bf-4a80-82ec-388c99ad4e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-d53dc195-ef26-4c9a-8032-9df3d48ab49e,DISK], DatanodeInfoWithStorage[127.0.0.1:41863,DS-9bdb351b-0347-422c-8159-001946b01ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-cc886da3-73cb-4d00-94dc-b4cda66af79d,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-10714db2-54fd-45a7-9e0b-ec2793ca7012,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-9e79dfb1-9345-4f85-a140-7b25994b8674,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-9e0a72b8-12bb-4495-9e48-72fa80046c56,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-f9602613-0930-48cc-a7c4-e9c52ed3feb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085412343-172.17.0.13-1596012754671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37902,DS-45e1cffa-ffa4-4b12-aadb-0d14c839f251,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-bec2e20d-55c8-4a8b-81b4-09bbad129ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-287032f7-ef1f-4841-876c-808cf1f4a77a,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-a3a43943-1971-470a-a19c-911199b22bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-e306bf95-8333-4e6c-9905-d2feacb3d7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-0800a2ad-0c55-4f0b-90a7-845dd038bac3,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-a10df4bf-8f73-4786-85a2-c78a2a79e970,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-560dd584-548f-455c-aa4f-ba7a3801ddc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085412343-172.17.0.13-1596012754671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37902,DS-45e1cffa-ffa4-4b12-aadb-0d14c839f251,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-bec2e20d-55c8-4a8b-81b4-09bbad129ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-287032f7-ef1f-4841-876c-808cf1f4a77a,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-a3a43943-1971-470a-a19c-911199b22bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-e306bf95-8333-4e6c-9905-d2feacb3d7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-0800a2ad-0c55-4f0b-90a7-845dd038bac3,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-a10df4bf-8f73-4786-85a2-c78a2a79e970,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-560dd584-548f-455c-aa4f-ba7a3801ddc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008445303-172.17.0.13-1596014057006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38191,DS-449a5425-9545-4094-ba97-e148f202fb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-42d8e383-bfb0-4d2e-a588-a14fb38adb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-ad3df7cd-e160-4b28-8ac1-95cf59271fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-78cdcbc8-1aae-4ab3-b1f6-3b24e6477a87,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-0cf49a26-019b-4a25-8a09-35e581613eda,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-e93514ad-4236-4662-b0d3-20e0a2d3ef65,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-538a4e49-5a17-4cd2-a320-49fcd482e826,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-71acc233-b409-4e79-bb3b-c1039fbdc85a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008445303-172.17.0.13-1596014057006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38191,DS-449a5425-9545-4094-ba97-e148f202fb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-42d8e383-bfb0-4d2e-a588-a14fb38adb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-ad3df7cd-e160-4b28-8ac1-95cf59271fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-78cdcbc8-1aae-4ab3-b1f6-3b24e6477a87,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-0cf49a26-019b-4a25-8a09-35e581613eda,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-e93514ad-4236-4662-b0d3-20e0a2d3ef65,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-538a4e49-5a17-4cd2-a320-49fcd482e826,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-71acc233-b409-4e79-bb3b-c1039fbdc85a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052554192-172.17.0.13-1596014090514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34656,DS-d2e50f64-1da0-4913-bacf-9c90b4167a39,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-7e476d76-a815-4826-9cc3-970d88da25d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-e7dd7619-f178-41d8-8dc1-2bde2723b66c,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-3d2f573c-6d92-4f95-babe-0e1fb68aab7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-b8b14225-ac0d-4a53-9cc5-ed071034b72f,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-eaf7b644-d58a-4305-b051-cb5cd724584a,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-0292bd18-eb33-4cea-9b3e-53906ea9375f,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-68cded2d-c3e4-4136-b680-2b772013cbf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052554192-172.17.0.13-1596014090514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34656,DS-d2e50f64-1da0-4913-bacf-9c90b4167a39,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-7e476d76-a815-4826-9cc3-970d88da25d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-e7dd7619-f178-41d8-8dc1-2bde2723b66c,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-3d2f573c-6d92-4f95-babe-0e1fb68aab7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-b8b14225-ac0d-4a53-9cc5-ed071034b72f,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-eaf7b644-d58a-4305-b051-cb5cd724584a,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-0292bd18-eb33-4cea-9b3e-53906ea9375f,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-68cded2d-c3e4-4136-b680-2b772013cbf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688195887-172.17.0.13-1596014133248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36481,DS-62226394-5587-43f7-adc0-b4b5a07da43b,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-f79eae73-94d1-463c-b784-530d462833a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-070cbffc-1ef0-4d71-b1ed-3ceafa104bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-527e2dc6-d485-45e2-90c0-72a2f2c837ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-a7adcae8-6041-4d47-be1a-4b51e143f85e,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-abf1a0bd-f5e7-498f-a77e-7edb32564d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-a81a1c19-7be7-453a-8468-16f0bb463b14,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-93152466-0882-42ff-a970-8b852e7504fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688195887-172.17.0.13-1596014133248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36481,DS-62226394-5587-43f7-adc0-b4b5a07da43b,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-f79eae73-94d1-463c-b784-530d462833a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-070cbffc-1ef0-4d71-b1ed-3ceafa104bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40847,DS-527e2dc6-d485-45e2-90c0-72a2f2c837ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-a7adcae8-6041-4d47-be1a-4b51e143f85e,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-abf1a0bd-f5e7-498f-a77e-7edb32564d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-a81a1c19-7be7-453a-8468-16f0bb463b14,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-93152466-0882-42ff-a970-8b852e7504fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355263082-172.17.0.13-1596014320523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46387,DS-2798bdc4-afbe-4e6e-b746-ce874dfe28a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-b0342573-95ac-4782-ba03-3dbb34ef1439,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-9d7b90f0-6927-4440-a45d-8659e36371a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-7e91ca8d-3241-411d-828a-857184d91d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-26558e62-0b08-4121-87a8-0316133f4b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-3c9bca0c-7e29-4375-ae53-69d8ec79499c,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-f3e2b14e-19e7-4e41-b80b-d009ec1bc59a,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-05fb3340-2417-4461-b9e3-b2715628b877,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355263082-172.17.0.13-1596014320523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46387,DS-2798bdc4-afbe-4e6e-b746-ce874dfe28a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-b0342573-95ac-4782-ba03-3dbb34ef1439,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-9d7b90f0-6927-4440-a45d-8659e36371a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-7e91ca8d-3241-411d-828a-857184d91d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-26558e62-0b08-4121-87a8-0316133f4b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-3c9bca0c-7e29-4375-ae53-69d8ec79499c,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-f3e2b14e-19e7-4e41-b80b-d009ec1bc59a,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-05fb3340-2417-4461-b9e3-b2715628b877,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5821
