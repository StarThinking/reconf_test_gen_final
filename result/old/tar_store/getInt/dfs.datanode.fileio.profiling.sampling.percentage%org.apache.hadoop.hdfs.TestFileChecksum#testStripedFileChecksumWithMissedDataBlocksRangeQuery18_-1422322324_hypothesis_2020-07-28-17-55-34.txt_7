reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047796810-172.17.0.11-1595959047518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33633,DS-ea477bbf-a74b-41ae-89f3-d253a05bb4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-ae5807bf-d62d-4ef2-8c94-b56fb7fc57ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-37219100-f9b9-4149-91bb-3f7d0f3530f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-e459e584-9077-4c67-ab5f-f763ac2e99ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-215b9217-0213-4865-9a53-b15202ed6441,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-22da9ba9-00f0-4f1f-a906-6051283b2112,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-57581aaa-bfc4-4842-83d6-7dabd0ed27f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-01b03549-bbfa-4b73-9ace-25e7c7975620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1047796810-172.17.0.11-1595959047518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33633,DS-ea477bbf-a74b-41ae-89f3-d253a05bb4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-ae5807bf-d62d-4ef2-8c94-b56fb7fc57ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-37219100-f9b9-4149-91bb-3f7d0f3530f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-e459e584-9077-4c67-ab5f-f763ac2e99ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-215b9217-0213-4865-9a53-b15202ed6441,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-22da9ba9-00f0-4f1f-a906-6051283b2112,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-57581aaa-bfc4-4842-83d6-7dabd0ed27f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-01b03549-bbfa-4b73-9ace-25e7c7975620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1056731364-172.17.0.11-1595959358966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45390,DS-b0edd4a0-ce79-4d1b-9486-8da49abdaea2,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-1fd1ab4d-6e97-4c56-a8ba-1cd1a5b83d29,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-281bad1d-ce55-4cf7-8b1c-56d40b4ff88b,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-47bafaa4-0fd1-4aa5-8410-57fba8c66535,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-442cc7bc-9a2f-439e-8f60-930d6f727e34,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-5c5447d3-1848-49e4-9370-6f535c6a54d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-51f845ea-a0d5-4d47-a92d-027f8b5e4881,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-5685cbba-1920-4338-a854-106f9fbf2705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1056731364-172.17.0.11-1595959358966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45390,DS-b0edd4a0-ce79-4d1b-9486-8da49abdaea2,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-1fd1ab4d-6e97-4c56-a8ba-1cd1a5b83d29,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-281bad1d-ce55-4cf7-8b1c-56d40b4ff88b,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-47bafaa4-0fd1-4aa5-8410-57fba8c66535,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-442cc7bc-9a2f-439e-8f60-930d6f727e34,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-5c5447d3-1848-49e4-9370-6f535c6a54d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-51f845ea-a0d5-4d47-a92d-027f8b5e4881,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-5685cbba-1920-4338-a854-106f9fbf2705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301154705-172.17.0.11-1595959765790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35906,DS-3d2a7554-6541-46d1-9f14-ab7f4783b39d,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-ae6527b7-a379-4866-895d-06126bbf653b,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-9704e5bf-e5a6-4a6a-ab91-0409e657b25a,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-27cebbb0-e621-4dab-9641-68cf04cbdc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-14f82078-8d29-4f78-b06e-6aff08f1d06a,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-4749f430-076b-44e0-8c5a-c148c2db0aef,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-d02368d0-471d-4e87-9d63-60bba96ff4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-18f21018-52bd-4109-869a-923040aef9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301154705-172.17.0.11-1595959765790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35906,DS-3d2a7554-6541-46d1-9f14-ab7f4783b39d,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-ae6527b7-a379-4866-895d-06126bbf653b,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-9704e5bf-e5a6-4a6a-ab91-0409e657b25a,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-27cebbb0-e621-4dab-9641-68cf04cbdc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-14f82078-8d29-4f78-b06e-6aff08f1d06a,DISK], DatanodeInfoWithStorage[127.0.0.1:44696,DS-4749f430-076b-44e0-8c5a-c148c2db0aef,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-d02368d0-471d-4e87-9d63-60bba96ff4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-18f21018-52bd-4109-869a-923040aef9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-533266971-172.17.0.11-1595959839089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39987,DS-3c813d50-59eb-4d6c-ad21-a2d849867250,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-6f7742fc-12d5-4c41-aa7f-12d3da59c105,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-ddc4c201-7e8c-4be4-9cc4-484fec445bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-9c46e73b-d7e8-42b6-a05c-791fb47626c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-776237a0-9ee4-4bd3-be95-fddf8bbbbbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-b0f60a5a-13a4-4dc5-aad8-ba0cffa48d46,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-61960b9a-abfd-44ab-98f8-97ac117d0df9,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-0ea18dd5-7ed9-4413-9193-fcdb826ddca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-533266971-172.17.0.11-1595959839089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39987,DS-3c813d50-59eb-4d6c-ad21-a2d849867250,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-6f7742fc-12d5-4c41-aa7f-12d3da59c105,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-ddc4c201-7e8c-4be4-9cc4-484fec445bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-9c46e73b-d7e8-42b6-a05c-791fb47626c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-776237a0-9ee4-4bd3-be95-fddf8bbbbbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-b0f60a5a-13a4-4dc5-aad8-ba0cffa48d46,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-61960b9a-abfd-44ab-98f8-97ac117d0df9,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-0ea18dd5-7ed9-4413-9193-fcdb826ddca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-210167960-172.17.0.11-1595960434196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-2ab36f54-81e5-4c36-9c3d-3bae920f1e88,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-0fe6900b-c875-4aff-827b-7acaaeac28a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-8a7d357d-9eec-4f4f-866f-f77da858a606,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-e25b7395-d8c9-4b5f-8f9a-639f63fde7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-5a3f5961-b11c-44c4-ab81-7b4659b4b3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-3d79a003-0b7a-4cce-b339-703d8d25bcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-1246f827-c6cd-4186-9c97-74f5c3e64867,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-e6c1e9b9-9eba-40ab-95a7-fc6af817cd43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-210167960-172.17.0.11-1595960434196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-2ab36f54-81e5-4c36-9c3d-3bae920f1e88,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-0fe6900b-c875-4aff-827b-7acaaeac28a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-8a7d357d-9eec-4f4f-866f-f77da858a606,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-e25b7395-d8c9-4b5f-8f9a-639f63fde7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-5a3f5961-b11c-44c4-ab81-7b4659b4b3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-3d79a003-0b7a-4cce-b339-703d8d25bcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-1246f827-c6cd-4186-9c97-74f5c3e64867,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-e6c1e9b9-9eba-40ab-95a7-fc6af817cd43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103887898-172.17.0.11-1595960511741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42495,DS-192690c0-5d42-478e-9bfb-6d3e9e66463c,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-c6802639-3348-4038-9615-00b4cfc43943,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-4a9a108f-95e9-4415-a28d-8edde38219fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-137032cd-1560-42ec-8ff6-183577b6f310,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-e86a7c38-f11c-4eeb-8c1f-29cb8aade416,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-50148dae-74f7-48b4-aa32-a43ca4c3a30d,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-717e5168-2c07-4343-adba-d1d551d298ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-9597d885-4187-48fe-9ce7-0b6725b94f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1103887898-172.17.0.11-1595960511741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42495,DS-192690c0-5d42-478e-9bfb-6d3e9e66463c,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-c6802639-3348-4038-9615-00b4cfc43943,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-4a9a108f-95e9-4415-a28d-8edde38219fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-137032cd-1560-42ec-8ff6-183577b6f310,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-e86a7c38-f11c-4eeb-8c1f-29cb8aade416,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-50148dae-74f7-48b4-aa32-a43ca4c3a30d,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-717e5168-2c07-4343-adba-d1d551d298ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-9597d885-4187-48fe-9ce7-0b6725b94f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294921357-172.17.0.11-1595960574967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32952,DS-49f7304c-9961-49e3-8521-495059cc2f59,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-3e133288-122f-4b1e-a1af-eaa7937adf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-b6a42068-e1d4-4a56-b712-9849f6443e97,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-ac3ddb6a-1daf-43cf-9d37-56c4f06ab605,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-439c8166-050f-4a37-a718-0050b54ced5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-71e6237f-3876-4ba9-abbc-5a8e44ea9b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-81120364-fa1f-4c17-af5e-37da487ec112,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-3b44cabf-3df7-4343-91d2-836dd30d1d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-294921357-172.17.0.11-1595960574967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32952,DS-49f7304c-9961-49e3-8521-495059cc2f59,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-3e133288-122f-4b1e-a1af-eaa7937adf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-b6a42068-e1d4-4a56-b712-9849f6443e97,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-ac3ddb6a-1daf-43cf-9d37-56c4f06ab605,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-439c8166-050f-4a37-a718-0050b54ced5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-71e6237f-3876-4ba9-abbc-5a8e44ea9b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-81120364-fa1f-4c17-af5e-37da487ec112,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-3b44cabf-3df7-4343-91d2-836dd30d1d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-291970707-172.17.0.11-1595961144821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45823,DS-439b5585-3819-4933-9398-9d6f9228f4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-44b7e5a5-d928-4b18-8d95-65d4768f69c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-08cae526-38c8-4c45-b6e2-f970f0a09978,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-60af7440-bcf0-49e7-93ed-b8d79d99bf86,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-13a644ba-042a-457b-8545-1c3fc150d676,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-ff89f94d-5fc5-4859-a463-b4a08ca8f8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-db31b6e7-24a0-4992-8b26-3462a3cd1ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-863dac48-c6ce-43bb-abfe-3e9740a767cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-291970707-172.17.0.11-1595961144821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45823,DS-439b5585-3819-4933-9398-9d6f9228f4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-44b7e5a5-d928-4b18-8d95-65d4768f69c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-08cae526-38c8-4c45-b6e2-f970f0a09978,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-60af7440-bcf0-49e7-93ed-b8d79d99bf86,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-13a644ba-042a-457b-8545-1c3fc150d676,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-ff89f94d-5fc5-4859-a463-b4a08ca8f8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-db31b6e7-24a0-4992-8b26-3462a3cd1ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-863dac48-c6ce-43bb-abfe-3e9740a767cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336440359-172.17.0.11-1595961915223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37190,DS-078072d2-09f7-43ae-89a6-1aa86b195db5,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-9e93144c-c5a2-4b88-8486-8a38be666b65,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-eeb601c4-6240-4d37-845a-b61197a8f5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-b0e5a20a-4d1f-46b3-a082-c7ad0fb14a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-311f5a7a-9062-4c46-93a0-681d2a47e7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-1e498b60-95c0-46ad-bc0e-c6150f094749,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-357b3a11-8823-4091-a86b-6ea8cd99cadf,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-29471249-6618-4455-be62-1047024e31b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336440359-172.17.0.11-1595961915223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37190,DS-078072d2-09f7-43ae-89a6-1aa86b195db5,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-9e93144c-c5a2-4b88-8486-8a38be666b65,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-eeb601c4-6240-4d37-845a-b61197a8f5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-b0e5a20a-4d1f-46b3-a082-c7ad0fb14a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-311f5a7a-9062-4c46-93a0-681d2a47e7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-1e498b60-95c0-46ad-bc0e-c6150f094749,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-357b3a11-8823-4091-a86b-6ea8cd99cadf,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-29471249-6618-4455-be62-1047024e31b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847286189-172.17.0.11-1595962402675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43437,DS-3c25a63b-f6a7-4bad-a763-77e41cce3fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-33c28dd8-7524-4f59-b469-e60b66a21482,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-a079e91f-bd0f-4bef-91c2-07f700fe26d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-3e7d84a1-58ab-4133-a750-418485ab0c30,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-fac67336-1517-44f5-952d-73f64c37ceab,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-8f854b7e-7050-4540-8bb8-4ae5a1a96d45,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-1d530b7b-cc9a-4d1a-ac1b-ac801dafa9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-f2867fd4-7dc1-4b66-81c9-576127a0ef99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847286189-172.17.0.11-1595962402675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43437,DS-3c25a63b-f6a7-4bad-a763-77e41cce3fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-33c28dd8-7524-4f59-b469-e60b66a21482,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-a079e91f-bd0f-4bef-91c2-07f700fe26d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-3e7d84a1-58ab-4133-a750-418485ab0c30,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-fac67336-1517-44f5-952d-73f64c37ceab,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-8f854b7e-7050-4540-8bb8-4ae5a1a96d45,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-1d530b7b-cc9a-4d1a-ac1b-ac801dafa9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-f2867fd4-7dc1-4b66-81c9-576127a0ef99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421110673-172.17.0.11-1595963051565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35487,DS-271446fd-8789-441c-b936-60d116be3250,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-8bcc6aef-3ec2-44f1-9d3a-5d66ccb47bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-40680f66-7c30-4dcd-bfd2-8708fd2218b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-62234759-76dd-47d8-96be-57526a573ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-f522bcc2-ba80-4470-952e-18aa46fa0ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-7d2d7f5e-2dd0-4af7-8ea1-09f66deb4b98,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-45f46be0-e4b2-4dc6-ac6b-470618101b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-7910ec98-0e67-44e8-a4c7-55074bbfc00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421110673-172.17.0.11-1595963051565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35487,DS-271446fd-8789-441c-b936-60d116be3250,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-8bcc6aef-3ec2-44f1-9d3a-5d66ccb47bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-40680f66-7c30-4dcd-bfd2-8708fd2218b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-62234759-76dd-47d8-96be-57526a573ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-f522bcc2-ba80-4470-952e-18aa46fa0ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-7d2d7f5e-2dd0-4af7-8ea1-09f66deb4b98,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-45f46be0-e4b2-4dc6-ac6b-470618101b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-7910ec98-0e67-44e8-a4c7-55074bbfc00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065031255-172.17.0.11-1595963235961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40930,DS-74febb0f-23cc-4e6d-b5fb-000545b9e990,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-5ed34345-397f-453d-8fd2-6ac9ec3c323a,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-ed731c55-9756-4c76-85bd-f24269cc04e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-9fbe2513-37b5-410e-9f98-79252c74dc97,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-d80ccb8b-3276-4840-8ca3-79676a5bd673,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-29424d36-074b-4e7e-ba69-ab4c58e14d94,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-9d3a66dc-bfe7-4558-b89e-52eb1548f777,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-2fd90efb-be06-42bb-a824-4b9f65621c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065031255-172.17.0.11-1595963235961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40930,DS-74febb0f-23cc-4e6d-b5fb-000545b9e990,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-5ed34345-397f-453d-8fd2-6ac9ec3c323a,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-ed731c55-9756-4c76-85bd-f24269cc04e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-9fbe2513-37b5-410e-9f98-79252c74dc97,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-d80ccb8b-3276-4840-8ca3-79676a5bd673,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-29424d36-074b-4e7e-ba69-ab4c58e14d94,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-9d3a66dc-bfe7-4558-b89e-52eb1548f777,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-2fd90efb-be06-42bb-a824-4b9f65621c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357206773-172.17.0.11-1595964044887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42578,DS-218bcdc4-ccd9-4f3b-8eab-307ed2aa0639,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-bc55571b-e116-47aa-ab11-554c59a8bd95,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-5b2b67f0-33c0-4ea6-a34e-992a164ac685,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-cd0db6b2-d1e8-492b-bcad-a1423df7999a,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-3774b2d6-e394-4ea7-a1d9-44b27ba7ad62,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-63dbf5fa-d708-4b35-91ac-9643f08a4890,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-ae6c5096-90c9-475f-b182-66444810a93f,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-58a41b8a-fba7-4b24-9a7a-7c1c1f7a34dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357206773-172.17.0.11-1595964044887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42578,DS-218bcdc4-ccd9-4f3b-8eab-307ed2aa0639,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-bc55571b-e116-47aa-ab11-554c59a8bd95,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-5b2b67f0-33c0-4ea6-a34e-992a164ac685,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-cd0db6b2-d1e8-492b-bcad-a1423df7999a,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-3774b2d6-e394-4ea7-a1d9-44b27ba7ad62,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-63dbf5fa-d708-4b35-91ac-9643f08a4890,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-ae6c5096-90c9-475f-b182-66444810a93f,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-58a41b8a-fba7-4b24-9a7a-7c1c1f7a34dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5130
