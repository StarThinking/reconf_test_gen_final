reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447610401-172.17.0.13-1595858147403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34341,DS-4152b29f-859d-4fb4-8ca4-c4731371c098,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-e1d0c873-f058-4a51-a1cb-5744f3854f38,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-3210aeab-0c3e-4665-901c-2f56bccc73d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-057ed8c1-a290-48df-9522-f3bb742a07cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-994fa70e-7af3-408b-aaa4-c72a1b1e8cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-e734084e-f9cb-4e1e-a902-cf4d154ffa68,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-27259741-51aa-4d2b-8736-c6446cf0cf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-245feff4-d3fa-4408-b1c9-1f817e712ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447610401-172.17.0.13-1595858147403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34341,DS-4152b29f-859d-4fb4-8ca4-c4731371c098,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-e1d0c873-f058-4a51-a1cb-5744f3854f38,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-3210aeab-0c3e-4665-901c-2f56bccc73d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-057ed8c1-a290-48df-9522-f3bb742a07cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-994fa70e-7af3-408b-aaa4-c72a1b1e8cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-e734084e-f9cb-4e1e-a902-cf4d154ffa68,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-27259741-51aa-4d2b-8736-c6446cf0cf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-245feff4-d3fa-4408-b1c9-1f817e712ea5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943667316-172.17.0.13-1595858223617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46731,DS-116da0ae-4472-4f8d-97e0-d987304f438e,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-563b93b5-a13e-4132-ae39-c021ae136252,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-f4d4e048-55a2-4a04-b87b-df27b953872a,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-c1b67171-21a0-496c-bee3-e697e39fa39d,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-32729be4-822b-48b1-98b5-ee94f42b24a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-bc977200-ab4f-485b-a7ff-0935d65647a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-e2707e22-48fa-4f07-a39e-96749226f3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-10789e12-9ea6-429d-bbd6-ceefbe15ca9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943667316-172.17.0.13-1595858223617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46731,DS-116da0ae-4472-4f8d-97e0-d987304f438e,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-563b93b5-a13e-4132-ae39-c021ae136252,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-f4d4e048-55a2-4a04-b87b-df27b953872a,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-c1b67171-21a0-496c-bee3-e697e39fa39d,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-32729be4-822b-48b1-98b5-ee94f42b24a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-bc977200-ab4f-485b-a7ff-0935d65647a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-e2707e22-48fa-4f07-a39e-96749226f3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-10789e12-9ea6-429d-bbd6-ceefbe15ca9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69171138-172.17.0.13-1595858260998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42834,DS-1ec2205d-bf6d-471c-a0c1-ab54076242bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-d55a8e36-df11-4c78-b4fa-4cc291d66f01,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-844aac6b-ed3d-4548-9aae-08f2fa7d4857,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-c0662344-446c-41f8-a871-08981eeb7837,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-f51ed7e1-a50c-4470-a6ae-447bab28e886,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-73ecb097-0128-40bc-b5e1-f91da100f911,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-da7e94a2-dccb-4916-a4a5-1f9e9e4aa291,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-7c0fa3c6-6192-43b9-9492-8c171b46324a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69171138-172.17.0.13-1595858260998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42834,DS-1ec2205d-bf6d-471c-a0c1-ab54076242bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-d55a8e36-df11-4c78-b4fa-4cc291d66f01,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-844aac6b-ed3d-4548-9aae-08f2fa7d4857,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-c0662344-446c-41f8-a871-08981eeb7837,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-f51ed7e1-a50c-4470-a6ae-447bab28e886,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-73ecb097-0128-40bc-b5e1-f91da100f911,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-da7e94a2-dccb-4916-a4a5-1f9e9e4aa291,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-7c0fa3c6-6192-43b9-9492-8c171b46324a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835608670-172.17.0.13-1595859151183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45396,DS-558365e9-3432-4760-b929-c8fe88eaa3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-e54a3c6e-cf85-4cb6-bcf8-f3b2553688e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-6791e230-90c5-47d7-9dfd-f99cb97c8d13,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-200af1a8-42f8-4259-bb34-6c2d66261573,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-95ff03e5-4de3-4a73-bc92-0f2abd3ca1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-1975bd16-98e5-4b53-9a0d-403ee5571e69,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-ceb3a5c3-c734-43e8-9df0-55e101c65a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-68067676-7dea-4bc6-89f4-947b0134b329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-835608670-172.17.0.13-1595859151183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45396,DS-558365e9-3432-4760-b929-c8fe88eaa3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-e54a3c6e-cf85-4cb6-bcf8-f3b2553688e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-6791e230-90c5-47d7-9dfd-f99cb97c8d13,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-200af1a8-42f8-4259-bb34-6c2d66261573,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-95ff03e5-4de3-4a73-bc92-0f2abd3ca1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-1975bd16-98e5-4b53-9a0d-403ee5571e69,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-ceb3a5c3-c734-43e8-9df0-55e101c65a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-68067676-7dea-4bc6-89f4-947b0134b329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39016618-172.17.0.13-1595859666938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-32cc7dbe-45de-4970-86bb-c67f35d9be23,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-d60ce672-cf02-48ce-825e-40951c14e845,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-4b1df7b8-2f36-4e36-90da-38415c5c193a,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-868c7d5b-be1e-4e61-9832-ce6473ede517,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-04c30015-1266-4808-a872-3ded582cf594,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-c628c49b-0701-4711-97c0-ec58344b8dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-ce14f4de-8248-4d8a-bdb8-517f971e9a12,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-0f0a1f33-9c76-48ce-ac3a-5c23de4d242b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39016618-172.17.0.13-1595859666938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-32cc7dbe-45de-4970-86bb-c67f35d9be23,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-d60ce672-cf02-48ce-825e-40951c14e845,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-4b1df7b8-2f36-4e36-90da-38415c5c193a,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-868c7d5b-be1e-4e61-9832-ce6473ede517,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-04c30015-1266-4808-a872-3ded582cf594,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-c628c49b-0701-4711-97c0-ec58344b8dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-ce14f4de-8248-4d8a-bdb8-517f971e9a12,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-0f0a1f33-9c76-48ce-ac3a-5c23de4d242b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338219234-172.17.0.13-1595859788002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38340,DS-ea22175b-68cb-436f-829a-4273806d10be,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-f490cd38-b259-46ee-895e-8c6e344c18c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-6a33c29b-626d-4886-9857-fce8efd3154d,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-90c5756c-e4d3-455e-b438-b19f2d1a251b,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-283dcd1c-c968-41a0-9e15-3a342cf1fb81,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-d56e99ca-b178-4699-b81c-44abf5359f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-8b75e6eb-1627-4df4-909f-e5205780fd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-56e48d7f-fbc6-4a58-86b1-5edc85ee6ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338219234-172.17.0.13-1595859788002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38340,DS-ea22175b-68cb-436f-829a-4273806d10be,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-f490cd38-b259-46ee-895e-8c6e344c18c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-6a33c29b-626d-4886-9857-fce8efd3154d,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-90c5756c-e4d3-455e-b438-b19f2d1a251b,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-283dcd1c-c968-41a0-9e15-3a342cf1fb81,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-d56e99ca-b178-4699-b81c-44abf5359f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-8b75e6eb-1627-4df4-909f-e5205780fd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-56e48d7f-fbc6-4a58-86b1-5edc85ee6ef3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928429321-172.17.0.13-1595860260120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-dd2955e4-9f7d-4703-a0a6-414f0ea84355,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-ef4836f6-221a-4425-b6bb-db29421a2b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-676d17b2-be9b-490f-b0ba-da3c5afa2d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-7a83f4fe-ae55-497d-a932-4fbb942243e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-d6eb2aee-c285-4c22-a788-dc4376ea1ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-619fa345-5abd-4e9a-bc19-9e0080d6f5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-87a4f9a2-d164-467f-935d-1b05e6eda359,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-de69f17b-78bf-4355-a1e6-f8d5645339c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928429321-172.17.0.13-1595860260120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-dd2955e4-9f7d-4703-a0a6-414f0ea84355,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-ef4836f6-221a-4425-b6bb-db29421a2b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-676d17b2-be9b-490f-b0ba-da3c5afa2d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-7a83f4fe-ae55-497d-a932-4fbb942243e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-d6eb2aee-c285-4c22-a788-dc4376ea1ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-619fa345-5abd-4e9a-bc19-9e0080d6f5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-87a4f9a2-d164-467f-935d-1b05e6eda359,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-de69f17b-78bf-4355-a1e6-f8d5645339c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083938138-172.17.0.13-1595860329220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-36af8e05-7d74-4602-b4d8-cd18b72d0507,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-076f5c24-058f-42f6-b9ff-478c163ae278,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-808d2f59-d456-4449-9eb9-a5481f708944,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-90c2adcb-a24a-47eb-a1f1-fd0975ff972d,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-7fa42063-d056-45f6-8653-5e49aa27d02d,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-9006b7fd-4521-4f45-9378-c467b6f96c62,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-2c41ab5f-0af2-41a7-aaae-acba23ae8d53,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-02e0c9e2-9857-4d45-b924-a7d5f834f549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083938138-172.17.0.13-1595860329220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45762,DS-36af8e05-7d74-4602-b4d8-cd18b72d0507,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-076f5c24-058f-42f6-b9ff-478c163ae278,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-808d2f59-d456-4449-9eb9-a5481f708944,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-90c2adcb-a24a-47eb-a1f1-fd0975ff972d,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-7fa42063-d056-45f6-8653-5e49aa27d02d,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-9006b7fd-4521-4f45-9378-c467b6f96c62,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-2c41ab5f-0af2-41a7-aaae-acba23ae8d53,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-02e0c9e2-9857-4d45-b924-a7d5f834f549,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949424972-172.17.0.13-1595860406264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46383,DS-be4d0bf3-badf-470c-afeb-bbac87e2bc91,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-6f4f32fb-d32b-444a-808f-17d9932eee29,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-dd789b08-7665-4f51-b77c-240c14f2863d,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-0e454e48-f894-4505-b050-95a15c6b6281,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-0a82464e-7ead-485e-8150-c3961e148799,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-a4cd638f-b4b0-4631-b886-2b6b8b9ca353,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-00b48630-15e8-4eef-8f9e-7936e9dcf75f,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-5fd7e098-8ff2-48cc-872f-06b8a461c731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949424972-172.17.0.13-1595860406264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46383,DS-be4d0bf3-badf-470c-afeb-bbac87e2bc91,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-6f4f32fb-d32b-444a-808f-17d9932eee29,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-dd789b08-7665-4f51-b77c-240c14f2863d,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-0e454e48-f894-4505-b050-95a15c6b6281,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-0a82464e-7ead-485e-8150-c3961e148799,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-a4cd638f-b4b0-4631-b886-2b6b8b9ca353,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-00b48630-15e8-4eef-8f9e-7936e9dcf75f,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-5fd7e098-8ff2-48cc-872f-06b8a461c731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610549081-172.17.0.13-1595860794703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33202,DS-7ca60012-82cd-4eb4-8c56-554988113302,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-345bb9d9-7b8c-4951-bc15-b75869a8f7da,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-1e61d7a6-0b93-42de-935c-e65b28facce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-39f14128-21e3-4e39-aa4e-32ddbafb2b34,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-c45b6c8f-1c4f-4157-a69a-de8511b5a1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-f2e805ee-9f45-4a6a-95da-419df4c1adea,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-e2c33cb9-58ca-4dcc-91a8-3c44a6882ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-2eb60b30-dbf8-4f3b-9281-7a0f4d41ed4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610549081-172.17.0.13-1595860794703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33202,DS-7ca60012-82cd-4eb4-8c56-554988113302,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-345bb9d9-7b8c-4951-bc15-b75869a8f7da,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-1e61d7a6-0b93-42de-935c-e65b28facce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-39f14128-21e3-4e39-aa4e-32ddbafb2b34,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-c45b6c8f-1c4f-4157-a69a-de8511b5a1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-f2e805ee-9f45-4a6a-95da-419df4c1adea,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-e2c33cb9-58ca-4dcc-91a8-3c44a6882ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-2eb60b30-dbf8-4f3b-9281-7a0f4d41ed4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961842773-172.17.0.13-1595860871932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35159,DS-f366b727-606b-4233-8c66-5360faeb4942,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-22980a9b-05aa-493f-b8a0-376e8c134812,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-0060ea6b-caa5-42bc-981a-5ed6a2d1a7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-83d8c9a9-60e5-461d-ae54-c411b2d32550,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-a7041353-e90a-44c5-87bf-fdd5e27fb8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-4a3c74bc-1026-4b29-a507-d3c800f99866,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-e42cf85d-7b2b-4c78-9236-8e5f315fbdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-cfe486ce-4ef4-4e5f-97f6-f8f64c34bfad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961842773-172.17.0.13-1595860871932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35159,DS-f366b727-606b-4233-8c66-5360faeb4942,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-22980a9b-05aa-493f-b8a0-376e8c134812,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-0060ea6b-caa5-42bc-981a-5ed6a2d1a7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-83d8c9a9-60e5-461d-ae54-c411b2d32550,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-a7041353-e90a-44c5-87bf-fdd5e27fb8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-4a3c74bc-1026-4b29-a507-d3c800f99866,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-e42cf85d-7b2b-4c78-9236-8e5f315fbdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-cfe486ce-4ef4-4e5f-97f6-f8f64c34bfad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489420747-172.17.0.13-1595861642461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38444,DS-c359815e-7e86-4283-aeb4-16639e481113,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-3691c6b6-54ce-41d0-b040-9851e5b030c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-591fd1c2-52a7-4c1c-b124-7179852067b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-551411b8-574c-4c54-a95a-67514a706176,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-0cd8ca24-417f-4f8d-9937-82de9a14f810,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-3cfc46b5-cacb-4dbd-81d9-c25731ce80b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-4caf89d3-8c7a-4b2d-8909-c08b45759186,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-2a448e6f-19bf-4927-8dfb-5cb61f6e9c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489420747-172.17.0.13-1595861642461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38444,DS-c359815e-7e86-4283-aeb4-16639e481113,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-3691c6b6-54ce-41d0-b040-9851e5b030c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-591fd1c2-52a7-4c1c-b124-7179852067b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-551411b8-574c-4c54-a95a-67514a706176,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-0cd8ca24-417f-4f8d-9937-82de9a14f810,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-3cfc46b5-cacb-4dbd-81d9-c25731ce80b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-4caf89d3-8c7a-4b2d-8909-c08b45759186,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-2a448e6f-19bf-4927-8dfb-5cb61f6e9c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258281502-172.17.0.13-1595861719101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37528,DS-00643290-b214-4975-946a-8cec5814e8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-3732f08a-a3a1-4fad-89fb-137988940a27,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-5496b991-102e-4e01-b9fd-45e0a42f660b,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-9cbe435d-6c24-4c8e-b012-1eaf1a0e1cad,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-498f709a-1325-4a40-aaa7-cc9376e56814,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-0cd66f8b-8223-4ff7-82af-62e41f3eb934,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-5e31ea6d-bc23-472c-a445-20c6ab67752b,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-b54a6bee-bb8d-4798-8801-bed89a67643f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258281502-172.17.0.13-1595861719101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37528,DS-00643290-b214-4975-946a-8cec5814e8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-3732f08a-a3a1-4fad-89fb-137988940a27,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-5496b991-102e-4e01-b9fd-45e0a42f660b,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-9cbe435d-6c24-4c8e-b012-1eaf1a0e1cad,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-498f709a-1325-4a40-aaa7-cc9376e56814,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-0cd66f8b-8223-4ff7-82af-62e41f3eb934,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-5e31ea6d-bc23-472c-a445-20c6ab67752b,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-b54a6bee-bb8d-4798-8801-bed89a67643f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216687497-172.17.0.13-1595862704952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43726,DS-553be556-0757-4e65-951b-69351aa403af,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-7ba60aa1-3f33-4f62-af05-cafd9b50f020,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-e486d361-f9ad-4c1e-aab2-7936364c5b21,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-11cbc3bc-52f4-4c69-9785-4734e274a775,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-f61a648c-f586-472d-8873-7d9e622c24ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-4389bcc7-7386-4f39-8822-b4a3fde53c30,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-b1c55765-83d0-48c4-987f-b0644da82f77,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-5852b47a-abe7-4242-8746-9be335a3a4f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216687497-172.17.0.13-1595862704952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43726,DS-553be556-0757-4e65-951b-69351aa403af,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-7ba60aa1-3f33-4f62-af05-cafd9b50f020,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-e486d361-f9ad-4c1e-aab2-7936364c5b21,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-11cbc3bc-52f4-4c69-9785-4734e274a775,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-f61a648c-f586-472d-8873-7d9e622c24ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-4389bcc7-7386-4f39-8822-b4a3fde53c30,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-b1c55765-83d0-48c4-987f-b0644da82f77,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-5852b47a-abe7-4242-8746-9be335a3a4f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643561147-172.17.0.13-1595863306150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35407,DS-bf6b5961-d1c6-4be3-85d4-c0a581bd8dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-8b26e3b4-e70f-4370-866a-dc47039d6ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-d07a2898-4aae-49f2-966b-17f762feae6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-f6fa5a02-464e-43c5-a484-6b1551f4b899,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-96d052bf-b72d-4cff-b93a-40afadd9e643,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-af614c00-daeb-4de2-83f3-b7af0c88547b,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-d75bf811-b779-4e89-b030-1ddcd1be209e,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-27bed602-752c-429d-8bb0-41e49fb792fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643561147-172.17.0.13-1595863306150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35407,DS-bf6b5961-d1c6-4be3-85d4-c0a581bd8dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-8b26e3b4-e70f-4370-866a-dc47039d6ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-d07a2898-4aae-49f2-966b-17f762feae6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-f6fa5a02-464e-43c5-a484-6b1551f4b899,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-96d052bf-b72d-4cff-b93a-40afadd9e643,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-af614c00-daeb-4de2-83f3-b7af0c88547b,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-d75bf811-b779-4e89-b030-1ddcd1be209e,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-27bed602-752c-429d-8bb0-41e49fb792fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268497989-172.17.0.13-1595863733893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34004,DS-4d8b6833-5a2c-41ab-a1db-1e22c891ec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-62c5f97a-a951-4c4a-b557-cabe698d8de5,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-22ec942a-4e5d-4a12-ac53-4b6540101450,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-2ce48b35-db79-41ea-b7d1-2bab18b74f95,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-18296b45-44fe-4c84-8b92-67c462d1845d,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-9b6161f1-fafb-43bd-9af0-bee95293e029,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-f0901fc3-272f-4cb0-bbc9-fc4669c42808,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-553d000e-4677-4ddd-9c8d-c116e5ef0955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1268497989-172.17.0.13-1595863733893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34004,DS-4d8b6833-5a2c-41ab-a1db-1e22c891ec6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-62c5f97a-a951-4c4a-b557-cabe698d8de5,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-22ec942a-4e5d-4a12-ac53-4b6540101450,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-2ce48b35-db79-41ea-b7d1-2bab18b74f95,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-18296b45-44fe-4c84-8b92-67c462d1845d,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-9b6161f1-fafb-43bd-9af0-bee95293e029,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-f0901fc3-272f-4cb0-bbc9-fc4669c42808,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-553d000e-4677-4ddd-9c8d-c116e5ef0955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5831
