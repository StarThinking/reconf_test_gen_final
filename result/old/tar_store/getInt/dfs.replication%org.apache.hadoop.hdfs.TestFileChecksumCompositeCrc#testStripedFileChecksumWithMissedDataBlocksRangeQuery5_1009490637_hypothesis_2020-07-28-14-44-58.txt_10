reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785887031-172.17.0.5-1595947550892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46759,DS-498a06d3-1c00-4ec1-bfe6-89dfef7661b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-1ff4ab53-8b1e-4c99-90da-797468187809,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-83f9be45-4270-46fb-81e9-b7a24af07cde,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-5dbb4f4a-c9b1-4290-9caf-f0c5e4bd0cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-7292904a-97d1-49fb-bb89-21a96f9db81a,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-d216fa86-c7c4-4f83-8c9e-061239838e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-03dcaf50-e826-40a9-b8b8-ccf11ce75c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-37485d51-b76f-4e98-ae8a-e21788566405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785887031-172.17.0.5-1595947550892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46759,DS-498a06d3-1c00-4ec1-bfe6-89dfef7661b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-1ff4ab53-8b1e-4c99-90da-797468187809,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-83f9be45-4270-46fb-81e9-b7a24af07cde,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-5dbb4f4a-c9b1-4290-9caf-f0c5e4bd0cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-7292904a-97d1-49fb-bb89-21a96f9db81a,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-d216fa86-c7c4-4f83-8c9e-061239838e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-03dcaf50-e826-40a9-b8b8-ccf11ce75c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-37485d51-b76f-4e98-ae8a-e21788566405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924465004-172.17.0.5-1595948232206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-038edf2c-895a-445f-8ae6-49c762b66e26,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-f070dd5a-b97c-45bf-afc9-4ab819375446,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-59a5ba2f-c29e-42dc-8e5f-17ab4067b49e,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-757afe56-a8b7-4e0a-8891-f0b4384f289d,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-e75bfa62-2756-4080-af80-30fdc47ba8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-baed68cf-e636-4ed8-8f7c-2afb6ae09514,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-ddc00578-6e52-482e-b854-733bcc487bec,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-d8d30b26-0985-4c89-bb21-a5b7c27bd9e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924465004-172.17.0.5-1595948232206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-038edf2c-895a-445f-8ae6-49c762b66e26,DISK], DatanodeInfoWithStorage[127.0.0.1:33593,DS-f070dd5a-b97c-45bf-afc9-4ab819375446,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-59a5ba2f-c29e-42dc-8e5f-17ab4067b49e,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-757afe56-a8b7-4e0a-8891-f0b4384f289d,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-e75bfa62-2756-4080-af80-30fdc47ba8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-baed68cf-e636-4ed8-8f7c-2afb6ae09514,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-ddc00578-6e52-482e-b854-733bcc487bec,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-d8d30b26-0985-4c89-bb21-a5b7c27bd9e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682424887-172.17.0.5-1595949540953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36871,DS-63db9859-dc92-4468-93e3-1721e316dd56,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-97d8e5dd-e0e5-4511-a106-15d8f1dadb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-00e7e7e8-f318-4d3a-ba82-aa9828c3fee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-522716be-4d2c-40b2-a893-40aac0acf6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-3342411d-c18c-4394-8b89-4a9dbcd0910e,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-51452262-ee10-4226-926e-2cc1fe8716d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-61822248-61a5-4425-b586-d2c3e844ede8,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-4bab2aa5-d166-4750-b7ee-61552cc64de7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682424887-172.17.0.5-1595949540953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36871,DS-63db9859-dc92-4468-93e3-1721e316dd56,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-97d8e5dd-e0e5-4511-a106-15d8f1dadb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-00e7e7e8-f318-4d3a-ba82-aa9828c3fee5,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-522716be-4d2c-40b2-a893-40aac0acf6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-3342411d-c18c-4394-8b89-4a9dbcd0910e,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-51452262-ee10-4226-926e-2cc1fe8716d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-61822248-61a5-4425-b586-d2c3e844ede8,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-4bab2aa5-d166-4750-b7ee-61552cc64de7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948021939-172.17.0.5-1595950129013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41456,DS-058fedaf-ed03-4bdc-b98e-d1bb33d0ccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-2b4c6697-6537-494d-a7e3-01d673fab2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-fc0b8aba-6b0e-4fef-b6fc-70c213d4341a,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-95f7906d-370e-495c-8493-6b6df2c211bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-4ef6d36e-40d4-45de-b03b-7be6e02fa144,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-2d6e5fad-256f-44a4-827e-c6f8eee54818,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-e922da0d-891c-46f9-ad76-96bc9b12a7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-f8e4d79a-40bd-411b-a8a4-535da526c727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948021939-172.17.0.5-1595950129013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41456,DS-058fedaf-ed03-4bdc-b98e-d1bb33d0ccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-2b4c6697-6537-494d-a7e3-01d673fab2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-fc0b8aba-6b0e-4fef-b6fc-70c213d4341a,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-95f7906d-370e-495c-8493-6b6df2c211bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-4ef6d36e-40d4-45de-b03b-7be6e02fa144,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-2d6e5fad-256f-44a4-827e-c6f8eee54818,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-e922da0d-891c-46f9-ad76-96bc9b12a7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-f8e4d79a-40bd-411b-a8a4-535da526c727,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865518796-172.17.0.5-1595950262586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40293,DS-3ad99c52-8639-4c75-b2ab-3a4f14824e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-d6e6f834-3c63-46dc-8b9b-9ba1a287b7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-fa3c06a1-2a0e-439a-9e57-7e2b178e573d,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-57cd23c4-384c-4506-84b1-4499c6ba9e75,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-ea6531c0-1987-4d1a-8a0b-7e5094ae6d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-878aa8c5-552e-4388-a5bc-33283dc7f029,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-d2e68a83-9a18-4964-a255-d630f8cfd42d,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-820def83-71fb-40f0-a64a-4b469f29e05e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865518796-172.17.0.5-1595950262586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40293,DS-3ad99c52-8639-4c75-b2ab-3a4f14824e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-d6e6f834-3c63-46dc-8b9b-9ba1a287b7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-fa3c06a1-2a0e-439a-9e57-7e2b178e573d,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-57cd23c4-384c-4506-84b1-4499c6ba9e75,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-ea6531c0-1987-4d1a-8a0b-7e5094ae6d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-878aa8c5-552e-4388-a5bc-33283dc7f029,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-d2e68a83-9a18-4964-a255-d630f8cfd42d,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-820def83-71fb-40f0-a64a-4b469f29e05e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850659601-172.17.0.5-1595950688707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33584,DS-b02382cb-0e47-4b64-8c50-2d90e66f0c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-ab3edbbe-e289-4810-aec2-d744e7c796e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-8404aeab-5296-46bb-95ca-70848f670af3,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-a8e19979-d5e7-4463-b536-31fc8e7fd3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-6408af13-1c58-4b84-83e6-dec9267982a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-cc1130b9-4491-451e-bf0e-8f890b0d78d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-7b98eec5-1835-4a6f-98bc-76c934afeb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-2f294837-fdf2-4164-b03c-6f13073af051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850659601-172.17.0.5-1595950688707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33584,DS-b02382cb-0e47-4b64-8c50-2d90e66f0c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-ab3edbbe-e289-4810-aec2-d744e7c796e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-8404aeab-5296-46bb-95ca-70848f670af3,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-a8e19979-d5e7-4463-b536-31fc8e7fd3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-6408af13-1c58-4b84-83e6-dec9267982a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-cc1130b9-4491-451e-bf0e-8f890b0d78d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-7b98eec5-1835-4a6f-98bc-76c934afeb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-2f294837-fdf2-4164-b03c-6f13073af051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996415145-172.17.0.5-1595951302530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40956,DS-481ad062-6f45-4a40-b203-6ed86e662573,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-25bad63c-115b-41ca-9915-0931440096b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-2d797da1-2366-4d4c-8776-07e35ea75094,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-38ef3278-23e4-43bc-8dc3-606b263ec371,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-ffeb1304-a08b-4fa4-bf15-c7bcdad87ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-18d40cd7-dd7f-42a1-95dc-43b5d3c4f89b,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-c11f1bf5-73fe-48c4-b731-47d4c5a2e70f,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-a26cd82e-b642-40b7-a12c-15ebadaabeed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996415145-172.17.0.5-1595951302530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40956,DS-481ad062-6f45-4a40-b203-6ed86e662573,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-25bad63c-115b-41ca-9915-0931440096b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-2d797da1-2366-4d4c-8776-07e35ea75094,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-38ef3278-23e4-43bc-8dc3-606b263ec371,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-ffeb1304-a08b-4fa4-bf15-c7bcdad87ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-18d40cd7-dd7f-42a1-95dc-43b5d3c4f89b,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-c11f1bf5-73fe-48c4-b731-47d4c5a2e70f,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-a26cd82e-b642-40b7-a12c-15ebadaabeed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364362646-172.17.0.5-1595951422644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35759,DS-d6174979-3074-4af3-90ca-a4339ccd9afc,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-4c300088-e96b-440d-956d-4f4787893bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-575d2924-c8ed-4dba-a790-715556007191,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-517a454a-45c9-4b2c-8c54-2c7f345ea825,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-59d76521-8a88-46ac-861d-2bf54899d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-f2a5ce3b-7c35-4cbf-8ed6-efda1dc3e278,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-9afdae6d-64b2-4290-b36e-be374ffb5b61,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-c5604f9f-6584-4506-9a51-145a7e63bb3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364362646-172.17.0.5-1595951422644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35759,DS-d6174979-3074-4af3-90ca-a4339ccd9afc,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-4c300088-e96b-440d-956d-4f4787893bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-575d2924-c8ed-4dba-a790-715556007191,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-517a454a-45c9-4b2c-8c54-2c7f345ea825,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-59d76521-8a88-46ac-861d-2bf54899d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-f2a5ce3b-7c35-4cbf-8ed6-efda1dc3e278,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-9afdae6d-64b2-4290-b36e-be374ffb5b61,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-c5604f9f-6584-4506-9a51-145a7e63bb3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875405674-172.17.0.5-1595951625544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43771,DS-1319ecdf-1aa1-4219-9393-7e54531643dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-4f4915e1-30ef-479e-9fe2-a0804cd3866a,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-2ada4c16-e1ac-425f-9503-bf3b9dbf461f,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-4963054d-c4e1-4a2d-95d7-83f4d98d28a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-e23a38d6-ce59-4a4b-9550-cdd6c59fe146,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-fe8d4862-bf58-4b6a-8eb4-e138d43d11a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-50ffe037-f8d9-47b9-9d56-be6b0e7252e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-7efe405e-8498-4c4f-87a0-15cf923624b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875405674-172.17.0.5-1595951625544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43771,DS-1319ecdf-1aa1-4219-9393-7e54531643dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-4f4915e1-30ef-479e-9fe2-a0804cd3866a,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-2ada4c16-e1ac-425f-9503-bf3b9dbf461f,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-4963054d-c4e1-4a2d-95d7-83f4d98d28a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-e23a38d6-ce59-4a4b-9550-cdd6c59fe146,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-fe8d4862-bf58-4b6a-8eb4-e138d43d11a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-50ffe037-f8d9-47b9-9d56-be6b0e7252e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-7efe405e-8498-4c4f-87a0-15cf923624b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023433138-172.17.0.5-1595951820083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39934,DS-502b56d4-be94-49b0-92cf-736acb97b957,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-bc2fcfb2-f54e-47db-b6ac-5bed5ec75ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-125f4ffc-9238-4790-acb2-aa5557004530,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-04b89ff3-b5ea-4c29-bb79-9c1590ca0ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-10bfc56a-4d3c-455f-b77b-efcecaf010ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-e83cab47-5fba-466b-81bb-c27d2b8791a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-a0c98508-1611-4501-b372-9eb1be5163ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-deddd29c-f5d7-4644-bcf0-87e0d77e7748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023433138-172.17.0.5-1595951820083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39934,DS-502b56d4-be94-49b0-92cf-736acb97b957,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-bc2fcfb2-f54e-47db-b6ac-5bed5ec75ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-125f4ffc-9238-4790-acb2-aa5557004530,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-04b89ff3-b5ea-4c29-bb79-9c1590ca0ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-10bfc56a-4d3c-455f-b77b-efcecaf010ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-e83cab47-5fba-466b-81bb-c27d2b8791a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-a0c98508-1611-4501-b372-9eb1be5163ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-deddd29c-f5d7-4644-bcf0-87e0d77e7748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011460035-172.17.0.5-1595952616009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39188,DS-c202a619-076c-437a-8402-1c185d8d3c42,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-477a4290-65d5-4b1f-9ef3-3280faf346cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-cc5bc3cb-63bc-4942-8f5b-1d500ad28fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-e70fe29e-a7d6-405f-beff-3cf0d219c31a,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-9cfe97da-00b9-45a6-8940-bcef7a9c47a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-5cec87b0-1d5f-44fd-9a43-bd1fded03ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-de3e91da-a036-4719-b9ca-5901332162f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-f5a673e1-80c4-49dc-9ee3-8c4e03eeebad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011460035-172.17.0.5-1595952616009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39188,DS-c202a619-076c-437a-8402-1c185d8d3c42,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-477a4290-65d5-4b1f-9ef3-3280faf346cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-cc5bc3cb-63bc-4942-8f5b-1d500ad28fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-e70fe29e-a7d6-405f-beff-3cf0d219c31a,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-9cfe97da-00b9-45a6-8940-bcef7a9c47a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-5cec87b0-1d5f-44fd-9a43-bd1fded03ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-de3e91da-a036-4719-b9ca-5901332162f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-f5a673e1-80c4-49dc-9ee3-8c4e03eeebad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718596166-172.17.0.5-1595953045910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33764,DS-d71a48fd-7892-497c-b621-be23550c69af,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-d2af5609-2b61-4b71-8c95-bfc1a651d5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-abcc807e-ca27-451a-8da1-06066cc36c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-b9754993-581d-495a-b59d-1293b0539c72,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-c599295c-12f7-49ae-ac93-1e3456bce135,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-67a85f1b-730c-4992-8bc1-ce4711151eef,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-2394a93f-8218-47d7-be4a-7ae11e0c7c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-27e684ab-9214-476c-b670-d30cd730e78d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718596166-172.17.0.5-1595953045910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33764,DS-d71a48fd-7892-497c-b621-be23550c69af,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-d2af5609-2b61-4b71-8c95-bfc1a651d5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-abcc807e-ca27-451a-8da1-06066cc36c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-b9754993-581d-495a-b59d-1293b0539c72,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-c599295c-12f7-49ae-ac93-1e3456bce135,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-67a85f1b-730c-4992-8bc1-ce4711151eef,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-2394a93f-8218-47d7-be4a-7ae11e0c7c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-27e684ab-9214-476c-b670-d30cd730e78d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557331380-172.17.0.5-1595953776342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-ba499fe0-a55e-4593-8dee-df9bbd08ab38,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-0a94cc13-eea0-48c8-807b-91bde390bfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-44d71870-b85e-4fe1-8687-09bdcfa834b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-1868fbed-c02b-4f64-913b-9b6b4ad1d4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-7994d60a-7000-4bbd-ad43-9ae307698fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-44ac4901-5d1a-4090-94b3-387b3b09ddcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-f525a9b0-d3d3-40ce-aa8d-6d522dd8769c,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-054ad05c-586a-489c-89b9-698208d807a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557331380-172.17.0.5-1595953776342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46634,DS-ba499fe0-a55e-4593-8dee-df9bbd08ab38,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-0a94cc13-eea0-48c8-807b-91bde390bfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-44d71870-b85e-4fe1-8687-09bdcfa834b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-1868fbed-c02b-4f64-913b-9b6b4ad1d4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-7994d60a-7000-4bbd-ad43-9ae307698fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-44ac4901-5d1a-4090-94b3-387b3b09ddcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33154,DS-f525a9b0-d3d3-40ce-aa8d-6d522dd8769c,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-054ad05c-586a-489c-89b9-698208d807a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6397
