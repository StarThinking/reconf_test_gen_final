reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778017032-172.17.0.8-1595525793977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37367,DS-8ddd775b-68fe-444d-87e0-d096fd87ac89,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-4e637fb5-e5f0-4898-b529-4a2a2ca90ade,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-2eea6c6e-e700-4fd6-9eb3-72ddf1dabdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-63a58e23-29cb-4aaf-b0c9-7dbcebcfae26,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-47a89501-d83f-4bce-96d8-fc133fcc70f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-10b7990e-c7af-4f58-a249-c4ac9a6ef24c,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-a3af53f5-fc2e-42f7-97e8-0a3092554e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-e2ce406f-240d-4049-aad4-2141ef2f2d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778017032-172.17.0.8-1595525793977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37367,DS-8ddd775b-68fe-444d-87e0-d096fd87ac89,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-4e637fb5-e5f0-4898-b529-4a2a2ca90ade,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-2eea6c6e-e700-4fd6-9eb3-72ddf1dabdd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-63a58e23-29cb-4aaf-b0c9-7dbcebcfae26,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-47a89501-d83f-4bce-96d8-fc133fcc70f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-10b7990e-c7af-4f58-a249-c4ac9a6ef24c,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-a3af53f5-fc2e-42f7-97e8-0a3092554e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-e2ce406f-240d-4049-aad4-2141ef2f2d6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1787112155-172.17.0.8-1595526157148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37901,DS-d9bff997-369a-4f6c-9690-04743b429664,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-330da1d9-be26-46eb-8300-aa925edaf6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-70de28bf-9960-4db6-a240-9bc54ff8e62d,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-39e28bfa-fb87-4fb6-b390-b41a8f066556,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-21fd3d48-c2c0-4def-a4a2-fdd6531c3633,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-df407aee-82b8-4a42-85ae-2c16911e29a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-f36dc249-624c-4e40-a1f1-8d2425220e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-c2fb6e48-085d-42be-bb9e-8de20cff06d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1787112155-172.17.0.8-1595526157148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37901,DS-d9bff997-369a-4f6c-9690-04743b429664,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-330da1d9-be26-46eb-8300-aa925edaf6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-70de28bf-9960-4db6-a240-9bc54ff8e62d,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-39e28bfa-fb87-4fb6-b390-b41a8f066556,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-21fd3d48-c2c0-4def-a4a2-fdd6531c3633,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-df407aee-82b8-4a42-85ae-2c16911e29a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35026,DS-f36dc249-624c-4e40-a1f1-8d2425220e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-c2fb6e48-085d-42be-bb9e-8de20cff06d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907328961-172.17.0.8-1595526221854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37701,DS-f24ffcd7-d964-4eda-a724-2dec4074ae42,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-0f5ce2c8-8acc-4a0f-9b15-3d1919798ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-9ed2297a-ee54-40b1-8697-7c0c83553152,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-b1bc9c19-d9b6-4b8a-b6d0-0a6da7a0f834,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-e680989f-073f-47bb-a276-efc106f5011e,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-85fe033a-555e-41f4-96cd-00f96ca15cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-a303acb9-7413-4e01-b8e3-34dded87f5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-6a3b8adb-128b-4eb9-8fb9-321f2b162289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907328961-172.17.0.8-1595526221854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37701,DS-f24ffcd7-d964-4eda-a724-2dec4074ae42,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-0f5ce2c8-8acc-4a0f-9b15-3d1919798ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-9ed2297a-ee54-40b1-8697-7c0c83553152,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-b1bc9c19-d9b6-4b8a-b6d0-0a6da7a0f834,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-e680989f-073f-47bb-a276-efc106f5011e,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-85fe033a-555e-41f4-96cd-00f96ca15cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-a303acb9-7413-4e01-b8e3-34dded87f5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-6a3b8adb-128b-4eb9-8fb9-321f2b162289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269241895-172.17.0.8-1595526325485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39094,DS-0a6abab2-4f51-487c-8e8f-7a04f7814522,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-15eb98f8-6ff5-4daa-b0cb-2795afe70b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-45d26a43-a374-4811-abef-b2d8ac52f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-ee613213-7c52-4701-b984-11e7887fc78b,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-9cecdd7f-c44d-4bfc-97b9-720ce169b8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-50c2d90c-0225-4aeb-b3d8-93880e03099e,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-416f44ea-f0f3-4537-a786-de31caa8542c,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-86cc2002-c8fc-436f-93a0-64166e412fc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269241895-172.17.0.8-1595526325485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39094,DS-0a6abab2-4f51-487c-8e8f-7a04f7814522,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-15eb98f8-6ff5-4daa-b0cb-2795afe70b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-45d26a43-a374-4811-abef-b2d8ac52f0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-ee613213-7c52-4701-b984-11e7887fc78b,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-9cecdd7f-c44d-4bfc-97b9-720ce169b8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-50c2d90c-0225-4aeb-b3d8-93880e03099e,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-416f44ea-f0f3-4537-a786-de31caa8542c,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-86cc2002-c8fc-436f-93a0-64166e412fc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710628113-172.17.0.8-1595526692510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40833,DS-95075e88-fe0b-495e-8e4b-228c4acba664,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-468e0a52-155c-408c-9563-fdbbf45af1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-fe274ac1-0100-4beb-a17a-7eeeb5a87190,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-6e9f7dd3-981c-47d4-b43f-996fc3b49508,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-bc3f2dd4-a83f-4f4e-9fc1-64f1d356699c,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-ff170979-aa2f-4123-a669-97bfc31b98ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-9402d3ff-c6d9-4e11-899e-f454c9c50ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-62854e3d-6ade-4e6a-8847-97a0539178a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710628113-172.17.0.8-1595526692510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40833,DS-95075e88-fe0b-495e-8e4b-228c4acba664,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-468e0a52-155c-408c-9563-fdbbf45af1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-fe274ac1-0100-4beb-a17a-7eeeb5a87190,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-6e9f7dd3-981c-47d4-b43f-996fc3b49508,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-bc3f2dd4-a83f-4f4e-9fc1-64f1d356699c,DISK], DatanodeInfoWithStorage[127.0.0.1:34233,DS-ff170979-aa2f-4123-a669-97bfc31b98ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-9402d3ff-c6d9-4e11-899e-f454c9c50ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-62854e3d-6ade-4e6a-8847-97a0539178a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976726071-172.17.0.8-1595527273004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38188,DS-0b1c33ae-f71f-43af-91a9-4a27ee522808,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-85b4c16d-e12c-4346-bd43-5ae072439152,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-1abeaf56-233a-49a5-9892-47d668184002,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-54ed1948-3815-4333-8d11-979a4225ac37,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-1597f712-06a2-4f1d-a9b1-7577ed0e6166,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-ac8fcfeb-dc0c-4496-9bac-f9002713bd44,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-46f44e68-2454-4123-b5ee-631cf7ca3ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-d5b9492b-caf2-4d45-99ef-9f39fb12af73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976726071-172.17.0.8-1595527273004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38188,DS-0b1c33ae-f71f-43af-91a9-4a27ee522808,DISK], DatanodeInfoWithStorage[127.0.0.1:45489,DS-85b4c16d-e12c-4346-bd43-5ae072439152,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-1abeaf56-233a-49a5-9892-47d668184002,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-54ed1948-3815-4333-8d11-979a4225ac37,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-1597f712-06a2-4f1d-a9b1-7577ed0e6166,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-ac8fcfeb-dc0c-4496-9bac-f9002713bd44,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-46f44e68-2454-4123-b5ee-631cf7ca3ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-d5b9492b-caf2-4d45-99ef-9f39fb12af73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889986952-172.17.0.8-1595527463767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33001,DS-b2cfc234-c40c-4b35-b842-e2c6a23b5c24,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-0733fb3c-2539-4d67-bc33-088c27343433,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-0b29f5ae-0331-4659-a787-26c04cd72681,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-d8cbb410-a220-429a-b83d-3150926c0d93,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-1d5de938-b320-4ad5-b0a8-79bd7d779e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-1ffd5ac2-90a4-45b9-b0fa-ee3a3ce3e751,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-9d55e00f-0a33-4d65-a6f1-9f4354352b22,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-170cdf18-e78b-43ab-bcc0-f0b00d0ee0cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889986952-172.17.0.8-1595527463767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33001,DS-b2cfc234-c40c-4b35-b842-e2c6a23b5c24,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-0733fb3c-2539-4d67-bc33-088c27343433,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-0b29f5ae-0331-4659-a787-26c04cd72681,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-d8cbb410-a220-429a-b83d-3150926c0d93,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-1d5de938-b320-4ad5-b0a8-79bd7d779e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-1ffd5ac2-90a4-45b9-b0fa-ee3a3ce3e751,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-9d55e00f-0a33-4d65-a6f1-9f4354352b22,DISK], DatanodeInfoWithStorage[127.0.0.1:40318,DS-170cdf18-e78b-43ab-bcc0-f0b00d0ee0cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707510509-172.17.0.8-1595528210779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33962,DS-a6bcf30f-5c9c-47c7-9fb5-efc6cb8c85d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-bfc4229c-46aa-463c-9c76-272834970d58,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-5c8c2314-aca2-4aa7-949c-fe4ae81493f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-f9e987f4-f19d-4a65-9c7d-223a728218fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-e8f27797-3748-4f40-8c98-d39e9e746ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-0ec7d393-6c19-4a41-806d-46d7b7026f89,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-c53dbe9b-d2ed-4203-ad79-0b52c1f70ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-0ac75073-d3ea-4db0-8730-8bb6935bdc50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707510509-172.17.0.8-1595528210779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33962,DS-a6bcf30f-5c9c-47c7-9fb5-efc6cb8c85d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-bfc4229c-46aa-463c-9c76-272834970d58,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-5c8c2314-aca2-4aa7-949c-fe4ae81493f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-f9e987f4-f19d-4a65-9c7d-223a728218fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-e8f27797-3748-4f40-8c98-d39e9e746ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-0ec7d393-6c19-4a41-806d-46d7b7026f89,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-c53dbe9b-d2ed-4203-ad79-0b52c1f70ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-0ac75073-d3ea-4db0-8730-8bb6935bdc50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1001577406-172.17.0.8-1595528428521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34353,DS-5b6d044c-e2ab-4dfc-bb08-c90d4eab4b58,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-7c24b464-4dc2-4ee7-af7e-1b8d38d7498b,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-34062796-3710-480c-9e94-dff811a7f3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-559ff21f-32fb-4db9-b484-ff92488ed0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-ade5f7fc-5d95-4b6a-8c7a-6e97ea45005c,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-886499a4-d049-42a6-8603-38980d83f606,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-d371201a-a8ee-4034-a2e4-d193941290d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-b33b5d4d-5b61-4d48-b090-dab0d0f60499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1001577406-172.17.0.8-1595528428521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34353,DS-5b6d044c-e2ab-4dfc-bb08-c90d4eab4b58,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-7c24b464-4dc2-4ee7-af7e-1b8d38d7498b,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-34062796-3710-480c-9e94-dff811a7f3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-559ff21f-32fb-4db9-b484-ff92488ed0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-ade5f7fc-5d95-4b6a-8c7a-6e97ea45005c,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-886499a4-d049-42a6-8603-38980d83f606,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-d371201a-a8ee-4034-a2e4-d193941290d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-b33b5d4d-5b61-4d48-b090-dab0d0f60499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-883612052-172.17.0.8-1595529022475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33145,DS-80a282e7-e560-430b-b085-4634ba3c2bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-90971132-314e-40e9-901a-572e1501478d,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-1d7f7a5b-5d36-4f9e-baf2-a6470cad3e44,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-1da2bb46-3ad6-49de-ae85-3e6c23dde3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-ee0143e4-f20b-4106-b981-5838dbb51e40,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-e035d2ec-e87c-415e-b4ba-32dde5643cee,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-5cd676ce-3578-4bf2-97ce-a4ed6e7b2283,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-852f2f3e-8462-4cca-a8fd-c0ec4d19a9f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-883612052-172.17.0.8-1595529022475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33145,DS-80a282e7-e560-430b-b085-4634ba3c2bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-90971132-314e-40e9-901a-572e1501478d,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-1d7f7a5b-5d36-4f9e-baf2-a6470cad3e44,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-1da2bb46-3ad6-49de-ae85-3e6c23dde3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-ee0143e4-f20b-4106-b981-5838dbb51e40,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-e035d2ec-e87c-415e-b4ba-32dde5643cee,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-5cd676ce-3578-4bf2-97ce-a4ed6e7b2283,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-852f2f3e-8462-4cca-a8fd-c0ec4d19a9f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408002980-172.17.0.8-1595529259437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44019,DS-1294e2f3-eba0-4bf3-866b-d58bed557b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-19c56f8c-6564-4929-99de-6df7ae8dacb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-197158a3-aade-4ba2-a804-2673eb29183f,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-fec75723-9dd8-4f6b-8f3d-afe1d10f0acc,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-0d421bd3-8856-481c-b245-68932c3aac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-b60dd90f-7a53-4a7c-881c-89a179d738f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-5e306bae-d2fa-4401-b393-83b07249e473,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-91c9f1c4-f37f-4889-9f15-bd38dcad6f2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408002980-172.17.0.8-1595529259437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44019,DS-1294e2f3-eba0-4bf3-866b-d58bed557b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-19c56f8c-6564-4929-99de-6df7ae8dacb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-197158a3-aade-4ba2-a804-2673eb29183f,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-fec75723-9dd8-4f6b-8f3d-afe1d10f0acc,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-0d421bd3-8856-481c-b245-68932c3aac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-b60dd90f-7a53-4a7c-881c-89a179d738f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-5e306bae-d2fa-4401-b393-83b07249e473,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-91c9f1c4-f37f-4889-9f15-bd38dcad6f2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210545315-172.17.0.8-1595529838460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46751,DS-6242ddee-3101-414f-bdfa-ff4d9bb87927,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-a0a18152-4c14-4bd8-9b6f-ef54bdaa511d,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-48c51ee2-1eb0-45f4-a528-ab0d44cd3490,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-ac510670-7cda-44fc-9046-596e6455e5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-43171c3a-09eb-4c24-a785-ae71561ef9be,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-ddcac1e7-70bb-4605-94f4-04f96adf35b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-1ba915dd-3c98-4920-ab01-e25bd0fdd272,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-d3f39062-e3f0-49ea-94bc-435f3f185eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210545315-172.17.0.8-1595529838460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46751,DS-6242ddee-3101-414f-bdfa-ff4d9bb87927,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-a0a18152-4c14-4bd8-9b6f-ef54bdaa511d,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-48c51ee2-1eb0-45f4-a528-ab0d44cd3490,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-ac510670-7cda-44fc-9046-596e6455e5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-43171c3a-09eb-4c24-a785-ae71561ef9be,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-ddcac1e7-70bb-4605-94f4-04f96adf35b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-1ba915dd-3c98-4920-ab01-e25bd0fdd272,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-d3f39062-e3f0-49ea-94bc-435f3f185eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92450859-172.17.0.8-1595529903198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40408,DS-0e05e835-c25e-4505-900c-a82af4808c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-6c5fcfe0-cec1-4def-9ab5-c184cba310e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-139cdd4f-de1b-43f1-9a97-11b03ef5c907,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-65ff15d4-759b-4921-8605-a0790f6735fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-fe6bb546-e9c7-45a5-863f-39b28e72c05a,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-1a6333b4-8815-436d-bf0d-d149e0b39f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-93a6b716-b0e6-471b-b56c-35f0daa6d520,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-880a40e9-5ae5-4cb4-918d-7cef452e5119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92450859-172.17.0.8-1595529903198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40408,DS-0e05e835-c25e-4505-900c-a82af4808c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-6c5fcfe0-cec1-4def-9ab5-c184cba310e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-139cdd4f-de1b-43f1-9a97-11b03ef5c907,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-65ff15d4-759b-4921-8605-a0790f6735fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-fe6bb546-e9c7-45a5-863f-39b28e72c05a,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-1a6333b4-8815-436d-bf0d-d149e0b39f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-93a6b716-b0e6-471b-b56c-35f0daa6d520,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-880a40e9-5ae5-4cb4-918d-7cef452e5119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.num.users
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721057585-172.17.0.8-1595530035759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46618,DS-8085f9de-f36b-43ea-a35f-4f1a6187d6be,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-58677295-93e3-4cb6-8504-e92b8aacee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-ddff6519-8f03-4062-8c76-0d9ef2150a19,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-bf89b7da-f85a-4317-b367-9b3f80493035,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-9f770d77-67d9-4b66-b8c9-369630d20612,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-09623711-b086-4684-9dd6-40acb2655be4,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-e869a32d-eb4a-441f-95f6-5e823777b36e,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-b236d85e-317f-4322-98a9-b456b6fb3255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721057585-172.17.0.8-1595530035759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46618,DS-8085f9de-f36b-43ea-a35f-4f1a6187d6be,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-58677295-93e3-4cb6-8504-e92b8aacee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-ddff6519-8f03-4062-8c76-0d9ef2150a19,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-bf89b7da-f85a-4317-b367-9b3f80493035,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-9f770d77-67d9-4b66-b8c9-369630d20612,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-09623711-b086-4684-9dd6-40acb2655be4,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-e869a32d-eb4a-441f-95f6-5e823777b36e,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-b236d85e-317f-4322-98a9-b456b6fb3255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5092
