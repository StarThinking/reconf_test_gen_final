reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608228499-172.17.0.5-1595895330750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38326,DS-5618799e-a281-4047-8c56-acf7805a295a,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-86faec2b-cd91-44bc-b443-6de5ba2b8de5,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-1a152f50-f1b0-47c9-be8a-9522da3a0011,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-052e7fd1-506d-4981-b319-3ad0bec34389,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-119a98ee-7853-48d7-8241-f365b52fbb49,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-fd8337a9-28df-4d63-98c1-afa564b9a606,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-76fa453a-d08c-4d4a-9bea-306fceb01ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-cfc8655e-6a7e-47c3-b84a-d230cba3a23f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608228499-172.17.0.5-1595895330750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38326,DS-5618799e-a281-4047-8c56-acf7805a295a,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-86faec2b-cd91-44bc-b443-6de5ba2b8de5,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-1a152f50-f1b0-47c9-be8a-9522da3a0011,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-052e7fd1-506d-4981-b319-3ad0bec34389,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-119a98ee-7853-48d7-8241-f365b52fbb49,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-fd8337a9-28df-4d63-98c1-afa564b9a606,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-76fa453a-d08c-4d4a-9bea-306fceb01ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-cfc8655e-6a7e-47c3-b84a-d230cba3a23f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23299166-172.17.0.5-1595895446270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-85d49607-09aa-4309-ae8e-1e0af5ea84a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-f2169ccc-c847-46aa-ae5b-8443c21e91be,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-f56b75e1-9df2-4390-a520-63f6f4b5e12c,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-dd87c8eb-3133-4416-8ba6-bd1755fdb12a,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-b011bfcc-7754-4584-8f75-165e10abe630,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-3924d51c-af5a-4157-855d-ee593ce4677a,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-0e923eb8-6ec2-4ba3-be2c-c3ee1be9d52c,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-6c81dd37-c0b1-48f2-9005-bdcced98a536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23299166-172.17.0.5-1595895446270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-85d49607-09aa-4309-ae8e-1e0af5ea84a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-f2169ccc-c847-46aa-ae5b-8443c21e91be,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-f56b75e1-9df2-4390-a520-63f6f4b5e12c,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-dd87c8eb-3133-4416-8ba6-bd1755fdb12a,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-b011bfcc-7754-4584-8f75-165e10abe630,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-3924d51c-af5a-4157-855d-ee593ce4677a,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-0e923eb8-6ec2-4ba3-be2c-c3ee1be9d52c,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-6c81dd37-c0b1-48f2-9005-bdcced98a536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97130173-172.17.0.5-1595895629215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45476,DS-024a4225-b721-4eb4-b27e-364f4d189b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-7d561f76-058e-442d-a8c3-ab97a22f957e,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-14676f62-d1a6-477f-97b9-426d50d42d36,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-6a1a1777-0312-4390-9bb6-c779a1b2cc59,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-796078fb-bb1f-48d2-970e-fcd22dd351fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-61906472-178e-470a-a6aa-6cdcb368d4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-e6d94cf2-2fbe-4a85-ac90-00cbad213fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-30613afe-d53a-44dc-af2f-f09cf5986add,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97130173-172.17.0.5-1595895629215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45476,DS-024a4225-b721-4eb4-b27e-364f4d189b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-7d561f76-058e-442d-a8c3-ab97a22f957e,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-14676f62-d1a6-477f-97b9-426d50d42d36,DISK], DatanodeInfoWithStorage[127.0.0.1:43194,DS-6a1a1777-0312-4390-9bb6-c779a1b2cc59,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-796078fb-bb1f-48d2-970e-fcd22dd351fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-61906472-178e-470a-a6aa-6cdcb368d4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-e6d94cf2-2fbe-4a85-ac90-00cbad213fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-30613afe-d53a-44dc-af2f-f09cf5986add,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889562581-172.17.0.5-1595896092328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37204,DS-0579c284-751d-4ac3-901b-8c762bda19e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-7b08eea3-79d7-4d95-9ed0-c1787d53d16a,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-be2fcef7-a9a9-49cd-8f5d-ec3f8b1117a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-96e7eaa6-bd80-41fb-9680-fec7e7d9ad26,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-8dcf5053-1d37-4dbf-83ba-205ecc3997cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-35b30b5d-ce89-4a5a-a375-581c92411c96,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-2ff67884-af49-4a14-b44d-c2d76ea30aae,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-b6d0e99e-9e55-41e8-9511-ffd0cd4a2c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889562581-172.17.0.5-1595896092328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37204,DS-0579c284-751d-4ac3-901b-8c762bda19e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-7b08eea3-79d7-4d95-9ed0-c1787d53d16a,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-be2fcef7-a9a9-49cd-8f5d-ec3f8b1117a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-96e7eaa6-bd80-41fb-9680-fec7e7d9ad26,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-8dcf5053-1d37-4dbf-83ba-205ecc3997cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-35b30b5d-ce89-4a5a-a375-581c92411c96,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-2ff67884-af49-4a14-b44d-c2d76ea30aae,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-b6d0e99e-9e55-41e8-9511-ffd0cd4a2c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718863510-172.17.0.5-1595896494407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33870,DS-c8a9f665-9c37-4ff5-aab8-8446085ccc63,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-7fabe509-bf7c-42fa-8979-5133253bdf16,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-08c9a391-70c4-4951-b073-f291381c6baf,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-68969756-260f-4740-9101-d458b1b81eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-1400da43-2127-4522-ae4d-be20dad0024a,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-1172089d-bb9d-431e-a16e-24c82972a07c,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-b0b45d7f-a5a1-4742-9795-f63841012315,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-5994588a-b415-46b9-956e-45234194b3ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718863510-172.17.0.5-1595896494407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33870,DS-c8a9f665-9c37-4ff5-aab8-8446085ccc63,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-7fabe509-bf7c-42fa-8979-5133253bdf16,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-08c9a391-70c4-4951-b073-f291381c6baf,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-68969756-260f-4740-9101-d458b1b81eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-1400da43-2127-4522-ae4d-be20dad0024a,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-1172089d-bb9d-431e-a16e-24c82972a07c,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-b0b45d7f-a5a1-4742-9795-f63841012315,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-5994588a-b415-46b9-956e-45234194b3ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249949976-172.17.0.5-1595897046800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39533,DS-a1343de6-13b4-4844-a86d-93ab301dc998,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-f627e6cb-0c2b-451d-914c-69147251a0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-abf5721e-ef59-4d43-86a5-6c5c024f5af0,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-9b09e3a9-6158-4714-b1ad-15e21cbbba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-d816738e-ec49-4496-a23e-a99b9c1a506a,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-c7454e22-5531-4be5-b6e7-a752c9740098,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-b3d8c297-b0be-4c09-9859-a2aeb9117edb,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-1dda6d94-03d1-41bf-8947-27c9440b8287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249949976-172.17.0.5-1595897046800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39533,DS-a1343de6-13b4-4844-a86d-93ab301dc998,DISK], DatanodeInfoWithStorage[127.0.0.1:32780,DS-f627e6cb-0c2b-451d-914c-69147251a0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-abf5721e-ef59-4d43-86a5-6c5c024f5af0,DISK], DatanodeInfoWithStorage[127.0.0.1:45188,DS-9b09e3a9-6158-4714-b1ad-15e21cbbba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-d816738e-ec49-4496-a23e-a99b9c1a506a,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-c7454e22-5531-4be5-b6e7-a752c9740098,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-b3d8c297-b0be-4c09-9859-a2aeb9117edb,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-1dda6d94-03d1-41bf-8947-27c9440b8287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067928143-172.17.0.5-1595897473776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35007,DS-21d55795-437f-4188-a548-ff34b722f91b,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-4c7fcb20-57c8-407c-abd6-5bcb574eedbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-ae6d0234-b7f9-43d0-b39c-2552d6524408,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-dc19dd9e-7cb1-4f6f-a745-f46f02f3e842,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-4f4cc9ef-d143-4fbf-be7e-c146eeba1baf,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-cfb12c59-80dd-4ea1-b398-8126901e270f,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-cd613af3-3c45-43e0-afd0-18c3700162d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-fc07107c-097a-40b2-add9-f48f8b5dd535,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067928143-172.17.0.5-1595897473776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35007,DS-21d55795-437f-4188-a548-ff34b722f91b,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-4c7fcb20-57c8-407c-abd6-5bcb574eedbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-ae6d0234-b7f9-43d0-b39c-2552d6524408,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-dc19dd9e-7cb1-4f6f-a745-f46f02f3e842,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-4f4cc9ef-d143-4fbf-be7e-c146eeba1baf,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-cfb12c59-80dd-4ea1-b398-8126901e270f,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-cd613af3-3c45-43e0-afd0-18c3700162d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-fc07107c-097a-40b2-add9-f48f8b5dd535,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296384342-172.17.0.5-1595897914876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32867,DS-5ead2b3f-b806-46d1-9255-d659fc581c28,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-c094cb27-c9b6-46c1-b772-131478447780,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-98e0bb74-27e5-43b0-9fce-4f36b88fac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-229c3e4d-05c8-465f-bfad-a0345068f185,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-63b653fc-47a7-48c1-8b23-582d33e2f2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-08503670-5205-4ae8-8645-12c7a8fbe523,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-5535cbcf-7707-46d9-9ae2-6182b78b2f75,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-9abde7df-503c-4d56-b90a-28264cd048b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296384342-172.17.0.5-1595897914876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32867,DS-5ead2b3f-b806-46d1-9255-d659fc581c28,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-c094cb27-c9b6-46c1-b772-131478447780,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-98e0bb74-27e5-43b0-9fce-4f36b88fac1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-229c3e4d-05c8-465f-bfad-a0345068f185,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-63b653fc-47a7-48c1-8b23-582d33e2f2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-08503670-5205-4ae8-8645-12c7a8fbe523,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-5535cbcf-7707-46d9-9ae2-6182b78b2f75,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-9abde7df-503c-4d56-b90a-28264cd048b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889996725-172.17.0.5-1595898022629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45728,DS-77f24cd8-7781-42c5-8d5d-a0c25358bf09,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-065122a8-80c4-4955-8b60-bbcfc5357b45,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-b476d34c-6a79-407d-b77f-14f2abed0c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-f56cda5e-8ca1-4ffa-942f-c6c69e1b70aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-a523f28c-82f1-4a35-a42a-347b94e3fdae,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-6fb482c0-008f-40ef-85d2-b8526d9a1fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-e130b0b8-d682-4736-b0dc-cc1d584f4bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-f87e8bb7-6ae5-4d13-848d-92befba002eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889996725-172.17.0.5-1595898022629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45728,DS-77f24cd8-7781-42c5-8d5d-a0c25358bf09,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-065122a8-80c4-4955-8b60-bbcfc5357b45,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-b476d34c-6a79-407d-b77f-14f2abed0c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-f56cda5e-8ca1-4ffa-942f-c6c69e1b70aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-a523f28c-82f1-4a35-a42a-347b94e3fdae,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-6fb482c0-008f-40ef-85d2-b8526d9a1fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-e130b0b8-d682-4736-b0dc-cc1d584f4bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-f87e8bb7-6ae5-4d13-848d-92befba002eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321453319-172.17.0.5-1595898162503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38195,DS-e4cf22e9-0370-437a-87ab-f178db55170b,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-925b13be-0953-490e-be0a-f7b2f40df78f,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-b2cfa00f-49af-4058-9439-c823b0345517,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-16db4141-8bc6-4f7f-95ec-e43d1e8cb469,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-83869843-a0b2-4535-870d-5ce15e884eae,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-b9aa1a7f-5df7-4c83-b68d-ffa6fcf84dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-a50f68a3-c1f6-4e0f-b0de-ab252c6eb17e,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-9862d04b-3dad-4a1e-bf7e-863d35619471,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321453319-172.17.0.5-1595898162503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38195,DS-e4cf22e9-0370-437a-87ab-f178db55170b,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-925b13be-0953-490e-be0a-f7b2f40df78f,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-b2cfa00f-49af-4058-9439-c823b0345517,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-16db4141-8bc6-4f7f-95ec-e43d1e8cb469,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-83869843-a0b2-4535-870d-5ce15e884eae,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-b9aa1a7f-5df7-4c83-b68d-ffa6fcf84dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-a50f68a3-c1f6-4e0f-b0de-ab252c6eb17e,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-9862d04b-3dad-4a1e-bf7e-863d35619471,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104016183-172.17.0.5-1595898259737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34541,DS-9422cd81-ffb4-49d7-96f3-1d7e427bcea2,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-5b85f9ab-132c-4945-b495-5c43992e7305,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-92c401fc-018d-4a45-a89a-6bf68e0af768,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-64688981-555f-4714-8999-2b3428694528,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-fc0d13dd-612c-4d4d-918b-9388ee609547,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-2ee828eb-c200-4e3b-9824-9cdbbbbb2238,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-dbd63843-233f-4514-b21d-4b3ee142802d,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-24c1e608-77dd-4218-a682-55ea5aba0c8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104016183-172.17.0.5-1595898259737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34541,DS-9422cd81-ffb4-49d7-96f3-1d7e427bcea2,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-5b85f9ab-132c-4945-b495-5c43992e7305,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-92c401fc-018d-4a45-a89a-6bf68e0af768,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-64688981-555f-4714-8999-2b3428694528,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-fc0d13dd-612c-4d4d-918b-9388ee609547,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-2ee828eb-c200-4e3b-9824-9cdbbbbb2238,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-dbd63843-233f-4514-b21d-4b3ee142802d,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-24c1e608-77dd-4218-a682-55ea5aba0c8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148368488-172.17.0.5-1595898375061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36350,DS-f1601b7a-be62-43b5-97d2-53e0948b7bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-40de298d-c3a4-46c4-8599-3191d459ce60,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-2f8dcdbb-1e77-4f2d-8959-93c054c5f2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-79534ee6-df6b-4a82-95a6-4817ade3c71c,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-223767ee-1c16-49db-86ac-4d293d04f0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-4449c588-5130-4bd0-88b6-514275171a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-c3d40253-ecc6-47e7-a860-876b0842377a,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-278ee49b-2e25-43f3-b016-25c539f1917b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148368488-172.17.0.5-1595898375061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36350,DS-f1601b7a-be62-43b5-97d2-53e0948b7bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-40de298d-c3a4-46c4-8599-3191d459ce60,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-2f8dcdbb-1e77-4f2d-8959-93c054c5f2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-79534ee6-df6b-4a82-95a6-4817ade3c71c,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-223767ee-1c16-49db-86ac-4d293d04f0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-4449c588-5130-4bd0-88b6-514275171a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-c3d40253-ecc6-47e7-a860-876b0842377a,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-278ee49b-2e25-43f3-b016-25c539f1917b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505516653-172.17.0.5-1595898832895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43067,DS-f4aea675-d279-4b77-ad8b-2ff2c3cc64dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-8db18d53-ceed-41a0-806c-ca3a09396aca,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-4c4b6d69-fb3c-4faf-82f8-a5e7fdc808d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-5dd875a1-24f3-4ce6-86f9-cf7559b8826e,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-c7133a5a-b180-445b-940b-f38ada37ad70,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-1ae05bc4-d622-4dba-a018-264937f7dbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-1aa064db-c60a-4317-9ab6-3f6022ac51ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-ad5e6641-2475-4f47-a69c-7c899ea6ef53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505516653-172.17.0.5-1595898832895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43067,DS-f4aea675-d279-4b77-ad8b-2ff2c3cc64dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-8db18d53-ceed-41a0-806c-ca3a09396aca,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-4c4b6d69-fb3c-4faf-82f8-a5e7fdc808d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-5dd875a1-24f3-4ce6-86f9-cf7559b8826e,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-c7133a5a-b180-445b-940b-f38ada37ad70,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-1ae05bc4-d622-4dba-a018-264937f7dbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-1aa064db-c60a-4317-9ab6-3f6022ac51ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-ad5e6641-2475-4f47-a69c-7c899ea6ef53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006694660-172.17.0.5-1595898950151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36780,DS-623234ed-e2a6-4ec5-a56b-c076dd1d5161,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-19279197-8886-442e-a7bb-ac32945d3dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-a682eaa3-af9f-4dd0-8ca4-d54cce36e885,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-ff2f89b0-ff8b-4dc2-ad94-bc137982168d,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-1b435075-ea79-4cdf-8c8b-c3418d48278d,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-a2e6e0d9-51bd-4bed-8bd5-93665021a352,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-a945aa08-4859-4864-b223-431206e13bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-0c566b4b-5178-4753-8bcb-882feb30aca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006694660-172.17.0.5-1595898950151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36780,DS-623234ed-e2a6-4ec5-a56b-c076dd1d5161,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-19279197-8886-442e-a7bb-ac32945d3dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-a682eaa3-af9f-4dd0-8ca4-d54cce36e885,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-ff2f89b0-ff8b-4dc2-ad94-bc137982168d,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-1b435075-ea79-4cdf-8c8b-c3418d48278d,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-a2e6e0d9-51bd-4bed-8bd5-93665021a352,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-a945aa08-4859-4864-b223-431206e13bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-0c566b4b-5178-4753-8bcb-882feb30aca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021198898-172.17.0.5-1595899550388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43958,DS-6a9ed441-c6f2-4500-b787-ea48ab502a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-38d71a99-f79b-4274-b16f-939585375055,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-b3287c95-c32d-40d6-8369-816ff32365b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-9999f635-c5c5-4827-85fc-e40fb39ec226,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-8552e588-58e1-489f-9d72-bcd6777c2277,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-61fce846-6a82-453e-9eb3-5f62e14a9320,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-8b6718fe-8cac-4da8-a348-7751f4361650,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-bbde3469-ba91-4db2-a5a4-120a6bdc8732,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021198898-172.17.0.5-1595899550388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43958,DS-6a9ed441-c6f2-4500-b787-ea48ab502a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-38d71a99-f79b-4274-b16f-939585375055,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-b3287c95-c32d-40d6-8369-816ff32365b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-9999f635-c5c5-4827-85fc-e40fb39ec226,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-8552e588-58e1-489f-9d72-bcd6777c2277,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-61fce846-6a82-453e-9eb3-5f62e14a9320,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-8b6718fe-8cac-4da8-a348-7751f4361650,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-bbde3469-ba91-4db2-a5a4-120a6bdc8732,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349260715-172.17.0.5-1595899731384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38786,DS-ba923692-7124-4c61-adfb-17d3914d06ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-d45a8855-3fa9-40e5-afac-4b0142301938,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-fe5ce983-739e-4ad5-b0b0-f17da1ba8f13,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-52778127-baa8-4f6c-99cc-868f1cf3ea45,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-fb77dcc5-3f54-4204-88b9-c0d2c586199a,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-efbebd6f-9bdf-4404-b888-56ccea5ced0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-bd8317f2-2932-47db-96fe-cfde9bcbb3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-a08191fd-e9e9-4f0d-8606-56c79070779b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349260715-172.17.0.5-1595899731384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38786,DS-ba923692-7124-4c61-adfb-17d3914d06ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-d45a8855-3fa9-40e5-afac-4b0142301938,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-fe5ce983-739e-4ad5-b0b0-f17da1ba8f13,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-52778127-baa8-4f6c-99cc-868f1cf3ea45,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-fb77dcc5-3f54-4204-88b9-c0d2c586199a,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-efbebd6f-9bdf-4404-b888-56ccea5ced0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-bd8317f2-2932-47db-96fe-cfde9bcbb3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-a08191fd-e9e9-4f0d-8606-56c79070779b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.replication.max
component: hdfs:NameNode
v1: 8
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131098455-172.17.0.5-1595900084999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35644,DS-1e16fb53-46b7-4d1f-bf79-3c43026d40b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-3892d884-32cb-4747-8637-972cb0d28cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-e57d6c73-abe5-4591-8ed1-5835129a77bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-3c5dfc52-10eb-4e31-95e4-99fedbb67a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-470309c6-c4ad-476b-9799-3f1bae5b41e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-9cb56a8e-f1b7-46ea-8a6b-b724d0949095,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-84a2ec8f-9d44-4c8d-a6e9-8424d3f123f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-f6d91131-ece2-4d51-bd36-b77c7e7d3062,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131098455-172.17.0.5-1595900084999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35644,DS-1e16fb53-46b7-4d1f-bf79-3c43026d40b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-3892d884-32cb-4747-8637-972cb0d28cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-e57d6c73-abe5-4591-8ed1-5835129a77bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-3c5dfc52-10eb-4e31-95e4-99fedbb67a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-470309c6-c4ad-476b-9799-3f1bae5b41e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-9cb56a8e-f1b7-46ea-8a6b-b724d0949095,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-84a2ec8f-9d44-4c8d-a6e9-8424d3f123f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-f6d91131-ece2-4d51-bd36-b77c7e7d3062,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5432
