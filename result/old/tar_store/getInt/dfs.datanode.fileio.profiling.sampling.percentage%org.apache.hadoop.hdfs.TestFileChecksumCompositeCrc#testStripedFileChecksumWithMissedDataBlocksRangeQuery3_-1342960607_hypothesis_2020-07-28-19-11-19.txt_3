reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108658125-172.17.0.17-1595963539833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41973,DS-1327730e-9103-4000-8d08-fa37d9e0d01e,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-90a87630-2263-4aa1-9759-e5d33ac1077e,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-fd9bf229-5ce8-4841-abf6-b5c263a886c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-c5573aad-4882-4927-8fe9-aa9b7ebfdeca,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-e6a4d748-fba7-4ad0-ae87-18c4ea38162f,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-8824f270-55a1-40e6-9197-bce9d7b5483c,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-ca7c0d6b-9d48-4232-957e-3ee591aaabce,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-88a0acfb-f01c-4340-a890-63bcef0f0cc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108658125-172.17.0.17-1595963539833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41973,DS-1327730e-9103-4000-8d08-fa37d9e0d01e,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-90a87630-2263-4aa1-9759-e5d33ac1077e,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-fd9bf229-5ce8-4841-abf6-b5c263a886c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-c5573aad-4882-4927-8fe9-aa9b7ebfdeca,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-e6a4d748-fba7-4ad0-ae87-18c4ea38162f,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-8824f270-55a1-40e6-9197-bce9d7b5483c,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-ca7c0d6b-9d48-4232-957e-3ee591aaabce,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-88a0acfb-f01c-4340-a890-63bcef0f0cc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107859560-172.17.0.17-1595965583281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43165,DS-53a51f3d-7011-4e70-8bab-367ce75d2c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-caec5bed-61d1-4708-ba2a-95fd1042ab2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-71b9a9e7-6aeb-4947-b33b-c80516f88e27,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-eeccd7b8-3043-4ab7-8a88-4db30e71903d,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-c0f559f0-c80d-43fc-a6a4-dcd05f9644bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-bc6529d0-9c31-498f-b286-458bad150322,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-2dc188d2-1b10-4ebc-8971-879eeb694cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-32ae1e47-95c2-43a5-b486-ce28601f56a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107859560-172.17.0.17-1595965583281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43165,DS-53a51f3d-7011-4e70-8bab-367ce75d2c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-caec5bed-61d1-4708-ba2a-95fd1042ab2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-71b9a9e7-6aeb-4947-b33b-c80516f88e27,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-eeccd7b8-3043-4ab7-8a88-4db30e71903d,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-c0f559f0-c80d-43fc-a6a4-dcd05f9644bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-bc6529d0-9c31-498f-b286-458bad150322,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-2dc188d2-1b10-4ebc-8971-879eeb694cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-32ae1e47-95c2-43a5-b486-ce28601f56a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-652465267-172.17.0.17-1595965848780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-56724a99-8ebc-49cd-a5c1-12361b9cfb33,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-cb584b30-a219-4125-80e9-35a7be9d7104,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-3aa0f4ca-2ba9-4216-82e2-b0240297c428,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-8834b68d-57f8-44c6-b9ef-71590e34dfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-3af0f119-aac3-4bd3-91a2-a9c1779e6407,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-7243883e-3897-463a-b257-9cc9724f7859,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-f07b454d-0508-474f-bc70-b10c3d78ee71,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-46f0b2f1-24a3-49bc-b93e-47d3a74d529c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-652465267-172.17.0.17-1595965848780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-56724a99-8ebc-49cd-a5c1-12361b9cfb33,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-cb584b30-a219-4125-80e9-35a7be9d7104,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-3aa0f4ca-2ba9-4216-82e2-b0240297c428,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-8834b68d-57f8-44c6-b9ef-71590e34dfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-3af0f119-aac3-4bd3-91a2-a9c1779e6407,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-7243883e-3897-463a-b257-9cc9724f7859,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-f07b454d-0508-474f-bc70-b10c3d78ee71,DISK], DatanodeInfoWithStorage[127.0.0.1:46448,DS-46f0b2f1-24a3-49bc-b93e-47d3a74d529c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659296654-172.17.0.17-1595965974820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41765,DS-f9e40fc4-229d-4190-81db-0a3d9076bc60,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-af00d0a2-18bb-4465-ad7b-985942ddac6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-5b133715-27b1-4cc5-a68a-2a94ddd4c608,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-6cff7d47-af14-4945-a9c6-b98eea315adb,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-eab07053-733b-458d-aa87-b1a2301c239d,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-f81605d6-5ae2-4920-ba0f-87b1e13b38be,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-8fff1a16-288a-4679-8880-cf67227dde9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-752df570-0bf8-40fe-b3a5-083d4f5f8fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659296654-172.17.0.17-1595965974820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41765,DS-f9e40fc4-229d-4190-81db-0a3d9076bc60,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-af00d0a2-18bb-4465-ad7b-985942ddac6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-5b133715-27b1-4cc5-a68a-2a94ddd4c608,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-6cff7d47-af14-4945-a9c6-b98eea315adb,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-eab07053-733b-458d-aa87-b1a2301c239d,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-f81605d6-5ae2-4920-ba0f-87b1e13b38be,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-8fff1a16-288a-4679-8880-cf67227dde9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-752df570-0bf8-40fe-b3a5-083d4f5f8fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266312410-172.17.0.17-1595966900173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38193,DS-43ae7df8-e411-4389-9561-395a090a5a94,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-af94f6dd-5aea-4039-aeff-9c69d564dce0,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-f4356b32-cf6f-439d-a2d2-013c2befa4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-77fef918-2e4c-4e2a-ab1c-1fa4a6c15e06,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-a8d3234b-9278-42a5-ad84-774cd2830106,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-8081decf-8a7d-41e5-bbab-a062f6ab5be8,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-2c5aac9c-655c-4eae-a185-1f656fde88a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-975f4321-3b13-43f9-9439-d713c40d6ab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1266312410-172.17.0.17-1595966900173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38193,DS-43ae7df8-e411-4389-9561-395a090a5a94,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-af94f6dd-5aea-4039-aeff-9c69d564dce0,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-f4356b32-cf6f-439d-a2d2-013c2befa4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-77fef918-2e4c-4e2a-ab1c-1fa4a6c15e06,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-a8d3234b-9278-42a5-ad84-774cd2830106,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-8081decf-8a7d-41e5-bbab-a062f6ab5be8,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-2c5aac9c-655c-4eae-a185-1f656fde88a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33950,DS-975f4321-3b13-43f9-9439-d713c40d6ab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962202662-172.17.0.17-1595967074633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-a344b220-d3f0-48f8-b5ce-2e6a7fe6b617,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-8cc3b376-720a-46c5-9112-4e81bb4270a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-015f0787-7acf-44a3-9acf-75397d7c54ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-5062005a-4651-4124-b8e5-325924aa3f85,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-46a43543-85d5-47f8-826b-f6ab2118ea5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-10bcadf0-4552-459b-a0d7-de5e1e0994b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-265534fa-8989-4fa5-a544-4bced4bcddeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-a4238ba0-c6bd-405b-9593-cc342049a021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962202662-172.17.0.17-1595967074633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-a344b220-d3f0-48f8-b5ce-2e6a7fe6b617,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-8cc3b376-720a-46c5-9112-4e81bb4270a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-015f0787-7acf-44a3-9acf-75397d7c54ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-5062005a-4651-4124-b8e5-325924aa3f85,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-46a43543-85d5-47f8-826b-f6ab2118ea5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-10bcadf0-4552-459b-a0d7-de5e1e0994b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-265534fa-8989-4fa5-a544-4bced4bcddeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-a4238ba0-c6bd-405b-9593-cc342049a021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900082245-172.17.0.17-1595967353051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39912,DS-65a2a8d4-9413-415e-835f-c17f4682e757,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-014e703d-d198-4a6c-b19b-d318b25860e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-5153076f-cc7a-4162-a6a4-749926be12f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-f4ab52dd-6432-4771-8cb5-afeed03f7694,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-0c65d5db-4acd-4049-914a-475609bf5cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-88eef460-0865-4a0c-b0ac-50a55d74a871,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-f056f36a-874a-4361-849b-a4ee083101d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-8e3242c7-c0b4-4dd3-92c4-e22ff2785dba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900082245-172.17.0.17-1595967353051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39912,DS-65a2a8d4-9413-415e-835f-c17f4682e757,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-014e703d-d198-4a6c-b19b-d318b25860e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-5153076f-cc7a-4162-a6a4-749926be12f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-f4ab52dd-6432-4771-8cb5-afeed03f7694,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-0c65d5db-4acd-4049-914a-475609bf5cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-88eef460-0865-4a0c-b0ac-50a55d74a871,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-f056f36a-874a-4361-849b-a4ee083101d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-8e3242c7-c0b4-4dd3-92c4-e22ff2785dba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558898785-172.17.0.17-1595968680065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45713,DS-76c0bde4-d4c2-471c-82cd-627118bbae59,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-8195f014-a62f-4791-be2d-ab6ed6457934,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-0488aa59-ab40-4d75-89a0-633dab7edd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-55df6a24-6e52-4a8f-ae30-81b670ffa0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-b08640fa-7716-4cf4-87bb-80b596d493fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-d386806f-71a0-47b5-9069-c1cb33a0f259,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-df76f4f5-62e8-4df2-955c-c77c1a906dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-342bbd0f-d0bb-4665-b172-a6cdc3647f37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558898785-172.17.0.17-1595968680065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45713,DS-76c0bde4-d4c2-471c-82cd-627118bbae59,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-8195f014-a62f-4791-be2d-ab6ed6457934,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-0488aa59-ab40-4d75-89a0-633dab7edd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-55df6a24-6e52-4a8f-ae30-81b670ffa0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-b08640fa-7716-4cf4-87bb-80b596d493fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-d386806f-71a0-47b5-9069-c1cb33a0f259,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-df76f4f5-62e8-4df2-955c-c77c1a906dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-342bbd0f-d0bb-4665-b172-a6cdc3647f37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1411928770-172.17.0.17-1595968725164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33553,DS-3b5a7b5f-a6c5-4855-b76e-d7551ddab2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-c570745a-bac3-43c5-8ebd-6af1aec6468a,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-ba852a85-aee1-4519-8bdc-010a5a976b33,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-88a7a517-f8a0-4ce1-a5bd-1f0b8257898e,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-fc7b4afe-a734-4413-8136-72915acb6c82,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-02e3a414-8000-40ee-9126-7402d2db9bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-66cfa708-3aa3-425a-8c56-e760facbee52,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-59970e20-3dc6-48ba-9424-f4a0c436cd81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1411928770-172.17.0.17-1595968725164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33553,DS-3b5a7b5f-a6c5-4855-b76e-d7551ddab2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-c570745a-bac3-43c5-8ebd-6af1aec6468a,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-ba852a85-aee1-4519-8bdc-010a5a976b33,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-88a7a517-f8a0-4ce1-a5bd-1f0b8257898e,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-fc7b4afe-a734-4413-8136-72915acb6c82,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-02e3a414-8000-40ee-9126-7402d2db9bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-66cfa708-3aa3-425a-8c56-e760facbee52,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-59970e20-3dc6-48ba-9424-f4a0c436cd81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398720855-172.17.0.17-1595970013788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35381,DS-9f8d2063-12c8-452a-b8dd-40ac827433e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-0d036c60-27cc-469e-8116-aa0aabf010d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-85c1178d-18e4-4dd1-9138-b01772bb17cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-10f20c0f-8651-4abe-a23f-a53f6bf42cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-b7f1c61b-a678-4974-bab6-79275d6839cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-4af02502-6644-4213-a3f3-654de0973c72,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-1ed58374-d2a2-4670-8aee-8a807bc983af,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-ba347100-a962-435d-99a6-02e9632ff609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398720855-172.17.0.17-1595970013788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35381,DS-9f8d2063-12c8-452a-b8dd-40ac827433e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-0d036c60-27cc-469e-8116-aa0aabf010d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-85c1178d-18e4-4dd1-9138-b01772bb17cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-10f20c0f-8651-4abe-a23f-a53f6bf42cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-b7f1c61b-a678-4974-bab6-79275d6839cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-4af02502-6644-4213-a3f3-654de0973c72,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-1ed58374-d2a2-4670-8aee-8a807bc983af,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-ba347100-a962-435d-99a6-02e9632ff609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6655
