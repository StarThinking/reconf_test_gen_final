reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224426376-172.17.0.3-1595613513075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44138,DS-ecfe3722-19fe-4ba6-8120-93dc1e35d412,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-4bdfce53-2e02-4dd3-b44e-719c03851b96,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-0a941b1e-c39d-4f08-9477-50f2b6609170,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-e2e5a692-0777-4f4e-9f1c-f6061ba1c3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-7db69da6-58f0-46f7-90bc-91d6578637aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-1ffb92d3-967e-44f6-bcee-4c29186f3156,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-8cbe6984-bf1d-4466-ae82-aa102d0d9b62,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-75636f3b-d71a-4b5b-8711-0bb15037c32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224426376-172.17.0.3-1595613513075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44138,DS-ecfe3722-19fe-4ba6-8120-93dc1e35d412,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-4bdfce53-2e02-4dd3-b44e-719c03851b96,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-0a941b1e-c39d-4f08-9477-50f2b6609170,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-e2e5a692-0777-4f4e-9f1c-f6061ba1c3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-7db69da6-58f0-46f7-90bc-91d6578637aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-1ffb92d3-967e-44f6-bcee-4c29186f3156,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-8cbe6984-bf1d-4466-ae82-aa102d0d9b62,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-75636f3b-d71a-4b5b-8711-0bb15037c32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530090945-172.17.0.3-1595613577470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34214,DS-2d31d8ae-58f1-4e26-aea1-e31f4a6e3f87,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-d52bbd91-ac5a-4874-af51-48b61569ab63,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-599f398c-cdc4-4476-a85f-1e1867f6ebd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-314b77cb-0456-464c-9397-12a488c2a230,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-2445d252-171e-4e94-b43a-07b5e82d882b,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-ec2adc84-cc66-4620-a6ca-f4451a093a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-743a3822-0960-4934-a485-e71b78adc635,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-ee047445-5174-4da1-ba66-c43d05a2a900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530090945-172.17.0.3-1595613577470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34214,DS-2d31d8ae-58f1-4e26-aea1-e31f4a6e3f87,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-d52bbd91-ac5a-4874-af51-48b61569ab63,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-599f398c-cdc4-4476-a85f-1e1867f6ebd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-314b77cb-0456-464c-9397-12a488c2a230,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-2445d252-171e-4e94-b43a-07b5e82d882b,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-ec2adc84-cc66-4620-a6ca-f4451a093a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-743a3822-0960-4934-a485-e71b78adc635,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-ee047445-5174-4da1-ba66-c43d05a2a900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282887558-172.17.0.3-1595614491974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34784,DS-4bc4cc24-52be-477b-9369-23034313168f,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-ddd60bce-3e86-4200-a48e-00dc7a3eed3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-d8f595c0-89ee-4ddb-8538-c63035ce49ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-4305ceae-a25d-4bb9-acc2-fe76ed66b50f,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-f134c4ee-c659-4616-8b65-52c32312fae3,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-7f8e8c7c-25c3-4e66-a8cd-b7d12b3dbed3,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-2a4d83d6-3303-4be3-9e34-52531ac82104,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-6fca915c-ea74-49ff-944b-509c73c89a11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282887558-172.17.0.3-1595614491974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34784,DS-4bc4cc24-52be-477b-9369-23034313168f,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-ddd60bce-3e86-4200-a48e-00dc7a3eed3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-d8f595c0-89ee-4ddb-8538-c63035ce49ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-4305ceae-a25d-4bb9-acc2-fe76ed66b50f,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-f134c4ee-c659-4616-8b65-52c32312fae3,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-7f8e8c7c-25c3-4e66-a8cd-b7d12b3dbed3,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-2a4d83d6-3303-4be3-9e34-52531ac82104,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-6fca915c-ea74-49ff-944b-509c73c89a11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617579683-172.17.0.3-1595614725659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41553,DS-893ac14c-9333-4277-8438-363d3a2e50f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-b342e3f3-8d18-450a-b699-9761a79e0177,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-aa8f13db-1919-48c6-993e-c6d18ca31c71,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-80e79c45-a2bb-46c5-b790-a8ef1acc15a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-fe38e386-9c4f-412f-84b4-fce50d8153a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-7a174a0e-7edc-424b-8d04-23506d55c149,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-b00a1307-1929-4751-9e3a-68bd4e4335f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-4c7a49df-0fd4-48d9-beb6-b5b622dabc48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617579683-172.17.0.3-1595614725659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41553,DS-893ac14c-9333-4277-8438-363d3a2e50f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-b342e3f3-8d18-450a-b699-9761a79e0177,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-aa8f13db-1919-48c6-993e-c6d18ca31c71,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-80e79c45-a2bb-46c5-b790-a8ef1acc15a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-fe38e386-9c4f-412f-84b4-fce50d8153a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-7a174a0e-7edc-424b-8d04-23506d55c149,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-b00a1307-1929-4751-9e3a-68bd4e4335f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-4c7a49df-0fd4-48d9-beb6-b5b622dabc48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425286468-172.17.0.3-1595614934055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34125,DS-5bcaa3b8-7222-4535-b579-3d69a29ae8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-98a70b27-cee5-4e97-9321-99f9d72f903b,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-a8eab764-169d-4be7-ac21-13c6efba2254,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-c757c76c-880d-47ed-a1ee-3984325787e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-440aa5bf-4c0f-4697-a7b1-d2f26e01cb92,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-1e9ffdfc-04e4-4dff-a2ac-e277df679fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-9812b879-f125-44be-8a28-b06ba7f4cf63,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-5ab7ba3a-5b8d-4182-b23b-fb7a5c67df6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425286468-172.17.0.3-1595614934055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34125,DS-5bcaa3b8-7222-4535-b579-3d69a29ae8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-98a70b27-cee5-4e97-9321-99f9d72f903b,DISK], DatanodeInfoWithStorage[127.0.0.1:44373,DS-a8eab764-169d-4be7-ac21-13c6efba2254,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-c757c76c-880d-47ed-a1ee-3984325787e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-440aa5bf-4c0f-4697-a7b1-d2f26e01cb92,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-1e9ffdfc-04e4-4dff-a2ac-e277df679fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-9812b879-f125-44be-8a28-b06ba7f4cf63,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-5ab7ba3a-5b8d-4182-b23b-fb7a5c67df6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774982105-172.17.0.3-1595614963240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37240,DS-4c490ef8-5134-4d72-8e2e-86ff3214af0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-42c81193-d830-455d-a729-b9bad1fc9eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-08c1b57e-3216-46cc-8556-4d097edfcb94,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-82af4e81-60cf-4428-b635-44293d9eb7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-60c0f08e-3193-4271-bd28-36f3b36e6623,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-4d484dfc-b298-482a-9ed6-564de40336b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-3b0cb278-8b91-4cf0-93d6-9b202a0cf54f,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-5aaa505b-6717-432e-898e-5dff4326626c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774982105-172.17.0.3-1595614963240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37240,DS-4c490ef8-5134-4d72-8e2e-86ff3214af0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-42c81193-d830-455d-a729-b9bad1fc9eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-08c1b57e-3216-46cc-8556-4d097edfcb94,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-82af4e81-60cf-4428-b635-44293d9eb7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-60c0f08e-3193-4271-bd28-36f3b36e6623,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-4d484dfc-b298-482a-9ed6-564de40336b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-3b0cb278-8b91-4cf0-93d6-9b202a0cf54f,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-5aaa505b-6717-432e-898e-5dff4326626c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-280945339-172.17.0.3-1595615698431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42292,DS-074ddc68-f7cf-4c57-9251-2ed85218c3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-af976d17-f54b-4fb1-b8ac-09c3555ff684,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-7b8be6e8-bd08-4570-9d93-051e11c49e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-34193329-2354-4aa4-a06c-37a6ce95e4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-914228e6-9163-45cf-906c-0df84a42f7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-149ad91a-d329-428c-b40f-8168fa453b88,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-4ea87517-f237-40aa-a171-245d8616769e,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-dab54141-3c5e-4e31-8650-b21d16ce6d56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-280945339-172.17.0.3-1595615698431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42292,DS-074ddc68-f7cf-4c57-9251-2ed85218c3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-af976d17-f54b-4fb1-b8ac-09c3555ff684,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-7b8be6e8-bd08-4570-9d93-051e11c49e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-34193329-2354-4aa4-a06c-37a6ce95e4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-914228e6-9163-45cf-906c-0df84a42f7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-149ad91a-d329-428c-b40f-8168fa453b88,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-4ea87517-f237-40aa-a171-245d8616769e,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-dab54141-3c5e-4e31-8650-b21d16ce6d56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982817064-172.17.0.3-1595615872542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45780,DS-407fc3c8-d0c4-4480-9df3-d9337b5ed3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-a75337c2-33c0-48f9-9a90-4649c025e142,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-a4dd1b5d-b680-49de-bd46-ffb2c7eae95c,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-04e09287-c36c-4f64-a4d6-08649bf981d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-4105826e-28ba-447b-8de6-6f2bc2fc22ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-d69ef7bb-bc8f-40bc-8456-a5a4440bfeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-41a76d1c-b1de-4665-bad2-4df90b31bf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-9c23a26a-003a-464d-bf48-788c6fc99565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982817064-172.17.0.3-1595615872542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45780,DS-407fc3c8-d0c4-4480-9df3-d9337b5ed3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-a75337c2-33c0-48f9-9a90-4649c025e142,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-a4dd1b5d-b680-49de-bd46-ffb2c7eae95c,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-04e09287-c36c-4f64-a4d6-08649bf981d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-4105826e-28ba-447b-8de6-6f2bc2fc22ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-d69ef7bb-bc8f-40bc-8456-a5a4440bfeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-41a76d1c-b1de-4665-bad2-4df90b31bf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-9c23a26a-003a-464d-bf48-788c6fc99565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696207556-172.17.0.3-1595616220249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40257,DS-075e3d21-8203-462f-9a7d-e34e8779655f,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-12b1f648-d708-49b1-ba72-16358b71efd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-1a88fbb6-8eb7-4dd8-b47c-609eefae5699,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-ad047588-6bf3-48d2-bea0-be3a3f9927c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-2ed4f80d-f817-437e-9c65-bb0d97a22df1,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-769f2c27-a008-4f01-b0dd-950fd95a234a,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-7e1d304a-8bf8-46a2-af8f-5302d0508cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-80f74f21-637f-4cdd-8f86-7a143ad37161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696207556-172.17.0.3-1595616220249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40257,DS-075e3d21-8203-462f-9a7d-e34e8779655f,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-12b1f648-d708-49b1-ba72-16358b71efd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-1a88fbb6-8eb7-4dd8-b47c-609eefae5699,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-ad047588-6bf3-48d2-bea0-be3a3f9927c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-2ed4f80d-f817-437e-9c65-bb0d97a22df1,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-769f2c27-a008-4f01-b0dd-950fd95a234a,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-7e1d304a-8bf8-46a2-af8f-5302d0508cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-80f74f21-637f-4cdd-8f86-7a143ad37161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564239563-172.17.0.3-1595617448964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40647,DS-1d7f9025-9f22-4fba-b089-1d31923e35a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-e6c0b827-487e-4b01-9a48-e0ca2803503d,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-8b77d8b9-32b3-4f8a-9f6b-35b2f2e57907,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-146a4393-bb17-4f55-9cee-2bd3161ab984,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-59781a8d-d0b8-4c49-83d2-df566a22ce24,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-5373566c-f454-4615-b287-060cef074b00,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-843de598-e812-41cd-80d9-fc480a5fee28,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-78046310-b3f1-4051-83b7-a5b3d2390ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564239563-172.17.0.3-1595617448964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40647,DS-1d7f9025-9f22-4fba-b089-1d31923e35a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-e6c0b827-487e-4b01-9a48-e0ca2803503d,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-8b77d8b9-32b3-4f8a-9f6b-35b2f2e57907,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-146a4393-bb17-4f55-9cee-2bd3161ab984,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-59781a8d-d0b8-4c49-83d2-df566a22ce24,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-5373566c-f454-4615-b287-060cef074b00,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-843de598-e812-41cd-80d9-fc480a5fee28,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-78046310-b3f1-4051-83b7-a5b3d2390ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473319255-172.17.0.3-1595617552833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35606,DS-da75acf2-29a9-4b2d-8555-716878fa88cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-1a1d3b27-4907-481c-8ff8-4dc2de76c099,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-168bf1af-c1a0-4117-99e2-0f4dcaaab5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-5999de7f-06d3-487d-8304-e320902c86fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-fdf5d12d-ba58-45e7-a89a-16197784f0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-b0cea0a8-dc09-4067-a74b-059e70c1e646,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-13c827a5-df61-41f2-85f6-3352e9463a86,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-f2b975b2-ecf9-4812-a4a6-811022097a4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473319255-172.17.0.3-1595617552833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35606,DS-da75acf2-29a9-4b2d-8555-716878fa88cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-1a1d3b27-4907-481c-8ff8-4dc2de76c099,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-168bf1af-c1a0-4117-99e2-0f4dcaaab5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-5999de7f-06d3-487d-8304-e320902c86fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-fdf5d12d-ba58-45e7-a89a-16197784f0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-b0cea0a8-dc09-4067-a74b-059e70c1e646,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-13c827a5-df61-41f2-85f6-3352e9463a86,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-f2b975b2-ecf9-4812-a4a6-811022097a4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556518402-172.17.0.3-1595617660772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-2450abfe-f5c6-49eb-af50-7562a4eb336c,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-2d458932-3695-4ff3-a7b3-42116984a19f,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-f3845722-927d-4244-89ae-7f3e32e28923,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-19daa2ad-808c-4956-b00b-f78302b5bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-ea3c3397-0650-4243-98df-f83d78ea5cab,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-e800c45a-8dea-4625-8105-be7bdf734da1,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-27548ed3-7cae-46f5-968f-b86828d4c37b,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-1ae056bf-37df-41ac-a751-27457cd3692f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556518402-172.17.0.3-1595617660772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35491,DS-2450abfe-f5c6-49eb-af50-7562a4eb336c,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-2d458932-3695-4ff3-a7b3-42116984a19f,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-f3845722-927d-4244-89ae-7f3e32e28923,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-19daa2ad-808c-4956-b00b-f78302b5bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-ea3c3397-0650-4243-98df-f83d78ea5cab,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-e800c45a-8dea-4625-8105-be7bdf734da1,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-27548ed3-7cae-46f5-968f-b86828d4c37b,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-1ae056bf-37df-41ac-a751-27457cd3692f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 4995
