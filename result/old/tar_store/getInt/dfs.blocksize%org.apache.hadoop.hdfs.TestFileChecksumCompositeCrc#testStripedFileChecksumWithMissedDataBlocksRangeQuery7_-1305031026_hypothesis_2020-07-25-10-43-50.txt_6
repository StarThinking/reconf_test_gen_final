reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318616119-172.17.0.12-1595673842144:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-ce622158-5a42-4eeb-8195-fe0380df3a00,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-10f4ecbd-6c08-4eee-a01c-79989e4d3c52,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-be4ffd7c-3f8a-49ea-bb73-8289d0fff0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-3d2bec6b-baab-4930-b454-44959afd9995,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-c2743af8-82de-4285-805f-211a121a37d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-6ef28d24-fccd-451d-9dde-697e200db262,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-060f836c-e524-483f-985e-ee1118545366,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-a2dcf019-1bbb-4d7b-bce8-68529b16855f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318616119-172.17.0.12-1595673842144:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39266,DS-ce622158-5a42-4eeb-8195-fe0380df3a00,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-10f4ecbd-6c08-4eee-a01c-79989e4d3c52,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-be4ffd7c-3f8a-49ea-bb73-8289d0fff0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-3d2bec6b-baab-4930-b454-44959afd9995,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-c2743af8-82de-4285-805f-211a121a37d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-6ef28d24-fccd-451d-9dde-697e200db262,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-060f836c-e524-483f-985e-ee1118545366,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-a2dcf019-1bbb-4d7b-bce8-68529b16855f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518833083-172.17.0.12-1595674068099:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39550,DS-412bd9cb-2b7b-40f4-a05c-f571eb869f02,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-428bdebb-1da9-49e1-8d63-fe49b95abbce,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-3d78ca4c-92d0-496f-ac1c-7048a0045ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-767a2442-eacc-4bdb-b900-ee8a7ae93e34,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-abb7bcdc-786f-4d27-af6c-1e0d1cbd0335,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-6bc5507f-6157-4a57-8387-74b7c1ee48be,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-4ab2cf82-ee6e-45ea-ba6a-8c96ba5587b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-c1162d0b-2188-450c-89e6-cda8626a28a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518833083-172.17.0.12-1595674068099:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39550,DS-412bd9cb-2b7b-40f4-a05c-f571eb869f02,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-428bdebb-1da9-49e1-8d63-fe49b95abbce,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-3d78ca4c-92d0-496f-ac1c-7048a0045ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-767a2442-eacc-4bdb-b900-ee8a7ae93e34,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-abb7bcdc-786f-4d27-af6c-1e0d1cbd0335,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-6bc5507f-6157-4a57-8387-74b7c1ee48be,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-4ab2cf82-ee6e-45ea-ba6a-8c96ba5587b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-c1162d0b-2188-450c-89e6-cda8626a28a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678339308-172.17.0.12-1595674105281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46713,DS-814748df-eef0-47e2-a45b-d05b6c4c08cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-567d24ef-e1a9-4ac8-8217-00aa91303786,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-b7361b17-d8fe-444a-aba1-8f7f243190f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-720522ff-2417-4e3e-9941-d118bdb1cd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-8df87c48-e0f9-4820-a003-d2b015fbf2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-42c49db3-8525-4f05-94dc-b14cd23b01e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-7ebdf85f-1d20-485c-b292-3d1c612ff853,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-2056c53d-5630-4109-9e97-e83b6c31257a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678339308-172.17.0.12-1595674105281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46713,DS-814748df-eef0-47e2-a45b-d05b6c4c08cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-567d24ef-e1a9-4ac8-8217-00aa91303786,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-b7361b17-d8fe-444a-aba1-8f7f243190f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-720522ff-2417-4e3e-9941-d118bdb1cd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-8df87c48-e0f9-4820-a003-d2b015fbf2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-42c49db3-8525-4f05-94dc-b14cd23b01e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-7ebdf85f-1d20-485c-b292-3d1c612ff853,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-2056c53d-5630-4109-9e97-e83b6c31257a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792474436-172.17.0.12-1595674680585:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40188,DS-0e3d08e9-c7a1-4d92-879d-2ae74592433d,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-5060f61e-4f36-4252-9829-0966c18b352a,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-ee683c16-eec7-4906-91ac-4f1712e4f56a,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-9193a447-785d-4cf2-a816-e53200bbb11b,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-347d6b4e-74c1-4a27-80fc-6cfe25e304ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-1aa0ef91-d747-48cb-9cb7-3056d3233cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-61df0a6e-10e0-4e9c-b35d-34754f05453b,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-1a1ddc68-1ae1-48bb-9071-9913dd99492c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792474436-172.17.0.12-1595674680585:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40188,DS-0e3d08e9-c7a1-4d92-879d-2ae74592433d,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-5060f61e-4f36-4252-9829-0966c18b352a,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-ee683c16-eec7-4906-91ac-4f1712e4f56a,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-9193a447-785d-4cf2-a816-e53200bbb11b,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-347d6b4e-74c1-4a27-80fc-6cfe25e304ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-1aa0ef91-d747-48cb-9cb7-3056d3233cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-61df0a6e-10e0-4e9c-b35d-34754f05453b,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-1a1ddc68-1ae1-48bb-9071-9913dd99492c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531558058-172.17.0.12-1595675058094:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39463,DS-b73e871d-5f08-44e1-a1db-dc6038a80732,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-5e1c877d-b116-4bb3-99ab-7d96fbb10433,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-529997a0-1d33-441b-a9c0-d166f3dd43c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-a5a869d9-76b3-4a2e-94a0-6c098fa4b9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-ef8747f8-9554-427c-88eb-c8ac44b3c36e,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-f84fe9a6-f356-4337-b2b0-153c9e0491da,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-dd182dcd-6b8c-4934-8b9b-ebbe250332c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-46b6665a-e931-40f5-9838-943f38187e8e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531558058-172.17.0.12-1595675058094:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39463,DS-b73e871d-5f08-44e1-a1db-dc6038a80732,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-5e1c877d-b116-4bb3-99ab-7d96fbb10433,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-529997a0-1d33-441b-a9c0-d166f3dd43c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-a5a869d9-76b3-4a2e-94a0-6c098fa4b9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-ef8747f8-9554-427c-88eb-c8ac44b3c36e,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-f84fe9a6-f356-4337-b2b0-153c9e0491da,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-dd182dcd-6b8c-4934-8b9b-ebbe250332c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-46b6665a-e931-40f5-9838-943f38187e8e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390570637-172.17.0.12-1595675129875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36511,DS-1bbd297a-24b8-4eeb-aca9-c35d6cf6aaed,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-b399ff9f-96ed-4f27-b8b0-60427072ec3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-8398a4c9-f1d8-4141-a675-0905520224e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-b415d962-1a9b-400d-89b4-c4370473845d,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-0c18b7ff-1ebc-4436-a9d3-6d47a1a368ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-205aa6dd-ad9d-42c7-bc2a-60b9cebfe47d,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-edf10640-63b5-43e2-9ea0-bb1b6ca4aaad,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-c303f6b9-19c9-4030-aa79-31eaf51d9c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390570637-172.17.0.12-1595675129875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36511,DS-1bbd297a-24b8-4eeb-aca9-c35d6cf6aaed,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-b399ff9f-96ed-4f27-b8b0-60427072ec3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-8398a4c9-f1d8-4141-a675-0905520224e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-b415d962-1a9b-400d-89b4-c4370473845d,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-0c18b7ff-1ebc-4436-a9d3-6d47a1a368ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-205aa6dd-ad9d-42c7-bc2a-60b9cebfe47d,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-edf10640-63b5-43e2-9ea0-bb1b6ca4aaad,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-c303f6b9-19c9-4030-aa79-31eaf51d9c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905591449-172.17.0.12-1595675203138:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45629,DS-cc06ca70-a356-4707-a6d0-cad36cecdd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-801bc522-d282-4bde-b619-336524d1421a,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-09e1482f-a2c4-42b2-a576-8974201436eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-7a074a90-9a01-4656-87d7-d63ef98c98eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-a53cb068-52ff-416e-b577-8d8a0134cf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-7bfde12b-9ff0-4d63-bfe6-d136f372e56d,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-1df42a8d-e14e-43ae-a573-30714f104c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-2bd4a665-cae0-49f4-a354-65cfd67492ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905591449-172.17.0.12-1595675203138:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45629,DS-cc06ca70-a356-4707-a6d0-cad36cecdd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-801bc522-d282-4bde-b619-336524d1421a,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-09e1482f-a2c4-42b2-a576-8974201436eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-7a074a90-9a01-4656-87d7-d63ef98c98eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-a53cb068-52ff-416e-b577-8d8a0134cf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-7bfde12b-9ff0-4d63-bfe6-d136f372e56d,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-1df42a8d-e14e-43ae-a573-30714f104c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-2bd4a665-cae0-49f4-a354-65cfd67492ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930621135-172.17.0.12-1595675243995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43541,DS-ead8630b-5cc0-4642-8082-eebf4c35f20c,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-1583c295-2bc3-4fae-b04e-a3e36aa60b98,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-8d9fbc11-c08d-4b85-a3be-974491d01d90,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-a1b2f31b-74e9-4255-80bd-d97425cbef17,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-abd8f780-ed64-42c9-a640-5eeff0cc3f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-31565171-6266-4eb2-9fb2-94a872eda36b,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-d53895a5-b858-4518-90e4-1d296fe4ed90,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-f7b6326f-9626-4d4c-93d8-d609c5e43942,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930621135-172.17.0.12-1595675243995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43541,DS-ead8630b-5cc0-4642-8082-eebf4c35f20c,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-1583c295-2bc3-4fae-b04e-a3e36aa60b98,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-8d9fbc11-c08d-4b85-a3be-974491d01d90,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-a1b2f31b-74e9-4255-80bd-d97425cbef17,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-abd8f780-ed64-42c9-a640-5eeff0cc3f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-31565171-6266-4eb2-9fb2-94a872eda36b,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-d53895a5-b858-4518-90e4-1d296fe4ed90,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-f7b6326f-9626-4d4c-93d8-d609c5e43942,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840932140-172.17.0.12-1595675382905:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38189,DS-6b503e70-5b1f-482a-8b3c-fe728b9c0be3,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-dfcf84cd-4d02-4813-8b7c-e122219df9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-85d4e09d-5d0b-4910-ad33-29969a85a5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-3368d1ed-24e5-4309-9761-f72ba8f8443d,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-bb634124-db70-46ef-a56a-82e2da87e5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-bc58e2e0-fa25-4c31-a4b6-ab57dd3cab47,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-97e0e41b-178e-488c-9635-16bf57167dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-9fa6081e-e69f-4385-81d8-5e1a8cbf76fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840932140-172.17.0.12-1595675382905:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38189,DS-6b503e70-5b1f-482a-8b3c-fe728b9c0be3,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-dfcf84cd-4d02-4813-8b7c-e122219df9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-85d4e09d-5d0b-4910-ad33-29969a85a5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-3368d1ed-24e5-4309-9761-f72ba8f8443d,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-bb634124-db70-46ef-a56a-82e2da87e5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-bc58e2e0-fa25-4c31-a4b6-ab57dd3cab47,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-97e0e41b-178e-488c-9635-16bf57167dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-9fa6081e-e69f-4385-81d8-5e1a8cbf76fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136133577-172.17.0.12-1595675583309:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33795,DS-bd890a65-52f2-4734-b4b0-8e6a9b99c671,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-d9739b6a-04c7-4961-8e8f-02a2d199c70b,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-5c2bf56b-33ac-43ce-b26f-f7bb8f651780,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-0d83fe7c-afc2-43f0-b93c-cd0a9a338e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-20057ec4-4bbc-4886-bc40-6d54608f3af1,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-021178ac-06e9-49ad-ba1e-984a425835c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-f061f86b-541e-4fc2-87b5-f3746429d7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-815357a3-2c00-48ff-94a9-3d4fe0ec26d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2136133577-172.17.0.12-1595675583309:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33795,DS-bd890a65-52f2-4734-b4b0-8e6a9b99c671,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-d9739b6a-04c7-4961-8e8f-02a2d199c70b,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-5c2bf56b-33ac-43ce-b26f-f7bb8f651780,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-0d83fe7c-afc2-43f0-b93c-cd0a9a338e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-20057ec4-4bbc-4886-bc40-6d54608f3af1,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-021178ac-06e9-49ad-ba1e-984a425835c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-f061f86b-541e-4fc2-87b5-f3746429d7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-815357a3-2c00-48ff-94a9-3d4fe0ec26d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895869275-172.17.0.12-1595675801459:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39353,DS-76d2ac94-191a-4e74-8982-9bd312013275,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-f7274ad7-29b9-4e7b-8b67-e7f3be7cc90b,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-56a36f83-b398-4bb3-9f34-d245bf759435,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-9e9fb7b7-85f4-4a33-a4ee-af1e6d94db60,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-5ebadc8b-b757-4537-8043-09da97cd3b74,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-83436874-54d9-4003-b87b-68315a84ad40,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-09b8ea28-6f56-4c05-85c8-5b452ad8b402,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-0affae7f-e4ab-4d30-8df3-d5a6d5e050fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895869275-172.17.0.12-1595675801459:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39353,DS-76d2ac94-191a-4e74-8982-9bd312013275,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-f7274ad7-29b9-4e7b-8b67-e7f3be7cc90b,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-56a36f83-b398-4bb3-9f34-d245bf759435,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-9e9fb7b7-85f4-4a33-a4ee-af1e6d94db60,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-5ebadc8b-b757-4537-8043-09da97cd3b74,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-83436874-54d9-4003-b87b-68315a84ad40,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-09b8ea28-6f56-4c05-85c8-5b452ad8b402,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-0affae7f-e4ab-4d30-8df3-d5a6d5e050fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042156304-172.17.0.12-1595676007688:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41953,DS-84343398-c499-4b3c-b4ef-44b103384075,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-e25d078b-2823-4363-97ff-74f536c5faa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-a98a6a04-38c3-4f36-87d5-7486041002e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-ef018e56-2544-4f45-8110-771c821ee262,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-6302408a-9409-4f9c-aded-ffd1ad54165b,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-689cfe07-25e3-4644-a2eb-9a8e5aa88ade,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-89f1ec55-ba9d-4f36-9766-afe12f4b39d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-4236fce9-c7a7-4b12-87fd-75eaf097c156,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042156304-172.17.0.12-1595676007688:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41953,DS-84343398-c499-4b3c-b4ef-44b103384075,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-e25d078b-2823-4363-97ff-74f536c5faa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-a98a6a04-38c3-4f36-87d5-7486041002e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-ef018e56-2544-4f45-8110-771c821ee262,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-6302408a-9409-4f9c-aded-ffd1ad54165b,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-689cfe07-25e3-4644-a2eb-9a8e5aa88ade,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-89f1ec55-ba9d-4f36-9766-afe12f4b39d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-4236fce9-c7a7-4b12-87fd-75eaf097c156,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369661364-172.17.0.12-1595676098866:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33202,DS-bef61ec8-9bda-4f0b-8445-3f02202820ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-805dd97e-d477-4b62-a5ee-3f5f5fd0edba,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-1a75928b-6abf-4ba7-85eb-427196f7b515,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-cee4da93-ed41-4299-a4a8-3c2827c82f10,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-aa50adfe-71c7-40a2-8235-af1c5de0e3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-649a78bb-b374-42a4-a5fd-fd2f7c1ca14e,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-6f42139f-8f71-4937-9454-6043c27f91f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-554eea2b-2fc8-4947-9166-f4cc1a0bd072,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369661364-172.17.0.12-1595676098866:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33202,DS-bef61ec8-9bda-4f0b-8445-3f02202820ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-805dd97e-d477-4b62-a5ee-3f5f5fd0edba,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-1a75928b-6abf-4ba7-85eb-427196f7b515,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-cee4da93-ed41-4299-a4a8-3c2827c82f10,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-aa50adfe-71c7-40a2-8235-af1c5de0e3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-649a78bb-b374-42a4-a5fd-fd2f7c1ca14e,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-6f42139f-8f71-4937-9454-6043c27f91f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-554eea2b-2fc8-4947-9166-f4cc1a0bd072,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048827143-172.17.0.12-1595676299874:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39945,DS-d8856d28-03b8-4e3f-94b9-44f852e1c6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-5c759d52-8471-426d-b9a9-9c074ce6033f,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-aef8a262-2430-4a5b-9dc9-28ffef9fa3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-b1fd190b-d19a-47cd-a8cc-317f81b6f114,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-3321fd99-49b4-434e-a273-366ada47f23b,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-9a7d3f82-198a-4341-97c3-b65458d22b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-35b31e8d-5e0f-4139-abad-981fa1ac7d49,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-86d0fb8b-0412-46ab-9ee2-0f10c0ac891d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048827143-172.17.0.12-1595676299874:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39945,DS-d8856d28-03b8-4e3f-94b9-44f852e1c6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-5c759d52-8471-426d-b9a9-9c074ce6033f,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-aef8a262-2430-4a5b-9dc9-28ffef9fa3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-b1fd190b-d19a-47cd-a8cc-317f81b6f114,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-3321fd99-49b4-434e-a273-366ada47f23b,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-9a7d3f82-198a-4341-97c3-b65458d22b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-35b31e8d-5e0f-4139-abad-981fa1ac7d49,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-86d0fb8b-0412-46ab-9ee2-0f10c0ac891d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116661656-172.17.0.12-1595676389333:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44493,DS-ea3e5bd6-9df4-4f06-b3db-329670885067,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-d74e9959-eb73-41bb-bdd7-5da37e52e46d,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-14b9265f-2926-44c4-b269-0576b5ac9da6,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-162eb5cc-c2b8-4d62-943f-f0d83d87a607,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-05ebf29f-e844-44c6-9d4e-924298cde162,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-f26c8037-9c09-431a-abe9-b782d2b75a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-9555f1f1-6ddc-48d0-97d9-216be5c9cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-7a23721e-8c03-433f-8ec4-31819f7f330b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116661656-172.17.0.12-1595676389333:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44493,DS-ea3e5bd6-9df4-4f06-b3db-329670885067,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-d74e9959-eb73-41bb-bdd7-5da37e52e46d,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-14b9265f-2926-44c4-b269-0576b5ac9da6,DISK], DatanodeInfoWithStorage[127.0.0.1:39629,DS-162eb5cc-c2b8-4d62-943f-f0d83d87a607,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-05ebf29f-e844-44c6-9d4e-924298cde162,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-f26c8037-9c09-431a-abe9-b782d2b75a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-9555f1f1-6ddc-48d0-97d9-216be5c9cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-7a23721e-8c03-433f-8ec4-31819f7f330b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130939416-172.17.0.12-1595676667756:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40272,DS-75721c00-cb24-444d-92ec-c4a60aa4c931,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-299595d7-cf6e-416d-a57a-b484d5f249e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-97dcf023-012d-4a61-ab38-466f753fc8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-20976a19-1eae-4576-a02b-12284deffd06,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-b8dbf498-0ac1-4ede-95ae-ad9083020a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-21fdedf6-b50c-482a-bf52-808e91a2f9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-7da6b6f7-3399-4ed3-825b-76ccd2d60341,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-a1fac506-6fc0-47d7-a245-9c0343ba0868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130939416-172.17.0.12-1595676667756:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40272,DS-75721c00-cb24-444d-92ec-c4a60aa4c931,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-299595d7-cf6e-416d-a57a-b484d5f249e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-97dcf023-012d-4a61-ab38-466f753fc8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-20976a19-1eae-4576-a02b-12284deffd06,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-b8dbf498-0ac1-4ede-95ae-ad9083020a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-21fdedf6-b50c-482a-bf52-808e91a2f9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-7da6b6f7-3399-4ed3-825b-76ccd2d60341,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-a1fac506-6fc0-47d7-a245-9c0343ba0868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911541618-172.17.0.12-1595676740009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35926,DS-91675383-c943-4567-94a0-b6163dd34b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-f8d25331-41c7-4a71-a07a-bd6807a7c9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-90524f50-933d-49c7-a357-468069e47141,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-633582b5-9f17-4298-a42e-4d55901821ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-b68e6bda-758b-443b-9c39-2f6ffb9bf6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-acfdc312-6c91-4f14-a4ea-be18f311d716,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-f9c8d6bf-2c95-46d7-8624-9ca920eba19a,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-7adaa19a-a645-448d-9439-26480c1a576a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-911541618-172.17.0.12-1595676740009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35926,DS-91675383-c943-4567-94a0-b6163dd34b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-f8d25331-41c7-4a71-a07a-bd6807a7c9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-90524f50-933d-49c7-a357-468069e47141,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-633582b5-9f17-4298-a42e-4d55901821ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-b68e6bda-758b-443b-9c39-2f6ffb9bf6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-acfdc312-6c91-4f14-a4ea-be18f311d716,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-f9c8d6bf-2c95-46d7-8624-9ca920eba19a,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-7adaa19a-a645-448d-9439-26480c1a576a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519876826-172.17.0.12-1595676844305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37485,DS-f0cfc88b-ed3c-462b-a387-f84afce38d34,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-d607dae4-b9b5-4e19-9088-20ef9b1cf719,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-790acbec-4986-40f8-9362-3d4bba0f08a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-5c460364-12bd-4dc4-88ef-c185ee0fdaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-7cbd251f-161a-4b0f-afc7-657278eeab3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-3a094c81-a22b-44ff-85ce-7ff032ae3bce,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-6bb00892-8696-4dad-8e5e-a0c0afc8a72e,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-fe8ba721-f360-41c8-bd66-7223543b4d39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519876826-172.17.0.12-1595676844305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37485,DS-f0cfc88b-ed3c-462b-a387-f84afce38d34,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-d607dae4-b9b5-4e19-9088-20ef9b1cf719,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-790acbec-4986-40f8-9362-3d4bba0f08a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-5c460364-12bd-4dc4-88ef-c185ee0fdaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-7cbd251f-161a-4b0f-afc7-657278eeab3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-3a094c81-a22b-44ff-85ce-7ff032ae3bce,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-6bb00892-8696-4dad-8e5e-a0c0afc8a72e,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-fe8ba721-f360-41c8-bd66-7223543b4d39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533241590-172.17.0.12-1595676877523:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32846,DS-1131ca57-3160-4d9c-8452-fbae29932922,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-f0d315a7-3dab-41aa-acf9-757daaa3a45c,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-9fa80434-2857-4b5d-a2e3-42555d729d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-f342a6df-599d-4788-946e-62a0dfb61651,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-8b1908a6-8633-4db7-b13b-726f9de91fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-413b902c-ea3c-4bad-993c-07e9b63fed04,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-95c61601-9f81-4296-9d9f-8938d3d9594f,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-7d47add4-3224-4b4d-9924-1b76da32a96d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533241590-172.17.0.12-1595676877523:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32846,DS-1131ca57-3160-4d9c-8452-fbae29932922,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-f0d315a7-3dab-41aa-acf9-757daaa3a45c,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-9fa80434-2857-4b5d-a2e3-42555d729d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-f342a6df-599d-4788-946e-62a0dfb61651,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-8b1908a6-8633-4db7-b13b-726f9de91fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-413b902c-ea3c-4bad-993c-07e9b63fed04,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-95c61601-9f81-4296-9d9f-8938d3d9594f,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-7d47add4-3224-4b4d-9924-1b76da32a96d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415680487-172.17.0.12-1595677048121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38765,DS-62c5d37c-3ef9-4092-b857-e9bc176a26eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-f9dd2e87-33ff-4d39-afda-b4db8e82823f,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-3b852ddf-bfec-453d-9393-12983898702b,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-3cb77595-51c7-4c01-b3aa-5380c335c9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-7a36ae0b-59f0-4ac9-914a-2cb82537f87a,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-3c160cd2-b421-4d88-ac86-f2248806eef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-136b1762-a000-4c3b-8a0b-4b99da4d2eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-94ed6bed-91df-44f0-9fc0-22337ae22f76,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1415680487-172.17.0.12-1595677048121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38765,DS-62c5d37c-3ef9-4092-b857-e9bc176a26eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-f9dd2e87-33ff-4d39-afda-b4db8e82823f,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-3b852ddf-bfec-453d-9393-12983898702b,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-3cb77595-51c7-4c01-b3aa-5380c335c9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-7a36ae0b-59f0-4ac9-914a-2cb82537f87a,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-3c160cd2-b421-4d88-ac86-f2248806eef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-136b1762-a000-4c3b-8a0b-4b99da4d2eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-94ed6bed-91df-44f0-9fc0-22337ae22f76,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887073013-172.17.0.12-1595677170429:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39791,DS-e59bb461-062f-4671-8cb4-374c7c9c5f59,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-2a61a56e-79bf-4a9e-852a-359160e6a8de,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-2b593361-ece0-4141-b853-1621033d8f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-b82494d7-c233-46c1-9b43-b58f5c26ceda,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-9f1f8c2e-1f86-4c58-ae43-7497660d286b,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-de682760-28dc-4cf7-8613-45c87af3318f,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-364df320-2a9e-432a-a0f6-4c6bc95bb57d,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-74f559a6-6b78-4d08-ad1d-f14c64b1d276,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1887073013-172.17.0.12-1595677170429:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39791,DS-e59bb461-062f-4671-8cb4-374c7c9c5f59,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-2a61a56e-79bf-4a9e-852a-359160e6a8de,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-2b593361-ece0-4141-b853-1621033d8f81,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-b82494d7-c233-46c1-9b43-b58f5c26ceda,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-9f1f8c2e-1f86-4c58-ae43-7497660d286b,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-de682760-28dc-4cf7-8613-45c87af3318f,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-364df320-2a9e-432a-a0f6-4c6bc95bb57d,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-74f559a6-6b78-4d08-ad1d-f14c64b1d276,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983130837-172.17.0.12-1595677387382:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38784,DS-75f6adce-1203-4b4a-8799-184bec1f948b,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-4504da0c-f27c-4e03-8a26-5e7c0d1a2e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-fc476506-97ec-45a9-8bce-3f7089beb94a,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-b3ec180b-bee0-4898-b2f3-9a63d3cc2db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-9b31a632-944c-4a26-9971-5e8f1b174b69,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-31f50061-5cfb-4822-a846-d80164b19e71,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-a94cff76-4e88-4f31-9a55-8b0bc0318faa,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-90602462-5cec-48dc-93b6-15489f70cd2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983130837-172.17.0.12-1595677387382:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38784,DS-75f6adce-1203-4b4a-8799-184bec1f948b,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-4504da0c-f27c-4e03-8a26-5e7c0d1a2e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-fc476506-97ec-45a9-8bce-3f7089beb94a,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-b3ec180b-bee0-4898-b2f3-9a63d3cc2db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-9b31a632-944c-4a26-9971-5e8f1b174b69,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-31f50061-5cfb-4822-a846-d80164b19e71,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-a94cff76-4e88-4f31-9a55-8b0bc0318faa,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-90602462-5cec-48dc-93b6-15489f70cd2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60846082-172.17.0.12-1595677524538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42021,DS-443a3092-9091-48c9-9ada-288d2534d07c,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-58a7ac2c-db3b-448f-817e-28f3f5b176a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-93f0362c-9e95-4c5d-92f6-65a4e58cdecd,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-3a5d4e82-a2e1-42c1-82d6-afd2590bb61d,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-059a6d46-16fd-46a9-b83c-44e071e75338,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-301e1aa5-d4c5-4c3f-9381-95fbdbb8d694,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-460596cb-0721-4882-9716-aaf70181854e,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-b31fa7b0-4cf3-4667-aa55-38b30624c321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60846082-172.17.0.12-1595677524538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42021,DS-443a3092-9091-48c9-9ada-288d2534d07c,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-58a7ac2c-db3b-448f-817e-28f3f5b176a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-93f0362c-9e95-4c5d-92f6-65a4e58cdecd,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-3a5d4e82-a2e1-42c1-82d6-afd2590bb61d,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-059a6d46-16fd-46a9-b83c-44e071e75338,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-301e1aa5-d4c5-4c3f-9381-95fbdbb8d694,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-460596cb-0721-4882-9716-aaf70181854e,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-b31fa7b0-4cf3-4667-aa55-38b30624c321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571099752-172.17.0.12-1595677559326:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34864,DS-31949bb0-78f1-4191-8551-79e5ecfa3e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-02802eb8-c8f1-4849-b71c-3e8aa5bc6470,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-44d9a235-ad98-48a2-a06d-6e99e12ae4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-fbced4f0-3f9e-4bb8-90b7-df270a4c9373,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-b0e6ad8d-6a8b-41b8-bfb5-91f55f63ca33,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-6869d7dd-1ad3-446a-bf03-62ad8e833a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-050e3c27-fc1e-4794-8a9d-4a45eb7ef833,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-d48cae17-e7d8-4f51-b413-30e2c42fd404,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571099752-172.17.0.12-1595677559326:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34864,DS-31949bb0-78f1-4191-8551-79e5ecfa3e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-02802eb8-c8f1-4849-b71c-3e8aa5bc6470,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-44d9a235-ad98-48a2-a06d-6e99e12ae4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-fbced4f0-3f9e-4bb8-90b7-df270a4c9373,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-b0e6ad8d-6a8b-41b8-bfb5-91f55f63ca33,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-6869d7dd-1ad3-446a-bf03-62ad8e833a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-050e3c27-fc1e-4794-8a9d-4a45eb7ef833,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-d48cae17-e7d8-4f51-b413-30e2c42fd404,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815155069-172.17.0.12-1595677627612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42282,DS-11183ea0-52bb-4dcb-803b-da503860cfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-3384d01f-862e-42d4-ad92-160656b39883,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-8ea137ee-3f17-4372-9809-06b7c017de11,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-c6090940-3125-4b8e-8aa7-2f9de0e3075b,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-2bc75c56-bca2-4ad6-8a0a-c823b31fc219,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-97ff5022-7ed3-4048-9bbd-4089c3712798,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-da1e95ca-84ff-4f17-a5bf-a300d7a6766b,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-f8e602ff-95c1-4ff6-bc75-ceba5ad84a96,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815155069-172.17.0.12-1595677627612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42282,DS-11183ea0-52bb-4dcb-803b-da503860cfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-3384d01f-862e-42d4-ad92-160656b39883,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-8ea137ee-3f17-4372-9809-06b7c017de11,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-c6090940-3125-4b8e-8aa7-2f9de0e3075b,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-2bc75c56-bca2-4ad6-8a0a-c823b31fc219,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-97ff5022-7ed3-4048-9bbd-4089c3712798,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-da1e95ca-84ff-4f17-a5bf-a300d7a6766b,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-f8e602ff-95c1-4ff6-bc75-ceba5ad84a96,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150474252-172.17.0.12-1595677669143:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42961,DS-d98785f5-ec16-4ffa-9e32-3f7a5119f9df,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-7e3f9574-17a2-4fa5-860e-98b3ea2b6091,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-d517ed08-d44a-4f61-9897-d4043c52babe,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-0c666c7f-b9c1-4367-a4cf-0e65536bb798,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-2beff6eb-e07b-4d42-82be-7cf32a5abf84,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-aa956083-528b-4426-a2d3-0062d0fafec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-befd1405-d398-494a-8713-8add8df944cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-7c49baa5-5329-4971-baa4-ce54b966db98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-150474252-172.17.0.12-1595677669143:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42961,DS-d98785f5-ec16-4ffa-9e32-3f7a5119f9df,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-7e3f9574-17a2-4fa5-860e-98b3ea2b6091,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-d517ed08-d44a-4f61-9897-d4043c52babe,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-0c666c7f-b9c1-4367-a4cf-0e65536bb798,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-2beff6eb-e07b-4d42-82be-7cf32a5abf84,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-aa956083-528b-4426-a2d3-0062d0fafec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-befd1405-d398-494a-8713-8add8df944cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-7c49baa5-5329-4971-baa4-ce54b966db98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146612547-172.17.0.12-1595677834952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43241,DS-517d50df-02ab-4307-bb88-1ae20b8c578d,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-5f0a3983-db27-4b93-9957-7c783bb0ce34,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-f1f90499-abba-4559-8dd2-da3ae224bcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-c173a18f-4af1-4249-82be-6b2f7898fdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-1257354a-ac0c-472f-88fb-c190ac715d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-0596ebbe-377e-49f1-95ae-ad15fd037c30,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-27c02568-9804-4981-97a2-d9c583bed8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-47f24b6b-82c5-4dc0-8eb3-73234224fc7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1146612547-172.17.0.12-1595677834952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43241,DS-517d50df-02ab-4307-bb88-1ae20b8c578d,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-5f0a3983-db27-4b93-9957-7c783bb0ce34,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-f1f90499-abba-4559-8dd2-da3ae224bcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-c173a18f-4af1-4249-82be-6b2f7898fdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-1257354a-ac0c-472f-88fb-c190ac715d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-0596ebbe-377e-49f1-95ae-ad15fd037c30,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-27c02568-9804-4981-97a2-d9c583bed8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-47f24b6b-82c5-4dc0-8eb3-73234224fc7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765248530-172.17.0.12-1595678071103:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43349,DS-6f04f6bb-a91c-4b6f-8522-5eb0df5e3262,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-53439e8f-a039-42fd-8e68-84408050a95c,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-f93df2c3-64b9-45e6-931e-7ca7dc4c9222,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-3b24c57b-1d4a-4ea7-ace0-01a992317dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-3c435775-e2fd-46a0-b771-59d9e9eba93f,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-ce635efa-7c7b-49a5-bbf4-57eac39e805d,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-61798d61-e32e-4cf2-8451-8b722a0c30fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-5e70cbe0-4131-481d-9599-e8963f58727a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765248530-172.17.0.12-1595678071103:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43349,DS-6f04f6bb-a91c-4b6f-8522-5eb0df5e3262,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-53439e8f-a039-42fd-8e68-84408050a95c,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-f93df2c3-64b9-45e6-931e-7ca7dc4c9222,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-3b24c57b-1d4a-4ea7-ace0-01a992317dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-3c435775-e2fd-46a0-b771-59d9e9eba93f,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-ce635efa-7c7b-49a5-bbf4-57eac39e805d,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-61798d61-e32e-4cf2-8451-8b722a0c30fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-5e70cbe0-4131-481d-9599-e8963f58727a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255360067-172.17.0.12-1595678139539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37160,DS-8cc4e23f-79e7-455a-abbf-c3bdaac13ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-3a2ab2ab-420c-46d2-ab86-ea868f8f8fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-f0949590-b85c-40f0-a711-945ffde521b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-208fde65-b5bc-43a1-8c26-b4ae9a3b1dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-f1cbaebe-0b74-4f7b-a447-2911ccb87a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-4a3c49fe-3cdd-44ca-96f7-dd8247614541,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-0789ab16-9ae2-4f1a-b496-0a03ad5f3402,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-e6cae971-abee-49c3-908f-f74cbb7caa05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255360067-172.17.0.12-1595678139539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37160,DS-8cc4e23f-79e7-455a-abbf-c3bdaac13ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-3a2ab2ab-420c-46d2-ab86-ea868f8f8fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-f0949590-b85c-40f0-a711-945ffde521b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-208fde65-b5bc-43a1-8c26-b4ae9a3b1dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-f1cbaebe-0b74-4f7b-a447-2911ccb87a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-4a3c49fe-3cdd-44ca-96f7-dd8247614541,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-0789ab16-9ae2-4f1a-b496-0a03ad5f3402,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-e6cae971-abee-49c3-908f-f74cbb7caa05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347008687-172.17.0.12-1595678174065:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46684,DS-a762886a-b9d2-4ec5-92b2-8af22f17aa31,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-363622f3-3f6c-4276-b398-25f177d5c2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-52c60998-a433-4b8c-959d-f1a8fadfcbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-8fd55334-511d-4255-80cb-764ffdcf1961,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-667d198f-3de5-456e-b0b3-d3d96a179dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-3ba74054-349f-4e35-a427-513a7d6c7a10,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-2ea2194f-125e-4369-a394-18dfd6c86558,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-9bf973b1-3981-4f1f-af95-269dea17a978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347008687-172.17.0.12-1595678174065:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46684,DS-a762886a-b9d2-4ec5-92b2-8af22f17aa31,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-363622f3-3f6c-4276-b398-25f177d5c2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-52c60998-a433-4b8c-959d-f1a8fadfcbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-8fd55334-511d-4255-80cb-764ffdcf1961,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-667d198f-3de5-456e-b0b3-d3d96a179dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-3ba74054-349f-4e35-a427-513a7d6c7a10,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-2ea2194f-125e-4369-a394-18dfd6c86558,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-9bf973b1-3981-4f1f-af95-269dea17a978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350680229-172.17.0.12-1595678567132:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42526,DS-63915145-79aa-49a9-adf3-087f794f19d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-ad5bcda2-272d-4b2c-b49c-426241bf9e74,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-c5966efd-97cb-46a5-9844-4bd4a64ff0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-7f089704-24be-4969-a62c-69edce9a339a,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-f5d8361f-2dcd-4a18-b796-8f9b3dfbd9de,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-66f85701-6128-4238-bda7-5b2c638a5a14,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-bfb0d457-8258-417a-8e36-b04623cd3572,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-b6218623-a06a-4549-a1e9-8d6603ba24fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350680229-172.17.0.12-1595678567132:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42526,DS-63915145-79aa-49a9-adf3-087f794f19d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-ad5bcda2-272d-4b2c-b49c-426241bf9e74,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-c5966efd-97cb-46a5-9844-4bd4a64ff0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-7f089704-24be-4969-a62c-69edce9a339a,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-f5d8361f-2dcd-4a18-b796-8f9b3dfbd9de,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-66f85701-6128-4238-bda7-5b2c638a5a14,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-bfb0d457-8258-417a-8e36-b04623cd3572,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-b6218623-a06a-4549-a1e9-8d6603ba24fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5030
