reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-358313011-172.17.0.6-1595519276441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41614,DS-17c05184-da95-4b07-8606-3f254ce59678,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-e6d8c6e0-3dc2-475c-9293-a929290364e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-4fed4d0e-f63b-43b7-90d5-277ac74804d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-f2bcdba1-1b5d-4d6c-81c0-727e393ccff6,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-1d0836cf-82ea-4c1e-9ada-8b907ba16cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-75be8e17-3864-42cd-8063-5648bdf7cc45,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-d4e35a1b-c152-441e-96d4-1651813e0652,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-63f44265-65a8-4c9c-a93b-44b91eee318e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-358313011-172.17.0.6-1595519276441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41614,DS-17c05184-da95-4b07-8606-3f254ce59678,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-e6d8c6e0-3dc2-475c-9293-a929290364e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-4fed4d0e-f63b-43b7-90d5-277ac74804d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-f2bcdba1-1b5d-4d6c-81c0-727e393ccff6,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-1d0836cf-82ea-4c1e-9ada-8b907ba16cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-75be8e17-3864-42cd-8063-5648bdf7cc45,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-d4e35a1b-c152-441e-96d4-1651813e0652,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-63f44265-65a8-4c9c-a93b-44b91eee318e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1455651135-172.17.0.6-1595519386881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34310,DS-e7efbd7b-34f4-49b1-ba92-aa3461180234,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-8aee8424-cc51-4d53-9cc3-afed7c5ded6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-c9a30e75-afec-46b1-adcc-d1001380c113,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-64362302-075e-446c-93d3-09be108efe26,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-48023795-c082-46e6-8166-48041d9bc3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-3e1df1c4-cb96-4bd2-bbd7-e291645deb73,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-1c573c31-a93a-48af-84cd-49d0f1806d44,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-7193590f-1b6a-44bc-a9b0-b8ebe67c2589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1455651135-172.17.0.6-1595519386881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34310,DS-e7efbd7b-34f4-49b1-ba92-aa3461180234,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-8aee8424-cc51-4d53-9cc3-afed7c5ded6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-c9a30e75-afec-46b1-adcc-d1001380c113,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-64362302-075e-446c-93d3-09be108efe26,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-48023795-c082-46e6-8166-48041d9bc3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-3e1df1c4-cb96-4bd2-bbd7-e291645deb73,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-1c573c31-a93a-48af-84cd-49d0f1806d44,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-7193590f-1b6a-44bc-a9b0-b8ebe67c2589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852125101-172.17.0.6-1595519556062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35609,DS-597fbb51-ed45-48b5-a28b-dc76454c4476,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-b6b2c46b-f692-4279-a9b2-f7cb3f1c405e,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-9c7065d8-a314-4c03-8629-8e54d3057f39,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-6f093f5b-f202-4255-b05d-014804e28979,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-59a64aff-25a1-4701-b6ec-bb52b436175b,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-f3db9c56-385b-4801-a3ae-798ff2e92942,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-25a058be-48bb-4bc7-9028-6708a2e7cf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-b97ddee7-df9f-41ac-9e49-90b2561d940c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852125101-172.17.0.6-1595519556062:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35609,DS-597fbb51-ed45-48b5-a28b-dc76454c4476,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-b6b2c46b-f692-4279-a9b2-f7cb3f1c405e,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-9c7065d8-a314-4c03-8629-8e54d3057f39,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-6f093f5b-f202-4255-b05d-014804e28979,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-59a64aff-25a1-4701-b6ec-bb52b436175b,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-f3db9c56-385b-4801-a3ae-798ff2e92942,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-25a058be-48bb-4bc7-9028-6708a2e7cf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-b97ddee7-df9f-41ac-9e49-90b2561d940c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069255211-172.17.0.6-1595519887681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38798,DS-81b8fcc5-cf50-4520-9810-74add2740822,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-7f8dae40-9cfa-416b-9992-73b29c1de7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-7895cfac-f65d-4740-ba9a-37b8be4f4e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-def57c52-79db-4f63-a4a2-e07b5b936d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-4d7ef388-e5db-4403-9436-5c5b18c071b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-c6ee1a2d-1af5-4de0-8f1f-a79ef123c455,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-091a168c-992b-417f-8a74-ecca3b6de9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-351b990d-efef-471c-b667-39344a8f22d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069255211-172.17.0.6-1595519887681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38798,DS-81b8fcc5-cf50-4520-9810-74add2740822,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-7f8dae40-9cfa-416b-9992-73b29c1de7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-7895cfac-f65d-4740-ba9a-37b8be4f4e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-def57c52-79db-4f63-a4a2-e07b5b936d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-4d7ef388-e5db-4403-9436-5c5b18c071b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-c6ee1a2d-1af5-4de0-8f1f-a79ef123c455,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-091a168c-992b-417f-8a74-ecca3b6de9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-351b990d-efef-471c-b667-39344a8f22d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-783836093-172.17.0.6-1595520334350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41031,DS-fb07ad68-20d2-4f93-9dc4-fe9ebf1e4e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-32b9c476-cca3-49a5-9c4c-1c184e5c9966,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-81a505d9-3049-4cf0-b90e-315384e4931f,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-a2deaaa5-8acc-41a2-97d7-830f4a876192,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-bda96d96-29a5-48af-9bae-3ed3ea5f4a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-cccfe2c7-8876-4dcc-9901-fb7d3fb60ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-53cacd06-1bbf-4e35-857c-fcd03ae2b85e,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-8cbd29cb-9ab1-4a18-8c0e-f38495a1221a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-783836093-172.17.0.6-1595520334350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41031,DS-fb07ad68-20d2-4f93-9dc4-fe9ebf1e4e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-32b9c476-cca3-49a5-9c4c-1c184e5c9966,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-81a505d9-3049-4cf0-b90e-315384e4931f,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-a2deaaa5-8acc-41a2-97d7-830f4a876192,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-bda96d96-29a5-48af-9bae-3ed3ea5f4a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-cccfe2c7-8876-4dcc-9901-fb7d3fb60ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-53cacd06-1bbf-4e35-857c-fcd03ae2b85e,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-8cbd29cb-9ab1-4a18-8c0e-f38495a1221a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989239514-172.17.0.6-1595520545365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32858,DS-bf91c400-a5a3-4e70-a5cf-b292fbedd01c,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-73d7c30f-fec3-4724-bd22-40da8d7615c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-558e55a4-faef-428e-ae17-8c9f33d15b36,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-55b26d02-0b01-4bfb-a841-d26b8f94f8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-575f2c5a-74ae-4a42-af02-b46483a1576e,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-0f06e121-7d82-4862-9a0b-12aaa8ab06fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-9541ee95-fae9-4249-8439-564ea178565a,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-8259d6ad-357e-4b1b-a8c1-cb260ecea2f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989239514-172.17.0.6-1595520545365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32858,DS-bf91c400-a5a3-4e70-a5cf-b292fbedd01c,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-73d7c30f-fec3-4724-bd22-40da8d7615c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-558e55a4-faef-428e-ae17-8c9f33d15b36,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-55b26d02-0b01-4bfb-a841-d26b8f94f8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-575f2c5a-74ae-4a42-af02-b46483a1576e,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-0f06e121-7d82-4862-9a0b-12aaa8ab06fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-9541ee95-fae9-4249-8439-564ea178565a,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-8259d6ad-357e-4b1b-a8c1-cb260ecea2f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575515579-172.17.0.6-1595520596499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36811,DS-4b30e626-27e8-423b-8dfd-a4a8c6a77acb,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-fe62e91a-8e3b-46df-a6cf-2f268be23b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-ad8b0f9f-9e73-4b75-bb30-4ed38f67d4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-8f6534e8-c1c7-4fca-bfb0-dcf349ecad0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-f776f4cc-13ac-48e4-83c6-845908364670,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-30797159-0d5c-4e8e-84d6-cf4cbcf08cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-f38e5d66-6f08-4669-9ced-e0e2e176cb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-a2bf99bb-d08e-4326-ab47-9a098e6feab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575515579-172.17.0.6-1595520596499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36811,DS-4b30e626-27e8-423b-8dfd-a4a8c6a77acb,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-fe62e91a-8e3b-46df-a6cf-2f268be23b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-ad8b0f9f-9e73-4b75-bb30-4ed38f67d4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-8f6534e8-c1c7-4fca-bfb0-dcf349ecad0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-f776f4cc-13ac-48e4-83c6-845908364670,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-30797159-0d5c-4e8e-84d6-cf4cbcf08cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-f38e5d66-6f08-4669-9ced-e0e2e176cb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-a2bf99bb-d08e-4326-ab47-9a098e6feab2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443426937-172.17.0.6-1595520720926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44351,DS-c1890891-9c74-4986-8328-256f5679f675,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-39afa02e-7abe-4fd1-9c3d-3d66c39ff6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-9a25743f-44c1-4400-8b7b-cb18395c02b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-f345512e-c9fa-4e6a-b043-3fbd7f56c626,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-64644dad-f8e1-44dd-9a66-f300539f1e37,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-3c44d9df-d49b-44c4-8dab-b0c21a41eb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-24bc64b4-5a5c-487f-beb9-2187fe6f4897,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-9cc5e24f-f643-4612-8225-8dedf5d9624e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443426937-172.17.0.6-1595520720926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44351,DS-c1890891-9c74-4986-8328-256f5679f675,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-39afa02e-7abe-4fd1-9c3d-3d66c39ff6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-9a25743f-44c1-4400-8b7b-cb18395c02b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-f345512e-c9fa-4e6a-b043-3fbd7f56c626,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-64644dad-f8e1-44dd-9a66-f300539f1e37,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-3c44d9df-d49b-44c4-8dab-b0c21a41eb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-24bc64b4-5a5c-487f-beb9-2187fe6f4897,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-9cc5e24f-f643-4612-8225-8dedf5d9624e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374691601-172.17.0.6-1595520884602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45909,DS-78343f50-07d2-45ca-bdc8-18280fc5ba92,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-c0c10263-f9c4-47b0-9341-839fcaebf32d,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-a384c61d-a3da-4e2b-8294-c7ad108ee45d,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-ea97dff2-685e-44af-9ddf-183ca051c407,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-8437b5a5-e9a3-4ec8-ad43-8ec1ee00bbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-1419e607-39b3-4db6-bdb4-a2f55ed68328,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-20eb35ec-42af-4786-9469-259bae725d96,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-ce4a5fdc-219c-433d-8224-0c0aaf70ecf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374691601-172.17.0.6-1595520884602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45909,DS-78343f50-07d2-45ca-bdc8-18280fc5ba92,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-c0c10263-f9c4-47b0-9341-839fcaebf32d,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-a384c61d-a3da-4e2b-8294-c7ad108ee45d,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-ea97dff2-685e-44af-9ddf-183ca051c407,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-8437b5a5-e9a3-4ec8-ad43-8ec1ee00bbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-1419e607-39b3-4db6-bdb4-a2f55ed68328,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-20eb35ec-42af-4786-9469-259bae725d96,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-ce4a5fdc-219c-433d-8224-0c0aaf70ecf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1426579759-172.17.0.6-1595521018571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45079,DS-342f8d2e-bedb-4be8-8f7b-3f3ead6d0845,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-a652e992-2e49-4032-a12c-fe7bf0b8e721,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-ad6d5bf4-c388-4ab7-9e0b-8998cb362543,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-a1b4f527-8ff5-4c73-aec4-3dbf0b8d64e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-139c6453-f4f9-466e-8dfa-9a8c5f29fbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-d226b644-364e-4cd6-90a0-5286405083fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-dac83e7e-cf22-43b1-b4c3-0a695c1da0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-d7dc4009-749b-4411-9e02-58b1d49dc640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1426579759-172.17.0.6-1595521018571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45079,DS-342f8d2e-bedb-4be8-8f7b-3f3ead6d0845,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-a652e992-2e49-4032-a12c-fe7bf0b8e721,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-ad6d5bf4-c388-4ab7-9e0b-8998cb362543,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-a1b4f527-8ff5-4c73-aec4-3dbf0b8d64e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-139c6453-f4f9-466e-8dfa-9a8c5f29fbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-d226b644-364e-4cd6-90a0-5286405083fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-dac83e7e-cf22-43b1-b4c3-0a695c1da0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-d7dc4009-749b-4411-9e02-58b1d49dc640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525626143-172.17.0.6-1595523453719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43392,DS-8b02b3c3-6ada-489c-aeba-af51a14a28ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-9a099540-e532-4956-ae8c-ba242513f929,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-30f96af6-e88d-411c-bbcc-fffa71fd8019,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-2fe859eb-f493-4926-979c-13cac777f871,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-21b0c1e2-4775-47eb-b659-5442caa961f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-e05ad27d-2ecd-4132-81c5-c105396f6595,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-c871c55b-4668-4f09-858f-6a60e4af7094,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-2e65edb5-0d0d-4620-86f3-f4bfb3dea189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525626143-172.17.0.6-1595523453719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43392,DS-8b02b3c3-6ada-489c-aeba-af51a14a28ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-9a099540-e532-4956-ae8c-ba242513f929,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-30f96af6-e88d-411c-bbcc-fffa71fd8019,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-2fe859eb-f493-4926-979c-13cac777f871,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-21b0c1e2-4775-47eb-b659-5442caa961f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-e05ad27d-2ecd-4132-81c5-c105396f6595,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-c871c55b-4668-4f09-858f-6a60e4af7094,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-2e65edb5-0d0d-4620-86f3-f4bfb3dea189,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1161661663-172.17.0.6-1595523917659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43773,DS-88aab5ba-c340-4dad-ad99-9b6435022e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-515a104b-6060-4914-a366-386a7bc9ac6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-4f9093b4-e985-4344-94d3-79edb0ad4672,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-5e4c6025-8265-4922-8b74-d36fdec95a11,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-a70f6c7f-8de6-4b4e-9a05-6994fc14dee9,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-cf262f90-957c-4fbb-a463-eac3f7994011,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-8871c45f-0f0a-4d76-8d70-8e31754e6974,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-c63408e2-aaf0-40fe-a1ed-b6e74dfb400b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1161661663-172.17.0.6-1595523917659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43773,DS-88aab5ba-c340-4dad-ad99-9b6435022e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-515a104b-6060-4914-a366-386a7bc9ac6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-4f9093b4-e985-4344-94d3-79edb0ad4672,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-5e4c6025-8265-4922-8b74-d36fdec95a11,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-a70f6c7f-8de6-4b4e-9a05-6994fc14dee9,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-cf262f90-957c-4fbb-a463-eac3f7994011,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-8871c45f-0f0a-4d76-8d70-8e31754e6974,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-c63408e2-aaf0-40fe-a1ed-b6e74dfb400b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707942472-172.17.0.6-1595523953312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-4d47c271-a6c4-4cf5-b47b-d768b818bb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-01ad2991-56bb-46d2-aae0-76d7d2a6407c,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-5922b4de-1bb3-4966-8b62-efd4585d515d,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-a87d3984-082f-43ee-8415-33d8301df873,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-cdae8667-f041-431c-81f3-06ce17d2951b,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-88a0e08f-3cd8-4739-9fda-bc4ed5404b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-dd0250cf-b475-4b45-973c-287ccb813dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-958d27a5-2a5c-4f6c-92f8-b729b1fdd148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707942472-172.17.0.6-1595523953312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-4d47c271-a6c4-4cf5-b47b-d768b818bb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-01ad2991-56bb-46d2-aae0-76d7d2a6407c,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-5922b4de-1bb3-4966-8b62-efd4585d515d,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-a87d3984-082f-43ee-8415-33d8301df873,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-cdae8667-f041-431c-81f3-06ce17d2951b,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-88a0e08f-3cd8-4739-9fda-bc4ed5404b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-dd0250cf-b475-4b45-973c-287ccb813dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-958d27a5-2a5c-4f6c-92f8-b729b1fdd148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131652674-172.17.0.6-1595524263704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38629,DS-d25a3520-16a1-4b96-8e2c-7e17fb3f9897,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-0df2c329-7ca8-482d-a85e-05b7a5328561,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-4b59c73e-b76f-4074-b8c0-f19df636a561,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-3da48fd0-3e6d-4101-a19d-a205aa677d36,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-70bc228e-45b7-4292-bc1b-7bcde00191ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-655e60be-b02d-477b-aaca-f37c3233e02d,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-f15be5d8-356d-486f-b666-1e87dbbb68f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-cfba1389-c33e-4502-b680-90382bff1b3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131652674-172.17.0.6-1595524263704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38629,DS-d25a3520-16a1-4b96-8e2c-7e17fb3f9897,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-0df2c329-7ca8-482d-a85e-05b7a5328561,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-4b59c73e-b76f-4074-b8c0-f19df636a561,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-3da48fd0-3e6d-4101-a19d-a205aa677d36,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-70bc228e-45b7-4292-bc1b-7bcde00191ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-655e60be-b02d-477b-aaca-f37c3233e02d,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-f15be5d8-356d-486f-b666-1e87dbbb68f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-cfba1389-c33e-4502-b680-90382bff1b3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-89461998-172.17.0.6-1595524578284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41652,DS-6246f50d-fe71-4d71-93b1-9ae0c2a9d28b,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-eacc7cc8-7815-4388-9517-aec9e2c9a87b,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-576cdc8a-355e-4943-8540-2a240444f257,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-3cb68df6-b61d-4db6-8b9d-f27b8c7a6e84,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-2cbbf5cc-6bcf-462a-a0be-7555524e8770,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-932fed39-41f5-45ba-8b85-6c43b8604194,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-7ce97b69-dc51-4d0f-bdc7-bd45571f977a,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-0a3d131f-f9ba-474b-bf43-16630967b6e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-89461998-172.17.0.6-1595524578284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41652,DS-6246f50d-fe71-4d71-93b1-9ae0c2a9d28b,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-eacc7cc8-7815-4388-9517-aec9e2c9a87b,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-576cdc8a-355e-4943-8540-2a240444f257,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-3cb68df6-b61d-4db6-8b9d-f27b8c7a6e84,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-2cbbf5cc-6bcf-462a-a0be-7555524e8770,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-932fed39-41f5-45ba-8b85-6c43b8604194,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-7ce97b69-dc51-4d0f-bdc7-bd45571f977a,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-0a3d131f-f9ba-474b-bf43-16630967b6e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.base.millis
component: hdfs:NameNode
v1: 5
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1683472988-172.17.0.6-1595524781504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-ad0a21df-fb48-4ac9-9e64-5a456da87051,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-dd8195be-a570-44b4-85b2-71258a66815a,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-30407a4e-2038-4e52-a115-7e7b2f291f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-eb9abbaa-005a-4912-95ac-58f1b25c9c72,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-5aeb512d-2e08-45b7-aa37-9a19a54372e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-86c52b81-9e1d-4c88-aecc-bdbc5207ae6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-e19f4504-d44a-4f57-9559-3010c12f695d,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-155070d5-632b-4250-9b89-0d2213926239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1683472988-172.17.0.6-1595524781504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-ad0a21df-fb48-4ac9-9e64-5a456da87051,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-dd8195be-a570-44b4-85b2-71258a66815a,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-30407a4e-2038-4e52-a115-7e7b2f291f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-eb9abbaa-005a-4912-95ac-58f1b25c9c72,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-5aeb512d-2e08-45b7-aa37-9a19a54372e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-86c52b81-9e1d-4c88-aecc-bdbc5207ae6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-e19f4504-d44a-4f57-9559-3010c12f695d,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-155070d5-632b-4250-9b89-0d2213926239,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6342
