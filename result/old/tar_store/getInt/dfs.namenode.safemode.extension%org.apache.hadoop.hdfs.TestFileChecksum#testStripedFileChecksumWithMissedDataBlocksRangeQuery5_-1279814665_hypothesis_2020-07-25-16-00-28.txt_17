reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-466972386-172.17.0.15-1595692987503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36614,DS-d410b6f5-89f8-4f8a-acbd-93928e541bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-a1ed901f-1354-4e66-8827-b1710609d111,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-a7ce9d2a-1a40-46ef-8956-90d0cd0b008b,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-3fb36827-23b0-4454-ac1f-da99d879c873,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-09ef74d2-f8b1-49b3-b1ac-80c3e8389cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-27b55354-ff77-42a0-bc22-71e3337543a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-0e48c17f-904d-41cb-ba72-414f430448f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-2b50b1cd-ea40-4dd8-a382-f573d4c1aa6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-466972386-172.17.0.15-1595692987503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36614,DS-d410b6f5-89f8-4f8a-acbd-93928e541bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-a1ed901f-1354-4e66-8827-b1710609d111,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-a7ce9d2a-1a40-46ef-8956-90d0cd0b008b,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-3fb36827-23b0-4454-ac1f-da99d879c873,DISK], DatanodeInfoWithStorage[127.0.0.1:43416,DS-09ef74d2-f8b1-49b3-b1ac-80c3e8389cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-27b55354-ff77-42a0-bc22-71e3337543a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-0e48c17f-904d-41cb-ba72-414f430448f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-2b50b1cd-ea40-4dd8-a382-f573d4c1aa6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551914299-172.17.0.15-1595693288073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40724,DS-73217403-f995-478b-84c3-88d980834e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-e7e71b1d-4eb0-425e-aafb-805a1d36f736,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-00204e3d-7eac-4f54-8250-b269959edb20,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-f51ea67c-b7f0-4ab8-98bc-1ca6c69b2b90,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-955ee596-47d8-4fcd-8958-447ca08914b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-5456964b-9e15-4e70-979a-6ef70d100716,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-51601460-3ee0-45ac-8b21-faf86fa1beae,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-c87f8cdd-e648-494b-918d-877e394c7152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551914299-172.17.0.15-1595693288073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40724,DS-73217403-f995-478b-84c3-88d980834e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-e7e71b1d-4eb0-425e-aafb-805a1d36f736,DISK], DatanodeInfoWithStorage[127.0.0.1:41893,DS-00204e3d-7eac-4f54-8250-b269959edb20,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-f51ea67c-b7f0-4ab8-98bc-1ca6c69b2b90,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-955ee596-47d8-4fcd-8958-447ca08914b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-5456964b-9e15-4e70-979a-6ef70d100716,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-51601460-3ee0-45ac-8b21-faf86fa1beae,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-c87f8cdd-e648-494b-918d-877e394c7152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518317846-172.17.0.15-1595693878891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36341,DS-dc8a49e4-b749-4a1b-93c2-93d820e8e5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-94305f13-4ecb-4643-8219-f47157f5ce3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-01a31a13-aed8-43a5-b5da-cb90a24e02aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-baefef8a-c796-4a67-84a1-aeede0c98f07,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-e42e2a36-8b23-40af-9e60-25c5bc1114d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-641d7dba-a40d-4bf0-b9b2-073cb6e22ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-f1c3ab4a-fba5-49ae-816a-0052c822c4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-1f2638b6-4d91-4103-ad17-5d67ab09a842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518317846-172.17.0.15-1595693878891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36341,DS-dc8a49e4-b749-4a1b-93c2-93d820e8e5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-94305f13-4ecb-4643-8219-f47157f5ce3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-01a31a13-aed8-43a5-b5da-cb90a24e02aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-baefef8a-c796-4a67-84a1-aeede0c98f07,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-e42e2a36-8b23-40af-9e60-25c5bc1114d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-641d7dba-a40d-4bf0-b9b2-073cb6e22ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-f1c3ab4a-fba5-49ae-816a-0052c822c4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-1f2638b6-4d91-4103-ad17-5d67ab09a842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748524787-172.17.0.15-1595694233842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42286,DS-116f07f8-e027-46e5-89d9-e0f3963d8b00,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-04921c27-a8ab-459b-b4ca-055abf2dd221,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-28a63f3c-9ad5-4ab2-a8ff-9dc58cbcd4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-c930d1eb-450c-4879-a4d3-2dda57e638b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-4b299e65-f0d8-45e6-874e-d83733f934cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-375597ee-deed-4a63-88a8-e3ff4ce05ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-6ea16d0d-d31a-459a-b1f2-f0f93ab14e37,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-9c8243e4-5224-4b91-9224-2c4a09a807f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748524787-172.17.0.15-1595694233842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42286,DS-116f07f8-e027-46e5-89d9-e0f3963d8b00,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-04921c27-a8ab-459b-b4ca-055abf2dd221,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-28a63f3c-9ad5-4ab2-a8ff-9dc58cbcd4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-c930d1eb-450c-4879-a4d3-2dda57e638b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-4b299e65-f0d8-45e6-874e-d83733f934cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-375597ee-deed-4a63-88a8-e3ff4ce05ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-6ea16d0d-d31a-459a-b1f2-f0f93ab14e37,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-9c8243e4-5224-4b91-9224-2c4a09a807f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418482612-172.17.0.15-1595694594008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34857,DS-98971579-72c0-48a1-b832-78260716d5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-4fa8ad23-8c9d-4d9f-adbf-af13dce3ddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-b3851a25-b57d-4e21-a937-abebceb33b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-d3b4dad9-4c02-4ef3-ad09-c887f56b2fea,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-93832e52-789f-4e43-ba52-0b67798fceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-61a77d88-89f6-4609-8858-6549feaef934,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-d012599a-bab3-42b2-a935-0879817e3d70,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-f6fa3449-03c8-48f4-81f9-d2aef4aa0968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418482612-172.17.0.15-1595694594008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34857,DS-98971579-72c0-48a1-b832-78260716d5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-4fa8ad23-8c9d-4d9f-adbf-af13dce3ddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-b3851a25-b57d-4e21-a937-abebceb33b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-d3b4dad9-4c02-4ef3-ad09-c887f56b2fea,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-93832e52-789f-4e43-ba52-0b67798fceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-61a77d88-89f6-4609-8858-6549feaef934,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-d012599a-bab3-42b2-a935-0879817e3d70,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-f6fa3449-03c8-48f4-81f9-d2aef4aa0968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478352689-172.17.0.15-1595694881846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34543,DS-90ea740b-6eba-4d34-8f39-a2d41fe09d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-fed550c8-9eeb-4ebc-9d59-f4082b61fb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-3bb22401-e999-4999-b490-a8f68085b819,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-9e0731aa-4fd3-49f5-9fdd-cfceea553a50,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-c01af9c3-771e-4fa1-bcfd-b2bd1c9bef9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-f9d6c177-6414-48e9-9c87-4ea8eda708e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-56e3a543-fdaf-4e7a-828d-8247436740e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-711eb9e9-3d64-4852-9b77-e59438e6e465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478352689-172.17.0.15-1595694881846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34543,DS-90ea740b-6eba-4d34-8f39-a2d41fe09d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-fed550c8-9eeb-4ebc-9d59-f4082b61fb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-3bb22401-e999-4999-b490-a8f68085b819,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-9e0731aa-4fd3-49f5-9fdd-cfceea553a50,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-c01af9c3-771e-4fa1-bcfd-b2bd1c9bef9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-f9d6c177-6414-48e9-9c87-4ea8eda708e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-56e3a543-fdaf-4e7a-828d-8247436740e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-711eb9e9-3d64-4852-9b77-e59438e6e465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954282826-172.17.0.15-1595695347780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45087,DS-3f8b93d3-2601-497f-8906-a7c7073e4754,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-edc8bf2f-99c4-4682-ae01-29a68c448e55,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-efe41be1-a21d-49b7-ad4e-934aec2ff550,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-ac75ab0c-d3db-489e-b94a-eb8a342f4db9,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-2ab4133d-3d42-4661-8e68-22a931040667,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-35499013-28c1-457f-a7ac-d8dd1198f9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-d6934567-0a75-4452-b3f4-ce41347a8f02,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-539d56f4-9ec4-4ccf-bcad-e18319debff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954282826-172.17.0.15-1595695347780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45087,DS-3f8b93d3-2601-497f-8906-a7c7073e4754,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-edc8bf2f-99c4-4682-ae01-29a68c448e55,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-efe41be1-a21d-49b7-ad4e-934aec2ff550,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-ac75ab0c-d3db-489e-b94a-eb8a342f4db9,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-2ab4133d-3d42-4661-8e68-22a931040667,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-35499013-28c1-457f-a7ac-d8dd1198f9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-d6934567-0a75-4452-b3f4-ce41347a8f02,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-539d56f4-9ec4-4ccf-bcad-e18319debff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186419886-172.17.0.15-1595695587835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33491,DS-1afcf0fc-94ea-41b0-8985-1ee5bdabcb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-7a249558-fe9b-4310-9248-83f510b49b37,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-f3ba226b-fa61-4162-806c-89d7cdb9424b,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-792d7004-f403-4f71-930d-e2cfcb76171f,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-03428ed5-2540-4c2e-92f7-81bf6393967c,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-53d1fa8c-4a78-44aa-b5d0-9b24f13522f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-e475215b-8fb5-4465-a63e-716d172ea915,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-fd529e6e-1719-4a29-8e31-dfe2a36640a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186419886-172.17.0.15-1595695587835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33491,DS-1afcf0fc-94ea-41b0-8985-1ee5bdabcb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-7a249558-fe9b-4310-9248-83f510b49b37,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-f3ba226b-fa61-4162-806c-89d7cdb9424b,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-792d7004-f403-4f71-930d-e2cfcb76171f,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-03428ed5-2540-4c2e-92f7-81bf6393967c,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-53d1fa8c-4a78-44aa-b5d0-9b24f13522f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-e475215b-8fb5-4465-a63e-716d172ea915,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-fd529e6e-1719-4a29-8e31-dfe2a36640a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360261414-172.17.0.15-1595695926552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36897,DS-44ecb614-b16d-47ee-9675-1a6bea82f049,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-8e86b379-483d-4025-800f-3b5f4d8eb28b,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-4d6ed982-6546-4680-887b-c68c7a6a2e15,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-6c83eee2-6fbf-405e-9fba-e7ead7afc0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-e77a2176-9b35-4f3f-a36b-4c3335cd1750,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-30394a2c-7f0d-47bd-9b3d-c13b0211e7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-a7823619-804e-4bfb-9813-1cca0ddd1704,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-00689c04-6339-4c06-a224-310d9bc250c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1360261414-172.17.0.15-1595695926552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36897,DS-44ecb614-b16d-47ee-9675-1a6bea82f049,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-8e86b379-483d-4025-800f-3b5f4d8eb28b,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-4d6ed982-6546-4680-887b-c68c7a6a2e15,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-6c83eee2-6fbf-405e-9fba-e7ead7afc0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-e77a2176-9b35-4f3f-a36b-4c3335cd1750,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-30394a2c-7f0d-47bd-9b3d-c13b0211e7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-a7823619-804e-4bfb-9813-1cca0ddd1704,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-00689c04-6339-4c06-a224-310d9bc250c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038832387-172.17.0.15-1595696611498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36986,DS-912d2918-f941-40a3-bf1b-433b2baf08db,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-39c82792-f07b-4839-af6b-ed0be841a55c,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-be8a90b4-6099-4f70-b429-d25745c08745,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-44fab0a3-9170-4dd0-8afb-f047b0922583,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-bdcd47b8-0ab2-4d11-94d9-d2185e695a19,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-8334235b-f791-46fb-97d7-c24cc22c0a27,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-3be5c106-9c1d-4355-8958-807c3e710072,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-edda70a7-e1f1-404f-ac1c-7bfe98ab49b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2038832387-172.17.0.15-1595696611498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36986,DS-912d2918-f941-40a3-bf1b-433b2baf08db,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-39c82792-f07b-4839-af6b-ed0be841a55c,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-be8a90b4-6099-4f70-b429-d25745c08745,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-44fab0a3-9170-4dd0-8afb-f047b0922583,DISK], DatanodeInfoWithStorage[127.0.0.1:37722,DS-bdcd47b8-0ab2-4d11-94d9-d2185e695a19,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-8334235b-f791-46fb-97d7-c24cc22c0a27,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-3be5c106-9c1d-4355-8958-807c3e710072,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-edda70a7-e1f1-404f-ac1c-7bfe98ab49b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275133116-172.17.0.15-1595697004881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34328,DS-3fb3cf5b-8f71-493d-8d82-8b0f2da99edb,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-28e1f8df-1527-449c-a0db-e568ee8f6227,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-d7ec1474-1515-47f9-a3fa-ad9f83ed7eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-3a22ddc6-2010-4806-8ae7-b277b86b1314,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-3233d743-a2a4-429a-a0a5-6315c71d4b87,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-6869f996-1ab6-41ff-9230-d9dd26d04f69,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-b97eafc2-2f02-49b7-8b00-985a5ab7fe58,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-dd38de5e-5715-49a0-ac4a-181bfba8912d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275133116-172.17.0.15-1595697004881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34328,DS-3fb3cf5b-8f71-493d-8d82-8b0f2da99edb,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-28e1f8df-1527-449c-a0db-e568ee8f6227,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-d7ec1474-1515-47f9-a3fa-ad9f83ed7eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-3a22ddc6-2010-4806-8ae7-b277b86b1314,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-3233d743-a2a4-429a-a0a5-6315c71d4b87,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-6869f996-1ab6-41ff-9230-d9dd26d04f69,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-b97eafc2-2f02-49b7-8b00-985a5ab7fe58,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-dd38de5e-5715-49a0-ac4a-181bfba8912d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324672388-172.17.0.15-1595697206904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44693,DS-d2f12c3f-1803-491e-a4cb-fae46073399b,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-a0390198-3108-43e8-a593-705987c9d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-79139370-e036-487f-9358-bdeecbbb0d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-8e8344ee-277c-45ae-a522-8462e29a7f63,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-2fe1a9f6-55ac-42f0-83e9-511abf81cd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-99b90ccd-8305-4849-a44f-34abbb5e93a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-78c5c66c-702a-4a1c-97cb-b08c231f2766,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-1c1f72ee-7aea-435c-9c17-6739cb142267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324672388-172.17.0.15-1595697206904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44693,DS-d2f12c3f-1803-491e-a4cb-fae46073399b,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-a0390198-3108-43e8-a593-705987c9d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-79139370-e036-487f-9358-bdeecbbb0d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-8e8344ee-277c-45ae-a522-8462e29a7f63,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-2fe1a9f6-55ac-42f0-83e9-511abf81cd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-99b90ccd-8305-4849-a44f-34abbb5e93a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-78c5c66c-702a-4a1c-97cb-b08c231f2766,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-1c1f72ee-7aea-435c-9c17-6739cb142267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51504575-172.17.0.15-1595697299437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35421,DS-eb015d7a-0ef3-4bbf-8741-70ce0fb6209b,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-b7df7e6b-856b-44af-acd4-0296a0d2874c,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-9c4ce4e9-8f96-40b7-99bf-330b84a9b21b,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-ae6eacb5-7afd-405d-84d5-bd0bb937c96f,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-bc4c1aa3-0335-4269-baef-1d09693ca14a,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-22fbebb6-2bb8-441e-98e3-cee8fc0f645e,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-62766248-7dd1-4b5f-b208-b6e30edfd5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-64fd5368-e3c4-437a-88b9-0c32b2701f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51504575-172.17.0.15-1595697299437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35421,DS-eb015d7a-0ef3-4bbf-8741-70ce0fb6209b,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-b7df7e6b-856b-44af-acd4-0296a0d2874c,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-9c4ce4e9-8f96-40b7-99bf-330b84a9b21b,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-ae6eacb5-7afd-405d-84d5-bd0bb937c96f,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-bc4c1aa3-0335-4269-baef-1d09693ca14a,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-22fbebb6-2bb8-441e-98e3-cee8fc0f645e,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-62766248-7dd1-4b5f-b208-b6e30edfd5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-64fd5368-e3c4-437a-88b9-0c32b2701f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549490223-172.17.0.15-1595697445668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42806,DS-68ba6dcc-bcbd-4db6-9017-317b281462bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-58fc902a-6116-4287-9137-90100d125d40,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-516554d4-a77a-4648-befb-dffa70b8a452,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-91a12436-f042-4a04-a348-eb8ea93ef42d,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-fd934a63-0f9c-4906-b276-67d08f9c7dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-4a510e05-5d33-4a7d-9a96-0e971350e0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-f26d09ad-766f-42b1-b1f3-b012e80ba0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-8c2bc469-f7d1-4d3c-a92b-b3c0ffef4423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549490223-172.17.0.15-1595697445668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42806,DS-68ba6dcc-bcbd-4db6-9017-317b281462bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-58fc902a-6116-4287-9137-90100d125d40,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-516554d4-a77a-4648-befb-dffa70b8a452,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-91a12436-f042-4a04-a348-eb8ea93ef42d,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-fd934a63-0f9c-4906-b276-67d08f9c7dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-4a510e05-5d33-4a7d-9a96-0e971350e0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-f26d09ad-766f-42b1-b1f3-b012e80ba0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-8c2bc469-f7d1-4d3c-a92b-b3c0ffef4423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199281570-172.17.0.15-1595697487265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33007,DS-d787ca90-ad1b-4c6d-8acb-cabd73d8af7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-cc154920-6ed8-45e7-8ee9-bb0979a5692c,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-f9bc4a00-0848-4c49-8a40-53e6e2d66d52,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-fbfc524a-94de-4658-8c22-dae399d6367f,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-300cf3e8-430f-4752-8cc6-180aa92ec980,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-ea8904e8-3976-4fbf-9552-7ff606318a20,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-cecf77e1-3a50-47c6-a152-288aa191aaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-7cbcbe85-6c0e-4473-98a9-c84ff4a22577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1199281570-172.17.0.15-1595697487265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33007,DS-d787ca90-ad1b-4c6d-8acb-cabd73d8af7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-cc154920-6ed8-45e7-8ee9-bb0979a5692c,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-f9bc4a00-0848-4c49-8a40-53e6e2d66d52,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-fbfc524a-94de-4658-8c22-dae399d6367f,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-300cf3e8-430f-4752-8cc6-180aa92ec980,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-ea8904e8-3976-4fbf-9552-7ff606318a20,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-cecf77e1-3a50-47c6-a152-288aa191aaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-7cbcbe85-6c0e-4473-98a9-c84ff4a22577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.extension
component: hdfs:NameNode
v1: 30
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651509853-172.17.0.15-1595698894303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37652,DS-abd7e992-e7dc-49e6-a062-c80ecc4b37a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-eb8ce8be-e739-47b0-98dc-953bd618ee29,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-7a6f40ca-180d-4ff0-86e1-be156f1935e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-7830d86b-bf58-4780-8f28-bf3be172766b,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-885d51f0-042c-41ee-838a-8274eb3bb7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-98bdc739-5ffe-4fc8-b01f-7f01f134a5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-1949c738-642a-4a1b-aee6-0798b558bd04,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-c07b2b86-46c2-4d41-af1e-74e552282b96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651509853-172.17.0.15-1595698894303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37652,DS-abd7e992-e7dc-49e6-a062-c80ecc4b37a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-eb8ce8be-e739-47b0-98dc-953bd618ee29,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-7a6f40ca-180d-4ff0-86e1-be156f1935e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-7830d86b-bf58-4780-8f28-bf3be172766b,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-885d51f0-042c-41ee-838a-8274eb3bb7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-98bdc739-5ffe-4fc8-b01f-7f01f134a5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-1949c738-642a-4a1b-aee6-0798b558bd04,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-c07b2b86-46c2-4d41-af1e-74e552282b96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6816
