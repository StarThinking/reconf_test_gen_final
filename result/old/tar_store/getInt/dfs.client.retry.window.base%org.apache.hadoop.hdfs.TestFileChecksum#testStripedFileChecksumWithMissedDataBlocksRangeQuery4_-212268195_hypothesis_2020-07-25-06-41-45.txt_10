reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381182560-172.17.0.13-1595659387417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-33512e3f-8dd9-4021-a63e-036de948a409,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-ea69b240-be48-4256-9c9d-4571dac2959b,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-0c834573-1465-4b0d-8823-251c12678865,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-ce4cc565-668f-408d-b3cb-8b977a65b5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-4a71c0f2-4c2c-4a9a-94ae-9042cd236afb,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-c2b13e2b-32fb-404d-b590-576fcffdade4,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-f07fb0fd-7b4e-4e59-89f0-2b3368c153da,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-3cfd5fc5-f72a-45b4-8d82-662ea1c130e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381182560-172.17.0.13-1595659387417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41122,DS-33512e3f-8dd9-4021-a63e-036de948a409,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-ea69b240-be48-4256-9c9d-4571dac2959b,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-0c834573-1465-4b0d-8823-251c12678865,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-ce4cc565-668f-408d-b3cb-8b977a65b5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-4a71c0f2-4c2c-4a9a-94ae-9042cd236afb,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-c2b13e2b-32fb-404d-b590-576fcffdade4,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-f07fb0fd-7b4e-4e59-89f0-2b3368c153da,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-3cfd5fc5-f72a-45b4-8d82-662ea1c130e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796283212-172.17.0.13-1595659422113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40250,DS-51225f7a-807e-4a81-9dba-0853acbb1f34,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-24da7f42-45cc-45fa-8f7a-cdebfbbe4021,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-5c53c688-9c44-4d5e-b103-303d786efb47,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-2738cfd5-ca11-4daf-a361-41eacfdf7e57,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-4940e0c7-8231-489f-81c4-18a4fee8b3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-f4f64952-adf7-4d2c-a5a7-b5cd87551d47,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-f3e859cf-9731-4c76-b264-2dab8177980b,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-fa432a3b-dec4-431c-aa6a-25137776a7f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796283212-172.17.0.13-1595659422113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40250,DS-51225f7a-807e-4a81-9dba-0853acbb1f34,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-24da7f42-45cc-45fa-8f7a-cdebfbbe4021,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-5c53c688-9c44-4d5e-b103-303d786efb47,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-2738cfd5-ca11-4daf-a361-41eacfdf7e57,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-4940e0c7-8231-489f-81c4-18a4fee8b3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-f4f64952-adf7-4d2c-a5a7-b5cd87551d47,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-f3e859cf-9731-4c76-b264-2dab8177980b,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-fa432a3b-dec4-431c-aa6a-25137776a7f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476594604-172.17.0.13-1595659470882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38718,DS-22fa5e86-ffb9-45bb-b241-6dff09e35460,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-5d1274f2-19f5-45d7-9c66-6ad5cadcd390,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-0a89ed28-7a9e-4227-8445-4e31e0e2d8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-0f912f66-f366-45cf-8682-b55bffeb586c,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-3b5f0ff2-7e64-40cd-8039-6a063fbc239a,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-65dcf178-6695-424f-a936-1a0c97c216cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-d4e689db-b40f-4b0f-9f6f-52113abe0707,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-b204fd0e-38dc-4f39-af7c-10218f0b1de9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476594604-172.17.0.13-1595659470882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38718,DS-22fa5e86-ffb9-45bb-b241-6dff09e35460,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-5d1274f2-19f5-45d7-9c66-6ad5cadcd390,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-0a89ed28-7a9e-4227-8445-4e31e0e2d8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-0f912f66-f366-45cf-8682-b55bffeb586c,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-3b5f0ff2-7e64-40cd-8039-6a063fbc239a,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-65dcf178-6695-424f-a936-1a0c97c216cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-d4e689db-b40f-4b0f-9f6f-52113abe0707,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-b204fd0e-38dc-4f39-af7c-10218f0b1de9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580605996-172.17.0.13-1595660693535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37098,DS-81e9e190-72f1-4e4a-a8a8-a27d8c9e1dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-dead2539-fdb5-4fbd-bc82-5a51c7c060aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-a4941de8-3f17-4231-be40-7aacc918cdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-ee7ff793-372c-4fa4-a6d6-fa6d028df31b,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-1f7958d3-2233-4a67-8678-04d604eca403,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-a43e36ac-2e86-40f0-8c44-c162df51005d,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-a8110815-4bd2-4113-8c4f-7d0ca1679f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-1eb6b967-7278-4c2c-a5f0-cd9533734be9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580605996-172.17.0.13-1595660693535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37098,DS-81e9e190-72f1-4e4a-a8a8-a27d8c9e1dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-dead2539-fdb5-4fbd-bc82-5a51c7c060aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-a4941de8-3f17-4231-be40-7aacc918cdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-ee7ff793-372c-4fa4-a6d6-fa6d028df31b,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-1f7958d3-2233-4a67-8678-04d604eca403,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-a43e36ac-2e86-40f0-8c44-c162df51005d,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-a8110815-4bd2-4113-8c4f-7d0ca1679f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-1eb6b967-7278-4c2c-a5f0-cd9533734be9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057984257-172.17.0.13-1595660766396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40825,DS-db1a08fc-a3dc-4612-8248-adc86dca7075,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-3fca6063-45a4-449a-9dff-e69fb3035e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-2816d56c-eea3-4515-a78c-513d7f10e8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-1cddbbe1-fc08-4c89-87ca-d44f870befdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-dc852498-be82-4873-adab-bb9dd0066d98,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-b2b1fe41-813d-4fe5-8bdd-ea5d8d4da2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-96831380-69aa-4b39-9165-8ad46d965d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-6fe48f6e-7176-4895-811f-e8ccb57b36d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2057984257-172.17.0.13-1595660766396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40825,DS-db1a08fc-a3dc-4612-8248-adc86dca7075,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-3fca6063-45a4-449a-9dff-e69fb3035e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-2816d56c-eea3-4515-a78c-513d7f10e8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-1cddbbe1-fc08-4c89-87ca-d44f870befdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-dc852498-be82-4873-adab-bb9dd0066d98,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-b2b1fe41-813d-4fe5-8bdd-ea5d8d4da2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-96831380-69aa-4b39-9165-8ad46d965d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-6fe48f6e-7176-4895-811f-e8ccb57b36d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872644184-172.17.0.13-1595660953814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44826,DS-3e88af64-4b1f-498b-a110-4dd0ca980995,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-13853810-e6af-4aca-9874-70b265b830e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-14f2c703-e9cc-4cae-83fa-bd94f22ca415,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-6c4e11c8-adc7-45bb-a2d0-50c37bca5926,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-de3eab09-0df7-4ef2-83ab-125fb280ddf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-425c9874-49a2-4fb2-85ef-c4a8bad130b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-0b9679b4-b980-41d3-8cad-ec60bbf9dc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-c4974484-bf5f-44cf-b66e-771a41aa9e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872644184-172.17.0.13-1595660953814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44826,DS-3e88af64-4b1f-498b-a110-4dd0ca980995,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-13853810-e6af-4aca-9874-70b265b830e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-14f2c703-e9cc-4cae-83fa-bd94f22ca415,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-6c4e11c8-adc7-45bb-a2d0-50c37bca5926,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-de3eab09-0df7-4ef2-83ab-125fb280ddf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-425c9874-49a2-4fb2-85ef-c4a8bad130b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-0b9679b4-b980-41d3-8cad-ec60bbf9dc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-c4974484-bf5f-44cf-b66e-771a41aa9e3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566816375-172.17.0.13-1595660986784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39471,DS-9a59e4e7-1de1-46b7-9d0d-d75999a84a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-228de2bb-baeb-4ba2-9f9f-59cb80806bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-6f6eb52f-a5c2-4d45-89eb-1cca12b520ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-c876379c-5dba-4494-acdc-c6ff6f1a3d04,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-5076540d-552f-4148-a3ac-99dd747dc50e,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-d672e4b9-7f84-4700-b3f3-eb4b3f6a9364,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-dbf29dfc-ae6e-4ee2-ba63-63225ba88803,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-ec1fbb84-2529-46af-8dfb-0d4eeb8adf5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-566816375-172.17.0.13-1595660986784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39471,DS-9a59e4e7-1de1-46b7-9d0d-d75999a84a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-228de2bb-baeb-4ba2-9f9f-59cb80806bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-6f6eb52f-a5c2-4d45-89eb-1cca12b520ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-c876379c-5dba-4494-acdc-c6ff6f1a3d04,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-5076540d-552f-4148-a3ac-99dd747dc50e,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-d672e4b9-7f84-4700-b3f3-eb4b3f6a9364,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-dbf29dfc-ae6e-4ee2-ba63-63225ba88803,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-ec1fbb84-2529-46af-8dfb-0d4eeb8adf5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563465942-172.17.0.13-1595661141371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43417,DS-3dbefd46-9bac-4656-8956-6b4a8ca92b44,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-f9a28bbb-22a3-4a8d-a98f-00e6ce6aa89f,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-dd072602-dd6e-4106-ad13-ecb5d6f66e46,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-b7a6dfc3-e8ea-4760-b0de-3d0b6132dd83,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-131a808d-9234-4768-b0df-4261f452b23d,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-17bb4915-99af-4013-8773-e286e9775123,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-7506694c-bca5-4142-98a5-b07c4ec474c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-804e6a97-e19e-4b7c-a71b-97ff4716516e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563465942-172.17.0.13-1595661141371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43417,DS-3dbefd46-9bac-4656-8956-6b4a8ca92b44,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-f9a28bbb-22a3-4a8d-a98f-00e6ce6aa89f,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-dd072602-dd6e-4106-ad13-ecb5d6f66e46,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-b7a6dfc3-e8ea-4760-b0de-3d0b6132dd83,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-131a808d-9234-4768-b0df-4261f452b23d,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-17bb4915-99af-4013-8773-e286e9775123,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-7506694c-bca5-4142-98a5-b07c4ec474c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-804e6a97-e19e-4b7c-a71b-97ff4716516e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514483473-172.17.0.13-1595662242399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39206,DS-17457d28-f406-4548-9125-6df46a55b649,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-c000c411-2f0b-4776-9b50-9499c73e6c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-8110cfac-e406-4db3-bebd-68e7994ff196,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-01b36cc0-ffed-43e3-811f-d604ab516fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-a9c255bf-8cf3-4148-8f5c-315ed3d5a22a,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-00d032ac-2183-491c-a1df-a8d162609d12,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-77cf6dd0-03e0-4e0d-ae29-63c4aec0010d,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-d23ae633-8875-40b4-a738-7276a23bdd6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1514483473-172.17.0.13-1595662242399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39206,DS-17457d28-f406-4548-9125-6df46a55b649,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-c000c411-2f0b-4776-9b50-9499c73e6c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-8110cfac-e406-4db3-bebd-68e7994ff196,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-01b36cc0-ffed-43e3-811f-d604ab516fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-a9c255bf-8cf3-4148-8f5c-315ed3d5a22a,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-00d032ac-2183-491c-a1df-a8d162609d12,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-77cf6dd0-03e0-4e0d-ae29-63c4aec0010d,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-d23ae633-8875-40b4-a738-7276a23bdd6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728126946-172.17.0.13-1595662402144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44875,DS-5ba59875-3919-4e48-8812-076063d76be8,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-3d6a298f-b3a6-4671-a5d3-803c43a137bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-e97c7676-154b-4194-b56c-b3e045e09784,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-eb33ec14-c7f9-4c06-a666-f7d37667d370,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-c7f7c179-f8f6-41a9-9511-a39ff0fae00c,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-4bbc48d7-e448-4549-acac-c6aeb3ee1026,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-f68ff6bd-34fb-447d-a80c-e0ef418701a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-d49041eb-6150-42b7-9712-934e89cef2be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728126946-172.17.0.13-1595662402144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44875,DS-5ba59875-3919-4e48-8812-076063d76be8,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-3d6a298f-b3a6-4671-a5d3-803c43a137bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-e97c7676-154b-4194-b56c-b3e045e09784,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-eb33ec14-c7f9-4c06-a666-f7d37667d370,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-c7f7c179-f8f6-41a9-9511-a39ff0fae00c,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-4bbc48d7-e448-4549-acac-c6aeb3ee1026,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-f68ff6bd-34fb-447d-a80c-e0ef418701a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-d49041eb-6150-42b7-9712-934e89cef2be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694567974-172.17.0.13-1595662558268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36441,DS-d4a42ad8-52a3-4016-9282-105a11b0ebc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-113c7d95-0c2d-4136-9571-d81fae260f43,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-92556ca2-ffa4-4bea-ab38-9b0cb9a8102e,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-eca1b1b2-f4b0-4249-9ff4-a08b181722f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-403b5fd8-3507-435d-a215-921bdc5fb853,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-6db09194-174f-4e78-b83e-95cde69071c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-86afe683-df19-4543-b3c5-d8e855672f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-2401efde-6546-46fc-bfe9-74c7c0299f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694567974-172.17.0.13-1595662558268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36441,DS-d4a42ad8-52a3-4016-9282-105a11b0ebc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-113c7d95-0c2d-4136-9571-d81fae260f43,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-92556ca2-ffa4-4bea-ab38-9b0cb9a8102e,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-eca1b1b2-f4b0-4249-9ff4-a08b181722f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-403b5fd8-3507-435d-a215-921bdc5fb853,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-6db09194-174f-4e78-b83e-95cde69071c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-86afe683-df19-4543-b3c5-d8e855672f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-2401efde-6546-46fc-bfe9-74c7c0299f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008970390-172.17.0.13-1595662640703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33579,DS-1f1b65d6-9549-4bd1-be26-2530b212823a,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-c7867023-8e1b-4bec-8991-17dd5fbd1abf,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-30ba4b44-3142-411d-9d52-9381984a736d,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-33232bf8-2b08-4311-af96-4d5ed93adaef,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-0c61334e-3ef0-43db-9330-82aa4631b01d,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-9007e1c2-09f5-4b8c-a6e9-0f3f4a2634df,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-d519d9ec-64de-4418-83db-cb06ef59b212,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-076d9bdf-8bf4-409b-a4fb-02f7e809d89a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008970390-172.17.0.13-1595662640703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33579,DS-1f1b65d6-9549-4bd1-be26-2530b212823a,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-c7867023-8e1b-4bec-8991-17dd5fbd1abf,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-30ba4b44-3142-411d-9d52-9381984a736d,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-33232bf8-2b08-4311-af96-4d5ed93adaef,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-0c61334e-3ef0-43db-9330-82aa4631b01d,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-9007e1c2-09f5-4b8c-a6e9-0f3f4a2634df,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-d519d9ec-64de-4418-83db-cb06ef59b212,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-076d9bdf-8bf4-409b-a4fb-02f7e809d89a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372728277-172.17.0.13-1595663040903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34565,DS-29d906a8-4b01-4055-be1a-ab740537d176,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-aad06d97-7788-409a-a65d-f875d0ef6bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-d706c7d2-51af-400a-89c2-82b0cadbe293,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-43d6b929-70b1-4334-9310-a640867f8494,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-f0416ef6-5e35-43d5-ab66-a0d919fda7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-8e936071-839a-4a3d-a05d-d61faffe0abb,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-e8685f04-b12a-4011-ba07-2db50d004f09,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-ee03345f-e519-4133-9405-b04603b14d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372728277-172.17.0.13-1595663040903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34565,DS-29d906a8-4b01-4055-be1a-ab740537d176,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-aad06d97-7788-409a-a65d-f875d0ef6bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-d706c7d2-51af-400a-89c2-82b0cadbe293,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-43d6b929-70b1-4334-9310-a640867f8494,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-f0416ef6-5e35-43d5-ab66-a0d919fda7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-8e936071-839a-4a3d-a05d-d61faffe0abb,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-e8685f04-b12a-4011-ba07-2db50d004f09,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-ee03345f-e519-4133-9405-b04603b14d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518101853-172.17.0.13-1595663269692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38900,DS-41911b30-e250-489b-9b0e-204b7d3fde2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-b0e9b442-904c-47a5-9c96-f307ccf6c5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-0605c45b-c439-4255-819c-e166d5303387,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-4ed3ad2d-e62b-4bb7-a265-628789e9e63c,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-33bb463f-ae38-4c25-8b6b-23ce9157a5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-1530e3c4-0c83-49c3-b46a-33876c489793,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-b0924074-78d4-482f-80a4-121a38e516d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-74dbadae-d495-4289-9593-def1392087cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518101853-172.17.0.13-1595663269692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38900,DS-41911b30-e250-489b-9b0e-204b7d3fde2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-b0e9b442-904c-47a5-9c96-f307ccf6c5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-0605c45b-c439-4255-819c-e166d5303387,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-4ed3ad2d-e62b-4bb7-a265-628789e9e63c,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-33bb463f-ae38-4c25-8b6b-23ce9157a5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-1530e3c4-0c83-49c3-b46a-33876c489793,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-b0924074-78d4-482f-80a4-121a38e516d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-74dbadae-d495-4289-9593-def1392087cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461314770-172.17.0.13-1595663902371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46668,DS-7d9206a7-dfe3-458b-bb7e-ef7e6d954ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-2c1d2c2a-aa3b-41e7-a7c9-6b05bd74a25c,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-196b8a68-46bc-4392-98c1-d457d433baf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-99ece8df-ac32-4298-87ab-e9ed7ff70e31,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-3bbfe24b-2e1a-4db6-be46-27dffe098a11,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-02ce287a-db66-4c5a-9979-0ba91ec7f968,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-347a90f9-780f-4789-9f21-6c8998ade515,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-ca4a2405-8f4e-41de-ab58-6174eef96aeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-461314770-172.17.0.13-1595663902371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46668,DS-7d9206a7-dfe3-458b-bb7e-ef7e6d954ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-2c1d2c2a-aa3b-41e7-a7c9-6b05bd74a25c,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-196b8a68-46bc-4392-98c1-d457d433baf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-99ece8df-ac32-4298-87ab-e9ed7ff70e31,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-3bbfe24b-2e1a-4db6-be46-27dffe098a11,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-02ce287a-db66-4c5a-9979-0ba91ec7f968,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-347a90f9-780f-4789-9f21-6c8998ade515,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-ca4a2405-8f4e-41de-ab58-6174eef96aeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85421516-172.17.0.13-1595664001365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38405,DS-f59cd2b3-46a3-4265-b5ef-5a6652f66f68,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-93137231-b23c-4d46-93db-4f8061c5f4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-9552d46b-c03f-4eae-89f3-c6a307f2bf68,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-a5aa008d-1848-4481-a55a-2be0a1a90387,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-c54f7643-f61f-4189-8a79-ec22710e38a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-c92c594f-acd8-445d-92da-af7f9a5692a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-5496e1c7-ed1a-4357-b24e-4745bac3f559,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-6c111dae-6201-4179-b664-d8d663e1a8b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85421516-172.17.0.13-1595664001365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38405,DS-f59cd2b3-46a3-4265-b5ef-5a6652f66f68,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-93137231-b23c-4d46-93db-4f8061c5f4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-9552d46b-c03f-4eae-89f3-c6a307f2bf68,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-a5aa008d-1848-4481-a55a-2be0a1a90387,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-c54f7643-f61f-4189-8a79-ec22710e38a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-c92c594f-acd8-445d-92da-af7f9a5692a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-5496e1c7-ed1a-4357-b24e-4745bac3f559,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-6c111dae-6201-4179-b664-d8d663e1a8b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508103457-172.17.0.13-1595664071588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39947,DS-4460dd71-4a91-4163-9718-0b066c37822b,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-c9bffcb7-efac-441e-94bb-858e1adfe2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-572b44c9-1b00-4277-beaa-6c4a3ffd6e02,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-66e31e75-35e0-4c6c-bf79-8196046b544f,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-fbd179ec-123d-4396-a4cc-a429f6885f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-e5364eb0-ea6f-43b3-bea5-31589b3185cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-bbaf5813-552f-4112-9f18-054aa10f4bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-4b4aa2dc-a64b-4310-bb83-f0bdbd00f57d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508103457-172.17.0.13-1595664071588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39947,DS-4460dd71-4a91-4163-9718-0b066c37822b,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-c9bffcb7-efac-441e-94bb-858e1adfe2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-572b44c9-1b00-4277-beaa-6c4a3ffd6e02,DISK], DatanodeInfoWithStorage[127.0.0.1:39633,DS-66e31e75-35e0-4c6c-bf79-8196046b544f,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-fbd179ec-123d-4396-a4cc-a429f6885f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-e5364eb0-ea6f-43b3-bea5-31589b3185cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-bbaf5813-552f-4112-9f18-054aa10f4bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-4b4aa2dc-a64b-4310-bb83-f0bdbd00f57d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.window.base
component: hdfs:NameNode
v1: 3000
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296076378-172.17.0.13-1595664680813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46356,DS-47c62818-4a91-47b2-9f06-8734f06971e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-4d66251f-e11d-405c-8245-aa27d6cad2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-e1931018-3ba9-4aaf-ac12-825a5bf8184b,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-cd075db0-d483-4a9e-b9b9-daa8c94087d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-79771d09-c3e9-455e-91e4-3596c5f08a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-13f47e80-2c94-491d-8619-991ff2668502,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-79d443fc-b2b8-4c78-96f6-41f52f3cae93,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-e3ad0e0a-e038-4086-8ee7-6ac03ae5e423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296076378-172.17.0.13-1595664680813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46356,DS-47c62818-4a91-47b2-9f06-8734f06971e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-4d66251f-e11d-405c-8245-aa27d6cad2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-e1931018-3ba9-4aaf-ac12-825a5bf8184b,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-cd075db0-d483-4a9e-b9b9-daa8c94087d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-79771d09-c3e9-455e-91e4-3596c5f08a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-13f47e80-2c94-491d-8619-991ff2668502,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-79d443fc-b2b8-4c78-96f6-41f52f3cae93,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-e3ad0e0a-e038-4086-8ee7-6ac03ae5e423,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5540
