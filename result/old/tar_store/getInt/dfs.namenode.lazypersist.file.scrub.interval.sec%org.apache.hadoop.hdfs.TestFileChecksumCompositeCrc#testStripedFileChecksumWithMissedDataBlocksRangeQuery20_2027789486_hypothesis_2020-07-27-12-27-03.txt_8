reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1932892807-172.17.0.19-1595853741598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46279,DS-c6f175cc-daea-4602-a901-e7daf86d864c,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-3cac0470-13dd-48a6-9267-5ad4be020aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-a4ad8166-00b3-4c82-9930-d630d1ed1f95,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-01c04cf2-45b9-474d-aea0-ae2754e2c048,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-ccbcceaf-4557-4165-9e67-4e48801454ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-c6c662ed-ee53-47f4-a8e0-91a8beec0e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-68f2df19-0e4a-4857-8027-ccdd3ad105d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-e2595cbd-a1db-468a-bc81-ae1f8e7ca4d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1932892807-172.17.0.19-1595853741598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46279,DS-c6f175cc-daea-4602-a901-e7daf86d864c,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-3cac0470-13dd-48a6-9267-5ad4be020aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-a4ad8166-00b3-4c82-9930-d630d1ed1f95,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-01c04cf2-45b9-474d-aea0-ae2754e2c048,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-ccbcceaf-4557-4165-9e67-4e48801454ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-c6c662ed-ee53-47f4-a8e0-91a8beec0e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-68f2df19-0e4a-4857-8027-ccdd3ad105d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-e2595cbd-a1db-468a-bc81-ae1f8e7ca4d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088861827-172.17.0.19-1595854823844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40050,DS-466e8935-e71c-48e3-8160-c0bde972a14f,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-7a5016ed-0c5a-409b-972d-0b35d1790b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-a9e6884e-7d04-4097-beb7-d920c60208b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-bd800d18-931c-4e40-be35-391aef7c4382,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-7ac324fb-8229-4409-bc40-1dfaa198deba,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-70e4ef35-2e0d-44d0-a3f1-cfcd2ee43cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-3616a25d-d933-42f7-b0f2-d627e5ecdc51,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-e1d152e0-8889-452a-8b85-33d2da80745b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088861827-172.17.0.19-1595854823844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40050,DS-466e8935-e71c-48e3-8160-c0bde972a14f,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-7a5016ed-0c5a-409b-972d-0b35d1790b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-a9e6884e-7d04-4097-beb7-d920c60208b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-bd800d18-931c-4e40-be35-391aef7c4382,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-7ac324fb-8229-4409-bc40-1dfaa198deba,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-70e4ef35-2e0d-44d0-a3f1-cfcd2ee43cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-3616a25d-d933-42f7-b0f2-d627e5ecdc51,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-e1d152e0-8889-452a-8b85-33d2da80745b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430538897-172.17.0.19-1595855212290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42940,DS-535c3b31-83b5-496f-91fc-7f6373c99e61,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-7ca9070c-561a-46ec-a6ea-e5c580e4085c,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-fe403c1c-9961-44c9-822c-0126fc7684dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-0d2ee54a-99c3-4ad3-b226-b0f8142c0f59,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-b885bf42-6394-48dc-9828-20f6d513c3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-8fd66812-d946-4b3f-8fa6-a1341654e074,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-ff890281-4b27-47d5-9f7e-2c3d5c76867c,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-69070fd7-c986-48f1-b9da-f9b52901111f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430538897-172.17.0.19-1595855212290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42940,DS-535c3b31-83b5-496f-91fc-7f6373c99e61,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-7ca9070c-561a-46ec-a6ea-e5c580e4085c,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-fe403c1c-9961-44c9-822c-0126fc7684dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-0d2ee54a-99c3-4ad3-b226-b0f8142c0f59,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-b885bf42-6394-48dc-9828-20f6d513c3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-8fd66812-d946-4b3f-8fa6-a1341654e074,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-ff890281-4b27-47d5-9f7e-2c3d5c76867c,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-69070fd7-c986-48f1-b9da-f9b52901111f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510251866-172.17.0.19-1595855312572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33949,DS-8bee32b4-6467-4d87-9c8c-1cba141cfd02,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-fe05e6c5-a42b-45e9-bcdb-bdef2e68174d,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-b6ce2045-851e-408a-9342-a4be71feebd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-d7cec60d-8cef-4cb6-9dd3-a76ee3648ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-8e401af2-4b07-482f-b32e-8f0eecad1a41,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-5bcabbb2-1c2c-4b7f-ad8f-09fe436c7ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-cc2f6a2e-7b2d-4fec-aaa5-4f40ba1ca5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-0419f5e1-b27d-464f-a15a-7db54e4bafb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510251866-172.17.0.19-1595855312572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33949,DS-8bee32b4-6467-4d87-9c8c-1cba141cfd02,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-fe05e6c5-a42b-45e9-bcdb-bdef2e68174d,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-b6ce2045-851e-408a-9342-a4be71feebd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-d7cec60d-8cef-4cb6-9dd3-a76ee3648ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-8e401af2-4b07-482f-b32e-8f0eecad1a41,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-5bcabbb2-1c2c-4b7f-ad8f-09fe436c7ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-cc2f6a2e-7b2d-4fec-aaa5-4f40ba1ca5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-0419f5e1-b27d-464f-a15a-7db54e4bafb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524125305-172.17.0.19-1595855403159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40123,DS-95c63261-db88-4328-a8ae-40760f9933a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-23d6989f-16b5-4d5f-a033-c4bab36e4714,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-1f63b452-2322-416b-ab7d-08573ff22dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-117aa431-aef1-47f3-bcc1-771f43490dda,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-beeed467-a2ee-495b-a866-c9e1f71683c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-62dbf63d-22b1-4b8b-8fcd-fba0dd7e3b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-678e8882-05ca-4883-9c9b-5f7176983fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-c600bac2-c9ef-4bf6-be1e-52c85ae95866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524125305-172.17.0.19-1595855403159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40123,DS-95c63261-db88-4328-a8ae-40760f9933a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-23d6989f-16b5-4d5f-a033-c4bab36e4714,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-1f63b452-2322-416b-ab7d-08573ff22dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-117aa431-aef1-47f3-bcc1-771f43490dda,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-beeed467-a2ee-495b-a866-c9e1f71683c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-62dbf63d-22b1-4b8b-8fcd-fba0dd7e3b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-678e8882-05ca-4883-9c9b-5f7176983fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-c600bac2-c9ef-4bf6-be1e-52c85ae95866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601841151-172.17.0.19-1595855541048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37072,DS-f439e6a6-d1d5-41e6-9cd7-e401a795273f,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-c7df6429-fb74-427e-9dd0-e4643047d407,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-f60d9b59-a036-484d-84b5-9f9ef37ebe66,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-ef81e124-44b4-43ed-a2ec-280b9e7b8b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-84780a8d-e5d8-40fa-87bc-c91536bd2a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-fe47d3be-3496-493b-895a-6c3e8d7bc617,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-023e934c-de7f-43c1-be65-9678eefbdadd,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-af88c7c9-f0a2-4260-ad62-ce6136c18ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601841151-172.17.0.19-1595855541048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37072,DS-f439e6a6-d1d5-41e6-9cd7-e401a795273f,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-c7df6429-fb74-427e-9dd0-e4643047d407,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-f60d9b59-a036-484d-84b5-9f9ef37ebe66,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-ef81e124-44b4-43ed-a2ec-280b9e7b8b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-84780a8d-e5d8-40fa-87bc-c91536bd2a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-fe47d3be-3496-493b-895a-6c3e8d7bc617,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-023e934c-de7f-43c1-be65-9678eefbdadd,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-af88c7c9-f0a2-4260-ad62-ce6136c18ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237631751-172.17.0.19-1595856037196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41958,DS-57ac904b-63c9-4d4b-a9ca-627d473efba6,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-3c942575-0d4b-42f1-9831-dfb25063bcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-3c6c8b76-8a0a-4beb-b6a3-39dcd232e847,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-3cd45375-2061-409f-bc94-2ebf3371f3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-871cceae-9c53-4f9c-b8de-b04bd0e5eecb,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-1e72c68a-6a0d-42d3-b6eb-5cefe01d9fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-6863a624-3f5c-4c6c-ae14-bd127aaa9d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-3fc79ea6-0cc4-4017-9e08-62c9d2e312e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-237631751-172.17.0.19-1595856037196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41958,DS-57ac904b-63c9-4d4b-a9ca-627d473efba6,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-3c942575-0d4b-42f1-9831-dfb25063bcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-3c6c8b76-8a0a-4beb-b6a3-39dcd232e847,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-3cd45375-2061-409f-bc94-2ebf3371f3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-871cceae-9c53-4f9c-b8de-b04bd0e5eecb,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-1e72c68a-6a0d-42d3-b6eb-5cefe01d9fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-6863a624-3f5c-4c6c-ae14-bd127aaa9d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-3fc79ea6-0cc4-4017-9e08-62c9d2e312e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442885619-172.17.0.19-1595856309368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46032,DS-c3678c05-4f7f-4034-b624-58b3db644ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-c3c94b47-7f75-4751-b542-69a5828c3841,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-83214812-f517-408c-828d-ac6ff1337d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-e9e0ef58-e517-49bb-9ec3-b186295b02dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-cd31f841-6ac4-460f-be81-55a8691c472b,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-431d4b79-086f-4cfb-b3cd-0eb94aa2d77f,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-3d00d511-b131-4cad-b4fb-924fbdd2274e,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-59c72ba1-27b8-4d60-a1c3-f591193ac7f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442885619-172.17.0.19-1595856309368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46032,DS-c3678c05-4f7f-4034-b624-58b3db644ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-c3c94b47-7f75-4751-b542-69a5828c3841,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-83214812-f517-408c-828d-ac6ff1337d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-e9e0ef58-e517-49bb-9ec3-b186295b02dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-cd31f841-6ac4-460f-be81-55a8691c472b,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-431d4b79-086f-4cfb-b3cd-0eb94aa2d77f,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-3d00d511-b131-4cad-b4fb-924fbdd2274e,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-59c72ba1-27b8-4d60-a1c3-f591193ac7f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411749302-172.17.0.19-1595856549338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35950,DS-8c9fc3ce-2402-4f1b-a384-44abcc4b537e,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-a4d3a835-c237-4e82-8681-9882fd42bd89,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-c32c0556-cb3d-45bb-aa3c-7dca4110a689,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-bf98bef5-5cc2-4453-abb9-39441e14a2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-49f4343c-9c05-4797-b34c-76418bf089f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-6a87a419-2870-4e28-818b-f33100522a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-1b8efb8f-cef2-4d41-a2a9-191e235226c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-de2c0a24-5ee0-42f9-9d69-b7427d8b4126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411749302-172.17.0.19-1595856549338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35950,DS-8c9fc3ce-2402-4f1b-a384-44abcc4b537e,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-a4d3a835-c237-4e82-8681-9882fd42bd89,DISK], DatanodeInfoWithStorage[127.0.0.1:43023,DS-c32c0556-cb3d-45bb-aa3c-7dca4110a689,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-bf98bef5-5cc2-4453-abb9-39441e14a2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-49f4343c-9c05-4797-b34c-76418bf089f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-6a87a419-2870-4e28-818b-f33100522a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-1b8efb8f-cef2-4d41-a2a9-191e235226c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-de2c0a24-5ee0-42f9-9d69-b7427d8b4126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681407078-172.17.0.19-1595858734469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46658,DS-c9a7ed9e-4d83-486f-b407-d5e6a5a96241,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-528d5d86-eec6-479c-9564-1d73a2fd1c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-31e25775-01f3-468b-9bd4-6cdb2792efa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-cdc73933-fb65-47b0-89b8-1a63985af5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-a8a4496f-63af-4378-b35d-8378f4b81759,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-347706b1-f361-466e-aa2d-7645efb9b190,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-0f8816ae-5085-489c-ac5c-36291e602bed,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-9dde28f0-8b49-4766-b809-bf1593ddd54c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681407078-172.17.0.19-1595858734469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46658,DS-c9a7ed9e-4d83-486f-b407-d5e6a5a96241,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-528d5d86-eec6-479c-9564-1d73a2fd1c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-31e25775-01f3-468b-9bd4-6cdb2792efa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-cdc73933-fb65-47b0-89b8-1a63985af5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-a8a4496f-63af-4378-b35d-8378f4b81759,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-347706b1-f361-466e-aa2d-7645efb9b190,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-0f8816ae-5085-489c-ac5c-36291e602bed,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-9dde28f0-8b49-4766-b809-bf1593ddd54c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210028817-172.17.0.19-1595859447731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43943,DS-63c60098-294c-4f55-85c2-409efc385c12,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-7102443c-66ac-4469-a1f0-6a048082744b,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-97bd6a02-509d-4fbe-843b-085d502ff29f,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-a8365e20-bc41-4e02-b96b-67731d518a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-9d489128-acdd-4ebf-a911-db60460a0249,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-de79546c-6365-466a-acb8-8a3bf85a8e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-15f7f922-44d7-4800-b726-dff6b4fc37aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-8883a702-d2ac-4eab-9b5d-0e659153fe54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210028817-172.17.0.19-1595859447731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43943,DS-63c60098-294c-4f55-85c2-409efc385c12,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-7102443c-66ac-4469-a1f0-6a048082744b,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-97bd6a02-509d-4fbe-843b-085d502ff29f,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-a8365e20-bc41-4e02-b96b-67731d518a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-9d489128-acdd-4ebf-a911-db60460a0249,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-de79546c-6365-466a-acb8-8a3bf85a8e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-15f7f922-44d7-4800-b726-dff6b4fc37aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-8883a702-d2ac-4eab-9b5d-0e659153fe54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6911
