reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922024004-172.17.0.20-1596007981971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37390,DS-fb776693-08c8-45fe-94c6-1cf1f4b5c57e,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-5b3d893e-ceb9-454b-bc26-c338dfa15ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-06f3c15e-128d-4856-84d5-064aa3fd4b35,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-9a444502-c2e5-4065-bc46-a9c351ae81b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-39593015-97a2-4fdf-a631-3e3848af772a,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-3ba5e731-65ae-4107-8487-d5ecf27dcf67,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-8dfe9b82-0042-4d50-b7c4-202d852ebc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-5a89dc43-0349-43a6-b7b6-74ad62299f0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922024004-172.17.0.20-1596007981971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37390,DS-fb776693-08c8-45fe-94c6-1cf1f4b5c57e,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-5b3d893e-ceb9-454b-bc26-c338dfa15ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-06f3c15e-128d-4856-84d5-064aa3fd4b35,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-9a444502-c2e5-4065-bc46-a9c351ae81b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-39593015-97a2-4fdf-a631-3e3848af772a,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-3ba5e731-65ae-4107-8487-d5ecf27dcf67,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-8dfe9b82-0042-4d50-b7c4-202d852ebc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-5a89dc43-0349-43a6-b7b6-74ad62299f0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336403723-172.17.0.20-1596008105589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46817,DS-6a13a347-fd59-48c3-b8a6-bf4fd1d78f73,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-614603be-f8af-4f31-ba80-ac7e58d9d2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-301c57d5-8cfd-434e-87c2-c877a2811290,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-b0ae9f28-945b-4880-b0cb-f80d4c6a7fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-efbe61b4-9880-401c-8470-1e3ac4728b03,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-0c6ada84-8a14-4240-84ca-d92f5819770c,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-31c85d7a-8708-47e3-9609-3c1180597ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-1e1cbe57-d25a-48f1-99a5-c074e307ad88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336403723-172.17.0.20-1596008105589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46817,DS-6a13a347-fd59-48c3-b8a6-bf4fd1d78f73,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-614603be-f8af-4f31-ba80-ac7e58d9d2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-301c57d5-8cfd-434e-87c2-c877a2811290,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-b0ae9f28-945b-4880-b0cb-f80d4c6a7fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38852,DS-efbe61b4-9880-401c-8470-1e3ac4728b03,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-0c6ada84-8a14-4240-84ca-d92f5819770c,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-31c85d7a-8708-47e3-9609-3c1180597ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-1e1cbe57-d25a-48f1-99a5-c074e307ad88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634659829-172.17.0.20-1596008219153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42073,DS-15661268-28e0-4094-a2f5-1f86a5241aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-b50f83bb-ffbd-4fa6-9230-7083eba8b5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-425f618a-4a22-4917-9f5d-a1bce7cee837,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-9a6f353a-ae1f-4e15-ab46-5b796ad63251,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-c929dde5-2b79-481a-883c-a54eb498aed6,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-646b6965-833a-42ad-ba9a-b188dd00cdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-251069f6-f15e-4daf-9ea2-b3ee89ef7394,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-bf544fb8-bfc9-43ef-8685-48b3aeef8cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634659829-172.17.0.20-1596008219153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42073,DS-15661268-28e0-4094-a2f5-1f86a5241aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-b50f83bb-ffbd-4fa6-9230-7083eba8b5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38837,DS-425f618a-4a22-4917-9f5d-a1bce7cee837,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-9a6f353a-ae1f-4e15-ab46-5b796ad63251,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-c929dde5-2b79-481a-883c-a54eb498aed6,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-646b6965-833a-42ad-ba9a-b188dd00cdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-251069f6-f15e-4daf-9ea2-b3ee89ef7394,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-bf544fb8-bfc9-43ef-8685-48b3aeef8cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52330651-172.17.0.20-1596008335470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37088,DS-1cf467ab-e2c5-4d6e-b527-9549d284cd32,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-d70a8097-8f1c-4290-8165-4ed075be4028,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-d2e8a11e-3b07-4997-be52-aee47fc199a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-86906580-650b-487b-bcdd-7ae878a02fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-87ea7c75-faaa-45e7-9e44-007123656fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-a82f81f2-b8ef-4840-8c3b-980ca8237200,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-f3147cb2-1ef4-42db-8f06-213f2ee79855,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-826d6035-24ea-407e-961e-0ffa2cd39ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52330651-172.17.0.20-1596008335470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37088,DS-1cf467ab-e2c5-4d6e-b527-9549d284cd32,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-d70a8097-8f1c-4290-8165-4ed075be4028,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-d2e8a11e-3b07-4997-be52-aee47fc199a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-86906580-650b-487b-bcdd-7ae878a02fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-87ea7c75-faaa-45e7-9e44-007123656fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-a82f81f2-b8ef-4840-8c3b-980ca8237200,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-f3147cb2-1ef4-42db-8f06-213f2ee79855,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-826d6035-24ea-407e-961e-0ffa2cd39ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301354133-172.17.0.20-1596008533833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38265,DS-b0048d69-b098-4649-b615-b12348cac1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-8e24a9d0-ecc7-44e9-bcde-2b8e3701e392,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-d83db9d7-57ce-47b3-9fc5-5e2384a7983e,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-55e86338-6608-47a6-a9fb-ff047362c98a,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-b7121213-b9c5-4c70-a14a-4de74f29bb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-9c08e6e7-796a-484d-9025-30d5c869a4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-acf6dfcc-c6d4-4271-84a9-0a88b4ec090e,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-56739a4b-208c-4ac2-87ec-0cf2ff897c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301354133-172.17.0.20-1596008533833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38265,DS-b0048d69-b098-4649-b615-b12348cac1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-8e24a9d0-ecc7-44e9-bcde-2b8e3701e392,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-d83db9d7-57ce-47b3-9fc5-5e2384a7983e,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-55e86338-6608-47a6-a9fb-ff047362c98a,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-b7121213-b9c5-4c70-a14a-4de74f29bb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-9c08e6e7-796a-484d-9025-30d5c869a4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-acf6dfcc-c6d4-4271-84a9-0a88b4ec090e,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-56739a4b-208c-4ac2-87ec-0cf2ff897c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592334192-172.17.0.20-1596008988552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34293,DS-e8715343-d12d-49cf-a9a6-b81ed3398f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-9bc3719d-0615-4603-ae2b-b9cfbea40bac,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-bfa0e85f-51fa-44ca-b5b3-636156fd8886,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-12816651-1b57-4506-b5bc-1f9a26bba73c,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-4f0d7642-5556-4dc0-8306-dee204d867e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-f06ac0ba-8d07-4ef4-a9c4-297a02a8792a,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-860bd79a-7f34-48aa-9d7c-8982a42ba210,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-58b66383-f987-4412-9f4c-096f3958509a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592334192-172.17.0.20-1596008988552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34293,DS-e8715343-d12d-49cf-a9a6-b81ed3398f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39340,DS-9bc3719d-0615-4603-ae2b-b9cfbea40bac,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-bfa0e85f-51fa-44ca-b5b3-636156fd8886,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-12816651-1b57-4506-b5bc-1f9a26bba73c,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-4f0d7642-5556-4dc0-8306-dee204d867e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-f06ac0ba-8d07-4ef4-a9c4-297a02a8792a,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-860bd79a-7f34-48aa-9d7c-8982a42ba210,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-58b66383-f987-4412-9f4c-096f3958509a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1076499975-172.17.0.20-1596009054369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33837,DS-0c95f203-9f80-4c01-b757-5cb7acc929b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-478af786-807a-487c-b174-2538e72633ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-3893286e-b0df-4147-b4a2-9b38bd5212cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-a4ab619f-e2f7-4bdb-a75f-df32d26aeefa,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-8d44e5cd-1151-4c66-8312-4f2ba8628064,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-bb4c346c-50cf-4bfa-85f0-50fe758291dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-58f83752-eb93-4afb-ac5a-330b1b710f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-3b9dc017-356f-48e2-af86-cdc0727bc790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1076499975-172.17.0.20-1596009054369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33837,DS-0c95f203-9f80-4c01-b757-5cb7acc929b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-478af786-807a-487c-b174-2538e72633ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-3893286e-b0df-4147-b4a2-9b38bd5212cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-a4ab619f-e2f7-4bdb-a75f-df32d26aeefa,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-8d44e5cd-1151-4c66-8312-4f2ba8628064,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-bb4c346c-50cf-4bfa-85f0-50fe758291dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-58f83752-eb93-4afb-ac5a-330b1b710f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-3b9dc017-356f-48e2-af86-cdc0727bc790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-337385228-172.17.0.20-1596009373077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36944,DS-d9d09e3d-ecf5-4463-b93a-9c53a5ea8217,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-31863a92-f916-4514-8b01-4b4c391779cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-3fa85073-68b5-4863-8627-b4bbba5f55df,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-f2eff31b-2172-4a17-8511-9ec7254b2d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-3f2b3931-de58-4105-985e-ab866ecd0ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-81cb3316-5be7-4635-8b25-5d273b97194d,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-0efbd8d0-2870-4950-be6c-a5ab62b552c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-9c913901-71d4-47bc-af3f-43d75d800d75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-337385228-172.17.0.20-1596009373077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36944,DS-d9d09e3d-ecf5-4463-b93a-9c53a5ea8217,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-31863a92-f916-4514-8b01-4b4c391779cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-3fa85073-68b5-4863-8627-b4bbba5f55df,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-f2eff31b-2172-4a17-8511-9ec7254b2d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-3f2b3931-de58-4105-985e-ab866ecd0ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-81cb3316-5be7-4635-8b25-5d273b97194d,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-0efbd8d0-2870-4950-be6c-a5ab62b552c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-9c913901-71d4-47bc-af3f-43d75d800d75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197477543-172.17.0.20-1596009410368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-0805ffed-ec08-4507-92c3-f81243bf2379,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-65d3f408-55cc-48f2-b40c-cdaf2794ec94,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-7aa3586a-77da-42ae-a22f-81677f84ce14,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-13efc656-4808-46a9-a075-1c638167776f,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-eb281efb-6291-4a54-9b8e-9a6dad319e31,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-596801be-f583-49d8-bf46-caf5448a894d,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-fb076436-bc47-4f9e-b991-d61efc406f93,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-897caba7-e4eb-40cb-9bcc-409e0d49b687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197477543-172.17.0.20-1596009410368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41705,DS-0805ffed-ec08-4507-92c3-f81243bf2379,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-65d3f408-55cc-48f2-b40c-cdaf2794ec94,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-7aa3586a-77da-42ae-a22f-81677f84ce14,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-13efc656-4808-46a9-a075-1c638167776f,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-eb281efb-6291-4a54-9b8e-9a6dad319e31,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-596801be-f583-49d8-bf46-caf5448a894d,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-fb076436-bc47-4f9e-b991-d61efc406f93,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-897caba7-e4eb-40cb-9bcc-409e0d49b687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411043208-172.17.0.20-1596009471802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43618,DS-b24ac410-ed79-490c-baca-851576337efb,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-bc286e9f-e8cd-4288-89cc-365940f04148,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-038b73d4-f277-40b6-8eca-85a2176b874d,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-0185fbc3-6266-42ed-a42f-31199f390e66,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-d4944ca2-ca54-4cd4-9f55-ebbc1d2c3d24,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-579a6569-9948-430f-a5bc-0fdca4ac8192,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-fe05f1d5-05f0-4633-b15c-0cf540eb7b85,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-b63e8651-31ab-488d-ac9c-cad53b0ec19c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411043208-172.17.0.20-1596009471802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43618,DS-b24ac410-ed79-490c-baca-851576337efb,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-bc286e9f-e8cd-4288-89cc-365940f04148,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-038b73d4-f277-40b6-8eca-85a2176b874d,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-0185fbc3-6266-42ed-a42f-31199f390e66,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-d4944ca2-ca54-4cd4-9f55-ebbc1d2c3d24,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-579a6569-9948-430f-a5bc-0fdca4ac8192,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-fe05f1d5-05f0-4633-b15c-0cf540eb7b85,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-b63e8651-31ab-488d-ac9c-cad53b0ec19c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91750327-172.17.0.20-1596010171038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34082,DS-d1848d28-5a50-4907-a392-099131315869,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-13b2c8ea-4e08-4de1-b30a-898b78b66e30,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-480d3271-8b05-41e9-87ab-5ea9f2e0ac26,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-78c6838d-570f-4df2-a4d1-c81f4badf7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-1e330eb8-1154-4f0b-8072-9fcd38b8d534,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-54e0f0c1-afb6-4b95-b206-bd7ca791d4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-f879b854-3ff6-498b-9f30-f2279ed0bcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-86130ac0-d728-4410-820a-52811c7b84ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91750327-172.17.0.20-1596010171038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34082,DS-d1848d28-5a50-4907-a392-099131315869,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-13b2c8ea-4e08-4de1-b30a-898b78b66e30,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-480d3271-8b05-41e9-87ab-5ea9f2e0ac26,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-78c6838d-570f-4df2-a4d1-c81f4badf7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-1e330eb8-1154-4f0b-8072-9fcd38b8d534,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-54e0f0c1-afb6-4b95-b206-bd7ca791d4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-f879b854-3ff6-498b-9f30-f2279ed0bcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-86130ac0-d728-4410-820a-52811c7b84ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788062660-172.17.0.20-1596010349019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46592,DS-ef7c277d-ab7d-463e-8f23-0ef06c1520f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-87ae5211-7ecd-446b-885b-8fd7f1879e11,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-d00d4b3e-26fd-4351-b622-e9dd0423207a,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-6d2d7b70-b5e9-48b6-8f89-486486d66b78,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-1d6dfc9a-5fd7-4209-bcff-92218bc72916,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-73cfde61-7dfa-47e6-8b3f-98abcdf6d722,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-a5118c5c-e0e9-452b-bda3-5402e1c8fc91,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-e48ec72f-70a5-4647-ae3e-9e13a1d62656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788062660-172.17.0.20-1596010349019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46592,DS-ef7c277d-ab7d-463e-8f23-0ef06c1520f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-87ae5211-7ecd-446b-885b-8fd7f1879e11,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-d00d4b3e-26fd-4351-b622-e9dd0423207a,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-6d2d7b70-b5e9-48b6-8f89-486486d66b78,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-1d6dfc9a-5fd7-4209-bcff-92218bc72916,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-73cfde61-7dfa-47e6-8b3f-98abcdf6d722,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-a5118c5c-e0e9-452b-bda3-5402e1c8fc91,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-e48ec72f-70a5-4647-ae3e-9e13a1d62656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983758866-172.17.0.20-1596010414537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45528,DS-0a6107e9-ed66-496e-9168-3e4bec6bd623,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-e41e8c1f-d3bf-4ee1-8aca-8b2e3854051a,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-a81c23f8-63c3-4193-9053-03eb5a5ed30c,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-fe6ac0aa-6e72-4e54-9cd2-71bd66aeac59,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-29580abc-b476-4d9c-b347-61e2913405b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-b6525d88-0724-4f01-844a-8141c79266ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-6a1c7c9d-1db0-4078-8253-01a6251ee22b,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-d211b5ae-4abf-4a2c-9a82-0948462cb65e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983758866-172.17.0.20-1596010414537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45528,DS-0a6107e9-ed66-496e-9168-3e4bec6bd623,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-e41e8c1f-d3bf-4ee1-8aca-8b2e3854051a,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-a81c23f8-63c3-4193-9053-03eb5a5ed30c,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-fe6ac0aa-6e72-4e54-9cd2-71bd66aeac59,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-29580abc-b476-4d9c-b347-61e2913405b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-b6525d88-0724-4f01-844a-8141c79266ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-6a1c7c9d-1db0-4078-8253-01a6251ee22b,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-d211b5ae-4abf-4a2c-9a82-0948462cb65e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009522469-172.17.0.20-1596010658789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34625,DS-e23dc6a6-275f-4428-9f7d-422718f09f79,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-4f9169c0-64a3-45a6-9099-ff081e9bd428,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-a69d6b5f-3d34-47ee-910f-14a7c75cd902,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-caed464b-bd4b-4252-ac20-fa3b4f456a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-11b0736b-41b2-4544-8c59-e0c4bd83920c,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-d36a64bf-33a5-4ca7-be73-4d528b59d1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-593673ff-d3f7-4d83-9f0b-02784b3de1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-598a48ea-617d-4450-98a5-13c0c13cacb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009522469-172.17.0.20-1596010658789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34625,DS-e23dc6a6-275f-4428-9f7d-422718f09f79,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-4f9169c0-64a3-45a6-9099-ff081e9bd428,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-a69d6b5f-3d34-47ee-910f-14a7c75cd902,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-caed464b-bd4b-4252-ac20-fa3b4f456a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-11b0736b-41b2-4544-8c59-e0c4bd83920c,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-d36a64bf-33a5-4ca7-be73-4d528b59d1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-593673ff-d3f7-4d83-9f0b-02784b3de1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-598a48ea-617d-4450-98a5-13c0c13cacb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551029127-172.17.0.20-1596010847665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41803,DS-f78e8fb7-8f23-48b5-9912-ebf0d4099f14,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-c5bcdaa3-34a6-4193-ae4c-d595dfa598e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-4ad8dabe-a8c1-4223-b334-825de133c319,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-04c518fc-fb15-45d7-ad02-b47bea9c59cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-bfc18ff7-b3fd-48de-9b23-4b6e9bf2d932,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-4afc2f81-5a66-4438-8ff4-af7db9323777,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-233707df-a14d-4d52-bcde-78e2e798b7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-a7d613c1-e728-4299-bab0-da1cf7c14641,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551029127-172.17.0.20-1596010847665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41803,DS-f78e8fb7-8f23-48b5-9912-ebf0d4099f14,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-c5bcdaa3-34a6-4193-ae4c-d595dfa598e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-4ad8dabe-a8c1-4223-b334-825de133c319,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-04c518fc-fb15-45d7-ad02-b47bea9c59cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-bfc18ff7-b3fd-48de-9b23-4b6e9bf2d932,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-4afc2f81-5a66-4438-8ff4-af7db9323777,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-233707df-a14d-4d52-bcde-78e2e798b7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-a7d613c1-e728-4299-bab0-da1cf7c14641,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124655511-172.17.0.20-1596010946962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40522,DS-55aa2fc9-bdb5-47be-a70d-9e2678b1b74d,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-91e2c493-142a-4ec0-a835-0eeecc7acac1,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-81987b61-6954-41ca-9572-9a6cc6fec42b,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-63ffc8b4-117d-4b2a-af90-0f619244eccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-987ddd78-2486-41db-8709-6fafcc2501b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-97bb1311-ea51-4c83-9290-8ee1d4e3dc24,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-4dead67e-2415-4f3a-b023-1371b863da18,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-3a1ddc93-13dc-440b-821c-7fde2ebc19d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124655511-172.17.0.20-1596010946962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40522,DS-55aa2fc9-bdb5-47be-a70d-9e2678b1b74d,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-91e2c493-142a-4ec0-a835-0eeecc7acac1,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-81987b61-6954-41ca-9572-9a6cc6fec42b,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-63ffc8b4-117d-4b2a-af90-0f619244eccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-987ddd78-2486-41db-8709-6fafcc2501b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-97bb1311-ea51-4c83-9290-8ee1d4e3dc24,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-4dead67e-2415-4f3a-b023-1371b863da18,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-3a1ddc93-13dc-440b-821c-7fde2ebc19d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934626552-172.17.0.20-1596011266805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37905,DS-9a159852-4a41-4669-8d41-93b9110c3f29,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-2a8ad3b5-352a-4349-9660-cf771af7e7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-b2a5e1fe-faa6-4995-8a0d-ffe0b2bab502,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-5a2f8557-fd8c-48c1-a551-39896ff7f868,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-eac1a722-4da0-4118-a53e-908a51cbc5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-3bd3a446-9a83-4306-9cb7-4e1805a33f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-5e2d3d6b-637e-4140-b96e-269e7d360179,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-81858bbc-776d-43c5-a4e3-eecf7fab3aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934626552-172.17.0.20-1596011266805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37905,DS-9a159852-4a41-4669-8d41-93b9110c3f29,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-2a8ad3b5-352a-4349-9660-cf771af7e7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-b2a5e1fe-faa6-4995-8a0d-ffe0b2bab502,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-5a2f8557-fd8c-48c1-a551-39896ff7f868,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-eac1a722-4da0-4118-a53e-908a51cbc5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-3bd3a446-9a83-4306-9cb7-4e1805a33f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-5e2d3d6b-637e-4140-b96e-269e7d360179,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-81858bbc-776d-43c5-a4e3-eecf7fab3aca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900509570-172.17.0.20-1596011505590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44343,DS-f2b176aa-4ec7-466d-b1b5-fdea9322517f,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-7e6b4520-03f7-4bda-b79c-d64744492e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-ab29c610-8b84-462f-abaf-b05458f59f33,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-cedb5e01-129f-4bcb-bf97-a19612fb2c22,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-6bcc3ada-3b23-4a52-a4b1-a75b0a9b4acb,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-2e5904b8-7833-4ec9-98d0-b8f76057a7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-fde0f2e3-0c1e-45b2-b005-cb116d2713fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-28b02987-e3d7-4337-8f16-f88d1057929b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900509570-172.17.0.20-1596011505590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44343,DS-f2b176aa-4ec7-466d-b1b5-fdea9322517f,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-7e6b4520-03f7-4bda-b79c-d64744492e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-ab29c610-8b84-462f-abaf-b05458f59f33,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-cedb5e01-129f-4bcb-bf97-a19612fb2c22,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-6bcc3ada-3b23-4a52-a4b1-a75b0a9b4acb,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-2e5904b8-7833-4ec9-98d0-b8f76057a7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-fde0f2e3-0c1e-45b2-b005-cb116d2713fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-28b02987-e3d7-4337-8f16-f88d1057929b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885875330-172.17.0.20-1596011627596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40259,DS-8f05ca29-7068-477e-bfc0-646ad0b967c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-c8d59543-26cb-4a26-993c-99a501433379,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-c510be7f-8b07-495a-bd77-f68a350c2e42,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-3713dc56-bd26-4287-b77e-6c5945d6f0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-d247592b-48dc-4f80-99dc-78fe821899f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-277070d2-aa67-4421-bd7c-2647b57db7db,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-7f037b0f-829e-4e5b-944d-e14da367a24b,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-67c05911-5a45-41bd-b4b5-520978f15dae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885875330-172.17.0.20-1596011627596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40259,DS-8f05ca29-7068-477e-bfc0-646ad0b967c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-c8d59543-26cb-4a26-993c-99a501433379,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-c510be7f-8b07-495a-bd77-f68a350c2e42,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-3713dc56-bd26-4287-b77e-6c5945d6f0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-d247592b-48dc-4f80-99dc-78fe821899f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35463,DS-277070d2-aa67-4421-bd7c-2647b57db7db,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-7f037b0f-829e-4e5b-944d-e14da367a24b,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-67c05911-5a45-41bd-b4b5-520978f15dae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-204163800-172.17.0.20-1596011753353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46577,DS-5b167d20-8960-4cdf-a315-592b13ad518c,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-fbdf5ffc-e603-4dec-b887-3ee818a96b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-38641cae-660d-4ee0-8776-88cea4ae5365,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-dd0f7aa2-0a36-4616-9038-d3e7218f0afa,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-7906c7bf-93d2-424d-8d8b-a56905f16124,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-0d81c97c-b6c3-42a2-a3e8-a346677e894a,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-3dca9168-646e-4663-8f6b-9e98c61972e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-b14b5af4-343a-43ef-8684-54d7975d89ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-204163800-172.17.0.20-1596011753353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46577,DS-5b167d20-8960-4cdf-a315-592b13ad518c,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-fbdf5ffc-e603-4dec-b887-3ee818a96b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-38641cae-660d-4ee0-8776-88cea4ae5365,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-dd0f7aa2-0a36-4616-9038-d3e7218f0afa,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-7906c7bf-93d2-424d-8d8b-a56905f16124,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-0d81c97c-b6c3-42a2-a3e8-a346677e894a,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-3dca9168-646e-4663-8f6b-9e98c61972e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-b14b5af4-343a-43ef-8684-54d7975d89ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642742345-172.17.0.20-1596011782267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-b35df436-ee84-4b78-80d5-7c16ee724851,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-6014288c-e794-4c82-a53a-3bd4ef04aa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-7fd64aae-2115-4a30-ac7f-5a6f4540b61c,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-34a890b8-7bc8-4054-9770-5e17924402ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-e2f90583-143b-4772-91fa-c95df827ef46,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-9c942b2a-c9f0-4192-b214-28320a74e034,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-4fc5e654-29ee-47b5-a2e2-0a031c87d3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-7835eea5-4f6e-48e5-8a05-61c32013659c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642742345-172.17.0.20-1596011782267:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36334,DS-b35df436-ee84-4b78-80d5-7c16ee724851,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-6014288c-e794-4c82-a53a-3bd4ef04aa2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-7fd64aae-2115-4a30-ac7f-5a6f4540b61c,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-34a890b8-7bc8-4054-9770-5e17924402ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-e2f90583-143b-4772-91fa-c95df827ef46,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-9c942b2a-c9f0-4192-b214-28320a74e034,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-4fc5e654-29ee-47b5-a2e2-0a031c87d3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-7835eea5-4f6e-48e5-8a05-61c32013659c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-779953545-172.17.0.20-1596011877123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44337,DS-ebd4a1f0-24fe-4118-ad31-0cfd53a07f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-16991ace-c33a-4502-b50c-dba0da9c4706,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-60247fa4-8749-49ac-af2e-955f1b3d3622,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-96b9e4f7-d73a-4461-aff6-7510221ced03,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-a8b43d0c-4b6b-4a7d-9eeb-0b2ccb3d8284,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-021cf3e0-e968-402f-93f0-97f662dec7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-a268d656-a5bc-4d1b-8ce2-aad9f3b90b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-9dd806c0-5826-4fe4-b936-1e3c9cbec2c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-779953545-172.17.0.20-1596011877123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44337,DS-ebd4a1f0-24fe-4118-ad31-0cfd53a07f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-16991ace-c33a-4502-b50c-dba0da9c4706,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-60247fa4-8749-49ac-af2e-955f1b3d3622,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-96b9e4f7-d73a-4461-aff6-7510221ced03,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-a8b43d0c-4b6b-4a7d-9eeb-0b2ccb3d8284,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-021cf3e0-e968-402f-93f0-97f662dec7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-a268d656-a5bc-4d1b-8ce2-aad9f3b90b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-9dd806c0-5826-4fe4-b936-1e3c9cbec2c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592683492-172.17.0.20-1596011914133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45071,DS-46a38fbf-ac9d-4036-8f25-8411389135c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-6e4b8530-a84e-4e4c-a276-de7999e04ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-d1192777-eb93-436d-9c65-10bd7073a00c,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-a8c4f56c-7f7b-40e0-a6a0-5e88328622ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-877e91f5-ed58-400b-8e50-89a185df46ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-83171bfe-9a8a-4c9a-9514-c0238b7a2f59,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-39faa100-3e0f-4645-9487-8f2c7d84430b,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-f2198f70-d555-43ef-b7be-e6b3e06a6732,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1592683492-172.17.0.20-1596011914133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45071,DS-46a38fbf-ac9d-4036-8f25-8411389135c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-6e4b8530-a84e-4e4c-a276-de7999e04ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-d1192777-eb93-436d-9c65-10bd7073a00c,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-a8c4f56c-7f7b-40e0-a6a0-5e88328622ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-877e91f5-ed58-400b-8e50-89a185df46ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-83171bfe-9a8a-4c9a-9514-c0238b7a2f59,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-39faa100-3e0f-4645-9487-8f2c7d84430b,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-f2198f70-d555-43ef-b7be-e6b3e06a6732,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155519977-172.17.0.20-1596011976566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38496,DS-5884d78c-f9ea-425d-b42f-590d9115a045,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-d85c5440-6bf5-4bce-842d-24e989199108,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-0c5fffa3-0cc2-493e-9aec-ebe148fde7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-814eca11-200f-4cf6-b0c1-5c84aec979de,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-5cb004b8-1bdc-4acb-84f6-88c8fca1a5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-158b637f-8e28-4aef-93b7-c9869f9cac22,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-95aae3c8-a04f-4521-9f12-0a76614d5a68,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-7524b9c0-5cf7-4326-9a41-ce1130405fa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155519977-172.17.0.20-1596011976566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38496,DS-5884d78c-f9ea-425d-b42f-590d9115a045,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-d85c5440-6bf5-4bce-842d-24e989199108,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-0c5fffa3-0cc2-493e-9aec-ebe148fde7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-814eca11-200f-4cf6-b0c1-5c84aec979de,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-5cb004b8-1bdc-4acb-84f6-88c8fca1a5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-158b637f-8e28-4aef-93b7-c9869f9cac22,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-95aae3c8-a04f-4521-9f12-0a76614d5a68,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-7524b9c0-5cf7-4326-9a41-ce1130405fa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-407059466-172.17.0.20-1596012095964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40093,DS-458fbca1-d046-47ee-ba22-77f14209cc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-50769db0-d097-4045-bd02-fb69e2422c41,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-7ac21b32-c5e4-45f1-88fe-6b5ceda050c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-769b8cbb-8af1-49aa-95b1-5a42e467e71f,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-8f58ec04-a4b7-4e81-8bf2-27f1059afaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-15a57025-afa6-42c0-acf9-ad1dea2158f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-fa986b9f-4fc5-4bac-bced-9f067a5cd349,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-3172868b-23ad-474a-bd6f-c6d58635c124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-407059466-172.17.0.20-1596012095964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40093,DS-458fbca1-d046-47ee-ba22-77f14209cc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-50769db0-d097-4045-bd02-fb69e2422c41,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-7ac21b32-c5e4-45f1-88fe-6b5ceda050c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-769b8cbb-8af1-49aa-95b1-5a42e467e71f,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-8f58ec04-a4b7-4e81-8bf2-27f1059afaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-15a57025-afa6-42c0-acf9-ad1dea2158f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-fa986b9f-4fc5-4bac-bced-9f067a5cd349,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-3172868b-23ad-474a-bd6f-c6d58635c124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1366545309-172.17.0.20-1596012127352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35026,DS-0f1ebba2-581a-469a-b9d1-0cbfc518aa71,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-279abd9f-17fa-4d3e-9a64-f345679ed399,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-578adc2a-7378-46b6-9aef-e20af7d7a1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-6a89e791-88ac-4bf1-a9c2-603e103eac15,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-c8bd15ae-d8cc-4ace-99d5-583b900dc97d,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-e4109885-cd73-424a-9418-65f5f0e68e17,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-19d9222d-cb5a-4329-953a-424085739aee,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-7d719d0f-70e7-4855-9899-b0feb5cf9639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1366545309-172.17.0.20-1596012127352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35026,DS-0f1ebba2-581a-469a-b9d1-0cbfc518aa71,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-279abd9f-17fa-4d3e-9a64-f345679ed399,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-578adc2a-7378-46b6-9aef-e20af7d7a1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-6a89e791-88ac-4bf1-a9c2-603e103eac15,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-c8bd15ae-d8cc-4ace-99d5-583b900dc97d,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-e4109885-cd73-424a-9418-65f5f0e68e17,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-19d9222d-cb5a-4329-953a-424085739aee,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-7d719d0f-70e7-4855-9899-b0feb5cf9639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833606073-172.17.0.20-1596012153670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-54d015bd-42c8-4784-b604-941483edaee4,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-9a33bfe3-cc70-48dc-bf7b-936fc102634c,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-b96c94f5-fa7f-467c-bb20-4d6a06fccd33,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-f18d01d0-5d3c-49e5-8d9b-5ac8dd146b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-99409065-4739-4e45-adc4-41c3c768a8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-a31d7c97-b16b-4899-afb5-23ad16559943,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-f38ff1a6-d962-42c4-804c-d629a9403ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-1c67d70c-d24b-4bde-9ac0-c4f3b2201d79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-833606073-172.17.0.20-1596012153670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-54d015bd-42c8-4784-b604-941483edaee4,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-9a33bfe3-cc70-48dc-bf7b-936fc102634c,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-b96c94f5-fa7f-467c-bb20-4d6a06fccd33,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-f18d01d0-5d3c-49e5-8d9b-5ac8dd146b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-99409065-4739-4e45-adc4-41c3c768a8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-a31d7c97-b16b-4899-afb5-23ad16559943,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-f38ff1a6-d962-42c4-804c-d629a9403ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-1c67d70c-d24b-4bde-9ac0-c4f3b2201d79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136027515-172.17.0.20-1596012304429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44641,DS-ff19e544-49a1-4455-8fbb-a4da607e86fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-4ecff564-259d-4e09-ab7f-d29445dee949,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-034a61d4-e464-4de5-abdc-641320f52731,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-dbf7c129-dd3f-45ac-9736-7e6faa5b8133,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-a34a6029-ff28-4fb4-aa1e-8e0f9e4b6cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-b8f0a434-3859-4ff3-b5da-b79e30ad7aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-3f9f7a8b-a5b6-471c-b303-ad3be9d8614b,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-3bba4201-3951-4f6f-9fca-52d73de40b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136027515-172.17.0.20-1596012304429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44641,DS-ff19e544-49a1-4455-8fbb-a4da607e86fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-4ecff564-259d-4e09-ab7f-d29445dee949,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-034a61d4-e464-4de5-abdc-641320f52731,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-dbf7c129-dd3f-45ac-9736-7e6faa5b8133,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-a34a6029-ff28-4fb4-aa1e-8e0f9e4b6cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-b8f0a434-3859-4ff3-b5da-b79e30ad7aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-3f9f7a8b-a5b6-471c-b303-ad3be9d8614b,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-3bba4201-3951-4f6f-9fca-52d73de40b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721371486-172.17.0.20-1596012453331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39602,DS-9878b05a-848d-4fb2-ab60-1bc13e993e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-489ed423-751a-4468-85ae-143ccd5184de,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-6079a72a-f2be-42da-9ec5-d168296d69f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-291cc50c-b45a-4083-8612-265189def3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-cf95efa8-ea9d-4d35-9c47-170219b1bf24,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-1e526ab0-0bf2-4611-b4b8-0cec099f97dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-fa6c05c0-4008-4850-8843-b27355088761,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-06d9774f-08c8-477e-b3f4-88a07cfaf46b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721371486-172.17.0.20-1596012453331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39602,DS-9878b05a-848d-4fb2-ab60-1bc13e993e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-489ed423-751a-4468-85ae-143ccd5184de,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-6079a72a-f2be-42da-9ec5-d168296d69f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-291cc50c-b45a-4083-8612-265189def3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-cf95efa8-ea9d-4d35-9c47-170219b1bf24,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-1e526ab0-0bf2-4611-b4b8-0cec099f97dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-fa6c05c0-4008-4850-8843-b27355088761,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-06d9774f-08c8-477e-b3f4-88a07cfaf46b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 4769
