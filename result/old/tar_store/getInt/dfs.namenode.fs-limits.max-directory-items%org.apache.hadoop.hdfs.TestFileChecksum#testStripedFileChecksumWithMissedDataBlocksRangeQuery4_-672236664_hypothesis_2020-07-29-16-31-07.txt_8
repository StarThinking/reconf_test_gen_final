reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339409741-172.17.0.19-1596040333956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38421,DS-de7d54fa-9241-4e2c-90fe-2c15f5838cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-00f30748-acb8-4670-84e5-f81f2a663a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-3d1d59b4-99d2-42d0-887f-34d73bfec3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-ca8178b4-8f08-4920-86eb-e0ab7b70ba5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-2d314ac1-9030-494c-b385-c7ff4d9d05bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-1f153581-a6ee-4aea-ac88-fe87b79996c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-a8f83ba8-f165-4fb6-a2d9-2aeb9e4dd629,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-b3b92a96-2e64-4268-9421-08120ac81e64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339409741-172.17.0.19-1596040333956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38421,DS-de7d54fa-9241-4e2c-90fe-2c15f5838cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-00f30748-acb8-4670-84e5-f81f2a663a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-3d1d59b4-99d2-42d0-887f-34d73bfec3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-ca8178b4-8f08-4920-86eb-e0ab7b70ba5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-2d314ac1-9030-494c-b385-c7ff4d9d05bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-1f153581-a6ee-4aea-ac88-fe87b79996c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-a8f83ba8-f165-4fb6-a2d9-2aeb9e4dd629,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-b3b92a96-2e64-4268-9421-08120ac81e64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224789265-172.17.0.19-1596040422494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40661,DS-75b0ca78-a311-457e-b487-387dafe84278,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-375b32c3-08ac-4dd1-9e55-e11af0fa38a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-ea16e891-12db-4bf0-849e-7de991a0345e,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-7c5df179-c53c-4001-83d8-9e4bb591e33d,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-759a865d-4c3b-4a1e-99fe-823fe9973644,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-0a91f7d6-a7c4-4da3-842b-8d96eeea92b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-0527a7b2-7d51-475f-8989-57228d850bad,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-a4e45552-f8e2-4840-93a5-bb69d0ed0586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224789265-172.17.0.19-1596040422494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40661,DS-75b0ca78-a311-457e-b487-387dafe84278,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-375b32c3-08ac-4dd1-9e55-e11af0fa38a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-ea16e891-12db-4bf0-849e-7de991a0345e,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-7c5df179-c53c-4001-83d8-9e4bb591e33d,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-759a865d-4c3b-4a1e-99fe-823fe9973644,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-0a91f7d6-a7c4-4da3-842b-8d96eeea92b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-0527a7b2-7d51-475f-8989-57228d850bad,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-a4e45552-f8e2-4840-93a5-bb69d0ed0586,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553125853-172.17.0.19-1596040698702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42332,DS-ef3588ff-eb69-41d7-b608-dcec544aec3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-0104b3ae-32a4-4f05-8c49-3804f38a9627,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-12400bbb-861f-47c0-bf76-32c5d51368d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-d6ae6adb-d57f-4ae3-be58-836af40eb915,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-5bccb409-5843-4fb4-8a6c-a8091be6894b,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-a25c703a-272f-4b4c-a521-deeaaaa03c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-62d891a1-8cfe-41b0-a6e6-56a9656775d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-4b2aef18-4a1b-4089-8dd3-a75a9d16b38d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553125853-172.17.0.19-1596040698702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42332,DS-ef3588ff-eb69-41d7-b608-dcec544aec3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-0104b3ae-32a4-4f05-8c49-3804f38a9627,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-12400bbb-861f-47c0-bf76-32c5d51368d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-d6ae6adb-d57f-4ae3-be58-836af40eb915,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-5bccb409-5843-4fb4-8a6c-a8091be6894b,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-a25c703a-272f-4b4c-a521-deeaaaa03c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-62d891a1-8cfe-41b0-a6e6-56a9656775d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-4b2aef18-4a1b-4089-8dd3-a75a9d16b38d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212693001-172.17.0.19-1596041090272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46826,DS-5dd6dd86-9fbb-428e-8c5d-0fbe5ce07c74,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-6563e51d-4e4a-4b9d-8ceb-596164511e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-16e534a4-0b1d-42dc-abea-87544ed6fc93,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-79056f9b-9fb1-406a-b8d9-7728efd84c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-8d63e0f9-a7c9-4a21-9928-6d8eccd4781f,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-b2f64ccb-d23d-40e0-9cd7-1df30bc71b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-390924f3-4f1a-4d9f-8169-e6dfe7a39ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-3d7c600e-3d5c-4c64-95d8-5d23826c56fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1212693001-172.17.0.19-1596041090272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46826,DS-5dd6dd86-9fbb-428e-8c5d-0fbe5ce07c74,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-6563e51d-4e4a-4b9d-8ceb-596164511e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-16e534a4-0b1d-42dc-abea-87544ed6fc93,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-79056f9b-9fb1-406a-b8d9-7728efd84c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-8d63e0f9-a7c9-4a21-9928-6d8eccd4781f,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-b2f64ccb-d23d-40e0-9cd7-1df30bc71b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-390924f3-4f1a-4d9f-8169-e6dfe7a39ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-3d7c600e-3d5c-4c64-95d8-5d23826c56fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156419663-172.17.0.19-1596042984854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35785,DS-5505276f-5895-44c2-a57f-c82609d1b10b,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-14378736-9a87-4030-a8b9-1f1e1c7d28c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-204e9262-8e6e-4bcd-b0a3-acabae022e97,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-9ac66acf-744e-4c78-8e70-38894f40f518,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-749f62fb-a70a-403d-88e8-8676158f567c,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-74eb6b18-abf9-46d4-9f66-29aa930b0be7,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-98934b8e-4a02-4768-a5ac-854319eabf18,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-50ddf04d-5dd5-4ecc-818c-f5adbe50e115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156419663-172.17.0.19-1596042984854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35785,DS-5505276f-5895-44c2-a57f-c82609d1b10b,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-14378736-9a87-4030-a8b9-1f1e1c7d28c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-204e9262-8e6e-4bcd-b0a3-acabae022e97,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-9ac66acf-744e-4c78-8e70-38894f40f518,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-749f62fb-a70a-403d-88e8-8676158f567c,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-74eb6b18-abf9-46d4-9f66-29aa930b0be7,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-98934b8e-4a02-4768-a5ac-854319eabf18,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-50ddf04d-5dd5-4ecc-818c-f5adbe50e115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115432181-172.17.0.19-1596043033755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42433,DS-812704b2-45a7-4904-91ae-7b3e5d5e994a,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-be5909b8-bf75-4bd9-878e-45832c9b101b,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-970c658c-6380-4473-a8ab-f9faf7446b65,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-3fba9eb4-fce0-4180-9af8-724b5f49845f,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-4e537935-6897-41f1-9bfa-22167a1db2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-7a8c5171-e88b-4c6a-b4a4-eb6ba2382662,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-a3a70f41-0dcc-44b1-9f03-26a7b56b246d,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-2c3b086f-1bf9-4b5b-b9d8-9ebea84937d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115432181-172.17.0.19-1596043033755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42433,DS-812704b2-45a7-4904-91ae-7b3e5d5e994a,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-be5909b8-bf75-4bd9-878e-45832c9b101b,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-970c658c-6380-4473-a8ab-f9faf7446b65,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-3fba9eb4-fce0-4180-9af8-724b5f49845f,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-4e537935-6897-41f1-9bfa-22167a1db2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-7a8c5171-e88b-4c6a-b4a4-eb6ba2382662,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-a3a70f41-0dcc-44b1-9f03-26a7b56b246d,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-2c3b086f-1bf9-4b5b-b9d8-9ebea84937d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358350098-172.17.0.19-1596044400254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44148,DS-0643d66d-84af-4bb4-b4ab-ec69cdb48567,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-9d1fc16c-ca13-442e-9077-a16fbd173090,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-da8ed641-3606-41d0-a294-f7f110c32ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-57c87777-d7d2-4b05-b8ce-78819f48523a,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-ac08f69e-9a63-4d4f-81a0-cfd7e86c9f11,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-5b6d25e0-b54e-40da-9cec-4220982aeeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-6aa9ff41-8010-4757-a8ca-4035866824c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-b0475d88-a87c-4173-b018-f18234c22612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358350098-172.17.0.19-1596044400254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44148,DS-0643d66d-84af-4bb4-b4ab-ec69cdb48567,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-9d1fc16c-ca13-442e-9077-a16fbd173090,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-da8ed641-3606-41d0-a294-f7f110c32ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-57c87777-d7d2-4b05-b8ce-78819f48523a,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-ac08f69e-9a63-4d4f-81a0-cfd7e86c9f11,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-5b6d25e0-b54e-40da-9cec-4220982aeeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-6aa9ff41-8010-4757-a8ca-4035866824c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-b0475d88-a87c-4173-b018-f18234c22612,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804793231-172.17.0.19-1596044571761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36202,DS-b0a93bc2-89f9-4ac2-9bd0-121f15465ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-3629fff8-0499-4a36-853c-129e286dc089,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-86e9798f-6a73-44fd-b037-f6a2ef710b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-3d456d75-8008-4c3a-9414-7065432b4d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-8c834fe1-cdd5-4729-ae6b-391478439812,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-1c0aea2f-486d-4688-a123-ba4ee1f7b5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-b489befa-b1c4-49b9-8505-951e4154d7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-e6f4de85-feb3-4286-884d-37c74632b711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1804793231-172.17.0.19-1596044571761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36202,DS-b0a93bc2-89f9-4ac2-9bd0-121f15465ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-3629fff8-0499-4a36-853c-129e286dc089,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-86e9798f-6a73-44fd-b037-f6a2ef710b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-3d456d75-8008-4c3a-9414-7065432b4d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-8c834fe1-cdd5-4729-ae6b-391478439812,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-1c0aea2f-486d-4688-a123-ba4ee1f7b5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-b489befa-b1c4-49b9-8505-951e4154d7e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-e6f4de85-feb3-4286-884d-37c74632b711,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994579000-172.17.0.19-1596045451476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37981,DS-5ec05018-51a1-42b4-855b-e86b8c500330,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-dd92bca0-5639-4e04-9e31-a249a4fb930d,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-54674190-b844-4387-b83f-974811360546,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-0a586f00-b611-4dd7-a71b-ca80fa051a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-fbc8de5f-5f9f-496d-801a-efd21e441374,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-282ad5f9-462e-4904-b4ed-59871f808d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-a4503ede-9d54-4170-b6a2-c31bf7cae2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-76464579-b27e-478a-b6c4-a0fe49e55996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994579000-172.17.0.19-1596045451476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37981,DS-5ec05018-51a1-42b4-855b-e86b8c500330,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-dd92bca0-5639-4e04-9e31-a249a4fb930d,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-54674190-b844-4387-b83f-974811360546,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-0a586f00-b611-4dd7-a71b-ca80fa051a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-fbc8de5f-5f9f-496d-801a-efd21e441374,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-282ad5f9-462e-4904-b4ed-59871f808d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-a4503ede-9d54-4170-b6a2-c31bf7cae2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-76464579-b27e-478a-b6c4-a0fe49e55996,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367442048-172.17.0.19-1596045564136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35441,DS-dd7e61e1-a4f9-4d80-8031-d1acb2aeb82c,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-f3aab778-e73c-4136-9a21-598ef040dd36,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-cca1da60-83d5-4aa3-8b1d-0956cda8820c,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-a7119115-e39b-40b8-aab6-b6e9205191e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-9bff024c-2af0-4fad-bfab-a4d8452039fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-9849d9df-6aca-4c47-9913-07ba2b4a103d,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-ffb8dfbf-a1e0-4a97-a296-b2ece5b85057,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-aff85827-c54a-4c0e-a2f5-06f7e777f4cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367442048-172.17.0.19-1596045564136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35441,DS-dd7e61e1-a4f9-4d80-8031-d1acb2aeb82c,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-f3aab778-e73c-4136-9a21-598ef040dd36,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-cca1da60-83d5-4aa3-8b1d-0956cda8820c,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-a7119115-e39b-40b8-aab6-b6e9205191e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-9bff024c-2af0-4fad-bfab-a4d8452039fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-9849d9df-6aca-4c47-9913-07ba2b4a103d,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-ffb8dfbf-a1e0-4a97-a296-b2ece5b85057,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-aff85827-c54a-4c0e-a2f5-06f7e777f4cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218757452-172.17.0.19-1596045642562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43316,DS-a83c141e-9fc9-42d5-9fd3-19c11a477b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-5db3c47c-5c3d-43d7-82d5-e2a096e2f6da,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-9facae8a-8952-4f04-a706-134e47d23b10,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-2fed3ff1-9f1d-4134-82d0-870d108bc6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-8e57bddd-0b23-474b-b638-0dee02dfd668,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-1ef50ccb-e255-4427-a055-0bbbf8e2ac16,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-93ab3c2d-c406-453c-bb27-aaafeb833ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-059047b5-9fde-40ea-9c38-4951c7bd5237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218757452-172.17.0.19-1596045642562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43316,DS-a83c141e-9fc9-42d5-9fd3-19c11a477b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-5db3c47c-5c3d-43d7-82d5-e2a096e2f6da,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-9facae8a-8952-4f04-a706-134e47d23b10,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-2fed3ff1-9f1d-4134-82d0-870d108bc6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-8e57bddd-0b23-474b-b638-0dee02dfd668,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-1ef50ccb-e255-4427-a055-0bbbf8e2ac16,DISK], DatanodeInfoWithStorage[127.0.0.1:42970,DS-93ab3c2d-c406-453c-bb27-aaafeb833ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-059047b5-9fde-40ea-9c38-4951c7bd5237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619719797-172.17.0.19-1596045728183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42775,DS-179c97ca-493b-48df-aeea-a8702079695c,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-6f07ad1f-40e1-4871-9d98-63303eee2acb,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-c6272dbe-aaa6-4ec0-8545-f366c1a66969,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-3183a031-5862-4d10-8899-03cf7cc6189b,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-2a607079-b060-437b-a0fa-6a23cfb9567a,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-0876cebc-fc65-4308-b132-0ad632efb5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-ff2370c8-95ab-4364-83a5-4a90def0a5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-781cd039-4d84-474b-9c98-6447538bd231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619719797-172.17.0.19-1596045728183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42775,DS-179c97ca-493b-48df-aeea-a8702079695c,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-6f07ad1f-40e1-4871-9d98-63303eee2acb,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-c6272dbe-aaa6-4ec0-8545-f366c1a66969,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-3183a031-5862-4d10-8899-03cf7cc6189b,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-2a607079-b060-437b-a0fa-6a23cfb9567a,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-0876cebc-fc65-4308-b132-0ad632efb5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-ff2370c8-95ab-4364-83a5-4a90def0a5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-781cd039-4d84-474b-9c98-6447538bd231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778386125-172.17.0.19-1596045764158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42085,DS-4c9f3eb6-e38e-40f7-aa7e-43acc995c437,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-824f7f80-b8df-4eee-8027-af8284ad47ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-f2be8d72-7b0c-4469-bd02-1a0769a173cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-c2864f19-432a-45be-ba9c-73720712bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-aaa7aa42-85de-44d7-a404-2cef78824bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-a0d0a38f-6e83-47b9-8037-f61f8a491a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-6dd04b4a-8238-4182-b9ac-6fb5cc85d017,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-4c99d250-e5d5-403a-91a8-ff317e124d0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778386125-172.17.0.19-1596045764158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42085,DS-4c9f3eb6-e38e-40f7-aa7e-43acc995c437,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-824f7f80-b8df-4eee-8027-af8284ad47ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-f2be8d72-7b0c-4469-bd02-1a0769a173cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-c2864f19-432a-45be-ba9c-73720712bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-aaa7aa42-85de-44d7-a404-2cef78824bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-a0d0a38f-6e83-47b9-8037-f61f8a491a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-6dd04b4a-8238-4182-b9ac-6fb5cc85d017,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-4c99d250-e5d5-403a-91a8-ff317e124d0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54576891-172.17.0.19-1596046298078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43836,DS-1b8af34c-8422-40a7-b4c5-e48ecf677b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-be2f2ef0-1d5b-4a44-9216-61e8aebf04cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-2bc6ee67-eee0-400a-b0ca-112e70aeb362,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-04f31c45-22ef-4892-9640-3bfeacabc0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-50a70a4f-0b04-431e-9871-fda19d92fe49,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-f1b5587d-5920-4e00-86bd-bcf32f3aeee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-7aba3653-f2ab-4fec-8583-35537c1f9af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-9661f385-eeb1-443c-b46d-add2822be0df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54576891-172.17.0.19-1596046298078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43836,DS-1b8af34c-8422-40a7-b4c5-e48ecf677b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-be2f2ef0-1d5b-4a44-9216-61e8aebf04cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-2bc6ee67-eee0-400a-b0ca-112e70aeb362,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-04f31c45-22ef-4892-9640-3bfeacabc0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-50a70a4f-0b04-431e-9871-fda19d92fe49,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-f1b5587d-5920-4e00-86bd-bcf32f3aeee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-7aba3653-f2ab-4fec-8583-35537c1f9af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-9661f385-eeb1-443c-b46d-add2822be0df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049025377-172.17.0.19-1596046563281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41358,DS-22f07e9b-5ac2-4118-bf92-85669f454b19,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-a058be28-57ca-46af-a492-3ea627da900b,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-0a4e267a-7225-44b2-8e2c-e6b8e0f918f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-9e4eda1c-7347-414e-b2ce-3dd13f7d31d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-8279a5cd-631a-45e3-b989-7b9f9225e019,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-b3c3d82c-6d10-4bd4-89fb-3b6d5350f1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-9276c86d-c30f-4d2a-a1cc-70f0bbcb1614,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-635461ce-d4e8-48d6-a1b7-d770a2e89292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049025377-172.17.0.19-1596046563281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41358,DS-22f07e9b-5ac2-4118-bf92-85669f454b19,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-a058be28-57ca-46af-a492-3ea627da900b,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-0a4e267a-7225-44b2-8e2c-e6b8e0f918f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-9e4eda1c-7347-414e-b2ce-3dd13f7d31d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-8279a5cd-631a-45e3-b989-7b9f9225e019,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-b3c3d82c-6d10-4bd4-89fb-3b6d5350f1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-9276c86d-c30f-4d2a-a1cc-70f0bbcb1614,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-635461ce-d4e8-48d6-a1b7-d770a2e89292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902470579-172.17.0.19-1596046610491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42016,DS-a1d4ffd7-1437-4851-80dc-f6ea65129418,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-8bf4a047-53e3-4aeb-b647-53f13e53b92d,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-1b4f8e16-8bd1-41b8-ba4e-2b8c85a97b97,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-87298291-fecb-4d1b-8fff-83db1a06111c,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-d41e07a4-b77b-4846-ac92-98d852b7fc80,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-a1ee53ba-02ce-44f3-9ebd-e4b7d813c924,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-3b69b21a-50a4-4991-91a0-49fbf7930d26,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-43f64a20-85eb-4024-8f94-54d12a88a8e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902470579-172.17.0.19-1596046610491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42016,DS-a1d4ffd7-1437-4851-80dc-f6ea65129418,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-8bf4a047-53e3-4aeb-b647-53f13e53b92d,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-1b4f8e16-8bd1-41b8-ba4e-2b8c85a97b97,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-87298291-fecb-4d1b-8fff-83db1a06111c,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-d41e07a4-b77b-4846-ac92-98d852b7fc80,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-a1ee53ba-02ce-44f3-9ebd-e4b7d813c924,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-3b69b21a-50a4-4991-91a0-49fbf7930d26,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-43f64a20-85eb-4024-8f94-54d12a88a8e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469858523-172.17.0.19-1596046833126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-b11550bd-3d91-4858-9945-60d8372faaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-30c0ccb8-db26-414a-a4f8-065291edad18,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-9f3ad85f-be9a-4dbf-a203-5f8f35419211,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-8ef3cd7a-f21a-4a7a-9838-9af785a39ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-0048295b-6824-406d-82cb-1750b85ef578,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-0a5a1044-7dc0-4145-963c-25762a6e7981,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-6f40466f-bc2d-4821-b435-f72d6e7e7018,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-429268a5-e7d2-462d-a52c-7e9b0d60aa43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469858523-172.17.0.19-1596046833126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-b11550bd-3d91-4858-9945-60d8372faaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-30c0ccb8-db26-414a-a4f8-065291edad18,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-9f3ad85f-be9a-4dbf-a203-5f8f35419211,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-8ef3cd7a-f21a-4a7a-9838-9af785a39ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-0048295b-6824-406d-82cb-1750b85ef578,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-0a5a1044-7dc0-4145-963c-25762a6e7981,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-6f40466f-bc2d-4821-b435-f72d6e7e7018,DISK], DatanodeInfoWithStorage[127.0.0.1:43490,DS-429268a5-e7d2-462d-a52c-7e9b0d60aa43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-directory-items
component: hdfs:NameNode
v1: 1048576
v2: 4
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39453077-172.17.0.19-1596046913644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44483,DS-efd38b9a-f942-4cd5-b732-840fb335e3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-b1db6f52-b1b9-44aa-b9b5-9340b37bce9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-8d7d2e9b-a1d5-4863-a314-8709396f7549,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-b3e1ab1a-b234-4acb-b67b-f7447ea6276a,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-b9df75c3-10cb-4ee8-9fdc-794a23bd0776,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-5451fa61-f1e0-421f-9411-7ab4490cc08f,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-8f3d9fb4-9581-444f-9311-9b2b048e3156,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-9561cd8c-eaf7-4b2f-b3b9-dc963b73323d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39453077-172.17.0.19-1596046913644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44483,DS-efd38b9a-f942-4cd5-b732-840fb335e3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-b1db6f52-b1b9-44aa-b9b5-9340b37bce9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-8d7d2e9b-a1d5-4863-a314-8709396f7549,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-b3e1ab1a-b234-4acb-b67b-f7447ea6276a,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-b9df75c3-10cb-4ee8-9fdc-794a23bd0776,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-5451fa61-f1e0-421f-9411-7ab4490cc08f,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-8f3d9fb4-9581-444f-9311-9b2b048e3156,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-9561cd8c-eaf7-4b2f-b3b9-dc963b73323d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6756
