reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-908586692-172.17.0.2-1595582246352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33608,DS-3396428a-07d7-45fc-b359-07552bc366c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-bbf8b95d-2d86-4da3-ba95-d0cb3300301f,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-0f94daea-b6ae-481c-9054-21272b35712f,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-b6057f1f-d8e4-46ab-ab67-52b49311f814,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-dadc010e-ffa9-4c5f-b2c6-5660837cad5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-b989206c-6c8a-4f90-a8b0-77f519de0ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-66c2c053-9945-49d6-a21f-37aa24f1b5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-d17ff191-b697-4571-ad0f-8f097f897ddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-908586692-172.17.0.2-1595582246352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33608,DS-3396428a-07d7-45fc-b359-07552bc366c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-bbf8b95d-2d86-4da3-ba95-d0cb3300301f,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-0f94daea-b6ae-481c-9054-21272b35712f,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-b6057f1f-d8e4-46ab-ab67-52b49311f814,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-dadc010e-ffa9-4c5f-b2c6-5660837cad5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42380,DS-b989206c-6c8a-4f90-a8b0-77f519de0ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-66c2c053-9945-49d6-a21f-37aa24f1b5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-d17ff191-b697-4571-ad0f-8f097f897ddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793663993-172.17.0.2-1595582282145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35687,DS-d7391870-1e16-441f-a270-7be802fcb0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-bc3fe2a1-e62c-4fb4-8df3-40f2a550f1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-6624a1cf-3eae-455a-8dc4-278c97b52fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-b6d7ada8-1763-44ce-a471-1293cd7e8a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-f801cde3-df15-4ec1-9685-3aa80a1577de,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-7c8fc4cb-104f-43ac-986d-b5ccea76d2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-f6b20aad-29a8-431c-8c04-b72f1882d840,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-b1e57eb5-6540-42d8-86e5-40bcbdc43203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793663993-172.17.0.2-1595582282145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35687,DS-d7391870-1e16-441f-a270-7be802fcb0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-bc3fe2a1-e62c-4fb4-8df3-40f2a550f1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-6624a1cf-3eae-455a-8dc4-278c97b52fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-b6d7ada8-1763-44ce-a471-1293cd7e8a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-f801cde3-df15-4ec1-9685-3aa80a1577de,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-7c8fc4cb-104f-43ac-986d-b5ccea76d2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-f6b20aad-29a8-431c-8c04-b72f1882d840,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-b1e57eb5-6540-42d8-86e5-40bcbdc43203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447276185-172.17.0.2-1595582322236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45223,DS-0f521963-e4a7-4447-8132-2acaca61f13d,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-0cecd8b6-3754-4f81-8a4c-bea45d5258ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-ee36cc0b-a5b2-4546-9886-c855bd4a5183,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-5a6c2313-5b25-42e5-97b3-2f88f2ee3901,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-a349657f-5035-4a9a-a161-cfddab209678,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-3d706605-89c7-4dab-9229-1f48fdf2891a,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-be524d3d-e844-4a4f-a963-6e4324e232e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-0cd93a05-a4a4-47bf-a541-72d81d7566a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447276185-172.17.0.2-1595582322236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45223,DS-0f521963-e4a7-4447-8132-2acaca61f13d,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-0cecd8b6-3754-4f81-8a4c-bea45d5258ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-ee36cc0b-a5b2-4546-9886-c855bd4a5183,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-5a6c2313-5b25-42e5-97b3-2f88f2ee3901,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-a349657f-5035-4a9a-a161-cfddab209678,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-3d706605-89c7-4dab-9229-1f48fdf2891a,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-be524d3d-e844-4a4f-a963-6e4324e232e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-0cd93a05-a4a4-47bf-a541-72d81d7566a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611606715-172.17.0.2-1595582509588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32984,DS-f1030173-4fa9-4062-a4ee-ce02e9efa348,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-837eaaa4-b3b4-48c1-97a7-6b0f97e1dc44,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-bf50d767-24cd-49dd-b80e-df0f4be00874,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-8d581594-ed8a-45c8-86e9-e656d677ba12,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-481a7c9d-4c5b-400e-95f2-65edbaab0832,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-9fccb81f-8dad-4c76-bfbc-25e0b34213d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-68ef499c-b363-47ff-935b-7b4ddb9f5473,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-89443854-3c9e-42b8-88d0-e02a9196d03e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611606715-172.17.0.2-1595582509588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32984,DS-f1030173-4fa9-4062-a4ee-ce02e9efa348,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-837eaaa4-b3b4-48c1-97a7-6b0f97e1dc44,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-bf50d767-24cd-49dd-b80e-df0f4be00874,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-8d581594-ed8a-45c8-86e9-e656d677ba12,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-481a7c9d-4c5b-400e-95f2-65edbaab0832,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-9fccb81f-8dad-4c76-bfbc-25e0b34213d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-68ef499c-b363-47ff-935b-7b4ddb9f5473,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-89443854-3c9e-42b8-88d0-e02a9196d03e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1630480327-172.17.0.2-1595582582499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45565,DS-e003f644-cf13-4297-b4c2-8a55faedfab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-4e663017-817e-4089-b88d-1d6946e1884e,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-6f881ddd-e680-4daa-a049-2dd8dc9dd4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-7745ee85-a1b9-41fe-a50d-e31e49dc1b66,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-89753f8a-cdaa-4933-afce-3a49d351ee79,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-2e63331e-2f6b-4a03-a0c2-3d8e038aacd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-e58767de-5106-41a9-ad74-6691b32ef459,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-bd7b8a2b-ead4-4437-8303-9af18712e8ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1630480327-172.17.0.2-1595582582499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45565,DS-e003f644-cf13-4297-b4c2-8a55faedfab9,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-4e663017-817e-4089-b88d-1d6946e1884e,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-6f881ddd-e680-4daa-a049-2dd8dc9dd4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-7745ee85-a1b9-41fe-a50d-e31e49dc1b66,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-89753f8a-cdaa-4933-afce-3a49d351ee79,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-2e63331e-2f6b-4a03-a0c2-3d8e038aacd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-e58767de-5106-41a9-ad74-6691b32ef459,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-bd7b8a2b-ead4-4437-8303-9af18712e8ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257504106-172.17.0.2-1595583767849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38922,DS-b8908332-036b-44f8-9750-c00526f2cb09,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-6775deed-04e3-4c40-a800-8b77138ea634,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-f0553c79-78ba-4578-a180-653f78c763d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-e682d8ec-00e5-45d6-91a1-497b1e36632b,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-d4f365b8-ed7f-4435-8ef8-722199679ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-c0fe0a16-712e-48e2-befa-81ba8fdba2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-ffc86a1e-de30-4094-ac29-814d4ea07c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-0e4f1858-68ef-4c33-b6d9-2e74c29d9b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-257504106-172.17.0.2-1595583767849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38922,DS-b8908332-036b-44f8-9750-c00526f2cb09,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-6775deed-04e3-4c40-a800-8b77138ea634,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-f0553c79-78ba-4578-a180-653f78c763d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-e682d8ec-00e5-45d6-91a1-497b1e36632b,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-d4f365b8-ed7f-4435-8ef8-722199679ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-c0fe0a16-712e-48e2-befa-81ba8fdba2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-ffc86a1e-de30-4094-ac29-814d4ea07c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-0e4f1858-68ef-4c33-b6d9-2e74c29d9b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564682827-172.17.0.2-1595584775346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35864,DS-17c8ba20-f6aa-412d-8711-6d690a3894fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-0f433948-34ce-448d-822b-32247fd4b59c,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-327a28e7-08f1-41d8-960f-1fc5ca7c7fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-44f5d936-ec82-437e-a485-e84697900294,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-7d036452-6de4-4179-9539-ed7325892b52,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-d1f7b465-2569-42e8-8a2f-a05f668ee6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-5a5b80c9-f687-4c1c-85db-5473f986d5de,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-8a2460dd-f217-41d7-905f-db091234a129,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564682827-172.17.0.2-1595584775346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35864,DS-17c8ba20-f6aa-412d-8711-6d690a3894fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-0f433948-34ce-448d-822b-32247fd4b59c,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-327a28e7-08f1-41d8-960f-1fc5ca7c7fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-44f5d936-ec82-437e-a485-e84697900294,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-7d036452-6de4-4179-9539-ed7325892b52,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-d1f7b465-2569-42e8-8a2f-a05f668ee6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-5a5b80c9-f687-4c1c-85db-5473f986d5de,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-8a2460dd-f217-41d7-905f-db091234a129,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563082269-172.17.0.2-1595584847781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44777,DS-f591f45b-471b-4b61-a0f8-0fba266f3834,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-5a1f3732-1479-4c8e-8e39-b4b39c38719a,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-1e484ed7-5555-4d21-a48a-69592e086e58,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-881dbb7d-314a-44a1-bd5c-444969750973,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-5b26ef4d-983f-4839-a654-cf7292a6da34,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-3100d032-aef9-4c2c-94ab-0522fdbaa3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-acdbf750-826d-4f49-a589-95f4bbe67a08,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-fa753921-2703-4017-abc9-2a7e32592bbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1563082269-172.17.0.2-1595584847781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44777,DS-f591f45b-471b-4b61-a0f8-0fba266f3834,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-5a1f3732-1479-4c8e-8e39-b4b39c38719a,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-1e484ed7-5555-4d21-a48a-69592e086e58,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-881dbb7d-314a-44a1-bd5c-444969750973,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-5b26ef4d-983f-4839-a654-cf7292a6da34,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-3100d032-aef9-4c2c-94ab-0522fdbaa3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-acdbf750-826d-4f49-a589-95f4bbe67a08,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-fa753921-2703-4017-abc9-2a7e32592bbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307981013-172.17.0.2-1595585317155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36816,DS-7b27a8f7-e56b-466a-ad34-8bef3274fab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-ca06236d-6e43-4b18-9d7c-5cb66796e23b,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-10d22f56-98af-47c1-b9cc-9efab8ac4b50,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-9bb1b706-a26d-422d-a401-732ae6500137,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-ff622353-efe4-4f85-b555-a936038123aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-5c99d912-e390-4f18-9013-f37a5a70639d,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-804c3005-e2c9-493d-b9e2-ffc66776eb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-b990e948-e1bb-4422-9783-64c8623b138e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307981013-172.17.0.2-1595585317155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36816,DS-7b27a8f7-e56b-466a-ad34-8bef3274fab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-ca06236d-6e43-4b18-9d7c-5cb66796e23b,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-10d22f56-98af-47c1-b9cc-9efab8ac4b50,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-9bb1b706-a26d-422d-a401-732ae6500137,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-ff622353-efe4-4f85-b555-a936038123aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-5c99d912-e390-4f18-9013-f37a5a70639d,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-804c3005-e2c9-493d-b9e2-ffc66776eb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-b990e948-e1bb-4422-9783-64c8623b138e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980532507-172.17.0.2-1595585767818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42543,DS-af54af11-bdf7-4404-a412-ebf1e41d1322,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-ea168ce2-7ae8-4643-a713-a5e9960dc792,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-c1022624-0a6a-43c4-8e1f-82f7b770ccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-17ecd549-c865-45c7-90f8-eb8d224e1511,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-ef9279e9-cc6f-4fd3-8af0-a571c5293286,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-0550316f-89c7-4cb3-ac2a-0d636d7d1a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-986c2c7f-9fe0-4453-be72-880edc73cb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-16cb6062-d9f8-478e-a83b-a25e4dff9c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980532507-172.17.0.2-1595585767818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42543,DS-af54af11-bdf7-4404-a412-ebf1e41d1322,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-ea168ce2-7ae8-4643-a713-a5e9960dc792,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-c1022624-0a6a-43c4-8e1f-82f7b770ccf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-17ecd549-c865-45c7-90f8-eb8d224e1511,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-ef9279e9-cc6f-4fd3-8af0-a571c5293286,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-0550316f-89c7-4cb3-ac2a-0d636d7d1a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-986c2c7f-9fe0-4453-be72-880edc73cb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-16cb6062-d9f8-478e-a83b-a25e4dff9c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601413764-172.17.0.2-1595585880673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33300,DS-d5cc7ceb-ded8-44a9-adae-5026585222c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-d4a733da-212a-4597-b6a6-334fcc911ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-c980c401-aa60-4b37-afdd-fb17810edd44,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-609de36a-1800-4438-ad8f-5f00981f3916,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-a0861f80-38e7-4c43-b0d5-b67cc2e47312,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-c1749493-0ac0-4a8f-b814-ba78b539c3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-04d3ca54-f194-452f-ad54-acaed1b7bd03,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-c5dccb90-675b-4751-b365-90060f840a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601413764-172.17.0.2-1595585880673:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33300,DS-d5cc7ceb-ded8-44a9-adae-5026585222c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-d4a733da-212a-4597-b6a6-334fcc911ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-c980c401-aa60-4b37-afdd-fb17810edd44,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-609de36a-1800-4438-ad8f-5f00981f3916,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-a0861f80-38e7-4c43-b0d5-b67cc2e47312,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-c1749493-0ac0-4a8f-b814-ba78b539c3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-04d3ca54-f194-452f-ad54-acaed1b7bd03,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-c5dccb90-675b-4751-b365-90060f840a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082959595-172.17.0.2-1595586214910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36595,DS-d581ac61-db91-4c2b-b402-0d0744ccd0af,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-827cd0e8-f132-42e9-9135-6aba675e8512,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-2f9763e7-b388-4951-9ab9-011d1a7e8e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-3e7f75ed-c025-485d-8f41-c8d3685f3199,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-45f7ac8b-df61-472e-a4ad-eee99a1e11bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-2475514f-34bb-4a99-bf36-2a46581c178a,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-a89daa81-511a-4bdb-bc0a-43559f94ab30,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-2db65d34-675c-44a3-95d0-6528815325fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082959595-172.17.0.2-1595586214910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36595,DS-d581ac61-db91-4c2b-b402-0d0744ccd0af,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-827cd0e8-f132-42e9-9135-6aba675e8512,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-2f9763e7-b388-4951-9ab9-011d1a7e8e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-3e7f75ed-c025-485d-8f41-c8d3685f3199,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-45f7ac8b-df61-472e-a4ad-eee99a1e11bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-2475514f-34bb-4a99-bf36-2a46581c178a,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-a89daa81-511a-4bdb-bc0a-43559f94ab30,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-2db65d34-675c-44a3-95d0-6528815325fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392912311-172.17.0.2-1595586427234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40748,DS-3cf067b7-aed5-48c4-8779-589897717b83,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-3f2f7eca-970a-406c-9bc4-37be080ef468,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-4f458f15-61ac-4857-8d27-5a33f0c0a07a,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-0b615f6c-2133-4664-b85a-4dd33986d808,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-7fb78626-e5bf-4c6c-a286-9cb8f6e98603,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-38116983-6ea4-4633-a969-53e975da79c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-a13b86be-8e20-49bc-a10f-3b225162e22d,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-f4724d0f-1bf2-40d6-90ee-efbc6179acc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392912311-172.17.0.2-1595586427234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40748,DS-3cf067b7-aed5-48c4-8779-589897717b83,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-3f2f7eca-970a-406c-9bc4-37be080ef468,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-4f458f15-61ac-4857-8d27-5a33f0c0a07a,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-0b615f6c-2133-4664-b85a-4dd33986d808,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-7fb78626-e5bf-4c6c-a286-9cb8f6e98603,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-38116983-6ea4-4633-a969-53e975da79c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-a13b86be-8e20-49bc-a10f-3b225162e22d,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-f4724d0f-1bf2-40d6-90ee-efbc6179acc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861854863-172.17.0.2-1595587387390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40586,DS-9db7572d-ba45-41c2-a069-bd6d0f5b27df,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-687639e4-9917-417d-aba0-cbb8c981093d,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-e686803b-c4a9-4abf-adda-555519cf9b35,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-6a400eac-a200-455c-b669-9031eb93c3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-f59b23db-b593-4ceb-8ee6-e2d240db6a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-2c5b069d-b131-479f-bfff-d85432a14912,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-fb39a2d9-d490-4e5c-9847-9d89ffc81535,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-0c2db944-8ff5-4b06-8f4a-c049687676fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861854863-172.17.0.2-1595587387390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40586,DS-9db7572d-ba45-41c2-a069-bd6d0f5b27df,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-687639e4-9917-417d-aba0-cbb8c981093d,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-e686803b-c4a9-4abf-adda-555519cf9b35,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-6a400eac-a200-455c-b669-9031eb93c3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-f59b23db-b593-4ceb-8ee6-e2d240db6a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-2c5b069d-b131-479f-bfff-d85432a14912,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-fb39a2d9-d490-4e5c-9847-9d89ffc81535,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-0c2db944-8ff5-4b06-8f4a-c049687676fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 4000000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996220494-172.17.0.2-1595587522659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42702,DS-442235f0-8647-4291-b48a-bb45e3bbc1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-e194ed20-3b6c-443f-aa42-4d3ca0a2b590,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-6543e65a-5b54-4e15-b93f-d70d03a3851b,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-55ff53b6-e078-489e-b619-24f94ae3548c,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-e46fbddd-f4bd-4687-ad08-79dcb29974f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-a98883fb-64d6-4524-981c-3a827e19f478,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-557ab420-f3e0-43f1-ab9e-fed4392eacdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-f20ceedd-83a9-4843-95af-2c824428ebc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996220494-172.17.0.2-1595587522659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42702,DS-442235f0-8647-4291-b48a-bb45e3bbc1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-e194ed20-3b6c-443f-aa42-4d3ca0a2b590,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-6543e65a-5b54-4e15-b93f-d70d03a3851b,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-55ff53b6-e078-489e-b619-24f94ae3548c,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-e46fbddd-f4bd-4687-ad08-79dcb29974f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-a98883fb-64d6-4524-981c-3a827e19f478,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-557ab420-f3e0-43f1-ab9e-fed4392eacdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-f20ceedd-83a9-4843-95af-2c824428ebc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5385
