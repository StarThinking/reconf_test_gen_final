reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-834119369-172.17.0.3-1595829586563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36062,DS-24608cf4-7033-44a4-a5cd-b47ec2869da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-5a2fadb7-07c6-4b7d-9cb5-67edc511ed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-0de4c2c5-a99d-4c5c-a23e-e177311927e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-724089c3-dbaf-4c6c-9e4c-50b8d8c24701,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-ff95bbe0-884b-4fa4-a678-a3344c8dca0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-b590af7e-80bf-4821-9040-e83e698bba72,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-df576e7b-9b32-49fa-9cd7-562f0fee3c34,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-a30c1bbd-8d62-4156-8590-4f088add01fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-834119369-172.17.0.3-1595829586563:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36062,DS-24608cf4-7033-44a4-a5cd-b47ec2869da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-5a2fadb7-07c6-4b7d-9cb5-67edc511ed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-0de4c2c5-a99d-4c5c-a23e-e177311927e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-724089c3-dbaf-4c6c-9e4c-50b8d8c24701,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-ff95bbe0-884b-4fa4-a678-a3344c8dca0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-b590af7e-80bf-4821-9040-e83e698bba72,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-df576e7b-9b32-49fa-9cd7-562f0fee3c34,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-a30c1bbd-8d62-4156-8590-4f088add01fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-63860143-172.17.0.3-1595829775671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45120,DS-096b1877-f286-4cfd-86cd-55c004c96652,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-28cdbef2-8b92-499f-a1ac-5425137c1d58,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-fb3697bd-fb63-4c49-bec5-98c010bf030f,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-eede7887-d92c-44ad-85b2-b5e789fccf97,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-458e721b-059f-4873-99af-2b5dac540440,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-2e24a25a-53c6-4239-b38d-b94517af01e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-c01c3051-6558-46f8-953c-90bcef632132,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-e6515a29-153b-4bc4-8886-779e526c9c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-63860143-172.17.0.3-1595829775671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45120,DS-096b1877-f286-4cfd-86cd-55c004c96652,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-28cdbef2-8b92-499f-a1ac-5425137c1d58,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-fb3697bd-fb63-4c49-bec5-98c010bf030f,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-eede7887-d92c-44ad-85b2-b5e789fccf97,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-458e721b-059f-4873-99af-2b5dac540440,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-2e24a25a-53c6-4239-b38d-b94517af01e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-c01c3051-6558-46f8-953c-90bcef632132,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-e6515a29-153b-4bc4-8886-779e526c9c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114413678-172.17.0.3-1595829810074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33427,DS-709cd658-b326-4405-bbe5-d4db238b892a,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-9799d451-d5d9-49af-9a67-13a8c4d7024e,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-b0d084e6-c3eb-4df3-b802-25e4c3bc4183,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-b8591f2b-0229-4d6b-85cf-26f875033e03,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-2a609bbf-7032-46b5-bf15-b4777f64bf50,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-8dd3f4ed-19dc-4ea8-8672-82b52fd3faa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-87e2691e-ca8e-4151-b9a5-5d8ce177c761,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-1204f6bc-0345-4e12-8f4b-03e4a5a10432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114413678-172.17.0.3-1595829810074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33427,DS-709cd658-b326-4405-bbe5-d4db238b892a,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-9799d451-d5d9-49af-9a67-13a8c4d7024e,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-b0d084e6-c3eb-4df3-b802-25e4c3bc4183,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-b8591f2b-0229-4d6b-85cf-26f875033e03,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-2a609bbf-7032-46b5-bf15-b4777f64bf50,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-8dd3f4ed-19dc-4ea8-8672-82b52fd3faa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41095,DS-87e2691e-ca8e-4151-b9a5-5d8ce177c761,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-1204f6bc-0345-4e12-8f4b-03e4a5a10432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650066863-172.17.0.3-1595830078490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36224,DS-da8d7360-2ecf-4f20-aab8-c81ae41c4962,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-0e7f4072-2380-4f78-8a30-2e89d024ead1,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-2f7a4679-3365-466f-a564-379a186280f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-5cbbe67c-40d7-4c9b-9142-f38bec3c0e47,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-91bccb05-54a8-4c2b-9d77-c13c2301e4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-0bafab90-c1e2-41b6-97fd-595c5a67d51e,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-ed7ad141-a645-4ec4-ac8f-534c80f6d9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-41e423f4-882e-4ceb-b1b7-8b24ae1d1ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650066863-172.17.0.3-1595830078490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36224,DS-da8d7360-2ecf-4f20-aab8-c81ae41c4962,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-0e7f4072-2380-4f78-8a30-2e89d024ead1,DISK], DatanodeInfoWithStorage[127.0.0.1:37510,DS-2f7a4679-3365-466f-a564-379a186280f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-5cbbe67c-40d7-4c9b-9142-f38bec3c0e47,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-91bccb05-54a8-4c2b-9d77-c13c2301e4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-0bafab90-c1e2-41b6-97fd-595c5a67d51e,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-ed7ad141-a645-4ec4-ac8f-534c80f6d9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-41e423f4-882e-4ceb-b1b7-8b24ae1d1ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7933736-172.17.0.3-1595830283545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40108,DS-ff12942f-cf3c-4f76-bd83-77f7afcbff73,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-90cb61ed-7962-484a-9ce0-311e2cdd635d,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-2628f172-ec15-4728-b61e-58034b914d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-6dac4ade-d5a2-4acf-a475-31133b481542,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-a11b4ef5-9775-45d3-a28f-bb7e9c8371d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-ecee21cf-e3eb-4a71-9492-6cc8051392bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-ea414b49-0939-4e19-9fff-37f7054341e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-dd5c2246-1a3f-4931-a185-5d266206f45f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7933736-172.17.0.3-1595830283545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40108,DS-ff12942f-cf3c-4f76-bd83-77f7afcbff73,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-90cb61ed-7962-484a-9ce0-311e2cdd635d,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-2628f172-ec15-4728-b61e-58034b914d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-6dac4ade-d5a2-4acf-a475-31133b481542,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-a11b4ef5-9775-45d3-a28f-bb7e9c8371d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-ecee21cf-e3eb-4a71-9492-6cc8051392bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-ea414b49-0939-4e19-9fff-37f7054341e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-dd5c2246-1a3f-4931-a185-5d266206f45f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184997050-172.17.0.3-1595830814804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36746,DS-cb7aa850-507f-4409-9478-017c2f752a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-1a7895e1-728d-4216-bf06-28a44c069a50,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-191f8211-ece6-433c-8fec-3823f226f52a,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-6356d3d7-221b-4d27-979d-7c9fbb511400,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-3493f6b2-60fa-49bf-b8a4-03d2019af19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-0238fb73-4a55-4262-acae-bf4ed6720498,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-aec3540f-0a2a-49c1-9957-93b1bbfbb2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-a98994dc-6eb1-492b-ab9d-f48a39c8c70d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184997050-172.17.0.3-1595830814804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36746,DS-cb7aa850-507f-4409-9478-017c2f752a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-1a7895e1-728d-4216-bf06-28a44c069a50,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-191f8211-ece6-433c-8fec-3823f226f52a,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-6356d3d7-221b-4d27-979d-7c9fbb511400,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-3493f6b2-60fa-49bf-b8a4-03d2019af19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-0238fb73-4a55-4262-acae-bf4ed6720498,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-aec3540f-0a2a-49c1-9957-93b1bbfbb2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-a98994dc-6eb1-492b-ab9d-f48a39c8c70d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861585439-172.17.0.3-1595831085003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46265,DS-f43496ec-ed07-4e67-a8fe-1463ff2aa660,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-77e5dc57-cf8f-4b94-b164-ed96aadef22d,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-8022a8c7-a52d-47f7-ac56-244fd473706a,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-29677f6d-8f8e-450e-a393-e82b0104fb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-e5840575-12fa-46fd-8921-1369b77683e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-14bb114b-951a-4c58-87f0-21ac1ac14bef,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-59593e1c-bb50-4d35-93b5-cf43a2249a75,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-cbeaaf07-2615-4ea8-93d7-7ba6286dd49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861585439-172.17.0.3-1595831085003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46265,DS-f43496ec-ed07-4e67-a8fe-1463ff2aa660,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-77e5dc57-cf8f-4b94-b164-ed96aadef22d,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-8022a8c7-a52d-47f7-ac56-244fd473706a,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-29677f6d-8f8e-450e-a393-e82b0104fb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-e5840575-12fa-46fd-8921-1369b77683e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-14bb114b-951a-4c58-87f0-21ac1ac14bef,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-59593e1c-bb50-4d35-93b5-cf43a2249a75,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-cbeaaf07-2615-4ea8-93d7-7ba6286dd49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393009249-172.17.0.3-1595831533474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33469,DS-e057362c-eca7-4c9f-8202-486880762a76,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-aa82ee78-8838-4de1-b61c-4eaff627ecea,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-89239541-add3-4248-ba9e-fc714ae5fac0,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-1de03bf3-3258-41ae-8827-b2cfb9f29696,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-d48af283-9ca4-448b-ba85-ff370f64720a,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-0ae8d149-47cf-4d61-ace8-400edcb595a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-e74ebd45-9d2f-42ac-8c4a-11caf27c2f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-2cc0f1a2-e850-496a-b883-8117a9a853d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1393009249-172.17.0.3-1595831533474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33469,DS-e057362c-eca7-4c9f-8202-486880762a76,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-aa82ee78-8838-4de1-b61c-4eaff627ecea,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-89239541-add3-4248-ba9e-fc714ae5fac0,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-1de03bf3-3258-41ae-8827-b2cfb9f29696,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-d48af283-9ca4-448b-ba85-ff370f64720a,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-0ae8d149-47cf-4d61-ace8-400edcb595a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-e74ebd45-9d2f-42ac-8c4a-11caf27c2f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34094,DS-2cc0f1a2-e850-496a-b883-8117a9a853d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733744663-172.17.0.3-1595831569702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45096,DS-127ced28-aee1-4145-afee-1baec6a2466b,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-af7bcb5a-deb4-4cc1-aedf-0f16da5d2998,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-f26c9362-1bfb-476b-95c9-1d4d216ac0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-c0b42503-4784-4ef5-b894-66ff3d7be506,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-18b77c63-273f-4e1c-95d7-e3c422da7668,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-efe120ad-b24f-4a0c-a735-1959c864b431,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-2972ce23-2ffb-4a5b-9454-9515d05b7a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-57eb407c-cec9-4c74-9f10-da07f442944c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1733744663-172.17.0.3-1595831569702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45096,DS-127ced28-aee1-4145-afee-1baec6a2466b,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-af7bcb5a-deb4-4cc1-aedf-0f16da5d2998,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-f26c9362-1bfb-476b-95c9-1d4d216ac0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-c0b42503-4784-4ef5-b894-66ff3d7be506,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-18b77c63-273f-4e1c-95d7-e3c422da7668,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-efe120ad-b24f-4a0c-a735-1959c864b431,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-2972ce23-2ffb-4a5b-9454-9515d05b7a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-57eb407c-cec9-4c74-9f10-da07f442944c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419149706-172.17.0.3-1595831716614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34551,DS-8d767a30-9abf-49aa-9646-1ebe74fc07ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-8244c342-bfc6-4aff-98a4-c91ded140f25,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-3ceb1de9-2110-4dbe-9e86-536867fa81b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-ca5abaa6-d776-4867-9235-df1f1c0f51cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-d15d4628-89ba-4452-bf6f-47eeb5ea38c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-dbb1a93a-f2c2-40eb-b713-e6988f11039e,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-09051355-0355-4783-b8ac-3a53737afaff,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-5d750c62-6a6e-4415-9aa3-23a2b6e67e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419149706-172.17.0.3-1595831716614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34551,DS-8d767a30-9abf-49aa-9646-1ebe74fc07ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-8244c342-bfc6-4aff-98a4-c91ded140f25,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-3ceb1de9-2110-4dbe-9e86-536867fa81b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-ca5abaa6-d776-4867-9235-df1f1c0f51cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-d15d4628-89ba-4452-bf6f-47eeb5ea38c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-dbb1a93a-f2c2-40eb-b713-e6988f11039e,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-09051355-0355-4783-b8ac-3a53737afaff,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-5d750c62-6a6e-4415-9aa3-23a2b6e67e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478794143-172.17.0.3-1595832081020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45897,DS-20c2b76f-59a9-4160-957f-25c35314fc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-8a2a7911-7397-4a58-b716-a073f93ee01f,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-63f84a56-445e-430e-809a-8e75bcba8396,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-61e499c8-4295-4923-8535-2eeb1175ba89,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-469f5768-fcde-4ff7-b0dd-5d1452df7882,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-d402b19a-dc36-414c-acc1-236b86b002c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-29065c0e-3b32-4f13-a6e8-4b4af3912feb,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-e61aeb83-0f62-40e8-9ed2-c3338ad13b18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478794143-172.17.0.3-1595832081020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45897,DS-20c2b76f-59a9-4160-957f-25c35314fc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-8a2a7911-7397-4a58-b716-a073f93ee01f,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-63f84a56-445e-430e-809a-8e75bcba8396,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-61e499c8-4295-4923-8535-2eeb1175ba89,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-469f5768-fcde-4ff7-b0dd-5d1452df7882,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-d402b19a-dc36-414c-acc1-236b86b002c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-29065c0e-3b32-4f13-a6e8-4b4af3912feb,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-e61aeb83-0f62-40e8-9ed2-c3338ad13b18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-99319375-172.17.0.3-1595832157290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40918,DS-b3a1ed0d-30b1-4b5f-8af1-0d6c46bdcd64,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-5d6973a0-72e8-43c4-993c-029aa7911810,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-8389fe26-4b82-4414-9ce6-6734d0447746,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-3b39f294-8c9b-4e4f-abbf-5ac7f969e76c,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-f1bc6557-ce3b-4b9d-9b0b-d8f27e9d126a,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-ad5038da-d666-42db-96b8-59b9eeed97d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-2087378c-a3c8-41d2-8f7b-8567e8a63baf,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-9b400082-d167-49db-930f-3a2a1bfebb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-99319375-172.17.0.3-1595832157290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40918,DS-b3a1ed0d-30b1-4b5f-8af1-0d6c46bdcd64,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-5d6973a0-72e8-43c4-993c-029aa7911810,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-8389fe26-4b82-4414-9ce6-6734d0447746,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-3b39f294-8c9b-4e4f-abbf-5ac7f969e76c,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-f1bc6557-ce3b-4b9d-9b0b-d8f27e9d126a,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-ad5038da-d666-42db-96b8-59b9eeed97d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-2087378c-a3c8-41d2-8f7b-8567e8a63baf,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-9b400082-d167-49db-930f-3a2a1bfebb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633452413-172.17.0.3-1595832259628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33066,DS-6564d9ab-cf2b-4c32-93c3-3c3851621762,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-90698317-bb50-40e3-bc61-d0a704e0e91d,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-1fefc21f-858d-4f5f-87bd-52d914a73dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-5ea8682f-7217-485c-9b68-6b87c07d9961,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-4781cf2a-6c3f-42a6-9704-dea39f103081,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-adadf71a-211a-421f-9704-51899ce8e948,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-7fe835a0-769f-407b-95dd-a347d05c3e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-efec413e-b1f2-4e9c-be7f-5f662d87d923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1633452413-172.17.0.3-1595832259628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33066,DS-6564d9ab-cf2b-4c32-93c3-3c3851621762,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-90698317-bb50-40e3-bc61-d0a704e0e91d,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-1fefc21f-858d-4f5f-87bd-52d914a73dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-5ea8682f-7217-485c-9b68-6b87c07d9961,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-4781cf2a-6c3f-42a6-9704-dea39f103081,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-adadf71a-211a-421f-9704-51899ce8e948,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-7fe835a0-769f-407b-95dd-a347d05c3e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-efec413e-b1f2-4e9c-be7f-5f662d87d923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746717778-172.17.0.3-1595832860634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41155,DS-f35c3620-5d6e-4a2b-88c7-e66b0241d738,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-942f56bf-ad5d-4bdc-abac-04af23bd3885,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-7ff66802-f6f5-4b25-8f7e-920949afb6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-b0889950-9e45-4996-ac10-c2a030851532,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-6ff852b9-d091-4bb9-b172-b0ea74b87cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-757e5180-103e-4ad4-9868-69cdc54adcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-b057d034-2f64-4617-8804-dd45f246fa14,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-2d0ad083-c51c-47ab-8af0-497717d27f64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746717778-172.17.0.3-1595832860634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41155,DS-f35c3620-5d6e-4a2b-88c7-e66b0241d738,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-942f56bf-ad5d-4bdc-abac-04af23bd3885,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-7ff66802-f6f5-4b25-8f7e-920949afb6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-b0889950-9e45-4996-ac10-c2a030851532,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-6ff852b9-d091-4bb9-b172-b0ea74b87cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-757e5180-103e-4ad4-9868-69cdc54adcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-b057d034-2f64-4617-8804-dd45f246fa14,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-2d0ad083-c51c-47ab-8af0-497717d27f64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542065275-172.17.0.3-1595832975329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41861,DS-279c7099-9369-4cd8-aff6-6262aae3526d,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-46b81d01-dc56-40d4-8e55-9f7b90d27534,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-83ce79c3-87e8-4f29-802d-39fa92157550,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-cfe6b0d8-b8db-4247-a0c0-315ce1f6a8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-8c68af2c-a634-4bd4-a519-879aad7c891a,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-464b1144-1800-4a3a-ab5c-b9c53ffb529d,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-4ba593fe-9e34-4626-86af-1a066466abfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-0f27b83d-dd4f-41e9-806d-4b5ad06252cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542065275-172.17.0.3-1595832975329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41861,DS-279c7099-9369-4cd8-aff6-6262aae3526d,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-46b81d01-dc56-40d4-8e55-9f7b90d27534,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-83ce79c3-87e8-4f29-802d-39fa92157550,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-cfe6b0d8-b8db-4247-a0c0-315ce1f6a8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-8c68af2c-a634-4bd4-a519-879aad7c891a,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-464b1144-1800-4a3a-ab5c-b9c53ffb529d,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-4ba593fe-9e34-4626-86af-1a066466abfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-0f27b83d-dd4f-41e9-806d-4b5ad06252cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-590575223-172.17.0.3-1595833243478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35645,DS-707185e2-cc58-4b3f-be16-1337e7cd01d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-c7ccba09-fdab-4de8-8af6-4c1e89286155,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-de6d2aa5-1fab-48d5-a770-87f86c84764a,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-9ab397bf-7008-41ed-808b-2cf7ade9781b,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-52efacd7-ae15-472e-84e7-6d4fee67c53a,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-3b8b69c6-74b4-4466-bc93-14a40bd6746c,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-43abe7f7-ab66-4cc9-b437-e1c0584c3571,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-014fd7af-9d31-44ab-8e26-a9837c9bfdfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-590575223-172.17.0.3-1595833243478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35645,DS-707185e2-cc58-4b3f-be16-1337e7cd01d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-c7ccba09-fdab-4de8-8af6-4c1e89286155,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-de6d2aa5-1fab-48d5-a770-87f86c84764a,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-9ab397bf-7008-41ed-808b-2cf7ade9781b,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-52efacd7-ae15-472e-84e7-6d4fee67c53a,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-3b8b69c6-74b4-4466-bc93-14a40bd6746c,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-43abe7f7-ab66-4cc9-b437-e1c0584c3571,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-014fd7af-9d31-44ab-8e26-a9837c9bfdfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921717788-172.17.0.3-1595833866329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42158,DS-7ee4631e-1a15-412c-86f2-23e202bf36a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-9bf46840-5f04-4cb8-9744-79552eb26066,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-444a885e-86ee-402c-8d21-a5d5b540c639,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-f763a452-22f2-4ad2-91d3-4f2057432628,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-f6fbbb70-52e7-4007-ac7f-1906514fd048,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-c6778e79-454d-4663-b2d8-7c54f07666fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-c6d62c54-e437-4f33-b3ee-36aeeaddceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-a1a785e4-aef8-4d99-a39e-57e550d632d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921717788-172.17.0.3-1595833866329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42158,DS-7ee4631e-1a15-412c-86f2-23e202bf36a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-9bf46840-5f04-4cb8-9744-79552eb26066,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-444a885e-86ee-402c-8d21-a5d5b540c639,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-f763a452-22f2-4ad2-91d3-4f2057432628,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-f6fbbb70-52e7-4007-ac7f-1906514fd048,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-c6778e79-454d-4663-b2d8-7c54f07666fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-c6d62c54-e437-4f33-b3ee-36aeeaddceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-a1a785e4-aef8-4d99-a39e-57e550d632d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127681586-172.17.0.3-1595834384234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41537,DS-0cf24209-8400-484c-ade1-d82fdbfae588,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-89da6963-9da8-4a03-af99-08bd81105218,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-fac43512-90d6-4fb2-a951-e0086ba3a859,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-d821353b-6452-4cb4-b524-414d1f2e5262,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-c0cbc8b1-6400-4e31-bcb3-4cdefeabc873,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-fdee124d-ee9d-4120-9b3c-962ed9a91de7,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-59bd83e6-2f47-4190-a646-693b20aec40f,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-d2220d14-53f1-4040-ae20-8d8994582b21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-127681586-172.17.0.3-1595834384234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41537,DS-0cf24209-8400-484c-ade1-d82fdbfae588,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-89da6963-9da8-4a03-af99-08bd81105218,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-fac43512-90d6-4fb2-a951-e0086ba3a859,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-d821353b-6452-4cb4-b524-414d1f2e5262,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-c0cbc8b1-6400-4e31-bcb3-4cdefeabc873,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-fdee124d-ee9d-4120-9b3c-962ed9a91de7,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-59bd83e6-2f47-4190-a646-693b20aec40f,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-d2220d14-53f1-4040-ae20-8d8994582b21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662658362-172.17.0.3-1595834419789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46748,DS-a2980697-4cbf-4686-9e7a-4a3145414fba,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-fde464fe-b4cc-4f61-aa3f-a61a9a85bded,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-ea6db5e1-4fd2-4ccc-95de-0c3f4774a131,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-ab5fa5a9-d6a1-45d5-83ba-79c81b4693ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-f13b92f1-7b0b-4d44-9e94-0430735b811e,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-622adf68-b60f-4537-b30a-de1c86a04c37,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-a81e5f70-99db-479e-96e5-309d47c017b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-8867e323-7c42-4174-a356-c7eaf67653f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662658362-172.17.0.3-1595834419789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46748,DS-a2980697-4cbf-4686-9e7a-4a3145414fba,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-fde464fe-b4cc-4f61-aa3f-a61a9a85bded,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-ea6db5e1-4fd2-4ccc-95de-0c3f4774a131,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-ab5fa5a9-d6a1-45d5-83ba-79c81b4693ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-f13b92f1-7b0b-4d44-9e94-0430735b811e,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-622adf68-b60f-4537-b30a-de1c86a04c37,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-a81e5f70-99db-479e-96e5-309d47c017b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-8867e323-7c42-4174-a356-c7eaf67653f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5288
