reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664306425-172.17.0.2-1595844500257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44378,DS-da3f5713-2f35-48a2-bdd3-cb08f2d349c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-bee14880-3387-42c7-9599-ca3b73ed22e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-d97407c5-ed86-444a-86f5-4e2ce5cc29d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-d0c2000d-b246-4f90-979c-38bdd0741118,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-3feca5d1-b9ea-42da-a2dd-277a5fee58b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-b6d815dc-acdc-4fe6-953f-886d0529c4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-2a052be4-30af-484c-a752-005432a5e4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-6e8802e5-0f9c-4277-b1b4-483f16362c6a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664306425-172.17.0.2-1595844500257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44378,DS-da3f5713-2f35-48a2-bdd3-cb08f2d349c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-bee14880-3387-42c7-9599-ca3b73ed22e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-d97407c5-ed86-444a-86f5-4e2ce5cc29d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-d0c2000d-b246-4f90-979c-38bdd0741118,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-3feca5d1-b9ea-42da-a2dd-277a5fee58b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-b6d815dc-acdc-4fe6-953f-886d0529c4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-2a052be4-30af-484c-a752-005432a5e4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41657,DS-6e8802e5-0f9c-4277-b1b4-483f16362c6a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1795301577-172.17.0.2-1595844535891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39569,DS-d249a059-3570-49b5-8e9b-66ab8007be08,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-242c9429-b148-4c79-bdd1-d689166bb10d,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-16b92b01-e2a0-48a8-bd58-03b79c9b28e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-a4fe5f40-4039-4ae3-b57b-70444f96255a,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-f50bd293-909d-4af4-bfb6-32bbbfc032ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-6704d05f-487d-4f63-a542-2d08bbf81803,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-9751ec61-2418-4e10-8c7c-15d1518f59ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-d66e1caf-23fd-4a7b-bab6-0c6291b8ba1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1795301577-172.17.0.2-1595844535891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39569,DS-d249a059-3570-49b5-8e9b-66ab8007be08,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-242c9429-b148-4c79-bdd1-d689166bb10d,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-16b92b01-e2a0-48a8-bd58-03b79c9b28e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-a4fe5f40-4039-4ae3-b57b-70444f96255a,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-f50bd293-909d-4af4-bfb6-32bbbfc032ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-6704d05f-487d-4f63-a542-2d08bbf81803,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-9751ec61-2418-4e10-8c7c-15d1518f59ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-d66e1caf-23fd-4a7b-bab6-0c6291b8ba1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745010931-172.17.0.2-1595844989318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35260,DS-49c0685a-d584-482f-9c72-1f8673d207cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-bf85be35-cb35-4d12-8ad7-679783cdff1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-140fc891-f402-404e-95d1-4ae8516a74aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-cc78d1a4-12f3-4e76-8843-889019ab5b74,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-93798924-6c6f-4e2a-ab5c-5cd56748f77c,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-c9ad8d42-2b10-44b4-84e4-4362d02ab987,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-b11fccd9-1f36-403f-9c6a-addd0fc65c52,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-17576153-2efa-42b9-8ecc-adf3bf4739b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745010931-172.17.0.2-1595844989318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35260,DS-49c0685a-d584-482f-9c72-1f8673d207cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-bf85be35-cb35-4d12-8ad7-679783cdff1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-140fc891-f402-404e-95d1-4ae8516a74aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-cc78d1a4-12f3-4e76-8843-889019ab5b74,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-93798924-6c6f-4e2a-ab5c-5cd56748f77c,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-c9ad8d42-2b10-44b4-84e4-4362d02ab987,DISK], DatanodeInfoWithStorage[127.0.0.1:38221,DS-b11fccd9-1f36-403f-9c6a-addd0fc65c52,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-17576153-2efa-42b9-8ecc-adf3bf4739b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697920043-172.17.0.2-1595845083672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43224,DS-2523e314-77e9-4639-8411-efb443403ade,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-f7eba43b-f964-4201-afae-487bd69039a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-8931642e-5b1c-40e1-8573-aa4fe5a96f21,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-b840eab6-71ff-4733-841b-46d8d1b192c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-cd4355d3-066f-4706-9ee5-bc8da4e41786,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-a11ab00f-6bd1-4aaf-8405-9b41579c55f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-8e2fdb9f-5c7e-4c01-b219-66f545af3c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-33a2e75c-f4a7-4ca0-abe6-1904d4c47575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697920043-172.17.0.2-1595845083672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43224,DS-2523e314-77e9-4639-8411-efb443403ade,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-f7eba43b-f964-4201-afae-487bd69039a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-8931642e-5b1c-40e1-8573-aa4fe5a96f21,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-b840eab6-71ff-4733-841b-46d8d1b192c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-cd4355d3-066f-4706-9ee5-bc8da4e41786,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-a11ab00f-6bd1-4aaf-8405-9b41579c55f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-8e2fdb9f-5c7e-4c01-b219-66f545af3c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-33a2e75c-f4a7-4ca0-abe6-1904d4c47575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259681377-172.17.0.2-1595845950414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36372,DS-2274ecaa-8a78-4640-a687-5428a8ad0cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-94454a11-bf95-480d-94fc-3c9fce1e7759,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-163570a9-27e5-423f-b734-5db65f01c880,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-ae9edb71-4f1a-4a6b-9742-4d1ca46fdb07,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-08204dd1-e179-4859-b951-417a9ad04736,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-c810a3d0-0b62-4ee0-b697-8b8fa3b395c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-62bcc81c-be14-4dc8-bb78-ce7db8b94c85,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-425c193c-c7f2-4475-bdec-1d6fd5358f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259681377-172.17.0.2-1595845950414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36372,DS-2274ecaa-8a78-4640-a687-5428a8ad0cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-94454a11-bf95-480d-94fc-3c9fce1e7759,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-163570a9-27e5-423f-b734-5db65f01c880,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-ae9edb71-4f1a-4a6b-9742-4d1ca46fdb07,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-08204dd1-e179-4859-b951-417a9ad04736,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-c810a3d0-0b62-4ee0-b697-8b8fa3b395c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-62bcc81c-be14-4dc8-bb78-ce7db8b94c85,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-425c193c-c7f2-4475-bdec-1d6fd5358f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451644662-172.17.0.2-1595846248719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34875,DS-12dd6cd5-7a63-463b-a253-82463ac85198,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-73926349-9c1e-4084-8b72-57df3fd89ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-2b05861a-953c-4197-8cbf-224cdba25fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-6cafbeb2-c985-4b93-8407-8d59af03d41e,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-c1d62a1f-0a0a-4f8f-8833-ea94f3e99e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-09134cfe-0e6b-4d36-b175-1818b67b1822,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-f3c80d17-19f3-42e8-b7dc-d80dfc0fb461,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-5bd10db5-8c3d-4232-b7ca-1be1dc5a329d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451644662-172.17.0.2-1595846248719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34875,DS-12dd6cd5-7a63-463b-a253-82463ac85198,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-73926349-9c1e-4084-8b72-57df3fd89ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-2b05861a-953c-4197-8cbf-224cdba25fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-6cafbeb2-c985-4b93-8407-8d59af03d41e,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-c1d62a1f-0a0a-4f8f-8833-ea94f3e99e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-09134cfe-0e6b-4d36-b175-1818b67b1822,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-f3c80d17-19f3-42e8-b7dc-d80dfc0fb461,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-5bd10db5-8c3d-4232-b7ca-1be1dc5a329d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551273577-172.17.0.2-1595846448717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41080,DS-a7a23886-53d6-4f78-99d6-ace0d388d8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-4d44e8c2-3f29-492e-a327-e2891800530e,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-52c09013-d017-4bad-a888-b729207eb233,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-9b5f8381-78a6-4f0a-980a-35d8c711f2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-8bf31668-a760-4d12-b1df-59e18baa38af,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-f5ffacc4-8990-460b-9be0-1809b66b6492,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-fcaa7f91-c22a-478a-b232-fc9fc6bc6b58,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-b86b7d45-dfd3-496b-87d8-c58ffdb4701d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-551273577-172.17.0.2-1595846448717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41080,DS-a7a23886-53d6-4f78-99d6-ace0d388d8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-4d44e8c2-3f29-492e-a327-e2891800530e,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-52c09013-d017-4bad-a888-b729207eb233,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-9b5f8381-78a6-4f0a-980a-35d8c711f2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-8bf31668-a760-4d12-b1df-59e18baa38af,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-f5ffacc4-8990-460b-9be0-1809b66b6492,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-fcaa7f91-c22a-478a-b232-fc9fc6bc6b58,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-b86b7d45-dfd3-496b-87d8-c58ffdb4701d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009800594-172.17.0.2-1595846532886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43382,DS-125e140c-80e8-48e1-9990-0cc06ce876e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-a38e4dab-b3ba-4594-8f56-8f8683b4e430,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-b78976d1-e6c5-4592-bf00-f2e213f6eb87,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-107ce23e-1851-49ae-8a1a-a845555eb6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-105ac65e-efa5-47d4-a188-8b79d036472b,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-7fe32818-fefd-4dbb-87e3-3fdd0e9228b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-62492757-4e58-4f5c-91c6-bea903bfc3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-68efa496-c95d-4bf7-aaac-c8a1225b68af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009800594-172.17.0.2-1595846532886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43382,DS-125e140c-80e8-48e1-9990-0cc06ce876e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-a38e4dab-b3ba-4594-8f56-8f8683b4e430,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-b78976d1-e6c5-4592-bf00-f2e213f6eb87,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-107ce23e-1851-49ae-8a1a-a845555eb6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-105ac65e-efa5-47d4-a188-8b79d036472b,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-7fe32818-fefd-4dbb-87e3-3fdd0e9228b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-62492757-4e58-4f5c-91c6-bea903bfc3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-68efa496-c95d-4bf7-aaac-c8a1225b68af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203051651-172.17.0.2-1595846728805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39861,DS-8b58495e-330e-4eef-b959-2dce63438bea,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-fdb81a6d-b26f-4163-b339-47ef3ea1c492,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-6e8544cf-c949-47dc-aece-473281f81066,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-f7bcda9a-6d1b-4e6d-bf53-a5b4d3eb748b,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-618acb95-3f62-40f7-9623-c44121dd9567,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-56c3fd40-2764-49ca-a88f-5faa7162c395,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-068b9b31-e01a-440f-afdd-43bee9e81fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-b3c2b5f6-61df-484b-a4fc-de537207ef33,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203051651-172.17.0.2-1595846728805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39861,DS-8b58495e-330e-4eef-b959-2dce63438bea,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-fdb81a6d-b26f-4163-b339-47ef3ea1c492,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-6e8544cf-c949-47dc-aece-473281f81066,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-f7bcda9a-6d1b-4e6d-bf53-a5b4d3eb748b,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-618acb95-3f62-40f7-9623-c44121dd9567,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-56c3fd40-2764-49ca-a88f-5faa7162c395,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-068b9b31-e01a-440f-afdd-43bee9e81fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-b3c2b5f6-61df-484b-a4fc-de537207ef33,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397295053-172.17.0.2-1595846891459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45766,DS-e61d2d34-d2d6-48ff-a016-41a5beabb6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-7bc07ebd-ca9b-451a-aa58-060e914e1b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-dea52257-d7f8-4dfe-9f20-85941e52206c,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-2055917f-8efd-4b0e-bdc7-5a406c699412,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-015b6f3f-e87d-4b8d-a672-1cb82b3f63d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-7f5cee34-500d-4c8a-838c-e0ffe1861566,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-25bf4dac-7e61-41ca-bce2-5f8519bfae62,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-92a3693a-3f94-4988-94d1-ae06aabaf662,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397295053-172.17.0.2-1595846891459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45766,DS-e61d2d34-d2d6-48ff-a016-41a5beabb6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-7bc07ebd-ca9b-451a-aa58-060e914e1b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-dea52257-d7f8-4dfe-9f20-85941e52206c,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-2055917f-8efd-4b0e-bdc7-5a406c699412,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-015b6f3f-e87d-4b8d-a672-1cb82b3f63d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-7f5cee34-500d-4c8a-838c-e0ffe1861566,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-25bf4dac-7e61-41ca-bce2-5f8519bfae62,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-92a3693a-3f94-4988-94d1-ae06aabaf662,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127113358-172.17.0.2-1595847052982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-53e8a14d-7f16-4351-b187-12429741987c,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-32645cdb-1252-4ec1-82e5-f28f4043d38c,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-86cf088a-1d6a-4af7-8840-5a30bf9a94e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-f8873f54-1b74-4128-afd5-40c7246be6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-59457d1f-4552-40d9-b342-8f0df056d618,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-0dc6bc2e-1fb9-47af-af81-5539ca744844,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-c1307982-1bb1-4bb1-81fb-bf3e8f5433b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-f2280a57-139a-49fc-9738-25853966099f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127113358-172.17.0.2-1595847052982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-53e8a14d-7f16-4351-b187-12429741987c,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-32645cdb-1252-4ec1-82e5-f28f4043d38c,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-86cf088a-1d6a-4af7-8840-5a30bf9a94e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-f8873f54-1b74-4128-afd5-40c7246be6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-59457d1f-4552-40d9-b342-8f0df056d618,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-0dc6bc2e-1fb9-47af-af81-5539ca744844,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-c1307982-1bb1-4bb1-81fb-bf3e8f5433b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-f2280a57-139a-49fc-9738-25853966099f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147706797-172.17.0.2-1595847347339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37828,DS-1e54bb5d-8cef-4b69-9164-fd216d6fcd25,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-f8ebce36-8d90-4e7b-8b2a-40538cfd5097,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-ca191733-2fbb-4a7c-9cb1-2ce64657f7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-4b1e08a0-fe57-4a4b-baea-120bf0364a72,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-3234ac21-484c-4b55-87a6-11cc7edbb180,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-5820ea29-deef-4460-9023-daea1d2d4cae,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-278fe8c8-b377-454d-b8a1-4c9990fb8bff,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-dd65d02b-81b1-471d-8141-c5740734c544,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147706797-172.17.0.2-1595847347339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37828,DS-1e54bb5d-8cef-4b69-9164-fd216d6fcd25,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-f8ebce36-8d90-4e7b-8b2a-40538cfd5097,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-ca191733-2fbb-4a7c-9cb1-2ce64657f7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-4b1e08a0-fe57-4a4b-baea-120bf0364a72,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-3234ac21-484c-4b55-87a6-11cc7edbb180,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-5820ea29-deef-4460-9023-daea1d2d4cae,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-278fe8c8-b377-454d-b8a1-4c9990fb8bff,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-dd65d02b-81b1-471d-8141-c5740734c544,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889866456-172.17.0.2-1595847873208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39171,DS-da61afe2-a05b-421b-8789-e429b220c119,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-f0b9f6a9-cc9f-4c53-ac94-18781b2a2fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-66fed482-cbc6-4ea2-a73c-472e9e64c592,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-c1395670-13c9-4676-9c43-80bfe81fb728,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-7caca062-2bdd-42fd-ab9e-85f0b3a8a71d,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-883d95f8-dbc0-4de8-8d66-d91fccf4efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-7b84e77b-7512-44f1-8c59-05f6ce38482b,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-daafb187-e818-4267-8e7e-29b19b310ce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889866456-172.17.0.2-1595847873208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39171,DS-da61afe2-a05b-421b-8789-e429b220c119,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-f0b9f6a9-cc9f-4c53-ac94-18781b2a2fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-66fed482-cbc6-4ea2-a73c-472e9e64c592,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-c1395670-13c9-4676-9c43-80bfe81fb728,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-7caca062-2bdd-42fd-ab9e-85f0b3a8a71d,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-883d95f8-dbc0-4de8-8d66-d91fccf4efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-7b84e77b-7512-44f1-8c59-05f6ce38482b,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-daafb187-e818-4267-8e7e-29b19b310ce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723187413-172.17.0.2-1595848217544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41932,DS-09df7f0f-7bb9-4e25-b753-372a02f82914,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-c08e30ac-805a-46a8-a299-62e522e923bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-12f39cb7-27e4-4618-863f-591aa65b7c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-9c3927c8-ff67-46e0-b068-dc4ac7bda652,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-e034c8f0-849d-4a2d-a554-53331314458e,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-9e3604e0-65d0-4710-b5df-e47632b1c6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-d92ab194-b404-4127-a1e4-36a50efc795b,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-6e8e60ae-b76f-4ef7-9761-d8a5d42532f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723187413-172.17.0.2-1595848217544:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41932,DS-09df7f0f-7bb9-4e25-b753-372a02f82914,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-c08e30ac-805a-46a8-a299-62e522e923bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-12f39cb7-27e4-4618-863f-591aa65b7c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-9c3927c8-ff67-46e0-b068-dc4ac7bda652,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-e034c8f0-849d-4a2d-a554-53331314458e,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-9e3604e0-65d0-4710-b5df-e47632b1c6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-d92ab194-b404-4127-a1e4-36a50efc795b,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-6e8e60ae-b76f-4ef7-9761-d8a5d42532f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397753222-172.17.0.2-1595848591644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45065,DS-87901d7a-70ce-4b44-9700-61d554607968,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-206dd32a-2f9d-4be2-bbf8-8dfe95298f94,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-e72d73b9-e2ff-431e-bc7f-12e227dc6f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-3cf97322-7fc8-42e7-9502-00721ade63bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-8f2eb162-41a0-4f7d-a261-636a7674b55c,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-082d0b19-c0ce-4b1d-bac8-b5bea474e3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-50931919-e5a4-40df-99c3-2197afccf02d,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-0a1cfb96-3b05-4fa9-aa98-d4563daef35f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397753222-172.17.0.2-1595848591644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45065,DS-87901d7a-70ce-4b44-9700-61d554607968,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-206dd32a-2f9d-4be2-bbf8-8dfe95298f94,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-e72d73b9-e2ff-431e-bc7f-12e227dc6f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-3cf97322-7fc8-42e7-9502-00721ade63bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-8f2eb162-41a0-4f7d-a261-636a7674b55c,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-082d0b19-c0ce-4b1d-bac8-b5bea474e3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-50931919-e5a4-40df-99c3-2197afccf02d,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-0a1cfb96-3b05-4fa9-aa98-d4563daef35f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069139251-172.17.0.2-1595848849196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42305,DS-41fc938a-5140-45d1-be1c-eff6bff66b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-3b0f7f2d-45c7-4dc8-85ed-e04c150e0b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-c1b7df56-8df7-4b7d-8177-5ec9ca85a50e,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-f8dc52bf-1b08-452e-92c0-e4edc166c23a,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-4387dc4c-b37d-4fb4-8675-8ece0e285562,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-f8a386dc-db8e-4320-a17b-8b1f9cadd24e,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-d362d09d-3156-453c-a4ca-82e45aba41bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-c686420f-8517-4237-910a-66a703233f35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1069139251-172.17.0.2-1595848849196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42305,DS-41fc938a-5140-45d1-be1c-eff6bff66b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-3b0f7f2d-45c7-4dc8-85ed-e04c150e0b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-c1b7df56-8df7-4b7d-8177-5ec9ca85a50e,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-f8dc52bf-1b08-452e-92c0-e4edc166c23a,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-4387dc4c-b37d-4fb4-8675-8ece0e285562,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-f8a386dc-db8e-4320-a17b-8b1f9cadd24e,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-d362d09d-3156-453c-a4ca-82e45aba41bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41803,DS-c686420f-8517-4237-910a-66a703233f35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992418201-172.17.0.2-1595848923888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33649,DS-5f7f8f97-b0bb-4dd2-a2a9-6258ff2ed361,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-07cb5731-c501-4dcd-9994-1f6681fa4f58,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-5facdab8-a1f6-44e3-b98e-c2a2e1aa66b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-d6d48433-5ca9-422f-8dbe-32c9fb27e81b,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-ae6d85dc-51ff-478b-ba25-3274d4d7ccf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-c3747d6b-80a4-487c-b639-e050b59eb67a,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-49733105-0cb0-4376-b629-b7ff771e2918,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-cb3f4c30-e942-4358-9eb0-ec02e084034b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992418201-172.17.0.2-1595848923888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33649,DS-5f7f8f97-b0bb-4dd2-a2a9-6258ff2ed361,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-07cb5731-c501-4dcd-9994-1f6681fa4f58,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-5facdab8-a1f6-44e3-b98e-c2a2e1aa66b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-d6d48433-5ca9-422f-8dbe-32c9fb27e81b,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-ae6d85dc-51ff-478b-ba25-3274d4d7ccf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-c3747d6b-80a4-487c-b639-e050b59eb67a,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-49733105-0cb0-4376-b629-b7ff771e2918,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-cb3f4c30-e942-4358-9eb0-ec02e084034b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290258561-172.17.0.2-1595848968538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33410,DS-18048404-df05-43b2-b652-9c126801657e,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-ec15310f-50ea-4811-883a-cb89fd38f0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-795d5adf-c4a9-4015-8352-275cbf700a87,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-93da4fcd-6bfc-465a-8986-45a8d6efbc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-567f8167-232c-4270-af5b-fd74c96df15c,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-c7b5c85d-c8ae-4628-bec5-bc5d5a59c9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-34046fd1-e974-43aa-99f3-d15c6dd7b37f,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-bfbc5bc7-d681-4393-98f6-288d46fc604e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290258561-172.17.0.2-1595848968538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33410,DS-18048404-df05-43b2-b652-9c126801657e,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-ec15310f-50ea-4811-883a-cb89fd38f0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-795d5adf-c4a9-4015-8352-275cbf700a87,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-93da4fcd-6bfc-465a-8986-45a8d6efbc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-567f8167-232c-4270-af5b-fd74c96df15c,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-c7b5c85d-c8ae-4628-bec5-bc5d5a59c9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-34046fd1-e974-43aa-99f3-d15c6dd7b37f,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-bfbc5bc7-d681-4393-98f6-288d46fc604e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631619045-172.17.0.2-1595849130357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40201,DS-970e2471-7cd4-4472-b202-9445b4a118fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-d2c5f8eb-76d4-4ee6-a749-5e8e5ca706b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-a33af578-eb09-47af-b5aa-a8a415d7cc69,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-cb563d92-b0cb-4294-9da6-17412f166511,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-ac960624-6bf2-4c03-b776-610ff7ec5b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-b091148b-20cf-4b1a-b9ab-a1a51a4ddb36,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-59c39a1b-a071-4c5e-be2f-636288051740,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-a0f25c18-1c07-4e5b-a018-d433d3490dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631619045-172.17.0.2-1595849130357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40201,DS-970e2471-7cd4-4472-b202-9445b4a118fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-d2c5f8eb-76d4-4ee6-a749-5e8e5ca706b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-a33af578-eb09-47af-b5aa-a8a415d7cc69,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-cb563d92-b0cb-4294-9da6-17412f166511,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-ac960624-6bf2-4c03-b776-610ff7ec5b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-b091148b-20cf-4b1a-b9ab-a1a51a4ddb36,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-59c39a1b-a071-4c5e-be2f-636288051740,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-a0f25c18-1c07-4e5b-a018-d433d3490dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1193539418-172.17.0.2-1595849167651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36909,DS-00eaf7dc-9adf-4431-b7af-381fb02a2693,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-3419aee8-d8c0-420c-bb67-a508fd29771c,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-039e2f22-0411-47e8-90d8-caed5f93bfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-8aa764ba-3ae8-454f-ac4e-4727f1abbeba,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-e96fc74b-788e-4f8a-a5ae-b7b4e5f92e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-cd51d0a2-385c-4f91-962d-de2d15911cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-9e9b3e77-c0b4-43b3-ba66-620c74f59cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-8e439618-576b-4eac-b0ff-b82c00a66ad0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1193539418-172.17.0.2-1595849167651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36909,DS-00eaf7dc-9adf-4431-b7af-381fb02a2693,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-3419aee8-d8c0-420c-bb67-a508fd29771c,DISK], DatanodeInfoWithStorage[127.0.0.1:38911,DS-039e2f22-0411-47e8-90d8-caed5f93bfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-8aa764ba-3ae8-454f-ac4e-4727f1abbeba,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-e96fc74b-788e-4f8a-a5ae-b7b4e5f92e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-cd51d0a2-385c-4f91-962d-de2d15911cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-9e9b3e77-c0b4-43b3-ba66-620c74f59cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-8e439618-576b-4eac-b0ff-b82c00a66ad0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158226996-172.17.0.2-1595849560901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34716,DS-67254070-444c-4f4a-b05b-8bd962efe135,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-9da4ecb1-d4d7-4e4e-b10c-05c42264cfba,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-e3689238-7d20-4e46-b8e5-17b34ba73cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-88e17f7a-1137-47d0-a881-83c6550dc560,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-2082eea1-a983-4e73-8b0a-5e227d4eea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-85658150-bab3-4910-bbc4-be43086d233d,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-72f28502-ef7e-4ac9-a949-e53505ee30cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-9a6e88d9-0abb-4a1b-ae2b-5f909f36f8ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158226996-172.17.0.2-1595849560901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34716,DS-67254070-444c-4f4a-b05b-8bd962efe135,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-9da4ecb1-d4d7-4e4e-b10c-05c42264cfba,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-e3689238-7d20-4e46-b8e5-17b34ba73cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-88e17f7a-1137-47d0-a881-83c6550dc560,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-2082eea1-a983-4e73-8b0a-5e227d4eea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-85658150-bab3-4910-bbc4-be43086d233d,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-72f28502-ef7e-4ac9-a949-e53505ee30cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-9a6e88d9-0abb-4a1b-ae2b-5f909f36f8ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127728900-172.17.0.2-1595849641756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33838,DS-65e7d249-1db6-4ef7-8c6a-fed9ae01dbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-3924b9be-1831-491a-aa07-7e867c3393a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-cf5e6588-0a7e-4db0-967d-b93b962250cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-27e1551b-ef6e-4578-b7c1-ebaecb4966ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-435e51d4-6501-44b7-a7f6-f2c44d7a3f89,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-0077ba2c-6e54-434c-bc97-2282d2495dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-16767543-b31a-4398-a51f-acdd9f8d453a,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-30329a25-6467-402a-8d09-a9819f45f90a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127728900-172.17.0.2-1595849641756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33838,DS-65e7d249-1db6-4ef7-8c6a-fed9ae01dbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-3924b9be-1831-491a-aa07-7e867c3393a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-cf5e6588-0a7e-4db0-967d-b93b962250cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-27e1551b-ef6e-4578-b7c1-ebaecb4966ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-435e51d4-6501-44b7-a7f6-f2c44d7a3f89,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-0077ba2c-6e54-434c-bc97-2282d2495dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-16767543-b31a-4398-a51f-acdd9f8d453a,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-30329a25-6467-402a-8d09-a9819f45f90a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012951284-172.17.0.2-1595849713010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38695,DS-1efe17cb-e808-4310-b9f5-d90f70edf011,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-aa3c0c5b-95e8-474f-abe6-9e4e832dc345,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-7419d761-fc1e-46b3-84d5-3ea2ded2079a,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-f546867c-bb66-4978-ab4a-652c94bc8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-13f34e82-8e69-4b88-9720-d7114c30fdef,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-180f54c1-84e4-49a2-8a6a-86eb7e3cc599,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-aad1b27f-bb6a-4067-9738-4524e4b92355,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-eff1f1c7-097a-46a3-8ba4-344e8eb3974d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012951284-172.17.0.2-1595849713010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38695,DS-1efe17cb-e808-4310-b9f5-d90f70edf011,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-aa3c0c5b-95e8-474f-abe6-9e4e832dc345,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-7419d761-fc1e-46b3-84d5-3ea2ded2079a,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-f546867c-bb66-4978-ab4a-652c94bc8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-13f34e82-8e69-4b88-9720-d7114c30fdef,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-180f54c1-84e4-49a2-8a6a-86eb7e3cc599,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-aad1b27f-bb6a-4067-9738-4524e4b92355,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-eff1f1c7-097a-46a3-8ba4-344e8eb3974d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036980012-172.17.0.2-1595849742444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36833,DS-1a4ff2f1-dfbc-46cd-b669-2cdf93613185,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-eaebda2b-0908-4b8d-ab9a-205877871658,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-67074634-e99a-40b5-97e1-f9ba553614da,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-2a651f0e-a922-4fdd-a7d3-191d3c7ac3de,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-fe36562d-bd78-49dd-82bc-33bf0ccf6897,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-4117c03d-95df-4b82-8201-58d20dd3d107,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-876630a0-a3e8-40a8-8623-176d337c6132,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-9833ef1f-8535-4fca-9f48-e689ec023660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036980012-172.17.0.2-1595849742444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36833,DS-1a4ff2f1-dfbc-46cd-b669-2cdf93613185,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-eaebda2b-0908-4b8d-ab9a-205877871658,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-67074634-e99a-40b5-97e1-f9ba553614da,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-2a651f0e-a922-4fdd-a7d3-191d3c7ac3de,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-fe36562d-bd78-49dd-82bc-33bf0ccf6897,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-4117c03d-95df-4b82-8201-58d20dd3d107,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-876630a0-a3e8-40a8-8623-176d337c6132,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-9833ef1f-8535-4fca-9f48-e689ec023660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 1
v2: 18
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788281584-172.17.0.2-1595849820915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43782,DS-c4c95bf3-72b8-461c-b014-0fad0db0e226,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-e0106f1c-6a7b-4157-a10c-57f55d2db87d,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-4a6a36f7-c195-44d8-b76c-396559cbe699,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-cd2f29ab-bc70-4cf3-a3ed-b9130a44b039,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-277c493e-5a07-4e95-85f6-e7057fe3be96,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-4dca0d44-0875-4355-8f0a-4ae97df04aac,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-5aa53c40-ed56-4a4d-b0fb-e2dd67db8ece,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-9f2a2e69-4f7b-411e-ab89-1805fbe35744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788281584-172.17.0.2-1595849820915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43782,DS-c4c95bf3-72b8-461c-b014-0fad0db0e226,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-e0106f1c-6a7b-4157-a10c-57f55d2db87d,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-4a6a36f7-c195-44d8-b76c-396559cbe699,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-cd2f29ab-bc70-4cf3-a3ed-b9130a44b039,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-277c493e-5a07-4e95-85f6-e7057fe3be96,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-4dca0d44-0875-4355-8f0a-4ae97df04aac,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-5aa53c40-ed56-4a4d-b0fb-e2dd67db8ece,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-9f2a2e69-4f7b-411e-ab89-1805fbe35744,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5619
