reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740443876-172.17.0.8-1595987464765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37579,DS-a7475d72-d463-41a9-9bf8-c2b6ad140242,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-565b4c0a-50e2-49e0-b78d-f614ee8df4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-3ce6bca6-84f0-46a7-ad7b-79868779fb03,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-2a48ce52-320b-4d65-973d-441485ef9685,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-d4c91fc9-2fa3-4603-a2b2-470e75f08781,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-9876aa8b-f806-4358-9d3d-3b2fc78b9146,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-11320273-c860-4ddf-87e7-44a92cfcb452,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-fa4b4869-ebc2-483f-9a7c-2ef1360033a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740443876-172.17.0.8-1595987464765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37579,DS-a7475d72-d463-41a9-9bf8-c2b6ad140242,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-565b4c0a-50e2-49e0-b78d-f614ee8df4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-3ce6bca6-84f0-46a7-ad7b-79868779fb03,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-2a48ce52-320b-4d65-973d-441485ef9685,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-d4c91fc9-2fa3-4603-a2b2-470e75f08781,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-9876aa8b-f806-4358-9d3d-3b2fc78b9146,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-11320273-c860-4ddf-87e7-44a92cfcb452,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-fa4b4869-ebc2-483f-9a7c-2ef1360033a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014216167-172.17.0.8-1595987607063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45633,DS-a499fe1b-b457-4709-a961-a8a2175ee15a,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-8915bb7a-6e09-4504-9d47-1a903656c02d,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-9823e77e-6f43-4996-af4b-5b4104cbf3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-87dffc87-3131-4049-871f-1d64e03ebaee,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-bf65f5ba-189c-416a-9b81-4f35fb10a07a,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-09f03c25-8a06-484d-bc40-fc7011989ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-46686884-2a1e-4864-9040-1450ffb77357,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-a4432872-e9f3-4ca7-a595-362272a67112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014216167-172.17.0.8-1595987607063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45633,DS-a499fe1b-b457-4709-a961-a8a2175ee15a,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-8915bb7a-6e09-4504-9d47-1a903656c02d,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-9823e77e-6f43-4996-af4b-5b4104cbf3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-87dffc87-3131-4049-871f-1d64e03ebaee,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-bf65f5ba-189c-416a-9b81-4f35fb10a07a,DISK], DatanodeInfoWithStorage[127.0.0.1:32793,DS-09f03c25-8a06-484d-bc40-fc7011989ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-46686884-2a1e-4864-9040-1450ffb77357,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-a4432872-e9f3-4ca7-a595-362272a67112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277237839-172.17.0.8-1595987776291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-3ac62618-999e-40db-9c88-31f9a0d21273,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-a52122e5-5a1f-478d-99cf-b90432d2d1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-d4efd447-d2dd-49e8-bd83-41e57684b511,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-58d47ad3-3432-4999-aba3-4d4696b44a32,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-cb20ff33-81a2-45f0-8d93-ac3d1b2e023a,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-fbf56a97-ef27-482b-adbf-426d84970682,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-4f87d34e-6cac-4563-bc29-b858aca4465a,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-a8322376-3f94-4df3-ae49-dfcd757b40bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277237839-172.17.0.8-1595987776291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42852,DS-3ac62618-999e-40db-9c88-31f9a0d21273,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-a52122e5-5a1f-478d-99cf-b90432d2d1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-d4efd447-d2dd-49e8-bd83-41e57684b511,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-58d47ad3-3432-4999-aba3-4d4696b44a32,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-cb20ff33-81a2-45f0-8d93-ac3d1b2e023a,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-fbf56a97-ef27-482b-adbf-426d84970682,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-4f87d34e-6cac-4563-bc29-b858aca4465a,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-a8322376-3f94-4df3-ae49-dfcd757b40bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689584147-172.17.0.8-1595987854158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46842,DS-6846cac5-a5fd-4068-ace6-1dab6ce413ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-d51a5d9a-42f6-4ff2-a12b-3f739b59b469,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-545fab17-0f3e-4407-9940-e7e0eda50981,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-71e75170-8429-42a9-8586-26594f2660d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-983b5f5d-1ff9-4f46-aba2-c1cb81c0222f,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-ece4ea6e-e602-411e-9187-090c22d24821,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-45c6b377-e7cb-45f2-a274-4b7759636bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-c05d5c21-6e75-419b-9472-e02e700091c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689584147-172.17.0.8-1595987854158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46842,DS-6846cac5-a5fd-4068-ace6-1dab6ce413ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-d51a5d9a-42f6-4ff2-a12b-3f739b59b469,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-545fab17-0f3e-4407-9940-e7e0eda50981,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-71e75170-8429-42a9-8586-26594f2660d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-983b5f5d-1ff9-4f46-aba2-c1cb81c0222f,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-ece4ea6e-e602-411e-9187-090c22d24821,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-45c6b377-e7cb-45f2-a274-4b7759636bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-c05d5c21-6e75-419b-9472-e02e700091c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172485663-172.17.0.8-1595988228807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37642,DS-41db57fd-1310-4c3f-b017-d82ab76cc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-d0cb7914-2e3f-4bc0-b390-3a4498209e61,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-9b42c24f-109a-40e6-811e-313066dc1de2,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-620d4804-56e0-4c07-89c7-c992d505457b,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-7ff9126e-568b-4f39-964e-95e44b5fa534,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-1f83073a-3088-4cc5-8d0c-4085bd0a0b75,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-8fc9423b-36dc-4373-808e-9ee211b0c645,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-164b92c4-b0a3-4bd0-a8a2-9a36b85400fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172485663-172.17.0.8-1595988228807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37642,DS-41db57fd-1310-4c3f-b017-d82ab76cc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-d0cb7914-2e3f-4bc0-b390-3a4498209e61,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-9b42c24f-109a-40e6-811e-313066dc1de2,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-620d4804-56e0-4c07-89c7-c992d505457b,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-7ff9126e-568b-4f39-964e-95e44b5fa534,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-1f83073a-3088-4cc5-8d0c-4085bd0a0b75,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-8fc9423b-36dc-4373-808e-9ee211b0c645,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-164b92c4-b0a3-4bd0-a8a2-9a36b85400fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394530384-172.17.0.8-1595988330515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40986,DS-d69693ef-b345-4781-88f3-6b6d5f60e9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-d2f9a677-8c0e-46dd-81cd-9aebcb2a6ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-afc4beb4-4506-4f09-8548-dedfcdfa7bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-18268f0b-3a3a-4cf8-bd39-66177e2cd722,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-d14a0233-12d2-4268-a743-049fc8c1b69c,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-98597e61-b281-4977-ba1d-e0d0cce527b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-24999401-1082-4cdb-8f10-b70425003524,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-0dfa8c6e-aa60-4484-9211-f4dfde5283e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394530384-172.17.0.8-1595988330515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40986,DS-d69693ef-b345-4781-88f3-6b6d5f60e9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-d2f9a677-8c0e-46dd-81cd-9aebcb2a6ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-afc4beb4-4506-4f09-8548-dedfcdfa7bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-18268f0b-3a3a-4cf8-bd39-66177e2cd722,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-d14a0233-12d2-4268-a743-049fc8c1b69c,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-98597e61-b281-4977-ba1d-e0d0cce527b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-24999401-1082-4cdb-8f10-b70425003524,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-0dfa8c6e-aa60-4484-9211-f4dfde5283e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1179050804-172.17.0.8-1595988473030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38678,DS-7576ab66-e477-4cf2-a0ec-72baeae63c13,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-ef52f8f4-6213-4613-880b-805adbe47b48,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-9c022e9d-a12b-4f96-a1a7-a77379793a67,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-45b6b993-1ef4-4d4b-b7bc-d61d79d8a86b,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-f88dba13-0ea8-49fd-aeab-fe4e48847cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-4359b4eb-0f0d-48f2-9e30-fcd8582c4f88,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-97401924-a2d8-4a15-973c-94b89bbb2162,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-22da8f58-123e-4f62-9c5a-59f2a08a0e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1179050804-172.17.0.8-1595988473030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38678,DS-7576ab66-e477-4cf2-a0ec-72baeae63c13,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-ef52f8f4-6213-4613-880b-805adbe47b48,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-9c022e9d-a12b-4f96-a1a7-a77379793a67,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-45b6b993-1ef4-4d4b-b7bc-d61d79d8a86b,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-f88dba13-0ea8-49fd-aeab-fe4e48847cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-4359b4eb-0f0d-48f2-9e30-fcd8582c4f88,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-97401924-a2d8-4a15-973c-94b89bbb2162,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-22da8f58-123e-4f62-9c5a-59f2a08a0e44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067093845-172.17.0.8-1595989023292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46724,DS-28240318-1774-45bd-b708-f68e55066127,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-89cbfe8f-9aa3-4ce3-933c-41002aa881d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-ac3f7b08-d1ea-43a2-b5a6-a0619a798aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-973a09d5-b0e6-43bf-b1b9-7b58a6f47a99,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-e4d7f3f6-44e8-476a-8e40-3821696ea371,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-75be61ca-8ec8-44aa-9730-52f2d0d6dc57,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-9082a23a-b18c-49f4-be57-a1e315de6055,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-546df922-47f6-449d-8531-af05034b3f5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067093845-172.17.0.8-1595989023292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46724,DS-28240318-1774-45bd-b708-f68e55066127,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-89cbfe8f-9aa3-4ce3-933c-41002aa881d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-ac3f7b08-d1ea-43a2-b5a6-a0619a798aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-973a09d5-b0e6-43bf-b1b9-7b58a6f47a99,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-e4d7f3f6-44e8-476a-8e40-3821696ea371,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-75be61ca-8ec8-44aa-9730-52f2d0d6dc57,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-9082a23a-b18c-49f4-be57-a1e315de6055,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-546df922-47f6-449d-8531-af05034b3f5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722214541-172.17.0.8-1595989054070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45242,DS-df061627-9b58-438a-be92-7f06fe2be478,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-6bd086b4-8b97-4052-b685-bd062dccae40,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-8df78413-2ee9-40f7-bb21-2d4e8d7c70d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-402fba13-948d-472e-8e98-9269c7f55075,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-53e54a7f-d8e1-4690-89f6-efacfc3c22da,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-076db15e-5c15-4b9d-a9be-28fb5f32dd31,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-6f49a225-2432-4b78-bebe-07f8b308e509,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-49e66caa-0269-4ee1-bc7b-8b27c43cb504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722214541-172.17.0.8-1595989054070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45242,DS-df061627-9b58-438a-be92-7f06fe2be478,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-6bd086b4-8b97-4052-b685-bd062dccae40,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-8df78413-2ee9-40f7-bb21-2d4e8d7c70d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44494,DS-402fba13-948d-472e-8e98-9269c7f55075,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-53e54a7f-d8e1-4690-89f6-efacfc3c22da,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-076db15e-5c15-4b9d-a9be-28fb5f32dd31,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-6f49a225-2432-4b78-bebe-07f8b308e509,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-49e66caa-0269-4ee1-bc7b-8b27c43cb504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-122564360-172.17.0.8-1595989209190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37528,DS-d7e69011-1230-4a56-a344-d35be934623c,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-24d56e36-823e-4ef7-9d8a-8171501bc592,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-7558c3f7-6517-46ac-bedc-167334e1405f,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-b145e58b-868e-4372-be28-8e1c60ace48f,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-ec030179-a008-4063-aa51-adb3be9c584f,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-04a83cfd-c3da-4e5e-8ba2-4c7c2c60f27b,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-85ace991-551c-4272-b823-c89866e98e87,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-7f01274a-b5f8-4659-847e-33777abec44b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-122564360-172.17.0.8-1595989209190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37528,DS-d7e69011-1230-4a56-a344-d35be934623c,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-24d56e36-823e-4ef7-9d8a-8171501bc592,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-7558c3f7-6517-46ac-bedc-167334e1405f,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-b145e58b-868e-4372-be28-8e1c60ace48f,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-ec030179-a008-4063-aa51-adb3be9c584f,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-04a83cfd-c3da-4e5e-8ba2-4c7c2c60f27b,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-85ace991-551c-4272-b823-c89866e98e87,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-7f01274a-b5f8-4659-847e-33777abec44b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1156547066-172.17.0.8-1595989389113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38694,DS-d27d8e66-d1ca-4bf2-adab-149a332c05cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-1fad1169-7ddd-4b8a-9561-37c2b36c5ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-0d09dab8-d2a2-49ec-8296-7572229987ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-8acf8d92-793f-43fe-9128-5b75290d4072,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-a9f31b5e-b31e-407a-819e-76a300fd6cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-a2abecf7-8b54-41f6-8387-fb47ca11f17b,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-b472b1e2-1df8-449c-a2e5-9a944c29b7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-737dc1e7-9e21-4843-a0ea-df616fe579f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1156547066-172.17.0.8-1595989389113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38694,DS-d27d8e66-d1ca-4bf2-adab-149a332c05cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-1fad1169-7ddd-4b8a-9561-37c2b36c5ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-0d09dab8-d2a2-49ec-8296-7572229987ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-8acf8d92-793f-43fe-9128-5b75290d4072,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-a9f31b5e-b31e-407a-819e-76a300fd6cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-a2abecf7-8b54-41f6-8387-fb47ca11f17b,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-b472b1e2-1df8-449c-a2e5-9a944c29b7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-737dc1e7-9e21-4843-a0ea-df616fe579f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1300743516-172.17.0.8-1595989756303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46034,DS-e1d039e3-2cac-4d5f-b0a8-52ec6705ad6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-463e7513-6414-4ccf-9fc8-dc70fc4f779d,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-085eb6b1-4565-490e-ad87-6fbcfbd5c13e,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-6896416c-832d-4806-98ce-6d484322db25,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-bb311066-bad2-4052-9b3a-c3c5fc57a7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-d6307272-9c5f-43c5-aa61-e2fa0ecc165c,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-eb6b4675-a08f-4e1b-9c27-f414e3b717b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-1e4c0f61-5469-4f6c-8702-59d880a91d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1300743516-172.17.0.8-1595989756303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46034,DS-e1d039e3-2cac-4d5f-b0a8-52ec6705ad6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-463e7513-6414-4ccf-9fc8-dc70fc4f779d,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-085eb6b1-4565-490e-ad87-6fbcfbd5c13e,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-6896416c-832d-4806-98ce-6d484322db25,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-bb311066-bad2-4052-9b3a-c3c5fc57a7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-d6307272-9c5f-43c5-aa61-e2fa0ecc165c,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-eb6b4675-a08f-4e1b-9c27-f414e3b717b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-1e4c0f61-5469-4f6c-8702-59d880a91d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272977653-172.17.0.8-1595989987348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-5301e2e6-15de-4593-a03a-c828b2a79b81,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-01f5f36c-3cd9-4d6e-a6b8-9b89eea5ed71,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-bedd14a0-fe38-4e15-8a5e-534740a04be8,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-0e4cc27c-8b14-4a9b-b834-1e585cb43269,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-6152d395-f2e9-4f67-a25c-0c969c45e826,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-52c6faf8-4dbf-4dc7-b792-de4d96db1787,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-09ecd149-8bcb-46e8-83c5-fa5d5afb7753,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-8970accf-c272-4336-80eb-9b1814a14977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272977653-172.17.0.8-1595989987348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-5301e2e6-15de-4593-a03a-c828b2a79b81,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-01f5f36c-3cd9-4d6e-a6b8-9b89eea5ed71,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-bedd14a0-fe38-4e15-8a5e-534740a04be8,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-0e4cc27c-8b14-4a9b-b834-1e585cb43269,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-6152d395-f2e9-4f67-a25c-0c969c45e826,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-52c6faf8-4dbf-4dc7-b792-de4d96db1787,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-09ecd149-8bcb-46e8-83c5-fa5d5afb7753,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-8970accf-c272-4336-80eb-9b1814a14977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1498090602-172.17.0.8-1595990452770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44768,DS-f0336774-be6a-4f76-9e87-2054b57248f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-82822402-2454-418f-a91f-0f1911cc9796,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-a9183e54-a298-43d4-94be-f2904ca39f19,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-5bbef7ba-54eb-4039-a063-06264beb1971,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-920b6293-7f7c-4aef-b356-f9871295712e,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-f76b2100-8ed6-48c5-9426-f922eb3f7dad,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-dd2c7323-fc53-4e7e-8d89-d11abdcc11d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-fea4a15b-b8c1-4bef-80c9-88172505b5f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1498090602-172.17.0.8-1595990452770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44768,DS-f0336774-be6a-4f76-9e87-2054b57248f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-82822402-2454-418f-a91f-0f1911cc9796,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-a9183e54-a298-43d4-94be-f2904ca39f19,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-5bbef7ba-54eb-4039-a063-06264beb1971,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-920b6293-7f7c-4aef-b356-f9871295712e,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-f76b2100-8ed6-48c5-9426-f922eb3f7dad,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-dd2c7323-fc53-4e7e-8d89-d11abdcc11d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-fea4a15b-b8c1-4bef-80c9-88172505b5f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584841938-172.17.0.8-1595990928253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-046cd4f9-f873-41a4-a18e-876b44c2d756,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-bc9fb013-0193-4e9b-b12f-e904fea717e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-6a19ab39-987a-4cc9-8e20-59ab9c699972,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-d4f11cb8-bc75-406d-8788-43890d40ea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-87d276db-2a89-4122-84eb-ad1647205a10,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-b7af7f57-242a-415e-81ee-b51037f68522,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-f56dabe8-04eb-461e-8783-e006ba9250d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-88279aa2-080d-468c-8b86-904d0dd96e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584841938-172.17.0.8-1595990928253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41087,DS-046cd4f9-f873-41a4-a18e-876b44c2d756,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-bc9fb013-0193-4e9b-b12f-e904fea717e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-6a19ab39-987a-4cc9-8e20-59ab9c699972,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-d4f11cb8-bc75-406d-8788-43890d40ea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-87d276db-2a89-4122-84eb-ad1647205a10,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-b7af7f57-242a-415e-81ee-b51037f68522,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-f56dabe8-04eb-461e-8783-e006ba9250d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-88279aa2-080d-468c-8b86-904d0dd96e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829708686-172.17.0.8-1595991132001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36620,DS-703224ca-d7b8-4a49-b878-77db5e72fe12,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-7ab3b14e-4ae9-474e-9916-7ff74eb6df30,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-f5b39cdd-52e7-499e-b107-d0dc548f9846,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-1c173772-dea4-4825-ae04-0461b4b5a3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-432e7d70-d021-4d79-a1f2-942d2ddca07b,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-bdecec92-34b5-4188-925a-d12130cf67ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-7688b375-ab7d-4fee-a595-3fe9860c0c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-4edf4521-e6b6-4a89-b0f4-4d55c7aa51fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829708686-172.17.0.8-1595991132001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36620,DS-703224ca-d7b8-4a49-b878-77db5e72fe12,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-7ab3b14e-4ae9-474e-9916-7ff74eb6df30,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-f5b39cdd-52e7-499e-b107-d0dc548f9846,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-1c173772-dea4-4825-ae04-0461b4b5a3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-432e7d70-d021-4d79-a1f2-942d2ddca07b,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-bdecec92-34b5-4188-925a-d12130cf67ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-7688b375-ab7d-4fee-a595-3fe9860c0c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-4edf4521-e6b6-4a89-b0f4-4d55c7aa51fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669769453-172.17.0.8-1595991313522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39693,DS-d14445e6-c38d-4dbd-b25a-92113826b8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-9aa9d7b1-35b6-43a0-9b3a-22433cb5811c,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-c445e79b-5cb9-4ffa-878b-4eb06c723375,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-babca122-3d7a-400f-a7a8-27f9f0fc2ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-c72b3fa3-74c6-47fa-9e52-25c23d0ce4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-d4343611-fe1d-4d2f-a335-fe17c4a83b95,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-b1b7f2ec-c3de-40e9-a214-08020516ede9,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-47e83b26-cae4-493f-81a4-b6d3c9089c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669769453-172.17.0.8-1595991313522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39693,DS-d14445e6-c38d-4dbd-b25a-92113826b8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-9aa9d7b1-35b6-43a0-9b3a-22433cb5811c,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-c445e79b-5cb9-4ffa-878b-4eb06c723375,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-babca122-3d7a-400f-a7a8-27f9f0fc2ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-c72b3fa3-74c6-47fa-9e52-25c23d0ce4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-d4343611-fe1d-4d2f-a335-fe17c4a83b95,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-b1b7f2ec-c3de-40e9-a214-08020516ede9,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-47e83b26-cae4-493f-81a4-b6d3c9089c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600045846-172.17.0.8-1595991990761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37904,DS-6358fbdb-9cad-432b-85e1-181c8604eb68,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-5fcd5d9c-9c0c-4619-a83c-b6fca8873d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-8fc3f6de-4436-47dc-a99a-2cb1a0251d84,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-3dcb4a1c-d797-4f52-ac34-5e308b4bef3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-64f38229-77ab-4106-86d8-5dd7dbb3a753,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-3e915f38-ca0d-4123-b977-43f4934c832d,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-c6e2d0a4-39a5-4820-82c4-5b9b4fdf06ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-08eb6e35-207a-4951-8841-3e9c1e5b4933,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1600045846-172.17.0.8-1595991990761:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37904,DS-6358fbdb-9cad-432b-85e1-181c8604eb68,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-5fcd5d9c-9c0c-4619-a83c-b6fca8873d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-8fc3f6de-4436-47dc-a99a-2cb1a0251d84,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-3dcb4a1c-d797-4f52-ac34-5e308b4bef3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-64f38229-77ab-4106-86d8-5dd7dbb3a753,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-3e915f38-ca0d-4123-b977-43f4934c832d,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-c6e2d0a4-39a5-4820-82c4-5b9b4fdf06ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-08eb6e35-207a-4951-8841-3e9c1e5b4933,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946416882-172.17.0.8-1595992133402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41416,DS-f83dd011-8bf2-4356-8a8e-ced34066afc3,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-e411041a-aa33-483c-8755-1b75293be707,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-72faefcb-17b9-4b1e-af59-f825af95690c,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-ed751259-9c82-487b-bd75-fbb046bd6ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-b5f49b9f-4500-43f8-86ed-5f23be6d6ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-6fbb223e-33d1-42fe-b3a8-9c0fd027e1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-9b508bef-4a6c-4960-aac1-521f57a3c5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-7e33a0de-0a9b-4787-b5b8-74cd717358d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946416882-172.17.0.8-1595992133402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41416,DS-f83dd011-8bf2-4356-8a8e-ced34066afc3,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-e411041a-aa33-483c-8755-1b75293be707,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-72faefcb-17b9-4b1e-af59-f825af95690c,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-ed751259-9c82-487b-bd75-fbb046bd6ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-b5f49b9f-4500-43f8-86ed-5f23be6d6ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-6fbb223e-33d1-42fe-b3a8-9c0fd027e1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-9b508bef-4a6c-4960-aac1-521f57a3c5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-7e33a0de-0a9b-4787-b5b8-74cd717358d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881337588-172.17.0.8-1595992233437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36836,DS-25fe12e4-94d8-47fe-b6e2-e456738ed7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-79628db6-9d5b-4922-b214-b9ca984cf74b,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-db3ffd22-ee83-40e9-a56e-ff5954a9ae0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-ae297172-2dce-4553-b542-27bf8f6e736b,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-56224c58-434c-4bca-b871-91b80e435e84,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-4bc27c76-3434-4e10-856b-c512f7100e55,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-33f81990-f4ed-413c-84e2-fdd28c99808a,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-4d08a2f6-246e-4546-847f-4e99603331c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881337588-172.17.0.8-1595992233437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36836,DS-25fe12e4-94d8-47fe-b6e2-e456738ed7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-79628db6-9d5b-4922-b214-b9ca984cf74b,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-db3ffd22-ee83-40e9-a56e-ff5954a9ae0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-ae297172-2dce-4553-b542-27bf8f6e736b,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-56224c58-434c-4bca-b871-91b80e435e84,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-4bc27c76-3434-4e10-856b-c512f7100e55,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-33f81990-f4ed-413c-84e2-fdd28c99808a,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-4d08a2f6-246e-4546-847f-4e99603331c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-348414897-172.17.0.8-1595992648325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39923,DS-d66a596f-18b0-44da-a4ec-b6907bac8ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-a56e25c0-0d8e-4cf0-bf08-de3b9499028b,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-f52bbde0-bb41-456e-91ee-8a4d1d8bd7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-3a2a46a5-4bf3-442f-8cab-696358e1d004,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-43aa5919-8e4c-4482-9c83-b63bb0a4671d,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-e314d41d-800f-4881-b919-01bc1a90737a,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-c338b0e8-095b-498e-955e-27ce7c7d202b,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-cb7eecc9-6248-4480-aaf6-5dcdd2753730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-348414897-172.17.0.8-1595992648325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39923,DS-d66a596f-18b0-44da-a4ec-b6907bac8ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-a56e25c0-0d8e-4cf0-bf08-de3b9499028b,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-f52bbde0-bb41-456e-91ee-8a4d1d8bd7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-3a2a46a5-4bf3-442f-8cab-696358e1d004,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-43aa5919-8e4c-4482-9c83-b63bb0a4671d,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-e314d41d-800f-4881-b919-01bc1a90737a,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-c338b0e8-095b-498e-955e-27ce7c7d202b,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-cb7eecc9-6248-4480-aaf6-5dcdd2753730,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5425
