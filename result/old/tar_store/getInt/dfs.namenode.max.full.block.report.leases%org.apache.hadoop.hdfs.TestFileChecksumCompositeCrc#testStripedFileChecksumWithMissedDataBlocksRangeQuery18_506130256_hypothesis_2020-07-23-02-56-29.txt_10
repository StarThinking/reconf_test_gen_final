reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172839242-172.17.0.3-1595473056810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-b83f4bea-0993-4010-b959-d4f25ca4956a,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-20daa1d9-6101-42d0-8e47-8aecd11940b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-e7ff6feb-5ec8-4002-8b5b-63154d052f05,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-ef62f46a-4182-4747-8f79-6f59f74e6e28,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-44ee5948-8dee-4626-9f9d-82618240ef28,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-dab269b4-a5eb-4baa-af58-ebcb75380e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-d3f507fc-3c66-40c6-98ae-f611492acb51,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-b646bfbe-292c-41b7-b1d5-2d31f8d61bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172839242-172.17.0.3-1595473056810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-b83f4bea-0993-4010-b959-d4f25ca4956a,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-20daa1d9-6101-42d0-8e47-8aecd11940b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-e7ff6feb-5ec8-4002-8b5b-63154d052f05,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-ef62f46a-4182-4747-8f79-6f59f74e6e28,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-44ee5948-8dee-4626-9f9d-82618240ef28,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-dab269b4-a5eb-4baa-af58-ebcb75380e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-d3f507fc-3c66-40c6-98ae-f611492acb51,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-b646bfbe-292c-41b7-b1d5-2d31f8d61bae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612130216-172.17.0.3-1595474039015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33623,DS-6799237b-6024-449c-8136-c67cc81c573f,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-c23bb572-5eb8-496d-b432-f1d753f59734,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-c80db991-8d15-4e9d-9db1-7653cff665d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-2e733827-6d52-4da8-b3bf-8785ad51fbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-f0a9f6c0-28cd-4ef0-b7f6-1022e7df125c,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-05217982-2dc4-4a63-bd49-431b146c53ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-21805444-e5f7-4960-9d5f-ecb4025fa614,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-038e65d9-527e-4113-ab1f-990c8fadae88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612130216-172.17.0.3-1595474039015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33623,DS-6799237b-6024-449c-8136-c67cc81c573f,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-c23bb572-5eb8-496d-b432-f1d753f59734,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-c80db991-8d15-4e9d-9db1-7653cff665d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-2e733827-6d52-4da8-b3bf-8785ad51fbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-f0a9f6c0-28cd-4ef0-b7f6-1022e7df125c,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-05217982-2dc4-4a63-bd49-431b146c53ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-21805444-e5f7-4960-9d5f-ecb4025fa614,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-038e65d9-527e-4113-ab1f-990c8fadae88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1256176134-172.17.0.3-1595474438133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-b07be6d4-b8f8-4199-93db-aa699c965dda,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-f7517b6d-fd65-4ef8-ba0b-6356c427fae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-136aef03-949f-49df-90c2-93ba8c7b3603,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-830f33e0-5ca8-48ff-a516-3d369f7a507b,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-a6fd7a29-b703-4aa4-a10a-f99a4cbb8d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-bb913096-d6fb-47a0-9832-f784a3f57b38,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-536afe95-39ab-46e0-851a-bb07264303bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-e02d59be-2549-430b-964b-3e5e3a468b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1256176134-172.17.0.3-1595474438133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44462,DS-b07be6d4-b8f8-4199-93db-aa699c965dda,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-f7517b6d-fd65-4ef8-ba0b-6356c427fae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-136aef03-949f-49df-90c2-93ba8c7b3603,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-830f33e0-5ca8-48ff-a516-3d369f7a507b,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-a6fd7a29-b703-4aa4-a10a-f99a4cbb8d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-bb913096-d6fb-47a0-9832-f784a3f57b38,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-536afe95-39ab-46e0-851a-bb07264303bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-e02d59be-2549-430b-964b-3e5e3a468b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510241883-172.17.0.3-1595474570297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40765,DS-0113f5ba-9e6a-4e90-8686-9c4d14686fde,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-23383b13-44b1-46d4-8e30-c30aa41ce92c,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-44b10b6b-72c6-4ebc-81ff-4e08a8e9410c,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-91f056e2-882f-4c40-897e-00b89ed145b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-d2187eea-fbe9-4f82-a8de-1e372c260fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-6b15d0b1-9f43-4361-b80a-d1abc911ae49,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-6bab5740-c206-463f-b505-a1cbddb7512c,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-71bb75b4-f961-485a-be53-64185b1436c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1510241883-172.17.0.3-1595474570297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40765,DS-0113f5ba-9e6a-4e90-8686-9c4d14686fde,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-23383b13-44b1-46d4-8e30-c30aa41ce92c,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-44b10b6b-72c6-4ebc-81ff-4e08a8e9410c,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-91f056e2-882f-4c40-897e-00b89ed145b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-d2187eea-fbe9-4f82-a8de-1e372c260fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-6b15d0b1-9f43-4361-b80a-d1abc911ae49,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-6bab5740-c206-463f-b505-a1cbddb7512c,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-71bb75b4-f961-485a-be53-64185b1436c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1681080598-172.17.0.3-1595475612277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42737,DS-75c01456-fdd9-4d19-b08a-cc7093ef3523,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-36f29096-c52b-4d57-a750-ed28ea82b051,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-b8ac4e61-8336-44f6-8b11-bf579f104297,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-3661e846-7cbc-45ef-a37a-6e14de33aaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-54b46780-1499-44cb-8828-a399637a13c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-34412ac1-246b-4934-b181-4d3ccb21d705,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-46b59435-65f5-41af-8ac2-7ce01682cd04,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-38fc2da3-70ae-4e3c-bb3a-d632f5181bd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1681080598-172.17.0.3-1595475612277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42737,DS-75c01456-fdd9-4d19-b08a-cc7093ef3523,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-36f29096-c52b-4d57-a750-ed28ea82b051,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-b8ac4e61-8336-44f6-8b11-bf579f104297,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-3661e846-7cbc-45ef-a37a-6e14de33aaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-54b46780-1499-44cb-8828-a399637a13c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-34412ac1-246b-4934-b181-4d3ccb21d705,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-46b59435-65f5-41af-8ac2-7ce01682cd04,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-38fc2da3-70ae-4e3c-bb3a-d632f5181bd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760921757-172.17.0.3-1595475649840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43739,DS-8810ceb5-6adc-4b21-8fa7-634949d564f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-6c2e7dc1-4296-4369-925d-2074a3fb6249,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-5b0ec420-2f0c-4296-963a-3d1bde65fafc,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-a8dd745b-af07-44c2-9892-5d7fb35d23be,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-f87b49b2-c692-4159-a8b9-6f0ad214e80e,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-8418e762-c5d2-4167-8066-4a10dfdd4c36,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-97650fd4-f7b8-428a-ab1d-9e3f4603c6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-dbd05149-c81c-48df-960a-ff47b9c2305a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760921757-172.17.0.3-1595475649840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43739,DS-8810ceb5-6adc-4b21-8fa7-634949d564f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-6c2e7dc1-4296-4369-925d-2074a3fb6249,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-5b0ec420-2f0c-4296-963a-3d1bde65fafc,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-a8dd745b-af07-44c2-9892-5d7fb35d23be,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-f87b49b2-c692-4159-a8b9-6f0ad214e80e,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-8418e762-c5d2-4167-8066-4a10dfdd4c36,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-97650fd4-f7b8-428a-ab1d-9e3f4603c6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-dbd05149-c81c-48df-960a-ff47b9c2305a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524597777-172.17.0.3-1595477032542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41336,DS-897479dc-de41-455a-a441-157ecd36b2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-8cbfdf20-5ad9-40f0-ac66-ec77fdd629e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-416f4389-25a0-4119-9d66-5e58f6c8dde3,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-62b82bb1-e9bd-4bd0-b87a-a689df2694f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-827860b8-ecc9-43af-a476-5a0241fc83b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-c7fc844b-6f96-474a-afdf-b0498d07c81e,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-83709b0f-6039-4597-b583-0f8624dc7321,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-087ac076-733e-4f6a-a053-a4959544dbba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524597777-172.17.0.3-1595477032542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41336,DS-897479dc-de41-455a-a441-157ecd36b2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-8cbfdf20-5ad9-40f0-ac66-ec77fdd629e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-416f4389-25a0-4119-9d66-5e58f6c8dde3,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-62b82bb1-e9bd-4bd0-b87a-a689df2694f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-827860b8-ecc9-43af-a476-5a0241fc83b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-c7fc844b-6f96-474a-afdf-b0498d07c81e,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-83709b0f-6039-4597-b583-0f8624dc7321,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-087ac076-733e-4f6a-a053-a4959544dbba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370477900-172.17.0.3-1595477398345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40741,DS-3cd9e64d-798d-424a-af21-143fc00b0f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-5462dbb0-ca80-4d5c-aee4-4122f8180b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-65fb832d-3b8f-4515-a130-f0b1991447fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-86596699-ba2b-4a4c-969f-11e55a01bead,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-01e3fac1-01ef-4601-b582-8907578e9832,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-f3d184b8-cab0-4abc-b3a9-695f8e54c83d,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-cfa2b20e-896c-485a-beb2-70c0258eba11,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-30c62070-0d08-4389-b1c4-b1dc1083924a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370477900-172.17.0.3-1595477398345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40741,DS-3cd9e64d-798d-424a-af21-143fc00b0f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-5462dbb0-ca80-4d5c-aee4-4122f8180b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-65fb832d-3b8f-4515-a130-f0b1991447fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-86596699-ba2b-4a4c-969f-11e55a01bead,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-01e3fac1-01ef-4601-b582-8907578e9832,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-f3d184b8-cab0-4abc-b3a9-695f8e54c83d,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-cfa2b20e-896c-485a-beb2-70c0258eba11,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-30c62070-0d08-4389-b1c4-b1dc1083924a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817201098-172.17.0.3-1595477864349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33881,DS-8e8fb3f7-8a13-4acf-8510-f54b862359e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-19a635c6-bd55-436f-90d9-51f24ef1c8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-b7fd8f1d-9a12-4a99-9313-4bf47d540586,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-b61a6a65-f852-4063-9060-2b38782fb809,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-fa0c96f0-edbe-47c4-a9ad-2999d1482785,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-23c203a1-e617-40f7-b99a-06f811f4fcce,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-0c0161f5-dd2f-4ae3-9e50-b6eb73972934,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-645a1eb8-7a72-463c-a706-90804d2fd928,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817201098-172.17.0.3-1595477864349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33881,DS-8e8fb3f7-8a13-4acf-8510-f54b862359e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-19a635c6-bd55-436f-90d9-51f24ef1c8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-b7fd8f1d-9a12-4a99-9313-4bf47d540586,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-b61a6a65-f852-4063-9060-2b38782fb809,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-fa0c96f0-edbe-47c4-a9ad-2999d1482785,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-23c203a1-e617-40f7-b99a-06f811f4fcce,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-0c0161f5-dd2f-4ae3-9e50-b6eb73972934,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-645a1eb8-7a72-463c-a706-90804d2fd928,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386673117-172.17.0.3-1595477983314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34050,DS-8f2e2073-7275-4aba-b8e5-7e435bf08195,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-2d2a88ae-7d94-424c-ac13-cdb9928a8bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-56b78f8d-3c78-4839-81e4-515f9acb9e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-33a9bc32-3dab-414c-970f-96770ca1f020,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-7f8ca0c6-450d-44c4-bc72-392b6c34ea65,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-79e2f8ab-3f9d-4f26-a7ad-5c16af0aef5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-e68aba2d-1a06-466c-8eb7-f0fb0ee0742c,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-3ef7d53c-3dac-49c1-ad5e-fe747c06f391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386673117-172.17.0.3-1595477983314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34050,DS-8f2e2073-7275-4aba-b8e5-7e435bf08195,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-2d2a88ae-7d94-424c-ac13-cdb9928a8bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-56b78f8d-3c78-4839-81e4-515f9acb9e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-33a9bc32-3dab-414c-970f-96770ca1f020,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-7f8ca0c6-450d-44c4-bc72-392b6c34ea65,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-79e2f8ab-3f9d-4f26-a7ad-5c16af0aef5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-e68aba2d-1a06-466c-8eb7-f0fb0ee0742c,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-3ef7d53c-3dac-49c1-ad5e-fe747c06f391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355847553-172.17.0.3-1595478288485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33903,DS-ba3dc204-db99-4d30-b8a3-5da01b240aba,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-4fb14166-92fe-4568-b8f9-237c7e88b14f,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-b68015a6-2df8-45c4-9ef1-e90a0226e183,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-0ab2f466-66c4-4d3a-8b79-2297398fc616,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-b89ff8d8-3e16-4aac-9de3-7da1a2577f08,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-b299b061-da97-4a74-8ae7-83a59410e633,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-a6b953c6-cf5a-4f13-af70-2193f7b23465,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-308eab77-81fb-4110-a6ca-fece6d44d724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-355847553-172.17.0.3-1595478288485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33903,DS-ba3dc204-db99-4d30-b8a3-5da01b240aba,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-4fb14166-92fe-4568-b8f9-237c7e88b14f,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-b68015a6-2df8-45c4-9ef1-e90a0226e183,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-0ab2f466-66c4-4d3a-8b79-2297398fc616,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-b89ff8d8-3e16-4aac-9de3-7da1a2577f08,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-b299b061-da97-4a74-8ae7-83a59410e633,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-a6b953c6-cf5a-4f13-af70-2193f7b23465,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-308eab77-81fb-4110-a6ca-fece6d44d724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2126022133-172.17.0.3-1595478461613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45840,DS-6ad071ef-4ff1-463b-9d3b-6515af0f71b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-dc858522-098e-4729-aba0-aa055ff1a93e,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-59a4e6a6-b3b6-427f-ac56-83900cb428a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-8de12406-6dd0-4241-9a2c-e86204c7d9de,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-5e080e8a-9c89-4d6c-8e58-d9bf2ca93eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-d02e3e31-d194-4bc0-86b5-36dbd6d88dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-7bc3f821-a9dd-45a6-bffc-23f6c567eedf,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-75804430-8482-4041-9ac0-15235d4e0570,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2126022133-172.17.0.3-1595478461613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45840,DS-6ad071ef-4ff1-463b-9d3b-6515af0f71b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-dc858522-098e-4729-aba0-aa055ff1a93e,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-59a4e6a6-b3b6-427f-ac56-83900cb428a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-8de12406-6dd0-4241-9a2c-e86204c7d9de,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-5e080e8a-9c89-4d6c-8e58-d9bf2ca93eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-d02e3e31-d194-4bc0-86b5-36dbd6d88dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-7bc3f821-a9dd-45a6-bffc-23f6c567eedf,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-75804430-8482-4041-9ac0-15235d4e0570,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-764390279-172.17.0.3-1595478750222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37695,DS-3bfaad6e-049c-412d-b6bb-f2af911bb278,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-627d3b8a-3b91-4e33-9851-f1d9cd7c0ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-68a9bcd2-3611-4956-9ce7-976867ac406f,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-1ed8946b-c28d-4f2f-9052-09006c506d38,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-759cb418-6355-40ba-9769-5539906832e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-5f8668cf-3f05-4119-a9cc-b922faff03e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-8dba29dc-9404-4581-be0d-16a27db682ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-1bfaf99e-de9f-4d27-afab-6815423d370c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-764390279-172.17.0.3-1595478750222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37695,DS-3bfaad6e-049c-412d-b6bb-f2af911bb278,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-627d3b8a-3b91-4e33-9851-f1d9cd7c0ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-68a9bcd2-3611-4956-9ce7-976867ac406f,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-1ed8946b-c28d-4f2f-9052-09006c506d38,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-759cb418-6355-40ba-9769-5539906832e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-5f8668cf-3f05-4119-a9cc-b922faff03e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-8dba29dc-9404-4581-be0d-16a27db682ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-1bfaf99e-de9f-4d27-afab-6815423d370c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 50
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67545145-172.17.0.3-1595479032249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-43fa8a24-5a34-4008-a35e-b98c4b0b2077,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-47199d46-e3d0-4cb8-ae36-16b63bb48089,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-e1677ee6-526c-4b4f-8174-40cbd2614e17,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-787291b9-ede4-4f99-b1aa-fd96fd7cef39,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-72615fc1-516e-48a0-b38c-a84327070f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-b6afa3b5-354c-4909-89ca-3178695ebd74,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-ee85b5a9-dd3c-4c02-b1fe-5015cec4dce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-b48a78c1-564d-4822-ac06-38a08d4a52d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67545145-172.17.0.3-1595479032249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-43fa8a24-5a34-4008-a35e-b98c4b0b2077,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-47199d46-e3d0-4cb8-ae36-16b63bb48089,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-e1677ee6-526c-4b4f-8174-40cbd2614e17,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-787291b9-ede4-4f99-b1aa-fd96fd7cef39,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-72615fc1-516e-48a0-b38c-a84327070f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-b6afa3b5-354c-4909-89ca-3178695ebd74,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-ee85b5a9-dd3c-4c02-b1fe-5015cec4dce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-b48a78c1-564d-4822-ac06-38a08d4a52d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6539
