reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179872789-172.17.0.9-1595925759872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34143,DS-bbc8e609-683b-4284-8f3a-90d03c553bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-ccdea28c-123e-482c-9557-90f65554b390,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-076fe847-cb89-4ace-ba48-9e8a0d941135,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-cd1f91ef-da35-4e19-a08a-932252ffcb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-fb494bb9-36c2-49e4-b4b0-b8e729e006b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-d5e7bf22-9358-4e36-aa84-6c78b883bade,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-83b96dfd-8b72-4c15-9946-6a94c3b03aff,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-d8fed637-0d87-4cae-a719-84982e0801e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179872789-172.17.0.9-1595925759872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34143,DS-bbc8e609-683b-4284-8f3a-90d03c553bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-ccdea28c-123e-482c-9557-90f65554b390,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-076fe847-cb89-4ace-ba48-9e8a0d941135,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-cd1f91ef-da35-4e19-a08a-932252ffcb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-fb494bb9-36c2-49e4-b4b0-b8e729e006b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-d5e7bf22-9358-4e36-aa84-6c78b883bade,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-83b96dfd-8b72-4c15-9946-6a94c3b03aff,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-d8fed637-0d87-4cae-a719-84982e0801e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054113468-172.17.0.9-1595925986145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33722,DS-a5266b38-c58c-4940-a96e-15f986c4ca88,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-1fd61477-2007-4426-9aac-65131d84f35c,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-08466648-9995-47e1-9188-af58ecd2e244,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-f6631b0c-d2ac-4616-ac86-28d09b7bcebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-d5ce25ac-4353-45ee-979a-26950ae86ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-b84aa9b0-45d2-4c31-928c-a4d4b51283cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-f33848a5-b54e-4861-8eee-7e9f2dffb19b,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-ef5be405-e903-4156-a3e6-cb20f27eda9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054113468-172.17.0.9-1595925986145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33722,DS-a5266b38-c58c-4940-a96e-15f986c4ca88,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-1fd61477-2007-4426-9aac-65131d84f35c,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-08466648-9995-47e1-9188-af58ecd2e244,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-f6631b0c-d2ac-4616-ac86-28d09b7bcebf,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-d5ce25ac-4353-45ee-979a-26950ae86ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-b84aa9b0-45d2-4c31-928c-a4d4b51283cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-f33848a5-b54e-4861-8eee-7e9f2dffb19b,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-ef5be405-e903-4156-a3e6-cb20f27eda9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1363623096-172.17.0.9-1595926117126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37338,DS-5e20f9ec-2e88-432e-b0b2-3c1d3d8ea0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-4ab75a85-5f50-471c-9efb-50866c65fe59,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-6de5f71a-12e8-4b61-8e70-ecc3c1889feb,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-a87f380a-ca30-4439-b391-3d2deff6f5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-9028748e-2151-42bf-952d-c8b3181ee572,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-07c00fe7-fb47-4ad4-a19c-5c6a7eba998e,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-2130e919-ea2b-4c44-b4c7-83465c11aa22,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-a96b61b6-39f5-4b3d-aae4-ad9861db3ce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1363623096-172.17.0.9-1595926117126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37338,DS-5e20f9ec-2e88-432e-b0b2-3c1d3d8ea0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-4ab75a85-5f50-471c-9efb-50866c65fe59,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-6de5f71a-12e8-4b61-8e70-ecc3c1889feb,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-a87f380a-ca30-4439-b391-3d2deff6f5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-9028748e-2151-42bf-952d-c8b3181ee572,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-07c00fe7-fb47-4ad4-a19c-5c6a7eba998e,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-2130e919-ea2b-4c44-b4c7-83465c11aa22,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-a96b61b6-39f5-4b3d-aae4-ad9861db3ce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592986008-172.17.0.9-1595926218955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36578,DS-97262dfe-6c95-44b7-8985-dca103e46a52,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-6e5d8d83-4b89-4591-85ba-ab9895c3e103,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-ba55a140-177e-44d3-a1bf-80349eabb87d,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-d19af74c-7283-4504-a691-6fbd5dee636d,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-f6a8394e-ebfb-463c-9b2e-c38d84db1057,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-0a536695-b29e-484a-a164-bc2241fd84d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-2e89d7e8-5eee-40e9-84ea-dc1aa592cc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-c2e10458-7b79-49f4-9031-ac252052d2bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592986008-172.17.0.9-1595926218955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36578,DS-97262dfe-6c95-44b7-8985-dca103e46a52,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-6e5d8d83-4b89-4591-85ba-ab9895c3e103,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-ba55a140-177e-44d3-a1bf-80349eabb87d,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-d19af74c-7283-4504-a691-6fbd5dee636d,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-f6a8394e-ebfb-463c-9b2e-c38d84db1057,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-0a536695-b29e-484a-a164-bc2241fd84d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-2e89d7e8-5eee-40e9-84ea-dc1aa592cc9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-c2e10458-7b79-49f4-9031-ac252052d2bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829054473-172.17.0.9-1595927041457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44096,DS-567b8755-0e35-48d2-a66c-1e0af9cfb7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-08b02dbe-be6e-4e13-88e0-27171a01d807,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-f0106823-1999-46a4-ace6-815af296bcca,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-531f1e9b-57d5-40fb-b99e-892f9b4af6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-b9916941-abfe-4b52-ac92-bad3ee453332,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-fadfa16b-b930-4cd8-af59-f2668629ac2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-4b1107b0-a49b-4941-bd81-112eef2b6234,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-13d0721f-cc06-48cf-b714-4d7afcfca149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829054473-172.17.0.9-1595927041457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44096,DS-567b8755-0e35-48d2-a66c-1e0af9cfb7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-08b02dbe-be6e-4e13-88e0-27171a01d807,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-f0106823-1999-46a4-ace6-815af296bcca,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-531f1e9b-57d5-40fb-b99e-892f9b4af6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-b9916941-abfe-4b52-ac92-bad3ee453332,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-fadfa16b-b930-4cd8-af59-f2668629ac2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-4b1107b0-a49b-4941-bd81-112eef2b6234,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-13d0721f-cc06-48cf-b714-4d7afcfca149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-893919706-172.17.0.9-1595927279989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35961,DS-82d98b82-4e47-484e-ac2f-6340a275358e,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-251f835f-4efe-46e6-819d-f102b6e167a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-edb993a8-8388-4b68-87fe-cd94fd9e128e,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-38934e0e-9b0e-4eaf-bd3c-2da766e113c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-e80ff8b5-3536-4c73-87e2-616275277a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-141e0abd-035e-44f7-81e2-500b086e5589,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-07be99df-5662-4dcf-823c-2fd8a1033bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-ce66525a-d843-4c72-9c27-4454c573b634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-893919706-172.17.0.9-1595927279989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35961,DS-82d98b82-4e47-484e-ac2f-6340a275358e,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-251f835f-4efe-46e6-819d-f102b6e167a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-edb993a8-8388-4b68-87fe-cd94fd9e128e,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-38934e0e-9b0e-4eaf-bd3c-2da766e113c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-e80ff8b5-3536-4c73-87e2-616275277a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-141e0abd-035e-44f7-81e2-500b086e5589,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-07be99df-5662-4dcf-823c-2fd8a1033bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-ce66525a-d843-4c72-9c27-4454c573b634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344406848-172.17.0.9-1595927321383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35157,DS-439caa10-643e-439a-bb2a-7fe9fee42080,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-385cf08d-0b48-48c6-90e5-baf4d9bff39f,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-119b4df2-3cf2-4dbf-ab7e-01027c83b834,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-9843fe56-ea19-4ad4-9644-c94daa9f3b23,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-cf3f6548-e28b-484e-894c-2929d3d255e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-edc4e5f1-a16d-4b41-946f-85d07ce000a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-dc88cc3a-0cc6-4eee-92c3-84ff38ccb9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-38ef4381-1204-4264-9829-f6764227bd95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1344406848-172.17.0.9-1595927321383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35157,DS-439caa10-643e-439a-bb2a-7fe9fee42080,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-385cf08d-0b48-48c6-90e5-baf4d9bff39f,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-119b4df2-3cf2-4dbf-ab7e-01027c83b834,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-9843fe56-ea19-4ad4-9644-c94daa9f3b23,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-cf3f6548-e28b-484e-894c-2929d3d255e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-edc4e5f1-a16d-4b41-946f-85d07ce000a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-dc88cc3a-0cc6-4eee-92c3-84ff38ccb9fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-38ef4381-1204-4264-9829-f6764227bd95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280162140-172.17.0.9-1595928223843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44142,DS-b2124993-7977-4d79-b644-9a797aa06591,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-a9e0c9ef-f35a-4b53-a75c-f547a36b7ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-6747c0cc-151b-4021-8525-cbc78da54cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-0d455275-a1f7-4235-b7ee-4a744b0cb278,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-7e23cac5-3bbb-4b7c-a76d-cf36ac3ad9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-62844ebb-17b4-4cf1-8464-fd8f13c99957,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-d76d9360-bd21-408f-bd03-f7c4738e20e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-cd8ba1d2-ad3e-4d8b-a3b5-77bebec61f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280162140-172.17.0.9-1595928223843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44142,DS-b2124993-7977-4d79-b644-9a797aa06591,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-a9e0c9ef-f35a-4b53-a75c-f547a36b7ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-6747c0cc-151b-4021-8525-cbc78da54cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-0d455275-a1f7-4235-b7ee-4a744b0cb278,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-7e23cac5-3bbb-4b7c-a76d-cf36ac3ad9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-62844ebb-17b4-4cf1-8464-fd8f13c99957,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-d76d9360-bd21-408f-bd03-f7c4738e20e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-cd8ba1d2-ad3e-4d8b-a3b5-77bebec61f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397323753-172.17.0.9-1595928749789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40084,DS-653e2b66-ac6a-467d-b261-3c68740ed702,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-e3d99a2c-19de-4594-ac0f-53e66efcb44b,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-f39836be-de4f-4e7e-aeb4-1c989e6acf23,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-2ca0a4c4-af01-4eb5-9760-bdcf7eb4265c,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-a6dc065a-8678-4fed-aef2-5674efba4c96,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-9eaa4925-eda7-4814-9ce9-d351af8d0287,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-45fe0979-2ce4-4256-8284-5f721d39bcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-337429f7-97de-4db4-a26b-d6185598e027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397323753-172.17.0.9-1595928749789:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40084,DS-653e2b66-ac6a-467d-b261-3c68740ed702,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-e3d99a2c-19de-4594-ac0f-53e66efcb44b,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-f39836be-de4f-4e7e-aeb4-1c989e6acf23,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-2ca0a4c4-af01-4eb5-9760-bdcf7eb4265c,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-a6dc065a-8678-4fed-aef2-5674efba4c96,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-9eaa4925-eda7-4814-9ce9-d351af8d0287,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-45fe0979-2ce4-4256-8284-5f721d39bcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-337429f7-97de-4db4-a26b-d6185598e027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012946904-172.17.0.9-1595929140821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46762,DS-736c0da7-f487-4ad3-a1db-01703dc3882b,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-ab8d9e19-f562-4a79-af92-1cd23fbab64d,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-ba908548-5498-423b-9542-a9d119960859,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-3b1ba5ac-ea38-4df0-aa68-41b0ffc96a30,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-9a7cf686-2053-44ba-bf94-788d4723ff84,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-e51c01d3-d442-43d0-badc-bee92f767ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-dfb7743a-09ac-4d73-82eb-9d73b8af12e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-30a5e6a3-e432-44ed-ad09-d54c48aa66ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012946904-172.17.0.9-1595929140821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46762,DS-736c0da7-f487-4ad3-a1db-01703dc3882b,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-ab8d9e19-f562-4a79-af92-1cd23fbab64d,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-ba908548-5498-423b-9542-a9d119960859,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-3b1ba5ac-ea38-4df0-aa68-41b0ffc96a30,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-9a7cf686-2053-44ba-bf94-788d4723ff84,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-e51c01d3-d442-43d0-badc-bee92f767ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-dfb7743a-09ac-4d73-82eb-9d73b8af12e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-30a5e6a3-e432-44ed-ad09-d54c48aa66ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470848051-172.17.0.9-1595929444810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41104,DS-d810c3be-9958-4ce9-9cb7-524df372a6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-4d44a118-38fa-4e62-a27f-d60c66f8bc20,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-ce033232-899e-4a7d-8289-859c90582764,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-e8c0ed5a-ff6a-43bd-8814-6c754d65f32f,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-c6d917f9-3721-406c-ae3e-c424e056ed04,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-c5cd1524-2e67-4be9-a9e9-d06e952c9028,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-590b6c3c-66f8-4256-91a0-91223d0ccc70,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-6be72f0d-64bc-4bbd-8955-70dddc1cf603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470848051-172.17.0.9-1595929444810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41104,DS-d810c3be-9958-4ce9-9cb7-524df372a6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-4d44a118-38fa-4e62-a27f-d60c66f8bc20,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-ce033232-899e-4a7d-8289-859c90582764,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-e8c0ed5a-ff6a-43bd-8814-6c754d65f32f,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-c6d917f9-3721-406c-ae3e-c424e056ed04,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-c5cd1524-2e67-4be9-a9e9-d06e952c9028,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-590b6c3c-66f8-4256-91a0-91223d0ccc70,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-6be72f0d-64bc-4bbd-8955-70dddc1cf603,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526765397-172.17.0.9-1595929792024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34705,DS-f17639c1-2d17-4e37-9d61-4760c78b54b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-5fdc01fc-65c9-4065-a1c3-ac7f67599a57,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-d588357f-ee56-4bd3-b87c-c54193e4eda2,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-2c2abac0-e8ad-40fd-9779-95bfff6cec18,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-431f6a65-5cca-4bb3-b915-2d081e4d3f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-69c27f31-437e-4861-a53c-158cfe6ec422,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-5c962ed2-1607-459e-97ce-b656f792247b,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-ebb2efeb-60d8-4bb3-917d-1c23e0b6d963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526765397-172.17.0.9-1595929792024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34705,DS-f17639c1-2d17-4e37-9d61-4760c78b54b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-5fdc01fc-65c9-4065-a1c3-ac7f67599a57,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-d588357f-ee56-4bd3-b87c-c54193e4eda2,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-2c2abac0-e8ad-40fd-9779-95bfff6cec18,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-431f6a65-5cca-4bb3-b915-2d081e4d3f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-69c27f31-437e-4861-a53c-158cfe6ec422,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-5c962ed2-1607-459e-97ce-b656f792247b,DISK], DatanodeInfoWithStorage[127.0.0.1:43832,DS-ebb2efeb-60d8-4bb3-917d-1c23e0b6d963,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863359455-172.17.0.9-1595929834909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40297,DS-2c247017-0ac9-45b9-9110-54e08f95f274,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-5c866f30-1a76-4ac9-8a6c-ee9edc28000b,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-d30d5aa3-453d-4bc8-aa7d-87cbb3ee5ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-4b49c517-68fe-4339-a154-818ee123b87e,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-70890cbd-bc05-4d79-bab0-8f7e2f1ec325,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-74693b9e-217b-49c7-ae28-0c754bb1949c,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-637d041a-21cb-4ef6-b39e-16ad16af3fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-464bf881-e50c-4d50-8118-778a6aaa6635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863359455-172.17.0.9-1595929834909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40297,DS-2c247017-0ac9-45b9-9110-54e08f95f274,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-5c866f30-1a76-4ac9-8a6c-ee9edc28000b,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-d30d5aa3-453d-4bc8-aa7d-87cbb3ee5ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-4b49c517-68fe-4339-a154-818ee123b87e,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-70890cbd-bc05-4d79-bab0-8f7e2f1ec325,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-74693b9e-217b-49c7-ae28-0c754bb1949c,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-637d041a-21cb-4ef6-b39e-16ad16af3fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-464bf881-e50c-4d50-8118-778a6aaa6635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061660385-172.17.0.9-1595929947019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-a77b4214-582a-4424-a683-4443fe8fb847,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-be490ed0-8602-4846-b8d2-beea099fbc41,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-bfe941fc-91c3-4447-afde-c3ea6266a433,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-97b50400-acad-468e-96a4-e1050d578d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-8b732426-4003-4ffa-b610-f1544f7848ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-8d7e5970-303e-43bc-b316-4bb8ae062477,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-2346eca0-e54b-4e7e-9326-30de57f68e86,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-c75c0565-061d-445e-b23d-ab2b0c7b54ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061660385-172.17.0.9-1595929947019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33493,DS-a77b4214-582a-4424-a683-4443fe8fb847,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-be490ed0-8602-4846-b8d2-beea099fbc41,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-bfe941fc-91c3-4447-afde-c3ea6266a433,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-97b50400-acad-468e-96a4-e1050d578d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-8b732426-4003-4ffa-b610-f1544f7848ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39268,DS-8d7e5970-303e-43bc-b316-4bb8ae062477,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-2346eca0-e54b-4e7e-9326-30de57f68e86,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-c75c0565-061d-445e-b23d-ab2b0c7b54ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78546376-172.17.0.9-1595930020101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-59a55f2e-4391-4718-bd6b-e688745cc702,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-3dad202e-ee18-4acf-92d5-23f373c11557,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-8e20e0b9-fb71-490f-a1e6-281b13089bca,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-6f3d975d-441b-4940-942b-4e1092950cba,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-d0173e14-013f-4dd8-820a-8124d52721ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-1011a282-ceac-4ee3-8ade-e4aca48e52af,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-a0b90567-4127-499b-afee-09195627aba8,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-d1e8692f-1e03-4e5b-8ef2-8a813c682f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-78546376-172.17.0.9-1595930020101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33209,DS-59a55f2e-4391-4718-bd6b-e688745cc702,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-3dad202e-ee18-4acf-92d5-23f373c11557,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-8e20e0b9-fb71-490f-a1e6-281b13089bca,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-6f3d975d-441b-4940-942b-4e1092950cba,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-d0173e14-013f-4dd8-820a-8124d52721ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-1011a282-ceac-4ee3-8ade-e4aca48e52af,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-a0b90567-4127-499b-afee-09195627aba8,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-d1e8692f-1e03-4e5b-8ef2-8a813c682f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503876926-172.17.0.9-1595930233242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33223,DS-5af01fb7-8224-44b7-9acf-baea65176811,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-87de3571-a970-405a-ac67-678628c9d619,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-4c18e407-679f-4754-a00c-8404cc6eaccf,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-d2f20413-09da-43a2-adcc-fab13ea197de,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-32589254-edee-4141-98ec-a3fe48dc2b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-c14dc893-4296-4569-a3b7-491c8015e01a,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-bfe788dc-dfb8-440f-8e07-4b02f0027180,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-a8658699-8979-483b-9d7b-d08a780f5fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503876926-172.17.0.9-1595930233242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33223,DS-5af01fb7-8224-44b7-9acf-baea65176811,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-87de3571-a970-405a-ac67-678628c9d619,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-4c18e407-679f-4754-a00c-8404cc6eaccf,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-d2f20413-09da-43a2-adcc-fab13ea197de,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-32589254-edee-4141-98ec-a3fe48dc2b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-c14dc893-4296-4569-a3b7-491c8015e01a,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-bfe788dc-dfb8-440f-8e07-4b02f0027180,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-a8658699-8979-483b-9d7b-d08a780f5fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792297607-172.17.0.9-1595930709798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44523,DS-c3f8dfe3-08e2-490b-90d6-d755e4434d94,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-a5cf0c76-d80e-4b67-b477-6d971ba2934a,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-6ff0e22d-7415-4d7d-80b2-aedbc21d8cde,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-217dccbf-9fa7-4188-accf-baed9f359008,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-6a91edbf-20d8-4919-b061-ac11e7535ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-5945f12a-0807-4d25-8fcc-8ef331a3fd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-c1927c6b-7212-4f17-92e8-0f5109e61ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-96770ac9-1beb-4bdd-8389-9225a81b8b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1792297607-172.17.0.9-1595930709798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44523,DS-c3f8dfe3-08e2-490b-90d6-d755e4434d94,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-a5cf0c76-d80e-4b67-b477-6d971ba2934a,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-6ff0e22d-7415-4d7d-80b2-aedbc21d8cde,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-217dccbf-9fa7-4188-accf-baed9f359008,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-6a91edbf-20d8-4919-b061-ac11e7535ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-5945f12a-0807-4d25-8fcc-8ef331a3fd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-c1927c6b-7212-4f17-92e8-0f5109e61ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-96770ac9-1beb-4bdd-8389-9225a81b8b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 3
v2: 6
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077715328-172.17.0.9-1595930897516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38953,DS-1494f17b-cb3c-4ef5-a313-fda4af6f9e96,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-981f259d-67c9-44d9-828d-6a45b77cafea,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-4f3df17a-c6ed-4580-a591-0a936456f31d,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-6b50f886-5b00-493e-9652-4a548c290dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-01efa96c-1722-4885-ba89-1f99872d2cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-d5362bb1-3200-4eb9-9ea1-2ed3541d4786,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-28d769e7-33c1-4ced-970c-2a4fbcc968b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-a6e5636a-bf65-463f-a1ea-8ee32b416d2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077715328-172.17.0.9-1595930897516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38953,DS-1494f17b-cb3c-4ef5-a313-fda4af6f9e96,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-981f259d-67c9-44d9-828d-6a45b77cafea,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-4f3df17a-c6ed-4580-a591-0a936456f31d,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-6b50f886-5b00-493e-9652-4a548c290dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-01efa96c-1722-4885-ba89-1f99872d2cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-d5362bb1-3200-4eb9-9ea1-2ed3541d4786,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-28d769e7-33c1-4ced-970c-2a4fbcc968b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-a6e5636a-bf65-463f-a1ea-8ee32b416d2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5494
