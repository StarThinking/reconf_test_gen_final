reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051541822-172.17.0.9-1595933723181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38539,DS-b5cb9556-d7f3-4e59-8a28-71dcc2853a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-b4df54f5-50bb-4066-9c94-5c96b6a8041f,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-bb372233-4847-4c79-9c4d-3cd38491e1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-b2a4cdc1-50cc-4371-b247-a5732a619505,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-2e8cb012-b935-437d-820b-b473130e8f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-2cc574d0-13ba-4a85-b463-05a0ebf1e80f,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-6aab8886-20fc-4d16-9a2e-f7160ce23865,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-594e8237-180f-4ffb-b3af-705bed0eb23b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2051541822-172.17.0.9-1595933723181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38539,DS-b5cb9556-d7f3-4e59-8a28-71dcc2853a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-b4df54f5-50bb-4066-9c94-5c96b6a8041f,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-bb372233-4847-4c79-9c4d-3cd38491e1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-b2a4cdc1-50cc-4371-b247-a5732a619505,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-2e8cb012-b935-437d-820b-b473130e8f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-2cc574d0-13ba-4a85-b463-05a0ebf1e80f,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-6aab8886-20fc-4d16-9a2e-f7160ce23865,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-594e8237-180f-4ffb-b3af-705bed0eb23b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167544212-172.17.0.9-1595934232031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38449,DS-874829e2-d1cb-4246-b3ab-f54a01858f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-b5c57925-e12d-43f1-b19a-e6cfb82a7c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-532ec88b-b9e8-4ef2-ace7-03afeb58e322,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-ffea9e64-2317-43ea-a9d4-808603c2ad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-4b7ae598-2e0c-439f-b502-378e1c5ed508,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-c5144d71-be27-4294-b4dc-88b82731364d,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-48947c17-91cd-4ccf-88ac-469e6732a7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-843bf220-f25e-4eeb-9bce-77a536f7e4aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167544212-172.17.0.9-1595934232031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38449,DS-874829e2-d1cb-4246-b3ab-f54a01858f18,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-b5c57925-e12d-43f1-b19a-e6cfb82a7c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-532ec88b-b9e8-4ef2-ace7-03afeb58e322,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-ffea9e64-2317-43ea-a9d4-808603c2ad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-4b7ae598-2e0c-439f-b502-378e1c5ed508,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-c5144d71-be27-4294-b4dc-88b82731364d,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-48947c17-91cd-4ccf-88ac-469e6732a7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-843bf220-f25e-4eeb-9bce-77a536f7e4aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144496842-172.17.0.9-1595934645825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43366,DS-48cfd771-0d33-4932-bf00-b4c7f11b2e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-b0819f19-b130-4e56-a0b5-1f849547d0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-3c30e03b-2bbc-4fdd-90e8-7a573a0b2e02,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-a0b9ec8f-d7f9-40c6-ae5b-2d3326364db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-99966f58-3786-4c1f-b509-e255fb1f279e,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-1bf49463-e033-468a-bc74-f553df5bb19c,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-50a2abd1-a583-4895-8b2d-221cb0a3d1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-297f2cfb-d40a-4c53-8b28-73305e15a755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144496842-172.17.0.9-1595934645825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43366,DS-48cfd771-0d33-4932-bf00-b4c7f11b2e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-b0819f19-b130-4e56-a0b5-1f849547d0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-3c30e03b-2bbc-4fdd-90e8-7a573a0b2e02,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-a0b9ec8f-d7f9-40c6-ae5b-2d3326364db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-99966f58-3786-4c1f-b509-e255fb1f279e,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-1bf49463-e033-468a-bc74-f553df5bb19c,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-50a2abd1-a583-4895-8b2d-221cb0a3d1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-297f2cfb-d40a-4c53-8b28-73305e15a755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766701497-172.17.0.9-1595935195239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33635,DS-cc490abe-1729-481e-a98b-e7403f4b6ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-dbe244ff-2d71-4a8c-94d0-0d5a513beef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-8b7241b8-7b23-44e9-8eb0-45f6ed9deec6,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-afb15d44-1b17-4a06-8e59-5123076c3a14,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-292cc31b-b85f-4415-9ea1-b7254674d161,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-f9818166-af37-46b2-a8fd-9f59db9e1f72,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-b2ca1aa5-e1b6-4608-b626-006220b205c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-b8c9e72c-7646-4d11-8900-5636a9e3d028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766701497-172.17.0.9-1595935195239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33635,DS-cc490abe-1729-481e-a98b-e7403f4b6ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-dbe244ff-2d71-4a8c-94d0-0d5a513beef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-8b7241b8-7b23-44e9-8eb0-45f6ed9deec6,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-afb15d44-1b17-4a06-8e59-5123076c3a14,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-292cc31b-b85f-4415-9ea1-b7254674d161,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-f9818166-af37-46b2-a8fd-9f59db9e1f72,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-b2ca1aa5-e1b6-4608-b626-006220b205c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-b8c9e72c-7646-4d11-8900-5636a9e3d028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727132608-172.17.0.9-1595935459710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33999,DS-d319e4cf-39c2-4bd8-9412-c243f2c43846,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-cbb9f261-7ed2-4db0-be9f-453dbd36308f,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-04845254-07ae-4573-b64d-f30e0a1f8911,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-f2142bef-31f4-403f-9c50-d4cb5495c8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-7ef4b821-df81-4ca9-9862-5dbd1c354046,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-953f831a-9812-4d58-b9bc-4b5472178001,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-fe12fbeb-8225-496a-b1b1-e55537261a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-939476f6-772b-4e41-8ef2-82e24f1c5f1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727132608-172.17.0.9-1595935459710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33999,DS-d319e4cf-39c2-4bd8-9412-c243f2c43846,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-cbb9f261-7ed2-4db0-be9f-453dbd36308f,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-04845254-07ae-4573-b64d-f30e0a1f8911,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-f2142bef-31f4-403f-9c50-d4cb5495c8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-7ef4b821-df81-4ca9-9862-5dbd1c354046,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-953f831a-9812-4d58-b9bc-4b5472178001,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-fe12fbeb-8225-496a-b1b1-e55537261a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-939476f6-772b-4e41-8ef2-82e24f1c5f1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512516620-172.17.0.9-1595935683947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44350,DS-de62a2e4-68a4-4618-849d-03cde4a9356d,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-ee9187ab-cf0f-4ea4-8fe8-1d3fb1a85999,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-ccf9f391-1321-4805-acdb-4fc2c6864e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-0ae180af-072c-4b21-9187-77f64ed7a201,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-87979edd-0f04-4548-a554-d5c7e63ade9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-5ec5c3c1-6fa6-413d-84d5-234281a935d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-f2f20834-cfec-4600-9038-4932eb1ebb47,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-c33e5a96-2bdf-4928-8456-ed4a10522efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512516620-172.17.0.9-1595935683947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44350,DS-de62a2e4-68a4-4618-849d-03cde4a9356d,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-ee9187ab-cf0f-4ea4-8fe8-1d3fb1a85999,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-ccf9f391-1321-4805-acdb-4fc2c6864e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-0ae180af-072c-4b21-9187-77f64ed7a201,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-87979edd-0f04-4548-a554-d5c7e63ade9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-5ec5c3c1-6fa6-413d-84d5-234281a935d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-f2f20834-cfec-4600-9038-4932eb1ebb47,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-c33e5a96-2bdf-4928-8456-ed4a10522efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356699019-172.17.0.9-1595935913663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41846,DS-c603e35d-ba15-453e-ae4a-64e4cf54ab36,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-6ed51db5-abb5-409d-b9e6-2af4402bc1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-f12984b8-672f-439b-a4f5-d2d4caaddb73,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-5a9f2b67-4d5e-4d5f-a1c9-c7c7c4fe10f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-bd0b6e12-a225-4210-bc32-5a57a073b5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-26615322-c7fb-4888-b1c7-ee272f8fcb83,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-7736aabe-da7c-4b22-a45a-322437638673,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-9e5e5052-6887-4fd6-b4b5-a8bcabc4b3ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-356699019-172.17.0.9-1595935913663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41846,DS-c603e35d-ba15-453e-ae4a-64e4cf54ab36,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-6ed51db5-abb5-409d-b9e6-2af4402bc1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-f12984b8-672f-439b-a4f5-d2d4caaddb73,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-5a9f2b67-4d5e-4d5f-a1c9-c7c7c4fe10f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-bd0b6e12-a225-4210-bc32-5a57a073b5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-26615322-c7fb-4888-b1c7-ee272f8fcb83,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-7736aabe-da7c-4b22-a45a-322437638673,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-9e5e5052-6887-4fd6-b4b5-a8bcabc4b3ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154134378-172.17.0.9-1595935993759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46347,DS-faf6cdb9-d0a1-44dc-8314-90d9d644c0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-2dafce7b-085f-4ff2-978d-d8c09107775d,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-46f6c31c-f017-47a9-8959-ce5c91349f85,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-3ecba41f-552b-45ab-ae12-b83a3a5ce239,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-67597cae-3150-432b-a677-3ac7dfc0a9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-a719d998-846b-4429-a9b9-18941e7451f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-2d34ae88-d222-449c-ba2f-0a1589c4213e,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-fd5cb409-8400-4bb1-9859-cb6d5f75205c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-154134378-172.17.0.9-1595935993759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46347,DS-faf6cdb9-d0a1-44dc-8314-90d9d644c0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-2dafce7b-085f-4ff2-978d-d8c09107775d,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-46f6c31c-f017-47a9-8959-ce5c91349f85,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-3ecba41f-552b-45ab-ae12-b83a3a5ce239,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-67597cae-3150-432b-a677-3ac7dfc0a9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-a719d998-846b-4429-a9b9-18941e7451f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-2d34ae88-d222-449c-ba2f-0a1589c4213e,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-fd5cb409-8400-4bb1-9859-cb6d5f75205c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150655990-172.17.0.9-1595936573823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46607,DS-b8f0d2c5-2fea-4856-80db-7058c8685c65,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-96737583-0d19-49c4-81a8-55aad025fe03,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-94a7fa4a-aec1-4271-9b1b-159fcc6c5b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-6b6d7f76-cf58-460f-b149-4bc04aef249d,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-ce7a639d-13c9-4339-b508-820691764f46,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-6ce7544f-b719-4b37-a0aa-dfe4c3e8c745,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-ecbccaf3-96e2-437a-8481-914fef23363f,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-393f0b85-6525-4a80-a7fb-4945d71a3321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150655990-172.17.0.9-1595936573823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46607,DS-b8f0d2c5-2fea-4856-80db-7058c8685c65,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-96737583-0d19-49c4-81a8-55aad025fe03,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-94a7fa4a-aec1-4271-9b1b-159fcc6c5b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-6b6d7f76-cf58-460f-b149-4bc04aef249d,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-ce7a639d-13c9-4339-b508-820691764f46,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-6ce7544f-b719-4b37-a0aa-dfe4c3e8c745,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-ecbccaf3-96e2-437a-8481-914fef23363f,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-393f0b85-6525-4a80-a7fb-4945d71a3321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381048076-172.17.0.9-1595937586986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34299,DS-6946a628-1391-4778-b4b7-c9c381c4b125,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-acefd8b4-d3e0-4a6e-ab63-20c8bd52a68d,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-2e44e90b-c0a9-44e3-b2c5-4f58fad5b4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-bf82c858-fdc8-434f-aa61-8733f5334dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-e36e9f46-8f15-48cc-8299-409d5f1b4309,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-b3716611-331e-4ee0-bab0-721984e0506f,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-4e7f0186-3e9f-4d39-8d7f-c427d7d3bab3,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-af2516f7-d6ad-46ea-86b5-996f1324c6fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381048076-172.17.0.9-1595937586986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34299,DS-6946a628-1391-4778-b4b7-c9c381c4b125,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-acefd8b4-d3e0-4a6e-ab63-20c8bd52a68d,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-2e44e90b-c0a9-44e3-b2c5-4f58fad5b4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-bf82c858-fdc8-434f-aa61-8733f5334dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-e36e9f46-8f15-48cc-8299-409d5f1b4309,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-b3716611-331e-4ee0-bab0-721984e0506f,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-4e7f0186-3e9f-4d39-8d7f-c427d7d3bab3,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-af2516f7-d6ad-46ea-86b5-996f1324c6fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630693351-172.17.0.9-1595937890195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34454,DS-ef1f7d30-7cf5-4b3f-a126-d2c8ffa43ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-a77a8503-0ee6-454f-82f9-8a94f2931cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-f91c7d02-af21-4955-81a9-a66fad814fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-17be5d5a-8de9-4424-9f48-9d980a6b3382,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-d5d27f06-60fc-43e7-90b1-1f9a50503812,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-c4089371-36c9-4a1e-932a-e24a431b0d00,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-64e287cb-63e5-4bc4-aac4-5c69cd909cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-e99991b6-51a9-4c65-baea-50c1b2ca3cc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630693351-172.17.0.9-1595937890195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34454,DS-ef1f7d30-7cf5-4b3f-a126-d2c8ffa43ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-a77a8503-0ee6-454f-82f9-8a94f2931cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-f91c7d02-af21-4955-81a9-a66fad814fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-17be5d5a-8de9-4424-9f48-9d980a6b3382,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-d5d27f06-60fc-43e7-90b1-1f9a50503812,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-c4089371-36c9-4a1e-932a-e24a431b0d00,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-64e287cb-63e5-4bc4-aac4-5c69cd909cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-e99991b6-51a9-4c65-baea-50c1b2ca3cc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291925157-172.17.0.9-1595937966256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43464,DS-d990116d-a470-4292-b1b9-7a79f19382d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-55dda3cd-dcc7-49c4-ab24-a886374dc7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-fc98e5b3-a259-428c-9250-4d8558ed8c49,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-d9e9aa92-4d9b-4b84-96a7-bd1f6f1ea36e,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-5e982567-fd90-4600-b5fb-e3701e0d246a,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-e661ac4e-da66-49b5-9d33-fe3ad3b33a33,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-fecbb7c6-da10-469d-8171-faa4a492e5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-169b178a-5578-4410-84b1-f5d18083c355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291925157-172.17.0.9-1595937966256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43464,DS-d990116d-a470-4292-b1b9-7a79f19382d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-55dda3cd-dcc7-49c4-ab24-a886374dc7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-fc98e5b3-a259-428c-9250-4d8558ed8c49,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-d9e9aa92-4d9b-4b84-96a7-bd1f6f1ea36e,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-5e982567-fd90-4600-b5fb-e3701e0d246a,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-e661ac4e-da66-49b5-9d33-fe3ad3b33a33,DISK], DatanodeInfoWithStorage[127.0.0.1:34460,DS-fecbb7c6-da10-469d-8171-faa4a492e5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-169b178a-5578-4410-84b1-f5d18083c355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770856392-172.17.0.9-1595938649027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-38c24fa0-8d1f-4318-9992-63447978fcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-da7dd496-9e36-4528-8eab-c2a104643537,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-18979f02-2d20-4569-9903-4ffd67a463ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-80e9e3ec-d6de-4315-bed5-c9e556162a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-24c4f2bc-ea27-4529-ab05-4c4d98ae8af4,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-c31358fa-e679-47eb-8dc6-43503959572d,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-c653f7ee-f6ee-4bd5-be85-1e5ad115111c,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-6a77f874-c8d7-4179-835a-138c08944b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770856392-172.17.0.9-1595938649027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-38c24fa0-8d1f-4318-9992-63447978fcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-da7dd496-9e36-4528-8eab-c2a104643537,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-18979f02-2d20-4569-9903-4ffd67a463ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-80e9e3ec-d6de-4315-bed5-c9e556162a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-24c4f2bc-ea27-4529-ab05-4c4d98ae8af4,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-c31358fa-e679-47eb-8dc6-43503959572d,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-c653f7ee-f6ee-4bd5-be85-1e5ad115111c,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-6a77f874-c8d7-4179-835a-138c08944b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913357137-172.17.0.9-1595938718419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35170,DS-7fabc438-9570-4eee-9329-95d9a933a3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-9193df12-7552-4a84-9b20-409366b0314e,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-e169aaee-5a70-4693-860b-6230a9d41b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-e0ea8f3e-1cb9-405d-ad07-790b231b5b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-213c70f6-77e6-47d5-a7cb-f4627d6b26c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-b6bcc72b-6bfe-445f-bd43-c0358c196ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-23c6cfe1-2f3a-4dd6-b67d-1562f130e703,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-ad6adc83-99ba-4c6e-9745-dd03d2b595ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1913357137-172.17.0.9-1595938718419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35170,DS-7fabc438-9570-4eee-9329-95d9a933a3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-9193df12-7552-4a84-9b20-409366b0314e,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-e169aaee-5a70-4693-860b-6230a9d41b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-e0ea8f3e-1cb9-405d-ad07-790b231b5b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-213c70f6-77e6-47d5-a7cb-f4627d6b26c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-b6bcc72b-6bfe-445f-bd43-c0358c196ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-23c6cfe1-2f3a-4dd6-b67d-1562f130e703,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-ad6adc83-99ba-4c6e-9745-dd03d2b595ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 5
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018822388-172.17.0.9-1595938748472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40480,DS-a6525cf8-f514-491c-a9af-f7c950da25fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-563e08f2-cc4e-4b2b-a38a-cb18d19b9989,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-3e09a21e-ba2d-4743-ae8c-60f29e274399,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-5f62e012-b03b-49b4-8d84-8212ecb85841,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-2a7c9780-9dea-4a6f-a6af-a54b117dd851,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-e1f13cab-8e64-4702-be56-fd585678ce7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-4eda8079-c64f-4118-9312-f8978f98de49,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-d5619d1b-e721-4b80-9eb1-c28f3a4bb008,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1018822388-172.17.0.9-1595938748472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40480,DS-a6525cf8-f514-491c-a9af-f7c950da25fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-563e08f2-cc4e-4b2b-a38a-cb18d19b9989,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-3e09a21e-ba2d-4743-ae8c-60f29e274399,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-5f62e012-b03b-49b4-8d84-8212ecb85841,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-2a7c9780-9dea-4a6f-a6af-a54b117dd851,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-e1f13cab-8e64-4702-be56-fd585678ce7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-4eda8079-c64f-4118-9312-f8978f98de49,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-d5619d1b-e721-4b80-9eb1-c28f3a4bb008,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5388
