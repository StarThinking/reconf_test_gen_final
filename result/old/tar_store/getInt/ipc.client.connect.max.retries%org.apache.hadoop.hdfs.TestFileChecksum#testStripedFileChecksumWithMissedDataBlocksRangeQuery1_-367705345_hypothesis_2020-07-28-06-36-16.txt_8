reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924510039-172.17.0.2-1595919264453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45871,DS-1244991d-a5f3-472b-aeec-ab5fc59b89d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-4cb2b762-eeee-4cf1-aca1-77df634e911e,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-835d2558-63dc-484c-9425-ac1c03862823,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-a96ccde8-1495-4c38-9b23-1a5e568c8f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-76f1cc3f-d050-4c03-b65f-69b80b406b48,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-4b36bf87-d8be-48bc-84dc-32302675775e,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-9c097c47-eaea-41cf-84be-37485a0d0915,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-04ff20bb-be42-41d9-8bbf-abea27a91722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924510039-172.17.0.2-1595919264453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45871,DS-1244991d-a5f3-472b-aeec-ab5fc59b89d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-4cb2b762-eeee-4cf1-aca1-77df634e911e,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-835d2558-63dc-484c-9425-ac1c03862823,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-a96ccde8-1495-4c38-9b23-1a5e568c8f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-76f1cc3f-d050-4c03-b65f-69b80b406b48,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-4b36bf87-d8be-48bc-84dc-32302675775e,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-9c097c47-eaea-41cf-84be-37485a0d0915,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-04ff20bb-be42-41d9-8bbf-abea27a91722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180012050-172.17.0.2-1595919885480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35193,DS-132acccd-f50a-4925-9700-f6ba8ac38bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-9d5e737c-2f89-4c34-89f8-264c22d6acd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-da417646-4b1e-4ec8-af72-00ee30c31657,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-5d0d8935-ace0-4793-ae95-41f52bb5c843,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-ed73136e-aae6-40b6-b760-fce4414579de,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-4f18709b-c60e-49c0-8df4-bca24e345f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-010cc83f-dd57-49b8-9d4d-303bbb3e01e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-9f8ba0a7-3f45-41f2-9cc3-f7dedd7bd0fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180012050-172.17.0.2-1595919885480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35193,DS-132acccd-f50a-4925-9700-f6ba8ac38bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-9d5e737c-2f89-4c34-89f8-264c22d6acd3,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-da417646-4b1e-4ec8-af72-00ee30c31657,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-5d0d8935-ace0-4793-ae95-41f52bb5c843,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-ed73136e-aae6-40b6-b760-fce4414579de,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-4f18709b-c60e-49c0-8df4-bca24e345f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-010cc83f-dd57-49b8-9d4d-303bbb3e01e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-9f8ba0a7-3f45-41f2-9cc3-f7dedd7bd0fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978066333-172.17.0.2-1595919954160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44596,DS-be635c43-20aa-457f-81a6-a97403fe9a39,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-cf0127be-fe46-43a2-a860-85738ba1b56c,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-e8a795ae-8da0-4af5-a7b9-d63fa764c137,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-cdfbc687-9d01-41e5-a538-60ce04e8428c,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-cbb0d5a9-f8ef-438a-a17d-7a6a4d646875,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-69ab9918-890f-4bf2-910c-b88ff00cf468,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-00845ff5-87dd-40ae-9631-32a41029193a,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-e5e1ca18-37a9-495a-bbc6-54546a6b051e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978066333-172.17.0.2-1595919954160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44596,DS-be635c43-20aa-457f-81a6-a97403fe9a39,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-cf0127be-fe46-43a2-a860-85738ba1b56c,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-e8a795ae-8da0-4af5-a7b9-d63fa764c137,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-cdfbc687-9d01-41e5-a538-60ce04e8428c,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-cbb0d5a9-f8ef-438a-a17d-7a6a4d646875,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-69ab9918-890f-4bf2-910c-b88ff00cf468,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-00845ff5-87dd-40ae-9631-32a41029193a,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-e5e1ca18-37a9-495a-bbc6-54546a6b051e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825390361-172.17.0.2-1595920184514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38777,DS-4e9e4dbe-0d68-445c-bc38-98c09e166fff,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-722e36db-536e-440e-b924-d26cd9317811,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-a5faa307-a7ca-4f7e-ac8b-7169cdd0924f,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-be2937f8-c939-430c-ac0b-348262dbf607,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-d16de9b0-bbc8-4c4e-948a-a3f4232d9803,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-03a77e10-b8d6-4a91-a33d-46c67e6e4e18,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-963f0f44-4da8-4067-9f91-8997b0c99cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-27c263c0-58b1-442b-9005-4f111202409a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825390361-172.17.0.2-1595920184514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38777,DS-4e9e4dbe-0d68-445c-bc38-98c09e166fff,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-722e36db-536e-440e-b924-d26cd9317811,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-a5faa307-a7ca-4f7e-ac8b-7169cdd0924f,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-be2937f8-c939-430c-ac0b-348262dbf607,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-d16de9b0-bbc8-4c4e-948a-a3f4232d9803,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-03a77e10-b8d6-4a91-a33d-46c67e6e4e18,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-963f0f44-4da8-4067-9f91-8997b0c99cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-27c263c0-58b1-442b-9005-4f111202409a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4471598-172.17.0.2-1595920290888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32858,DS-852f436d-8b92-4add-bb6d-72d91609375c,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-e78a8677-d329-4eaa-9ddf-f906f0514b19,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-70be81c4-858c-4aed-b0bf-483491c84964,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-fc6db3b9-cb1c-48f7-8585-54b050003345,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-42d8d9aa-a021-4cb7-8bd6-45cb5c29ef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-c098e371-c9ff-45dc-8f6c-12d1c3219dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-9b4aad90-ee42-451f-a98e-52187b8f74dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-94cca45e-02ba-4b82-a739-18abc8f41e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4471598-172.17.0.2-1595920290888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32858,DS-852f436d-8b92-4add-bb6d-72d91609375c,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-e78a8677-d329-4eaa-9ddf-f906f0514b19,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-70be81c4-858c-4aed-b0bf-483491c84964,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-fc6db3b9-cb1c-48f7-8585-54b050003345,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-42d8d9aa-a021-4cb7-8bd6-45cb5c29ef8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-c098e371-c9ff-45dc-8f6c-12d1c3219dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-9b4aad90-ee42-451f-a98e-52187b8f74dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-94cca45e-02ba-4b82-a739-18abc8f41e38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356825192-172.17.0.2-1595920324051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35581,DS-117b70ed-6bad-497e-a1a8-ec00ef303de5,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-1b0cf25d-8826-4e03-b70a-796e54753254,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-5afe37ea-608a-409c-96c8-952f00b9e618,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-665ae8b4-8c4f-4851-afd7-1ce1584acaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-ba6026e2-9cd8-4e3d-a565-ec70fe3e387f,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-d967d975-4ff2-4585-858f-3eb606a4aa48,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-9e99bac2-2ea3-47b5-aa01-c28419b57302,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-583cc18f-22c6-48f3-9571-bffa7aa08871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356825192-172.17.0.2-1595920324051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35581,DS-117b70ed-6bad-497e-a1a8-ec00ef303de5,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-1b0cf25d-8826-4e03-b70a-796e54753254,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-5afe37ea-608a-409c-96c8-952f00b9e618,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-665ae8b4-8c4f-4851-afd7-1ce1584acaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-ba6026e2-9cd8-4e3d-a565-ec70fe3e387f,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-d967d975-4ff2-4585-858f-3eb606a4aa48,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-9e99bac2-2ea3-47b5-aa01-c28419b57302,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-583cc18f-22c6-48f3-9571-bffa7aa08871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319814667-172.17.0.2-1595920607174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44171,DS-e397941b-bb54-412e-8215-e1b42e3f604c,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-bb63c287-da32-4648-88f8-d3dafc00dd50,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-37ce2fa0-cfdb-4e27-8dec-09f30e138b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-f4aa4db4-74ae-477c-ac40-44ae26930758,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-485425c1-839d-42f2-b1f9-e735713bdb76,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-26c135b5-6a94-4b42-b20e-37f34d30274f,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-9c2d7d46-1180-48cc-8137-353784a5b4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-8bf434cd-7880-451a-90a0-a88797cef691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319814667-172.17.0.2-1595920607174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44171,DS-e397941b-bb54-412e-8215-e1b42e3f604c,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-bb63c287-da32-4648-88f8-d3dafc00dd50,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-37ce2fa0-cfdb-4e27-8dec-09f30e138b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-f4aa4db4-74ae-477c-ac40-44ae26930758,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-485425c1-839d-42f2-b1f9-e735713bdb76,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-26c135b5-6a94-4b42-b20e-37f34d30274f,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-9c2d7d46-1180-48cc-8137-353784a5b4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-8bf434cd-7880-451a-90a0-a88797cef691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449388935-172.17.0.2-1595920680038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32883,DS-226adc8f-4b95-4ae7-b7a6-accbf4efcbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-e8088828-b72a-486a-9ea4-540a36de336a,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-00bfe414-5aeb-4891-b7b3-a3a261ca461e,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-a814b5ff-4e78-4c68-a26c-18b84e824b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-50c2b02a-4add-4436-8201-917d82ca4150,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-ce1fa2cc-7b58-4a36-b99c-72bbbedddf01,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-cb5e94b1-ce81-4bec-8359-67345c53a51e,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-5c9e1c55-2126-4f3e-b993-897718024198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449388935-172.17.0.2-1595920680038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32883,DS-226adc8f-4b95-4ae7-b7a6-accbf4efcbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-e8088828-b72a-486a-9ea4-540a36de336a,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-00bfe414-5aeb-4891-b7b3-a3a261ca461e,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-a814b5ff-4e78-4c68-a26c-18b84e824b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-50c2b02a-4add-4436-8201-917d82ca4150,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-ce1fa2cc-7b58-4a36-b99c-72bbbedddf01,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-cb5e94b1-ce81-4bec-8359-67345c53a51e,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-5c9e1c55-2126-4f3e-b993-897718024198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586596055-172.17.0.2-1595920783238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38991,DS-37151228-5570-47b2-bc0c-799192c64cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-6a2fe9c7-86b3-4f9b-baa8-566061dc6117,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-cb7aefd6-ae92-4988-bf88-1a029945b742,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-0f6033ff-c9af-4029-9eb9-e423b484761e,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-ee7806dd-7ac5-4214-8c13-09bf7e900ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-aa5f9087-a310-438a-96ad-5c9fcaa1a058,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-c3d3bf77-aa47-4988-8eea-bedbc376e18f,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-e0fd5dfb-d672-4bd0-ba66-3ff0d74684ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-586596055-172.17.0.2-1595920783238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38991,DS-37151228-5570-47b2-bc0c-799192c64cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-6a2fe9c7-86b3-4f9b-baa8-566061dc6117,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-cb7aefd6-ae92-4988-bf88-1a029945b742,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-0f6033ff-c9af-4029-9eb9-e423b484761e,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-ee7806dd-7ac5-4214-8c13-09bf7e900ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-aa5f9087-a310-438a-96ad-5c9fcaa1a058,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-c3d3bf77-aa47-4988-8eea-bedbc376e18f,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-e0fd5dfb-d672-4bd0-ba66-3ff0d74684ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565133868-172.17.0.2-1595921096985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33382,DS-904ada60-3389-4935-b3db-e66350a63b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-b14830bc-c05d-463d-afc9-b5b5b469ab57,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-84abc8df-cef8-4b11-8c6c-6d429af9f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-b4c91cba-19b9-444f-8197-2b091eb21898,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-2028392c-c77f-4b52-b346-a699d8daaf02,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-c1f818a9-02e6-4457-af9e-a458e550d2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-31e69014-7d76-449c-a565-681346be7f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-1b5241fb-203d-48e1-b97d-659963ba1c10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565133868-172.17.0.2-1595921096985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33382,DS-904ada60-3389-4935-b3db-e66350a63b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-b14830bc-c05d-463d-afc9-b5b5b469ab57,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-84abc8df-cef8-4b11-8c6c-6d429af9f73a,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-b4c91cba-19b9-444f-8197-2b091eb21898,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-2028392c-c77f-4b52-b346-a699d8daaf02,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-c1f818a9-02e6-4457-af9e-a458e550d2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-31e69014-7d76-449c-a565-681346be7f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-1b5241fb-203d-48e1-b97d-659963ba1c10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440045644-172.17.0.2-1595921364168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37557,DS-e9297c2c-6f22-4317-9910-21c4b6c6c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-ffc4fe75-03a3-4efa-95b2-f38265e1b301,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-ce4da48f-7070-4d31-8846-14028fff4344,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-72ee66d3-0c32-4f10-bb80-5e59a6f5163b,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-2624492a-cf9a-49cc-a7f7-faaec3c0c87c,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-61c26a93-d29b-423f-a959-a3e39f299332,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-daef8e66-62b0-4c0d-862b-a308e10090d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-0c937f42-86c2-43f2-9dd5-04462b5f81fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440045644-172.17.0.2-1595921364168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37557,DS-e9297c2c-6f22-4317-9910-21c4b6c6c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-ffc4fe75-03a3-4efa-95b2-f38265e1b301,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-ce4da48f-7070-4d31-8846-14028fff4344,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-72ee66d3-0c32-4f10-bb80-5e59a6f5163b,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-2624492a-cf9a-49cc-a7f7-faaec3c0c87c,DISK], DatanodeInfoWithStorage[127.0.0.1:44168,DS-61c26a93-d29b-423f-a959-a3e39f299332,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-daef8e66-62b0-4c0d-862b-a308e10090d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-0c937f42-86c2-43f2-9dd5-04462b5f81fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917560136-172.17.0.2-1595922353890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44802,DS-1a1e7488-ac45-41a2-bb5c-bcce264edf84,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-1dc75e05-9daf-4a70-ab4c-10e5abfc6b04,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-961aaa06-d622-4985-a15c-31b6cec01122,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-16bdd406-0009-4f28-a266-1e02e17f6932,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-fd08e4fe-3e99-44e1-ad19-36580a978abd,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-07bc3004-ef5a-4440-9061-ac6a9f26e395,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-242d9572-4b55-48ad-9d98-add372afb83a,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-a475ccee-ecbb-4821-a175-01b4de07f91a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917560136-172.17.0.2-1595922353890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44802,DS-1a1e7488-ac45-41a2-bb5c-bcce264edf84,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-1dc75e05-9daf-4a70-ab4c-10e5abfc6b04,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-961aaa06-d622-4985-a15c-31b6cec01122,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-16bdd406-0009-4f28-a266-1e02e17f6932,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-fd08e4fe-3e99-44e1-ad19-36580a978abd,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-07bc3004-ef5a-4440-9061-ac6a9f26e395,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-242d9572-4b55-48ad-9d98-add372afb83a,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-a475ccee-ecbb-4821-a175-01b4de07f91a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314980951-172.17.0.2-1595922823250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33341,DS-154cecc4-4069-4151-93b6-0b6962cf6903,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-b2b54614-5c31-43a1-9e64-d4d11f14953d,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-4262499a-0488-46e6-bde5-13a4b07cc75f,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-d24fe547-f979-4054-b0bd-3affad71b6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-9a6b26fc-dec4-4a70-970d-3303be8d01bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-8a71228b-fbf3-42e6-a11f-120f28f59b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-34e044c6-2c28-477e-9209-5d5a4f634d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-bb9deb27-dec1-4d24-9f3c-60c18fa9f670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314980951-172.17.0.2-1595922823250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33341,DS-154cecc4-4069-4151-93b6-0b6962cf6903,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-b2b54614-5c31-43a1-9e64-d4d11f14953d,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-4262499a-0488-46e6-bde5-13a4b07cc75f,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-d24fe547-f979-4054-b0bd-3affad71b6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-9a6b26fc-dec4-4a70-970d-3303be8d01bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-8a71228b-fbf3-42e6-a11f-120f28f59b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-34e044c6-2c28-477e-9209-5d5a4f634d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-bb9deb27-dec1-4d24-9f3c-60c18fa9f670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081138872-172.17.0.2-1595923115371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34570,DS-ea7d259c-ec2e-4c84-b705-4fdb77702080,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-3e88e4d4-37f3-496c-8424-92efbe1acc77,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-8d0a6260-ac4c-4320-a291-3157dd281384,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-a19574e6-b0e4-4af1-904f-ea77c6265e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-c4680683-de41-4f7e-8ed3-f6ff48b50bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-f004add6-d2b6-4366-ac76-588595aaf932,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-a6c630c1-976d-44d2-804a-66944f148ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-fa3b97ec-ea3f-46d1-8344-94545544f4c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081138872-172.17.0.2-1595923115371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34570,DS-ea7d259c-ec2e-4c84-b705-4fdb77702080,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-3e88e4d4-37f3-496c-8424-92efbe1acc77,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-8d0a6260-ac4c-4320-a291-3157dd281384,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-a19574e6-b0e4-4af1-904f-ea77c6265e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-c4680683-de41-4f7e-8ed3-f6ff48b50bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-f004add6-d2b6-4366-ac76-588595aaf932,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-a6c630c1-976d-44d2-804a-66944f148ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-fa3b97ec-ea3f-46d1-8344-94545544f4c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537775088-172.17.0.2-1595923345199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41343,DS-1144ca2d-5b78-4e98-97f5-0367541e4bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-af871f95-396c-4cff-bc5d-ca117994ad36,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-d1005130-9c71-4cd2-96b9-ea115ed2ff4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-f3138e38-7569-4660-84a3-3067a8c4c426,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-428eb7d0-6dc8-412e-a368-c3e24a140707,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-3356122b-ba9b-4fbb-8678-e5dc26019e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-10340cb0-db03-465a-9919-add26c513b77,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-c5532a52-a1dc-4566-be72-3f69649eef05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537775088-172.17.0.2-1595923345199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41343,DS-1144ca2d-5b78-4e98-97f5-0367541e4bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-af871f95-396c-4cff-bc5d-ca117994ad36,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-d1005130-9c71-4cd2-96b9-ea115ed2ff4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-f3138e38-7569-4660-84a3-3067a8c4c426,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-428eb7d0-6dc8-412e-a368-c3e24a140707,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-3356122b-ba9b-4fbb-8678-e5dc26019e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-10340cb0-db03-465a-9919-add26c513b77,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-c5532a52-a1dc-4566-be72-3f69649eef05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338817719-172.17.0.2-1595923420806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33940,DS-ce62c6e7-a591-4492-8e7d-66a1b0d1905f,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-6af5d9ce-f396-455e-ba62-b61b59cbd574,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-6e699fa1-9827-4faa-8e5d-4e440c9868a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-fee15acf-aeb8-4f80-abab-cb69ca9128c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-f13466c4-c907-48ba-b932-61d71f2b405d,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-cddfe23e-c8fd-4049-8698-12a16978bb79,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-fe989239-b028-45c6-b640-2cd2eccdb499,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-fd2015f1-9552-44f0-bbf3-627dda8244e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338817719-172.17.0.2-1595923420806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33940,DS-ce62c6e7-a591-4492-8e7d-66a1b0d1905f,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-6af5d9ce-f396-455e-ba62-b61b59cbd574,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-6e699fa1-9827-4faa-8e5d-4e440c9868a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-fee15acf-aeb8-4f80-abab-cb69ca9128c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-f13466c4-c907-48ba-b932-61d71f2b405d,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-cddfe23e-c8fd-4049-8698-12a16978bb79,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-fe989239-b028-45c6-b640-2cd2eccdb499,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-fd2015f1-9552-44f0-bbf3-627dda8244e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082710560-172.17.0.2-1595923495445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33097,DS-efb43089-a73b-49c5-bcc2-e721b6bf2954,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-a568e07c-a644-484d-ae18-22df0f39eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-2adbd4b9-221a-4b19-946a-b723712fe3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-0de6d62b-244d-4e01-a06b-fc479e242b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-124e59f3-dbbf-4521-85f6-7007a27a6376,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-da2467d6-f621-40b4-9eed-1b9017ac069a,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-1ab0cf39-c694-4980-bd09-1de0bf3313e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-2a32a81a-1732-4a1c-9125-f7ff5548345a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082710560-172.17.0.2-1595923495445:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33097,DS-efb43089-a73b-49c5-bcc2-e721b6bf2954,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-a568e07c-a644-484d-ae18-22df0f39eb27,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-2adbd4b9-221a-4b19-946a-b723712fe3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-0de6d62b-244d-4e01-a06b-fc479e242b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-124e59f3-dbbf-4521-85f6-7007a27a6376,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-da2467d6-f621-40b4-9eed-1b9017ac069a,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-1ab0cf39-c694-4980-bd09-1de0bf3313e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-2a32a81a-1732-4a1c-9125-f7ff5548345a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647171310-172.17.0.2-1595923627350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40073,DS-18828ebe-aec5-4ef1-be42-991923b28e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-1fc011a2-c609-4088-af9d-0f57c246a904,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-f3a3344c-b0f9-4b33-8720-1418b6ed259c,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-f5c45536-2e8a-41e1-aad5-7f5357a8a0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-689ffe81-68a1-4db0-ad72-e0a826de88d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-cc58ba10-43f5-464a-878d-49026b4ee0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-e201477d-53e7-4323-9f7c-9ebcaceb4cda,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-d8d26d27-8c72-4ed2-9795-df4461da1aad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647171310-172.17.0.2-1595923627350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40073,DS-18828ebe-aec5-4ef1-be42-991923b28e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-1fc011a2-c609-4088-af9d-0f57c246a904,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-f3a3344c-b0f9-4b33-8720-1418b6ed259c,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-f5c45536-2e8a-41e1-aad5-7f5357a8a0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-689ffe81-68a1-4db0-ad72-e0a826de88d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-cc58ba10-43f5-464a-878d-49026b4ee0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-e201477d-53e7-4323-9f7c-9ebcaceb4cda,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-d8d26d27-8c72-4ed2-9795-df4461da1aad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933700377-172.17.0.2-1595923660316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36297,DS-9066c43d-8b69-4490-827d-ba3650ba27b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-0e868f9b-23ef-4c01-871c-23c3366fabaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-509bc580-559c-4562-9be2-7de66893388b,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-587d0191-112d-4cc9-b82d-86fa84d104a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-0154efa4-6ca6-4c80-aaaf-b73d9751beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-1f136aca-00e1-4e26-8051-b40ae27bd70b,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-46fa838c-6d08-4934-b007-f99cc7b5d41b,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-e414dab5-5443-48c5-8a06-3401692d2d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933700377-172.17.0.2-1595923660316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36297,DS-9066c43d-8b69-4490-827d-ba3650ba27b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-0e868f9b-23ef-4c01-871c-23c3366fabaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-509bc580-559c-4562-9be2-7de66893388b,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-587d0191-112d-4cc9-b82d-86fa84d104a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-0154efa4-6ca6-4c80-aaaf-b73d9751beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-1f136aca-00e1-4e26-8051-b40ae27bd70b,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-46fa838c-6d08-4934-b007-f99cc7b5d41b,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-e414dab5-5443-48c5-8a06-3401692d2d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5537
