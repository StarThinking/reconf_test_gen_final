reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-122301458-172.17.0.21-1595521241565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34615,DS-1cb593ea-949f-4c3a-9942-bea795fffe7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-a3b7c1c5-669f-4bda-956c-0d374ef1f2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-30cc72f2-b6fe-4bb2-b3e9-b6ead56e042d,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-a924a8f4-84fa-4f35-a156-ba6abf5c0e07,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-787ebe03-e911-4203-8fe4-9e526f7d1729,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-34032e32-99ac-47ce-ad1c-83a13fb1ec6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-40fe017b-9637-45d6-89bf-a83d8842f301,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-071b77db-b260-4b10-8e76-85a0667f4f16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-122301458-172.17.0.21-1595521241565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34615,DS-1cb593ea-949f-4c3a-9942-bea795fffe7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-a3b7c1c5-669f-4bda-956c-0d374ef1f2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-30cc72f2-b6fe-4bb2-b3e9-b6ead56e042d,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-a924a8f4-84fa-4f35-a156-ba6abf5c0e07,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-787ebe03-e911-4203-8fe4-9e526f7d1729,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-34032e32-99ac-47ce-ad1c-83a13fb1ec6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-40fe017b-9637-45d6-89bf-a83d8842f301,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-071b77db-b260-4b10-8e76-85a0667f4f16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082381567-172.17.0.21-1595521609331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36353,DS-e4596f94-3c24-462a-8fbf-e649c34f65d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-794aee22-5b0c-488b-ae30-3dfeac7fce69,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-03d2a768-8559-4d20-a6c5-363902ddafe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-ba71d1cc-2dc4-4ac0-b997-c8dcb32bef02,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-14cfcbc0-ba88-465e-8f71-4eb395c95803,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-960379c6-634d-4747-912c-88f4aff79cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-412d9ce1-3b22-48eb-a374-858515fc210a,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-2a18a62b-58ac-4b7b-8f30-9404ac6abc4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082381567-172.17.0.21-1595521609331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36353,DS-e4596f94-3c24-462a-8fbf-e649c34f65d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-794aee22-5b0c-488b-ae30-3dfeac7fce69,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-03d2a768-8559-4d20-a6c5-363902ddafe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-ba71d1cc-2dc4-4ac0-b997-c8dcb32bef02,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-14cfcbc0-ba88-465e-8f71-4eb395c95803,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-960379c6-634d-4747-912c-88f4aff79cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-412d9ce1-3b22-48eb-a374-858515fc210a,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-2a18a62b-58ac-4b7b-8f30-9404ac6abc4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-791727269-172.17.0.21-1595522222508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42597,DS-6fa93154-921b-4d11-ae5a-9e0a40a76cef,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-2460ced5-4014-467d-8e93-bf5b1f348a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-edbb2796-c7ab-4774-aa03-1f5c137dc160,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-c84cb7c5-5608-49cd-8755-a70d4ba09371,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-92ef52fd-86ef-4c6e-a753-8b5ec5255c82,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-c6d4510e-8d42-4aab-884c-70b81b2d2c50,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-c43c5bcc-7230-495f-9842-0e57a28e50e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-ad5cd9a9-02c4-4b44-8ecb-bc21a010072c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-791727269-172.17.0.21-1595522222508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42597,DS-6fa93154-921b-4d11-ae5a-9e0a40a76cef,DISK], DatanodeInfoWithStorage[127.0.0.1:45823,DS-2460ced5-4014-467d-8e93-bf5b1f348a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-edbb2796-c7ab-4774-aa03-1f5c137dc160,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-c84cb7c5-5608-49cd-8755-a70d4ba09371,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-92ef52fd-86ef-4c6e-a753-8b5ec5255c82,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-c6d4510e-8d42-4aab-884c-70b81b2d2c50,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-c43c5bcc-7230-495f-9842-0e57a28e50e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-ad5cd9a9-02c4-4b44-8ecb-bc21a010072c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935895342-172.17.0.21-1595522748930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39286,DS-22e5b2a8-c70b-4a55-9858-988ab6c4cdef,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-c8ba8e84-9aa9-4d69-922b-a221b54171b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-e23ed923-4aa4-4f46-8a02-22ee11916316,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-50ad58bf-d2b0-4627-9d69-af89fc2aed51,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-5fedb691-db56-4e55-a6fc-837b4f97d3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-623865d8-f406-4a47-a304-698195f844a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-dd3061e1-9639-4637-8346-36057aafd6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-e119bf3c-2158-4bcc-bcc9-7c3dca464a59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935895342-172.17.0.21-1595522748930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39286,DS-22e5b2a8-c70b-4a55-9858-988ab6c4cdef,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-c8ba8e84-9aa9-4d69-922b-a221b54171b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-e23ed923-4aa4-4f46-8a02-22ee11916316,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-50ad58bf-d2b0-4627-9d69-af89fc2aed51,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-5fedb691-db56-4e55-a6fc-837b4f97d3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-623865d8-f406-4a47-a304-698195f844a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-dd3061e1-9639-4637-8346-36057aafd6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-e119bf3c-2158-4bcc-bcc9-7c3dca464a59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819219790-172.17.0.21-1595522822029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33461,DS-ca650377-b1d0-4ae3-94f8-4b9f74d4149b,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-3324c9e9-996c-430f-bda2-2a2828d17ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-8f2fdc0d-1dbb-45de-8e23-9822e735a82c,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-d896349f-d030-4100-b1eb-1a3aa9d7dcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-31977b3b-09f9-4529-8978-f5e4cb5b3dec,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-e124562c-f823-4b1f-b934-54c372e775d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-9c6bde8c-639e-4905-be5b-094e7fd19275,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-033c584c-8693-4011-af23-460ba85190e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1819219790-172.17.0.21-1595522822029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33461,DS-ca650377-b1d0-4ae3-94f8-4b9f74d4149b,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-3324c9e9-996c-430f-bda2-2a2828d17ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-8f2fdc0d-1dbb-45de-8e23-9822e735a82c,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-d896349f-d030-4100-b1eb-1a3aa9d7dcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-31977b3b-09f9-4529-8978-f5e4cb5b3dec,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-e124562c-f823-4b1f-b934-54c372e775d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-9c6bde8c-639e-4905-be5b-094e7fd19275,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-033c584c-8693-4011-af23-460ba85190e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-749077495-172.17.0.21-1595522949126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37826,DS-6ad6f80a-ee0f-4242-8a4c-5a9ffb521742,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-d0390c3d-e1f6-498c-be3e-b2dfd418369b,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-c9ba5ba4-d183-41cf-bf8a-1cef0cfe5372,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-5ed32c3e-6bdf-49f9-859a-5621ee34cb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-7dedcf48-4747-4cb8-8128-ef8c156ebbec,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-75ee2a86-61c9-4d03-bbc2-9c1101faeaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-5743d28c-73f1-4803-8c7e-761c700b58d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-c52db0b3-08c3-4b3a-b88e-79d7f2840032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-749077495-172.17.0.21-1595522949126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37826,DS-6ad6f80a-ee0f-4242-8a4c-5a9ffb521742,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-d0390c3d-e1f6-498c-be3e-b2dfd418369b,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-c9ba5ba4-d183-41cf-bf8a-1cef0cfe5372,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-5ed32c3e-6bdf-49f9-859a-5621ee34cb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-7dedcf48-4747-4cb8-8128-ef8c156ebbec,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-75ee2a86-61c9-4d03-bbc2-9c1101faeaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-5743d28c-73f1-4803-8c7e-761c700b58d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-c52db0b3-08c3-4b3a-b88e-79d7f2840032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720765210-172.17.0.21-1595524201447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34207,DS-e9437dff-40b4-4980-acfe-832446e6f450,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-1ca50204-745c-44ed-81c7-c29a14045300,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-aa4da48e-4e20-4f21-8d22-1350d913c5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-505f5994-f0d5-4674-8f3b-972b241cf689,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-34c453fb-5ffc-4b38-943c-c73547373357,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-e5189e76-a91c-4bf1-ae76-9f494fb5c199,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-fb8ad363-5a5b-492e-9855-fdc1cfc8dba2,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-440f89af-5b87-4774-9129-a84175d3aa61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720765210-172.17.0.21-1595524201447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34207,DS-e9437dff-40b4-4980-acfe-832446e6f450,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-1ca50204-745c-44ed-81c7-c29a14045300,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-aa4da48e-4e20-4f21-8d22-1350d913c5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-505f5994-f0d5-4674-8f3b-972b241cf689,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-34c453fb-5ffc-4b38-943c-c73547373357,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-e5189e76-a91c-4bf1-ae76-9f494fb5c199,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-fb8ad363-5a5b-492e-9855-fdc1cfc8dba2,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-440f89af-5b87-4774-9129-a84175d3aa61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720253859-172.17.0.21-1595524449402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36744,DS-12ac8720-8ad3-4f59-aa1a-7f52342441cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-5afb1e56-9ece-4f89-9286-727d5f7ecf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-9cfb404c-56d3-4c1e-979b-ab0b52b1b5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-bc203131-6157-402c-a14d-997014ca6b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-4525abe3-abdb-4eb6-a0e1-df3b868b7f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-cc8fde4f-463f-4b41-8a55-5f8975ada920,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-de82617c-b273-4ead-a043-fcc996d410f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-0de78836-b87c-4ac8-905b-acf84fcf3e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720253859-172.17.0.21-1595524449402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36744,DS-12ac8720-8ad3-4f59-aa1a-7f52342441cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-5afb1e56-9ece-4f89-9286-727d5f7ecf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-9cfb404c-56d3-4c1e-979b-ab0b52b1b5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-bc203131-6157-402c-a14d-997014ca6b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-4525abe3-abdb-4eb6-a0e1-df3b868b7f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-cc8fde4f-463f-4b41-8a55-5f8975ada920,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-de82617c-b273-4ead-a043-fcc996d410f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-0de78836-b87c-4ac8-905b-acf84fcf3e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666892861-172.17.0.21-1595524726533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44524,DS-fe3d9fef-1637-464b-85a2-25b6f0d4c297,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-732df903-2ffa-4c63-838a-3e38aaa1e86f,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-577a9341-9e28-473a-b05e-af7bcadb36da,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-2392ccdf-d3c5-44ee-bd59-c45c669f5375,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-6fa11790-16e4-4087-a4b1-1419dc1e40ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-6a84bf82-74f1-460f-98ad-cf4446c6f0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-c153b360-03e9-442e-9e1e-1044dc847081,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-bb30e11a-054f-4572-9f1b-bcfe0d072ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666892861-172.17.0.21-1595524726533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44524,DS-fe3d9fef-1637-464b-85a2-25b6f0d4c297,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-732df903-2ffa-4c63-838a-3e38aaa1e86f,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-577a9341-9e28-473a-b05e-af7bcadb36da,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-2392ccdf-d3c5-44ee-bd59-c45c669f5375,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-6fa11790-16e4-4087-a4b1-1419dc1e40ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-6a84bf82-74f1-460f-98ad-cf4446c6f0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-c153b360-03e9-442e-9e1e-1044dc847081,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-bb30e11a-054f-4572-9f1b-bcfe0d072ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794534771-172.17.0.21-1595524834516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34820,DS-9aeaa807-2504-4d83-a183-cd7c6d54f487,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-600aef22-55b6-4add-8e95-9d753de5b8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-9ba207a2-6ce7-4076-9296-3cb394d51a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-7cf236f8-12c2-46ad-8173-68be3a180110,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-e4a5c6e8-18f9-433a-819f-ceed8073a7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-cd6f4546-ecda-4bd9-a83b-3b8f608fd4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-47b5c713-34d8-43ba-8a99-fd7ca5c8f94f,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-51b64e70-bbc9-41a5-ae2e-d310bc9c46a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794534771-172.17.0.21-1595524834516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34820,DS-9aeaa807-2504-4d83-a183-cd7c6d54f487,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-600aef22-55b6-4add-8e95-9d753de5b8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-9ba207a2-6ce7-4076-9296-3cb394d51a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-7cf236f8-12c2-46ad-8173-68be3a180110,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-e4a5c6e8-18f9-433a-819f-ceed8073a7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-cd6f4546-ecda-4bd9-a83b-3b8f608fd4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-47b5c713-34d8-43ba-8a99-fd7ca5c8f94f,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-51b64e70-bbc9-41a5-ae2e-d310bc9c46a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733137487-172.17.0.21-1595526083786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38457,DS-d793a1d3-672a-495c-ae9b-87b400626cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-9d03c726-b1e3-43fc-83e6-07d528f144bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-ab5cbd36-7cef-472e-91d5-06a8a0f68c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-fb032bc5-72c8-41b7-8bee-51124b0b9478,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-f4f7a421-9be0-4319-b3e6-1925bb5b7123,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-5dc98844-80b4-4796-ab13-59d37968b772,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-202313e8-bf9c-4624-ab66-fa2ec42174d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-6aa11e4a-de7a-462e-b6ac-5d9e4c91b770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733137487-172.17.0.21-1595526083786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38457,DS-d793a1d3-672a-495c-ae9b-87b400626cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-9d03c726-b1e3-43fc-83e6-07d528f144bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-ab5cbd36-7cef-472e-91d5-06a8a0f68c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-fb032bc5-72c8-41b7-8bee-51124b0b9478,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-f4f7a421-9be0-4319-b3e6-1925bb5b7123,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-5dc98844-80b4-4796-ab13-59d37968b772,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-202313e8-bf9c-4624-ab66-fa2ec42174d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-6aa11e4a-de7a-462e-b6ac-5d9e4c91b770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5081
