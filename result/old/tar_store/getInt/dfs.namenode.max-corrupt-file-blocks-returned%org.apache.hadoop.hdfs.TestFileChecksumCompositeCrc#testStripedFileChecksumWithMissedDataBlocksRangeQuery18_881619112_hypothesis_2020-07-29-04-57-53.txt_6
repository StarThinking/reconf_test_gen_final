reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548961609-172.17.0.21-1595998924451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38428,DS-943b9218-786d-4b03-be0f-a6f3a067ef56,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-5f96cf41-ae1e-440b-8768-4c69de55bb29,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-126753bd-d219-4540-ae12-89bbfcf50e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-0f4e004f-ad55-43fc-920a-62866a077426,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-e64ca6ca-05b2-4602-922a-822b23fdc83a,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-7d8766b2-6106-42d3-8bf0-31292721db4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-46fe0fd5-d394-4249-a400-062ccb13ffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-d19f90a6-ba6d-4754-b54a-7bc266f18c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548961609-172.17.0.21-1595998924451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38428,DS-943b9218-786d-4b03-be0f-a6f3a067ef56,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-5f96cf41-ae1e-440b-8768-4c69de55bb29,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-126753bd-d219-4540-ae12-89bbfcf50e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-0f4e004f-ad55-43fc-920a-62866a077426,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-e64ca6ca-05b2-4602-922a-822b23fdc83a,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-7d8766b2-6106-42d3-8bf0-31292721db4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-46fe0fd5-d394-4249-a400-062ccb13ffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-d19f90a6-ba6d-4754-b54a-7bc266f18c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990542880-172.17.0.21-1595999061249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-f5388789-80d5-4877-88bb-2853cb871a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-610e50f6-5bf0-428c-996f-9d6f1e309f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-d712d3ee-0046-4ffb-8c65-cc8a730f49b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-3fa64b4f-bc81-447b-9a0f-1696d7049e24,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-5216cded-c03c-4bc1-aa2e-bdcb0c1a4e13,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-fca4d6f3-0564-4162-adf7-66ee6f668f23,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-07a41067-54d6-4ac1-a831-6342f2b2bc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-26503715-2b35-4887-99fd-a4d5f94c6947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990542880-172.17.0.21-1595999061249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-f5388789-80d5-4877-88bb-2853cb871a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-610e50f6-5bf0-428c-996f-9d6f1e309f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-d712d3ee-0046-4ffb-8c65-cc8a730f49b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-3fa64b4f-bc81-447b-9a0f-1696d7049e24,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-5216cded-c03c-4bc1-aa2e-bdcb0c1a4e13,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-fca4d6f3-0564-4162-adf7-66ee6f668f23,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-07a41067-54d6-4ac1-a831-6342f2b2bc3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-26503715-2b35-4887-99fd-a4d5f94c6947,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599219720-172.17.0.21-1595999125436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43097,DS-af32f3a1-220a-4859-8ae8-99f5530489d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-8acda728-a857-4272-922b-1b52b746a47d,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-8eccd5b4-b927-4f2d-b354-113dc9fa9855,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-834d9412-0edc-432b-9541-ddc8981bf13f,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-ae4db423-3440-48dc-bb53-0e3636a33ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-041648e1-4216-45b8-9a3a-b49f7e5ac983,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-5a771072-8cf6-41ee-8c6d-7f540ad23a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-c6637862-d37b-4349-b6e6-0a7ef1b69ad0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599219720-172.17.0.21-1595999125436:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43097,DS-af32f3a1-220a-4859-8ae8-99f5530489d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-8acda728-a857-4272-922b-1b52b746a47d,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-8eccd5b4-b927-4f2d-b354-113dc9fa9855,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-834d9412-0edc-432b-9541-ddc8981bf13f,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-ae4db423-3440-48dc-bb53-0e3636a33ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-041648e1-4216-45b8-9a3a-b49f7e5ac983,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-5a771072-8cf6-41ee-8c6d-7f540ad23a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-c6637862-d37b-4349-b6e6-0a7ef1b69ad0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702780477-172.17.0.21-1595999230895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33822,DS-520bc563-b3a1-4f73-8253-b1d57d57b23a,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-d8246d73-9748-482d-a90c-9a9f3dc93475,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-4d15e8c9-8b6e-4fb6-b6c9-e9c40389d53b,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-a0b8f15f-8e68-4961-853d-68bb7f8eefa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-e07e53c2-5bb7-4484-9d0f-867667c85f81,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-2114d2e6-437f-4d85-b654-b2eddcd31509,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-e8d77e13-792e-4e97-83f6-73ac3b369a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-cefeff91-28e1-4473-a06b-b4afe7abe716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702780477-172.17.0.21-1595999230895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33822,DS-520bc563-b3a1-4f73-8253-b1d57d57b23a,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-d8246d73-9748-482d-a90c-9a9f3dc93475,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-4d15e8c9-8b6e-4fb6-b6c9-e9c40389d53b,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-a0b8f15f-8e68-4961-853d-68bb7f8eefa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-e07e53c2-5bb7-4484-9d0f-867667c85f81,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-2114d2e6-437f-4d85-b654-b2eddcd31509,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-e8d77e13-792e-4e97-83f6-73ac3b369a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-cefeff91-28e1-4473-a06b-b4afe7abe716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778651210-172.17.0.21-1595999614813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39210,DS-18f1f2ea-a858-4595-99e2-622fa74ab513,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-0be3be1c-b6f0-4b1c-9e37-bf3f5c22f993,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-7e4bb843-54f3-4365-a213-ca92539550e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-8f99bcfd-515e-4136-ac4f-d0437643687f,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-fd1533d2-0aac-4a92-afd8-865ac8a2e432,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-0d5a3113-72b7-42d0-aa33-659fefcfc033,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-af030fd9-8f64-4c6e-b0bb-4304215e9717,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-ebfd72bb-dc80-4a79-b176-3e206abac9a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778651210-172.17.0.21-1595999614813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39210,DS-18f1f2ea-a858-4595-99e2-622fa74ab513,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-0be3be1c-b6f0-4b1c-9e37-bf3f5c22f993,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-7e4bb843-54f3-4365-a213-ca92539550e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-8f99bcfd-515e-4136-ac4f-d0437643687f,DISK], DatanodeInfoWithStorage[127.0.0.1:44014,DS-fd1533d2-0aac-4a92-afd8-865ac8a2e432,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-0d5a3113-72b7-42d0-aa33-659fefcfc033,DISK], DatanodeInfoWithStorage[127.0.0.1:43783,DS-af030fd9-8f64-4c6e-b0bb-4304215e9717,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-ebfd72bb-dc80-4a79-b176-3e206abac9a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-284857675-172.17.0.21-1595999995569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44651,DS-13abac75-d734-43dc-8bb9-927f03140f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-9af8cf32-c02d-41f3-ab96-ff39a173c534,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-14480ea9-f721-4684-934c-fbe1dab312ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-1d9ea3b9-58a0-4d98-808d-818d5442028b,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-1272c3c1-79c5-40b7-b337-47107bbb17bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-7b028049-12f5-4e80-89cd-0d6e0a40bad4,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-57e13a7a-3f0e-4108-9dd0-43c4312861bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-56a8be33-eeca-4a4f-8b82-2189dbda7e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-284857675-172.17.0.21-1595999995569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44651,DS-13abac75-d734-43dc-8bb9-927f03140f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-9af8cf32-c02d-41f3-ab96-ff39a173c534,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-14480ea9-f721-4684-934c-fbe1dab312ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-1d9ea3b9-58a0-4d98-808d-818d5442028b,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-1272c3c1-79c5-40b7-b337-47107bbb17bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-7b028049-12f5-4e80-89cd-0d6e0a40bad4,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-57e13a7a-3f0e-4108-9dd0-43c4312861bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-56a8be33-eeca-4a4f-8b82-2189dbda7e13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91166233-172.17.0.21-1596000073108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45282,DS-9361eeaf-061d-482c-a623-c0046284fd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-ab113b0a-e54e-4338-a4fe-c5f0fccb67b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-ff46e02f-e301-4d92-95b5-4f4c8428af3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-85b197ff-043f-4d3e-8e71-52c515744522,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-b9ed108a-5e56-457f-a559-0cb83bdca6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-3fa3267b-6567-49a2-96b0-0f7ff3b3da65,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-0377561a-82e0-4543-9fbe-392a8974516e,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-996a5ef2-624b-4a40-96e1-b699e4d59d09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91166233-172.17.0.21-1596000073108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45282,DS-9361eeaf-061d-482c-a623-c0046284fd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-ab113b0a-e54e-4338-a4fe-c5f0fccb67b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-ff46e02f-e301-4d92-95b5-4f4c8428af3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-85b197ff-043f-4d3e-8e71-52c515744522,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-b9ed108a-5e56-457f-a559-0cb83bdca6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-3fa3267b-6567-49a2-96b0-0f7ff3b3da65,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-0377561a-82e0-4543-9fbe-392a8974516e,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-996a5ef2-624b-4a40-96e1-b699e4d59d09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1992338165-172.17.0.21-1596000143358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37460,DS-e456a45e-a8a7-4834-954e-f2d8786f5054,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-055ca0ec-9e00-4a41-b550-d86f6cb8ffec,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-67322144-3758-4707-8159-e8f3bae368ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-ce9e9311-8987-4e7f-ba5b-398aac496331,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-c33115e4-ec2f-45e7-b213-54a04c2ae1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-577b7a93-45f0-4f96-a876-9e63e5a20924,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-c29e564e-ff24-489d-8fe4-2dc9d790f44e,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-032ffef7-7fe6-47e5-bfee-638b51959439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1992338165-172.17.0.21-1596000143358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37460,DS-e456a45e-a8a7-4834-954e-f2d8786f5054,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-055ca0ec-9e00-4a41-b550-d86f6cb8ffec,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-67322144-3758-4707-8159-e8f3bae368ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-ce9e9311-8987-4e7f-ba5b-398aac496331,DISK], DatanodeInfoWithStorage[127.0.0.1:34353,DS-c33115e4-ec2f-45e7-b213-54a04c2ae1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-577b7a93-45f0-4f96-a876-9e63e5a20924,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-c29e564e-ff24-489d-8fe4-2dc9d790f44e,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-032ffef7-7fe6-47e5-bfee-638b51959439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454527452-172.17.0.21-1596000216796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42905,DS-6f92b1f7-e78a-41f3-806f-b19e605e7ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-db495cc0-e34c-4f21-8fce-1b908e0cf082,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-15524199-e7a6-4f9b-8854-06d16195f1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-87e3e277-3edf-4df8-aa4e-9fb8130a21e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-c4ef74e1-9204-463a-b746-66bf7aed3170,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-c5279011-f416-44b9-a78c-123bc2adc893,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-2fb56d94-b18a-4214-b739-2a5b0fe670ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-fc185849-995d-47f0-a572-b936a496165b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454527452-172.17.0.21-1596000216796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42905,DS-6f92b1f7-e78a-41f3-806f-b19e605e7ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-db495cc0-e34c-4f21-8fce-1b908e0cf082,DISK], DatanodeInfoWithStorage[127.0.0.1:39202,DS-15524199-e7a6-4f9b-8854-06d16195f1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-87e3e277-3edf-4df8-aa4e-9fb8130a21e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-c4ef74e1-9204-463a-b746-66bf7aed3170,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-c5279011-f416-44b9-a78c-123bc2adc893,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-2fb56d94-b18a-4214-b739-2a5b0fe670ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42773,DS-fc185849-995d-47f0-a572-b936a496165b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980010022-172.17.0.21-1596000370760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43082,DS-175cb2af-2b9f-446e-8345-121347763769,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-a42d6568-b5db-484d-9649-09cfe93478d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-942adef5-9d78-406c-b4f5-0a9f3e05cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-17e8ad9b-5068-4ae1-a91a-197c30c9d9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-77da440f-bd84-4770-a332-4807c55006bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-b2e0f8a5-5498-4e85-8380-49b3f5a7eca5,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-673ef7dd-31f1-4741-bd02-d2d321580795,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-d859fab5-368a-4acd-bb43-cbcc64182964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980010022-172.17.0.21-1596000370760:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43082,DS-175cb2af-2b9f-446e-8345-121347763769,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-a42d6568-b5db-484d-9649-09cfe93478d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-942adef5-9d78-406c-b4f5-0a9f3e05cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-17e8ad9b-5068-4ae1-a91a-197c30c9d9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-77da440f-bd84-4770-a332-4807c55006bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-b2e0f8a5-5498-4e85-8380-49b3f5a7eca5,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-673ef7dd-31f1-4741-bd02-d2d321580795,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-d859fab5-368a-4acd-bb43-cbcc64182964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226464918-172.17.0.21-1596000413100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33401,DS-bfffe299-ac2d-45f0-a307-b2dd32043d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-fb551093-627f-4b60-a047-c5225fe9b615,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-27238cf5-122d-4530-9046-7f74a4d12a13,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-43b5284d-091b-4267-92c9-5b516d658f70,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-6e674025-7ae0-4488-8faa-cfbb12547c63,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-c7b8d7de-c6f2-41a7-9bc9-cc9c7d675736,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-f4006d63-e676-4a06-88b3-22b9d16a4fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-b8566b72-5fbb-49ed-a86a-c4bdf278201e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-226464918-172.17.0.21-1596000413100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33401,DS-bfffe299-ac2d-45f0-a307-b2dd32043d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-fb551093-627f-4b60-a047-c5225fe9b615,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-27238cf5-122d-4530-9046-7f74a4d12a13,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-43b5284d-091b-4267-92c9-5b516d658f70,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-6e674025-7ae0-4488-8faa-cfbb12547c63,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-c7b8d7de-c6f2-41a7-9bc9-cc9c7d675736,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-f4006d63-e676-4a06-88b3-22b9d16a4fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-b8566b72-5fbb-49ed-a86a-c4bdf278201e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081936060-172.17.0.21-1596000895609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36834,DS-d58cfc67-5451-4b0e-a5bf-12b35a835b16,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-bdfb8e0e-0098-4a47-9e5d-3f9ad6b4eaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-c9450fd3-c82c-4513-9ec2-28fb7c1d8674,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-f09653ea-b1af-43d7-af03-f51bb3d77c17,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-c00dd957-a81d-421f-9999-a12caaf6e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-90d58558-541f-4ac7-b2e3-01891f3c4b08,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b4628d4b-dc6e-4e6d-8090-8e5f9384a63a,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-796d7ae2-9ec1-4abb-9eb6-443fe3b7d31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081936060-172.17.0.21-1596000895609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36834,DS-d58cfc67-5451-4b0e-a5bf-12b35a835b16,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-bdfb8e0e-0098-4a47-9e5d-3f9ad6b4eaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-c9450fd3-c82c-4513-9ec2-28fb7c1d8674,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-f09653ea-b1af-43d7-af03-f51bb3d77c17,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-c00dd957-a81d-421f-9999-a12caaf6e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-90d58558-541f-4ac7-b2e3-01891f3c4b08,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b4628d4b-dc6e-4e6d-8090-8e5f9384a63a,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-796d7ae2-9ec1-4abb-9eb6-443fe3b7d31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539017960-172.17.0.21-1596001098392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42901,DS-0b29576b-989e-4fa0-92ab-4f02c8ae05c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-39019625-7bb8-4a28-9e96-ddad86590d48,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-1379b7da-c501-483e-853f-620b51556c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-40656c9d-a4ab-4a2f-a744-6732ec7a16ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-cf9f2bb1-fbc5-4266-97df-11b9109fa5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-fcd82fcf-eb4b-42d6-a5bc-1ccaa3a640d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-591ceb57-7f77-48d1-b3ee-b6898d6f63f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-7272eacb-ade4-4ebc-b7b2-c7e14f4a642f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539017960-172.17.0.21-1596001098392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42901,DS-0b29576b-989e-4fa0-92ab-4f02c8ae05c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-39019625-7bb8-4a28-9e96-ddad86590d48,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-1379b7da-c501-483e-853f-620b51556c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-40656c9d-a4ab-4a2f-a744-6732ec7a16ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-cf9f2bb1-fbc5-4266-97df-11b9109fa5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-fcd82fcf-eb4b-42d6-a5bc-1ccaa3a640d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-591ceb57-7f77-48d1-b3ee-b6898d6f63f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-7272eacb-ade4-4ebc-b7b2-c7e14f4a642f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315752653-172.17.0.21-1596001202048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43398,DS-7a26c2ab-1a65-42b5-a112-a51a0f4fb9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-7d1be907-00cc-4a57-b9b6-649264887f99,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-2be8fce7-18dc-40c2-b2a0-0be4e7694d68,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-a25cafa7-1161-445f-b503-f1860abe74a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-2c2ec87f-02d4-42cd-a713-018362bc8754,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-63aaa7a2-7a20-4998-9085-8c21fcd96f11,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-8514535c-a1ad-4bd7-a14a-44f3a208a0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-259f663b-c9f0-4133-b1be-d7c1a6916a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315752653-172.17.0.21-1596001202048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43398,DS-7a26c2ab-1a65-42b5-a112-a51a0f4fb9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-7d1be907-00cc-4a57-b9b6-649264887f99,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-2be8fce7-18dc-40c2-b2a0-0be4e7694d68,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-a25cafa7-1161-445f-b503-f1860abe74a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-2c2ec87f-02d4-42cd-a713-018362bc8754,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-63aaa7a2-7a20-4998-9085-8c21fcd96f11,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-8514535c-a1ad-4bd7-a14a-44f3a208a0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-259f663b-c9f0-4133-b1be-d7c1a6916a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486514940-172.17.0.21-1596002098725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39125,DS-18548c50-a51c-4151-85ab-2a2c9116c0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-953e8829-c6d2-4361-a56a-0298286bf26a,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-2d0d7103-d88e-49db-a5d6-b05231dbdc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-ec8e8e71-5658-4dcb-ad06-c1621900254d,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-589ea886-511a-4137-99de-c20e420d1b79,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-36ec783c-4115-48fa-93e0-e08164b74ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-9ff76f30-f51c-4d04-bf11-411bcdbba61f,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-feb9f804-1e04-4233-975c-e65dcae9ed86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486514940-172.17.0.21-1596002098725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39125,DS-18548c50-a51c-4151-85ab-2a2c9116c0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-953e8829-c6d2-4361-a56a-0298286bf26a,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-2d0d7103-d88e-49db-a5d6-b05231dbdc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-ec8e8e71-5658-4dcb-ad06-c1621900254d,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-589ea886-511a-4137-99de-c20e420d1b79,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-36ec783c-4115-48fa-93e0-e08164b74ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-9ff76f30-f51c-4d04-bf11-411bcdbba61f,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-feb9f804-1e04-4233-975c-e65dcae9ed86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353784432-172.17.0.21-1596002576864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44176,DS-5cd7db0b-9aaa-4e05-8a24-e2fb21a91468,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-1360d00f-8980-4643-93da-6801fb448d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-3d19b061-a58d-4645-9afd-c8787c4c7189,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-624c641a-8fec-42a4-8e73-df7aaa03580b,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-2e25e5aa-16c3-4b06-b9a2-e913a58637fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-4165d4fd-f21b-4390-80e0-6a5fed7f6642,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-2215e463-2b46-4abf-aafa-389fc6f614de,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-8725d29a-deed-40e2-b8b8-3e8a8877db64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353784432-172.17.0.21-1596002576864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44176,DS-5cd7db0b-9aaa-4e05-8a24-e2fb21a91468,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-1360d00f-8980-4643-93da-6801fb448d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-3d19b061-a58d-4645-9afd-c8787c4c7189,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-624c641a-8fec-42a4-8e73-df7aaa03580b,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-2e25e5aa-16c3-4b06-b9a2-e913a58637fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-4165d4fd-f21b-4390-80e0-6a5fed7f6642,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-2215e463-2b46-4abf-aafa-389fc6f614de,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-8725d29a-deed-40e2-b8b8-3e8a8877db64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656132089-172.17.0.21-1596002611773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39801,DS-c5a2e5f5-749b-4682-af4b-e401646d14ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-6dc3e1c5-bdb1-4955-9c59-547e98dd3506,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-b7fe18d6-e73d-46fa-b6e5-2ecbeb33647a,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-fb7d5bce-b317-41e7-be53-235ebebf9a24,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-d6e1aa1a-2707-46b3-b553-ed87aa1f87d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-acdbb036-2567-43c5-b2a4-7a701221845d,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-ca86aa10-ab4f-467c-b176-9c6ab8e72480,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-66d2a168-c79f-47bb-9e2b-829840bbaab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656132089-172.17.0.21-1596002611773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39801,DS-c5a2e5f5-749b-4682-af4b-e401646d14ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-6dc3e1c5-bdb1-4955-9c59-547e98dd3506,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-b7fe18d6-e73d-46fa-b6e5-2ecbeb33647a,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-fb7d5bce-b317-41e7-be53-235ebebf9a24,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-d6e1aa1a-2707-46b3-b553-ed87aa1f87d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-acdbb036-2567-43c5-b2a4-7a701221845d,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-ca86aa10-ab4f-467c-b176-9c6ab8e72480,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-66d2a168-c79f-47bb-9e2b-829840bbaab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918632692-172.17.0.21-1596003622231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37959,DS-f8d05540-4bc9-417e-92bb-106f3d6de223,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-b3c5ed86-76ad-44dd-8172-e2e5fe8d7206,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-96b0e605-7cf9-4681-a457-3018c113dd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-f7d4855d-580e-4e34-863b-f9cc4578c4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-6e6befc4-a443-4301-aa07-07fb33a86211,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-89045627-d561-4c97-ae38-649eed29d62b,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-388fb92d-ec73-409e-ac53-47331fec1bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-650bd912-b182-4d53-8248-047588b13fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-918632692-172.17.0.21-1596003622231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37959,DS-f8d05540-4bc9-417e-92bb-106f3d6de223,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-b3c5ed86-76ad-44dd-8172-e2e5fe8d7206,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-96b0e605-7cf9-4681-a457-3018c113dd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-f7d4855d-580e-4e34-863b-f9cc4578c4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-6e6befc4-a443-4301-aa07-07fb33a86211,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-89045627-d561-4c97-ae38-649eed29d62b,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-388fb92d-ec73-409e-ac53-47331fec1bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-650bd912-b182-4d53-8248-047588b13fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1432519361-172.17.0.21-1596003654384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36749,DS-67e785ba-bdf5-4653-8702-224a695ff602,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-34831a1e-6752-4df6-b632-ac7d802d9d01,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-dcccbd59-382b-4820-860e-a896db4404f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-13174227-bebb-44ff-8957-17b0fc4981cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-89147244-9b3c-4bc0-b878-bda6329a8750,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-e78d7629-9103-4c6e-8d3c-2574309b1f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-ba989962-40e2-4dd8-9bde-6f8a29e2798e,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-f8aeec56-70c1-456a-9ecf-6956301196c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1432519361-172.17.0.21-1596003654384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36749,DS-67e785ba-bdf5-4653-8702-224a695ff602,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-34831a1e-6752-4df6-b632-ac7d802d9d01,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-dcccbd59-382b-4820-860e-a896db4404f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-13174227-bebb-44ff-8957-17b0fc4981cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-89147244-9b3c-4bc0-b878-bda6329a8750,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-e78d7629-9103-4c6e-8d3c-2574309b1f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-ba989962-40e2-4dd8-9bde-6f8a29e2798e,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-f8aeec56-70c1-456a-9ecf-6956301196c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356403685-172.17.0.21-1596003747939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37770,DS-e3723b78-6810-420a-bba6-1fa381f711a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-867c14b6-07e0-42e9-967f-1ae2a12babb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-3db4e319-8055-4717-8469-38b52893b878,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-435b7e37-fb69-4341-a0da-09aecb80ee0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-78efa2e7-6ebb-4e50-9cbe-9347e3d0af04,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-e5780b37-368f-4ff8-bbe9-a6d4b0217ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-2b8f515c-b478-48f9-9f99-6a3bab1b0107,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-c98bae25-58d9-4446-9cc1-eaaf621c1cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356403685-172.17.0.21-1596003747939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37770,DS-e3723b78-6810-420a-bba6-1fa381f711a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-867c14b6-07e0-42e9-967f-1ae2a12babb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-3db4e319-8055-4717-8469-38b52893b878,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-435b7e37-fb69-4341-a0da-09aecb80ee0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-78efa2e7-6ebb-4e50-9cbe-9347e3d0af04,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-e5780b37-368f-4ff8-bbe9-a6d4b0217ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-2b8f515c-b478-48f9-9f99-6a3bab1b0107,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-c98bae25-58d9-4446-9cc1-eaaf621c1cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-corrupt-file-blocks-returned
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1954003769-172.17.0.21-1596003952817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37082,DS-26cced0b-01e1-4320-9c7a-f8c2236fe819,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-deba98ac-11ff-44a5-9e32-2d48c2180b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-eb922e3b-c4de-4ba8-bb08-f8248a000910,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-6d8409c2-bea3-4bed-9f84-7dbba0ae681c,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-90dd2538-247e-43a9-a23d-582db65e4c22,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-12321e87-96b3-4e26-93ec-08367cc126c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-bc96b9e8-dde0-41e7-b3ff-d8b877f31784,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-8b6e3895-b4d4-44a9-9fd6-16db473dac14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1954003769-172.17.0.21-1596003952817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37082,DS-26cced0b-01e1-4320-9c7a-f8c2236fe819,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-deba98ac-11ff-44a5-9e32-2d48c2180b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-eb922e3b-c4de-4ba8-bb08-f8248a000910,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-6d8409c2-bea3-4bed-9f84-7dbba0ae681c,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-90dd2538-247e-43a9-a23d-582db65e4c22,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-12321e87-96b3-4e26-93ec-08367cc126c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-bc96b9e8-dde0-41e7-b3ff-d8b877f31784,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-8b6e3895-b4d4-44a9-9fd6-16db473dac14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5349
