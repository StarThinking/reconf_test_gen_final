reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972374152-172.17.0.12-1595864274707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40468,DS-24267678-425f-44e9-8375-701873e9fac6,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-bd84954d-575c-4d07-929d-04ab728a3acb,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-602d373e-c087-46dc-826f-2343c7064bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-57a1217a-3097-456c-be53-a3ed9bda7f29,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-2a1ff63b-f856-4693-869f-5a243c89bed4,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-ae7babee-0e79-42ad-bd18-e55684272aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-73c3d298-b1e0-423b-bdbc-040807733e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-f0e4d622-8980-4cd0-932f-7c2b99e1c18b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972374152-172.17.0.12-1595864274707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40468,DS-24267678-425f-44e9-8375-701873e9fac6,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-bd84954d-575c-4d07-929d-04ab728a3acb,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-602d373e-c087-46dc-826f-2343c7064bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-57a1217a-3097-456c-be53-a3ed9bda7f29,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-2a1ff63b-f856-4693-869f-5a243c89bed4,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-ae7babee-0e79-42ad-bd18-e55684272aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-73c3d298-b1e0-423b-bdbc-040807733e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-f0e4d622-8980-4cd0-932f-7c2b99e1c18b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478160685-172.17.0.12-1595864472192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36919,DS-3e38e2df-51cf-4bf2-9ca6-3075bfdac485,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-9ad99233-128f-461e-9a2f-83a4c47cbc85,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-9878ac77-7656-42af-9021-52e23b1401a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-f28256fa-d445-4f8a-a20e-0351da1a7b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-85430521-66ec-4200-b464-6296721adf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-975286b0-5145-4334-824a-aedaf63e6806,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-33224f4f-86bc-495b-a99f-dcc11b19c95e,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-768b0c9c-4257-4097-b847-f9acb0b12c92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478160685-172.17.0.12-1595864472192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36919,DS-3e38e2df-51cf-4bf2-9ca6-3075bfdac485,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-9ad99233-128f-461e-9a2f-83a4c47cbc85,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-9878ac77-7656-42af-9021-52e23b1401a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-f28256fa-d445-4f8a-a20e-0351da1a7b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-85430521-66ec-4200-b464-6296721adf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-975286b0-5145-4334-824a-aedaf63e6806,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-33224f4f-86bc-495b-a99f-dcc11b19c95e,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-768b0c9c-4257-4097-b847-f9acb0b12c92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320797351-172.17.0.12-1595864509928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45521,DS-1ff929ed-9dc1-4607-8eb2-00e324d9ed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-1a19f2e3-f804-4f1d-b8ea-aac041251f53,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-e5c82725-2c61-47e8-8659-742bd0e0d869,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-37789d4a-82b7-4e54-9525-1ad9dedf237d,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-4f6e3435-82fa-492c-9c3f-fbb128390377,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-b3898c03-081f-4fdb-a22a-b289b9b728ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-d716bd03-fa66-431f-ac96-d6fc36acb047,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-f867f00d-4373-4e41-8057-4cf221274df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320797351-172.17.0.12-1595864509928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45521,DS-1ff929ed-9dc1-4607-8eb2-00e324d9ed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-1a19f2e3-f804-4f1d-b8ea-aac041251f53,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-e5c82725-2c61-47e8-8659-742bd0e0d869,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-37789d4a-82b7-4e54-9525-1ad9dedf237d,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-4f6e3435-82fa-492c-9c3f-fbb128390377,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-b3898c03-081f-4fdb-a22a-b289b9b728ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-d716bd03-fa66-431f-ac96-d6fc36acb047,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-f867f00d-4373-4e41-8057-4cf221274df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135509143-172.17.0.12-1595865038531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38501,DS-0a0f83d6-970a-47bd-986c-f11f64d1e349,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-bbfdd0c5-9eaf-4a7e-8afb-144a75c846ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-b1647bba-c6b1-43a6-8379-9df9dd537641,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-5a474b80-cd02-4759-b348-15c745bfcffa,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-a5d858c1-7e0e-4578-a40f-079c717b6692,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-7d0e147f-3ec4-4dfb-bed0-9d2a4f049379,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-06a938ff-2dd2-4869-91a5-1fa68dca624a,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-278a7cf0-72e9-404f-9699-b16764300105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1135509143-172.17.0.12-1595865038531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38501,DS-0a0f83d6-970a-47bd-986c-f11f64d1e349,DISK], DatanodeInfoWithStorage[127.0.0.1:36973,DS-bbfdd0c5-9eaf-4a7e-8afb-144a75c846ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-b1647bba-c6b1-43a6-8379-9df9dd537641,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-5a474b80-cd02-4759-b348-15c745bfcffa,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-a5d858c1-7e0e-4578-a40f-079c717b6692,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-7d0e147f-3ec4-4dfb-bed0-9d2a4f049379,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-06a938ff-2dd2-4869-91a5-1fa68dca624a,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-278a7cf0-72e9-404f-9699-b16764300105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176470458-172.17.0.12-1595865173195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37764,DS-274af4e3-1166-43ee-9496-b5cedb51e449,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-1ea9f01b-704f-445b-b795-d4b01d61ed3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-172140c4-e4f5-478b-a6aa-7a9ade646abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-0878c346-e322-4825-b779-9429a583dd85,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-5ed65330-ff88-4a07-9872-4b2d744e32af,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-7418fc8a-8b74-4d8a-88e4-791479c8862b,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-1ce28a4e-56db-48ff-9088-0d109be1741b,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-e6e0be08-be3a-492a-9d88-581f7544a388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176470458-172.17.0.12-1595865173195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37764,DS-274af4e3-1166-43ee-9496-b5cedb51e449,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-1ea9f01b-704f-445b-b795-d4b01d61ed3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-172140c4-e4f5-478b-a6aa-7a9ade646abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-0878c346-e322-4825-b779-9429a583dd85,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-5ed65330-ff88-4a07-9872-4b2d744e32af,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-7418fc8a-8b74-4d8a-88e4-791479c8862b,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-1ce28a4e-56db-48ff-9088-0d109be1741b,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-e6e0be08-be3a-492a-9d88-581f7544a388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224372567-172.17.0.12-1595865747282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45538,DS-89d7d20f-7c2d-4623-b9ef-aa42556f16ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-575a40c9-76bc-4b37-8642-111e66db93e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-f899b573-8661-469b-b607-0eeff788ea59,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-d3076e5c-c4fb-4a77-aa48-c6cff143d73d,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-fd580793-d0e9-43bf-b1cd-48622f4930df,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-8b389229-521e-4701-9995-75536eb2fba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-1d00d67d-b160-426c-8358-00d243b8c387,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-b2499c6d-c938-462e-a1dc-368c4a303fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224372567-172.17.0.12-1595865747282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45538,DS-89d7d20f-7c2d-4623-b9ef-aa42556f16ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-575a40c9-76bc-4b37-8642-111e66db93e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-f899b573-8661-469b-b607-0eeff788ea59,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-d3076e5c-c4fb-4a77-aa48-c6cff143d73d,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-fd580793-d0e9-43bf-b1cd-48622f4930df,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-8b389229-521e-4701-9995-75536eb2fba7,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-1d00d67d-b160-426c-8358-00d243b8c387,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-b2499c6d-c938-462e-a1dc-368c4a303fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058305442-172.17.0.12-1595866232584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43168,DS-1cc006f2-f975-4202-b3c0-4c77c4ccd3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-bc12fd71-3f9d-4711-8c00-cdddba8c3e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-e4c6887b-8595-410f-94d8-0ae608cd2592,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-13927dac-3204-4610-b382-d864e5de8305,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-86f265cf-797b-4825-815a-188aa0c3fa05,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-bce59814-d208-477e-ba68-630bc0a64cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-ae07c23f-a63d-488b-95c8-29a7913feffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-20e1daa6-24da-447b-99ff-af68cd4c7740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1058305442-172.17.0.12-1595866232584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43168,DS-1cc006f2-f975-4202-b3c0-4c77c4ccd3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-bc12fd71-3f9d-4711-8c00-cdddba8c3e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-e4c6887b-8595-410f-94d8-0ae608cd2592,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-13927dac-3204-4610-b382-d864e5de8305,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-86f265cf-797b-4825-815a-188aa0c3fa05,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-bce59814-d208-477e-ba68-630bc0a64cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-ae07c23f-a63d-488b-95c8-29a7913feffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-20e1daa6-24da-447b-99ff-af68cd4c7740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269350933-172.17.0.12-1595866437414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43703,DS-f7ff6f3d-387b-44c9-b0cd-82e7745c5004,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-1e17b738-fe1e-4029-8ee5-9b1f1cbfce0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-37c25add-068c-4ef7-b96f-83159086b066,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-fc2e73e1-8c32-473a-9db9-28bb1bbbe898,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-57a6ad59-e951-41cf-8137-af03fe76c44b,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-a88ad0b6-72b6-42f3-a9bc-3405fe7e2be2,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-2620c811-b9ad-4d09-baa5-e270673fc465,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-71a3cec6-54c2-466d-9623-3a027971040a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269350933-172.17.0.12-1595866437414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43703,DS-f7ff6f3d-387b-44c9-b0cd-82e7745c5004,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-1e17b738-fe1e-4029-8ee5-9b1f1cbfce0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-37c25add-068c-4ef7-b96f-83159086b066,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-fc2e73e1-8c32-473a-9db9-28bb1bbbe898,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-57a6ad59-e951-41cf-8137-af03fe76c44b,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-a88ad0b6-72b6-42f3-a9bc-3405fe7e2be2,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-2620c811-b9ad-4d09-baa5-e270673fc465,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-71a3cec6-54c2-466d-9623-3a027971040a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662599058-172.17.0.12-1595866995292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41023,DS-bb0418cd-4e6e-470e-9f5f-b3ae38ec8ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-be1eda89-99c9-42a4-8c47-da70451090ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-b15f5322-a6a7-4622-b003-bf56f47215ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-a1b894a2-08fc-4c7d-96f9-606b12fce784,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-b426c9bb-0c01-4773-a89d-cf1c2f6694d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-72e47da0-c596-4ba1-a3f0-11d17eeaaf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-35737135-11b5-417d-a9b8-72138a55e8de,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-fbda3e83-11f0-47ff-8b6a-e8990af1189d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662599058-172.17.0.12-1595866995292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41023,DS-bb0418cd-4e6e-470e-9f5f-b3ae38ec8ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-be1eda89-99c9-42a4-8c47-da70451090ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-b15f5322-a6a7-4622-b003-bf56f47215ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-a1b894a2-08fc-4c7d-96f9-606b12fce784,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-b426c9bb-0c01-4773-a89d-cf1c2f6694d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-72e47da0-c596-4ba1-a3f0-11d17eeaaf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-35737135-11b5-417d-a9b8-72138a55e8de,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-fbda3e83-11f0-47ff-8b6a-e8990af1189d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590613107-172.17.0.12-1595867291983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44814,DS-33118925-ea95-48de-905f-eb51d73d55bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-e077d784-cd51-4171-a4e9-ac32cc3cbeed,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-2bbf09fd-df7a-4f9a-9421-911956696f93,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-0d0e152e-aac8-428a-b9f0-48b796fe36c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-7db5b877-1f7a-4123-817f-62eb10bff287,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-04719c35-1880-49b9-a883-92f31a0fb17b,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-4876f48a-08b2-45d1-933d-355559e18770,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-e5031e39-a854-4812-b7c7-4938781aa3d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590613107-172.17.0.12-1595867291983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44814,DS-33118925-ea95-48de-905f-eb51d73d55bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-e077d784-cd51-4171-a4e9-ac32cc3cbeed,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-2bbf09fd-df7a-4f9a-9421-911956696f93,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-0d0e152e-aac8-428a-b9f0-48b796fe36c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-7db5b877-1f7a-4123-817f-62eb10bff287,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-04719c35-1880-49b9-a883-92f31a0fb17b,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-4876f48a-08b2-45d1-933d-355559e18770,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-e5031e39-a854-4812-b7c7-4938781aa3d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782918848-172.17.0.12-1595867726403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45649,DS-8453b0f9-577b-4463-a014-129639f2a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-26faa1f7-b0ed-46b2-89ad-8c9abd042f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-9aed42d9-9a69-492e-a494-ae9f041b282a,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-43a8edd9-0043-44a0-83aa-b630f8092e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-9a70cc63-db66-43d8-8cec-7cbcd9303abf,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-f3720fe2-3764-40d9-8fae-afc908f60f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-71e6b459-5075-46e5-889a-3a9adcf616db,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-98ad53ff-fb2a-4ac3-aaee-b0be1145702c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782918848-172.17.0.12-1595867726403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45649,DS-8453b0f9-577b-4463-a014-129639f2a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-26faa1f7-b0ed-46b2-89ad-8c9abd042f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-9aed42d9-9a69-492e-a494-ae9f041b282a,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-43a8edd9-0043-44a0-83aa-b630f8092e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-9a70cc63-db66-43d8-8cec-7cbcd9303abf,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-f3720fe2-3764-40d9-8fae-afc908f60f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-71e6b459-5075-46e5-889a-3a9adcf616db,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-98ad53ff-fb2a-4ac3-aaee-b0be1145702c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348081395-172.17.0.12-1595868062996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42205,DS-f55febe2-f29b-47b1-8c15-4ff1cc422c76,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-d2e567cb-7050-464c-b5fa-70b1fb3a9fab,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-1c561b0c-d2ab-4a14-8fa3-eee1076c292f,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-8f4481a9-33b4-49b4-bd1a-1356aea8c799,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-df6c6621-0193-4480-bb25-6b109aab7e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-190fd696-cc8c-44a4-8bfe-97c7be38fd73,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-8f085c82-20c3-48bb-8716-7c953f9c9f04,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-9ba12898-a500-437a-a70e-dab453eae79c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348081395-172.17.0.12-1595868062996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42205,DS-f55febe2-f29b-47b1-8c15-4ff1cc422c76,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-d2e567cb-7050-464c-b5fa-70b1fb3a9fab,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-1c561b0c-d2ab-4a14-8fa3-eee1076c292f,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-8f4481a9-33b4-49b4-bd1a-1356aea8c799,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-df6c6621-0193-4480-bb25-6b109aab7e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-190fd696-cc8c-44a4-8bfe-97c7be38fd73,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-8f085c82-20c3-48bb-8716-7c953f9c9f04,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-9ba12898-a500-437a-a70e-dab453eae79c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43492371-172.17.0.12-1595868105654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42653,DS-1a77b44d-c3f9-4384-bef4-b70aa5d23d22,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-14c0a352-bc84-4883-97e0-b326b05c4bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-22ad5c19-5191-4f47-bc84-b6a250b88c48,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-4e9a55e0-3467-4959-b385-783262c64ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-ffddc023-c915-4901-ae6e-3466d7de62da,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-5c697284-4bac-4bd9-beec-cd2c69516159,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-5ff6ffb7-8237-45fb-969f-6c6072d92006,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-c2e811e0-5972-47b8-8c77-f940903d6537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43492371-172.17.0.12-1595868105654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42653,DS-1a77b44d-c3f9-4384-bef4-b70aa5d23d22,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-14c0a352-bc84-4883-97e0-b326b05c4bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-22ad5c19-5191-4f47-bc84-b6a250b88c48,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-4e9a55e0-3467-4959-b385-783262c64ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-ffddc023-c915-4901-ae6e-3466d7de62da,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-5c697284-4bac-4bd9-beec-cd2c69516159,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-5ff6ffb7-8237-45fb-969f-6c6072d92006,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-c2e811e0-5972-47b8-8c77-f940903d6537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964820093-172.17.0.12-1595868589580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35601,DS-35d5f1e7-29a7-4af1-a91f-7b33df6e89d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-51688e38-6d1b-4aec-ab9f-52f30be99e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-a670a448-7157-4d5f-bbab-b7d7a8cf0db9,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-bb135e01-4645-47a8-a73f-ddb0b7fdbb25,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-c4c32ad4-8ac1-4e73-b037-09cb72be90ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-e455d09b-3572-49ae-ba5d-4498e2e4e7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-276eba81-e060-4315-aa48-faf902d5b95b,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-0c03851e-ee04-47f7-b5ba-025d767e7441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964820093-172.17.0.12-1595868589580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35601,DS-35d5f1e7-29a7-4af1-a91f-7b33df6e89d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-51688e38-6d1b-4aec-ab9f-52f30be99e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-a670a448-7157-4d5f-bbab-b7d7a8cf0db9,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-bb135e01-4645-47a8-a73f-ddb0b7fdbb25,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-c4c32ad4-8ac1-4e73-b037-09cb72be90ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-e455d09b-3572-49ae-ba5d-4498e2e4e7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-276eba81-e060-4315-aa48-faf902d5b95b,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-0c03851e-ee04-47f7-b5ba-025d767e7441,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800073257-172.17.0.12-1595868854497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37824,DS-9ca7ada9-c623-4b17-861b-687187732f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-6420512e-dbf4-44f9-a6d7-1941646efd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-8aac7ac7-08e8-448f-8759-e569cfda540c,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-7c58b744-c058-4254-8b46-2ffb3f2604d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-41eff41e-1447-49ed-b2a6-d5324f608c18,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-1db53a0b-b07c-4dd3-9024-00f129969f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-95fca470-7478-40b9-bf40-a330d9623df3,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-7d77cf1e-98f4-4991-81a1-ed1858796290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800073257-172.17.0.12-1595868854497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37824,DS-9ca7ada9-c623-4b17-861b-687187732f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-6420512e-dbf4-44f9-a6d7-1941646efd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-8aac7ac7-08e8-448f-8759-e569cfda540c,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-7c58b744-c058-4254-8b46-2ffb3f2604d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-41eff41e-1447-49ed-b2a6-d5324f608c18,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-1db53a0b-b07c-4dd3-9024-00f129969f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-95fca470-7478-40b9-bf40-a330d9623df3,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-7d77cf1e-98f4-4991-81a1-ed1858796290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063924119-172.17.0.12-1595869205394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44849,DS-01e213d8-83ff-42c4-afcb-1b86f5cd98a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-4daecd78-4794-4e20-befa-72280de85d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-55cb1af5-bb9c-4a51-a929-e4c60a388a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-1af38ec5-73a9-4a7d-9a7a-c70f64b3fa63,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-3b304e51-c4bf-4ed8-843e-b0dfc6ccd011,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-4d4e4350-a8bd-46cc-9eca-be1cef3b38ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-86aa14dd-a380-4a9f-b816-e43e7d09619a,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-79a88205-c630-45b5-b60b-ce2a02d85ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063924119-172.17.0.12-1595869205394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44849,DS-01e213d8-83ff-42c4-afcb-1b86f5cd98a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-4daecd78-4794-4e20-befa-72280de85d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-55cb1af5-bb9c-4a51-a929-e4c60a388a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-1af38ec5-73a9-4a7d-9a7a-c70f64b3fa63,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-3b304e51-c4bf-4ed8-843e-b0dfc6ccd011,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-4d4e4350-a8bd-46cc-9eca-be1cef3b38ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-86aa14dd-a380-4a9f-b816-e43e7d09619a,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-79a88205-c630-45b5-b60b-ce2a02d85ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203161724-172.17.0.12-1595869928079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36777,DS-06e9a522-f522-412d-8ba4-cad1ee1c5d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-3faa5f42-4393-4737-a973-17d8315317be,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-1d69711c-ba5b-4df4-ae3d-2f0a28da8ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-d05eac42-fbcc-4941-843c-eb1c4af498fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-b6e99977-fbfc-4a3c-8732-60bbc50b93cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-d70fb7d6-daf9-4c67-8ed2-8420fc3b30d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-15c3427f-429e-4da0-9648-1a55227acee2,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-6e0a1e9d-ded2-49a5-b1e0-d04d2f735a59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203161724-172.17.0.12-1595869928079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36777,DS-06e9a522-f522-412d-8ba4-cad1ee1c5d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-3faa5f42-4393-4737-a973-17d8315317be,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-1d69711c-ba5b-4df4-ae3d-2f0a28da8ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-d05eac42-fbcc-4941-843c-eb1c4af498fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-b6e99977-fbfc-4a3c-8732-60bbc50b93cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-d70fb7d6-daf9-4c67-8ed2-8420fc3b30d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-15c3427f-429e-4da0-9648-1a55227acee2,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-6e0a1e9d-ded2-49a5-b1e0-d04d2f735a59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329309472-172.17.0.12-1595870323451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36232,DS-acdbadea-7be7-49f2-aa39-e56f4bf664c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-a93fa1d3-bdb9-4544-90bf-ff614fea39fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-b9290859-ac90-48ce-be93-fa1d29291b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-c962732b-3395-449c-8821-8ed763153c87,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-b958fdec-3dbd-443c-b06c-f37760338af3,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-2d71f118-9f14-49b0-9f49-08dc42c41beb,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-0b442d64-efa6-4d29-bd29-37c3001aa68c,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-d30d9b48-64f2-42c1-964f-995ae540218f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329309472-172.17.0.12-1595870323451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36232,DS-acdbadea-7be7-49f2-aa39-e56f4bf664c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-a93fa1d3-bdb9-4544-90bf-ff614fea39fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-b9290859-ac90-48ce-be93-fa1d29291b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-c962732b-3395-449c-8821-8ed763153c87,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-b958fdec-3dbd-443c-b06c-f37760338af3,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-2d71f118-9f14-49b0-9f49-08dc42c41beb,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-0b442d64-efa6-4d29-bd29-37c3001aa68c,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-d30d9b48-64f2-42c1-964f-995ae540218f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752115737-172.17.0.12-1595870506787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39801,DS-0e733f0f-c27e-41be-8409-298c7a72e972,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-9aca104e-5d8e-4ebf-b0dc-75410df66f98,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-e2219fd4-c949-43e3-980a-f69c5da86986,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-1a53a050-257e-4d61-975b-3096c51ae2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-d0cbca9f-d8cf-4c5a-9453-b85bd30ef724,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-ae878edc-43ce-411f-a16b-65bf277e927c,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-4fede99e-b5d2-48d5-a69d-9d4675ae9a96,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-89bd07ac-d22e-494e-9afe-949601adf3ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752115737-172.17.0.12-1595870506787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39801,DS-0e733f0f-c27e-41be-8409-298c7a72e972,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-9aca104e-5d8e-4ebf-b0dc-75410df66f98,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-e2219fd4-c949-43e3-980a-f69c5da86986,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-1a53a050-257e-4d61-975b-3096c51ae2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-d0cbca9f-d8cf-4c5a-9453-b85bd30ef724,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-ae878edc-43ce-411f-a16b-65bf277e927c,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-4fede99e-b5d2-48d5-a69d-9d4675ae9a96,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-89bd07ac-d22e-494e-9afe-949601adf3ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.max.block.acquire.failures
component: hdfs:NameNode
v1: 3
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499290950-172.17.0.12-1595870683757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35664,DS-851726b4-ec14-42b7-9657-bf3ad16a2bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-3b133ded-4764-424a-85e8-6a6574b3e8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-f2d83978-4961-4d35-9118-9162228a0053,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-f04f31f4-3b25-4bf9-89e6-1e0073425d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-031a2fe7-5137-4612-86b2-d4e06f36b15c,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-3e0e1232-6a5d-436a-8cbc-b9adf2ccbdff,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-d0498504-7371-49cb-9b25-5af92e537d02,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-c83e1f7e-bd58-451f-9421-03e0b5c46978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499290950-172.17.0.12-1595870683757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35664,DS-851726b4-ec14-42b7-9657-bf3ad16a2bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-3b133ded-4764-424a-85e8-6a6574b3e8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-f2d83978-4961-4d35-9118-9162228a0053,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-f04f31f4-3b25-4bf9-89e6-1e0073425d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-031a2fe7-5137-4612-86b2-d4e06f36b15c,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-3e0e1232-6a5d-436a-8cbc-b9adf2ccbdff,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-d0498504-7371-49cb-9b25-5af92e537d02,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-c83e1f7e-bd58-451f-9421-03e0b5c46978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6599
