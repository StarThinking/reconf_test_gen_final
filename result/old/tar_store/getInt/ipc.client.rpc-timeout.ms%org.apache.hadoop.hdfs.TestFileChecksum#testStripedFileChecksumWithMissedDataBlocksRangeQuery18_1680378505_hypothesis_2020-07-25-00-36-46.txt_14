reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380556844-172.17.0.4-1595638360072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38621,DS-2a5a7fdc-8c3e-436c-8be0-c6e622c30543,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-632916df-9df5-43cf-baa6-08ef6f47861c,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-5ed49333-3c1c-4505-9393-d166d619029c,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-c7c4e9bd-c50d-4f4b-9496-366823ed2084,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-76d43db4-77fd-42e2-8dee-7d12d4384dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-b6bfc3d4-f6df-4991-8271-470b5753adda,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-5d10180e-c097-41fa-97fc-405ed3f7ff39,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-b41dbae8-d7d9-44ba-a44a-ce1e71bc05d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380556844-172.17.0.4-1595638360072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38621,DS-2a5a7fdc-8c3e-436c-8be0-c6e622c30543,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-632916df-9df5-43cf-baa6-08ef6f47861c,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-5ed49333-3c1c-4505-9393-d166d619029c,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-c7c4e9bd-c50d-4f4b-9496-366823ed2084,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-76d43db4-77fd-42e2-8dee-7d12d4384dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-b6bfc3d4-f6df-4991-8271-470b5753adda,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-5d10180e-c097-41fa-97fc-405ed3f7ff39,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-b41dbae8-d7d9-44ba-a44a-ce1e71bc05d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574241894-172.17.0.4-1595639511380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46716,DS-c3cc5e27-24c5-405e-b1a8-ac67ea247dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-22ca818f-619c-421f-9c53-9f70e9fbb62f,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-93dab4d5-d27d-461f-996c-739a7e2f4254,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-dcd9d74d-b69a-4c80-9a93-66be8ec09391,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-b108340c-aa6e-4383-9a23-6ec6831d67a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-0f9496a5-0746-4578-b60c-f1772f2c2879,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-69f5f5ad-020e-4618-8793-629687f8668a,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-b5adf04f-fbd3-41cd-9ca9-ec0d8c9e5448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574241894-172.17.0.4-1595639511380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46716,DS-c3cc5e27-24c5-405e-b1a8-ac67ea247dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-22ca818f-619c-421f-9c53-9f70e9fbb62f,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-93dab4d5-d27d-461f-996c-739a7e2f4254,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-dcd9d74d-b69a-4c80-9a93-66be8ec09391,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-b108340c-aa6e-4383-9a23-6ec6831d67a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-0f9496a5-0746-4578-b60c-f1772f2c2879,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-69f5f5ad-020e-4618-8793-629687f8668a,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-b5adf04f-fbd3-41cd-9ca9-ec0d8c9e5448,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1096834556-172.17.0.4-1595639759799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32801,DS-1e53eec6-5686-46fb-91d9-d7a5b1b45f97,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-dd4f6260-d79b-4959-8e09-d0351b0fda5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-7caa6cdb-5efd-432b-9727-accf3941f0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-771a97cf-a95f-4c46-8e68-58dc9151c6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-652ac69e-cce0-4391-81fa-c52290ede46f,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-fe34417a-f1b9-48e5-8ebe-abcaf6d76829,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-f59464d7-293e-415d-8f60-73141ab4b638,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-444eec79-60dc-4b2b-8dc1-7ee1c86f0b1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1096834556-172.17.0.4-1595639759799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32801,DS-1e53eec6-5686-46fb-91d9-d7a5b1b45f97,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-dd4f6260-d79b-4959-8e09-d0351b0fda5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-7caa6cdb-5efd-432b-9727-accf3941f0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-771a97cf-a95f-4c46-8e68-58dc9151c6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-652ac69e-cce0-4391-81fa-c52290ede46f,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-fe34417a-f1b9-48e5-8ebe-abcaf6d76829,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-f59464d7-293e-415d-8f60-73141ab4b638,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-444eec79-60dc-4b2b-8dc1-7ee1c86f0b1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054572414-172.17.0.4-1595640590297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-d95f3863-d486-4e0c-9ea9-c189f1265fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-85a91222-ef7e-4dd5-9d4f-ed9830b22b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-aa8bfb96-e36b-4e93-b521-cdb36b3c94e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-07c3ddfa-d25d-46ab-a147-d4f17a6f50c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-ba13ec2b-bcc4-4373-8489-d673a1a20366,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-85c116a6-ca4a-46bd-9ba8-25eb58e3d934,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-475bf04a-e09c-4b8a-8ff6-9ffe9dfcac92,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-ed143b29-dd14-428e-9394-506e490362b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054572414-172.17.0.4-1595640590297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-d95f3863-d486-4e0c-9ea9-c189f1265fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-85a91222-ef7e-4dd5-9d4f-ed9830b22b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-aa8bfb96-e36b-4e93-b521-cdb36b3c94e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-07c3ddfa-d25d-46ab-a147-d4f17a6f50c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-ba13ec2b-bcc4-4373-8489-d673a1a20366,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-85c116a6-ca4a-46bd-9ba8-25eb58e3d934,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-475bf04a-e09c-4b8a-8ff6-9ffe9dfcac92,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-ed143b29-dd14-428e-9394-506e490362b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812765145-172.17.0.4-1595640960641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46224,DS-7b958875-64ba-401f-b207-64dd911902eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-776fc0e5-cb65-4352-84d0-4faa74acbcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-919d04c4-120c-4e99-b92c-1e4351b11ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-4d986f19-05f4-481d-ae3f-3a6b179edc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-4e05af55-f62b-46b3-9174-c891abc27a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-55989ae4-a906-46ab-a96f-b62fd6f78f04,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-cc5e86d6-63ec-4663-b264-15d5648c3ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-f0a1e800-4549-4b8b-aa33-09dddea3c7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812765145-172.17.0.4-1595640960641:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46224,DS-7b958875-64ba-401f-b207-64dd911902eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-776fc0e5-cb65-4352-84d0-4faa74acbcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-919d04c4-120c-4e99-b92c-1e4351b11ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-4d986f19-05f4-481d-ae3f-3a6b179edc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-4e05af55-f62b-46b3-9174-c891abc27a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-55989ae4-a906-46ab-a96f-b62fd6f78f04,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-cc5e86d6-63ec-4663-b264-15d5648c3ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-f0a1e800-4549-4b8b-aa33-09dddea3c7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830953997-172.17.0.4-1595641237083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41852,DS-2250f328-af2a-4591-8cad-337922672a28,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-bc3eae56-9a6c-4774-8a89-1bdbb16cf4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-f4e411d1-3558-430b-96ef-0e1b5862af69,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-c17fd954-d766-4665-935e-095ad630c437,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-cb3289a1-2a6b-431d-b9b8-d927568d56af,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-0854fbef-e6f6-4690-b6bf-20e37433c9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-f899bfdd-19da-42d0-be4e-31a324917eea,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-fc2bd864-2e00-4682-9f1b-c167c9273283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830953997-172.17.0.4-1595641237083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41852,DS-2250f328-af2a-4591-8cad-337922672a28,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-bc3eae56-9a6c-4774-8a89-1bdbb16cf4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-f4e411d1-3558-430b-96ef-0e1b5862af69,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-c17fd954-d766-4665-935e-095ad630c437,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-cb3289a1-2a6b-431d-b9b8-d927568d56af,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-0854fbef-e6f6-4690-b6bf-20e37433c9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-f899bfdd-19da-42d0-be4e-31a324917eea,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-fc2bd864-2e00-4682-9f1b-c167c9273283,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-482868031-172.17.0.4-1595641267725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41486,DS-cc7d4b2c-5cb3-4193-a978-a28285695f15,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-34fc7f83-6a67-42cf-94f4-e7ab2c49ad13,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-c9d75461-c342-4a32-ad0c-5579e0e550a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-830ecc82-86ee-4d0c-a108-34463a888112,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-7bc564a8-6e83-47c7-830c-61b587163f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-c43f61e6-2949-409c-9b1b-eabb43acd9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-9bbc431c-bfe3-4e87-a272-35834bdeadca,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-9d4e219a-925a-491a-a87c-8d20153a590c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-482868031-172.17.0.4-1595641267725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41486,DS-cc7d4b2c-5cb3-4193-a978-a28285695f15,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-34fc7f83-6a67-42cf-94f4-e7ab2c49ad13,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-c9d75461-c342-4a32-ad0c-5579e0e550a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-830ecc82-86ee-4d0c-a108-34463a888112,DISK], DatanodeInfoWithStorage[127.0.0.1:37074,DS-7bc564a8-6e83-47c7-830c-61b587163f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-c43f61e6-2949-409c-9b1b-eabb43acd9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-9bbc431c-bfe3-4e87-a272-35834bdeadca,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-9d4e219a-925a-491a-a87c-8d20153a590c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-779513543-172.17.0.4-1595641456420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44880,DS-46fd0e9f-968e-4725-a983-075ed151f34d,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-78359f78-f15a-4b52-9228-d449a92cec49,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-a84d2a8d-8f5e-489b-bb01-ccedce3e8401,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-a8172768-4a5c-4dc3-a602-7d00dcb22789,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-c2daf645-59b3-4adf-8af2-a4ab9328c782,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-ee4b4c1a-01f1-4f30-97c8-55f8950ab78e,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-583689c9-ef71-4b59-a29b-b12c8e12fa05,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-5c8e5d26-5a9d-4379-9995-b04b3a808124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-779513543-172.17.0.4-1595641456420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44880,DS-46fd0e9f-968e-4725-a983-075ed151f34d,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-78359f78-f15a-4b52-9228-d449a92cec49,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-a84d2a8d-8f5e-489b-bb01-ccedce3e8401,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-a8172768-4a5c-4dc3-a602-7d00dcb22789,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-c2daf645-59b3-4adf-8af2-a4ab9328c782,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-ee4b4c1a-01f1-4f30-97c8-55f8950ab78e,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-583689c9-ef71-4b59-a29b-b12c8e12fa05,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-5c8e5d26-5a9d-4379-9995-b04b3a808124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133753509-172.17.0.4-1595641685708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36447,DS-ff7f3105-a5ac-430c-916f-f0ef8ae0039d,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-282167e6-465f-4c2c-89e1-4bc62cce7e10,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-633657a4-3247-477e-88e4-c7f2ba6383dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-6a5ab118-707b-4863-ab13-60fe5be39c13,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-30cb45b2-ecb4-4201-9490-714fd0630202,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-2688a8dc-8e7a-40e5-85de-268cf9076845,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-2c884527-8b05-4627-8a4f-6b865233b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-6884a642-55f8-4cc8-92c7-4f9d7b872cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133753509-172.17.0.4-1595641685708:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36447,DS-ff7f3105-a5ac-430c-916f-f0ef8ae0039d,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-282167e6-465f-4c2c-89e1-4bc62cce7e10,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-633657a4-3247-477e-88e4-c7f2ba6383dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-6a5ab118-707b-4863-ab13-60fe5be39c13,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-30cb45b2-ecb4-4201-9490-714fd0630202,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-2688a8dc-8e7a-40e5-85de-268cf9076845,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-2c884527-8b05-4627-8a4f-6b865233b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-6884a642-55f8-4cc8-92c7-4f9d7b872cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131386168-172.17.0.4-1595641720852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-fd598417-efb3-4bd3-a5f6-903743042d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-1f9453c6-706d-4af0-a61d-0b42212859e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-100fe877-9ba9-4d14-bd7a-29696bacbf52,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-3a739a01-af8e-43c9-a071-2f079dd81d15,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-1391c99a-81ed-4985-a1be-5ac00d12a771,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-a4d425c9-796c-4ad7-ba22-62c2cfbc2e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-342cf238-be39-4374-94f0-c52c0f24fc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-a7937a69-9a19-474e-9233-224a5c173765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131386168-172.17.0.4-1595641720852:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-fd598417-efb3-4bd3-a5f6-903743042d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-1f9453c6-706d-4af0-a61d-0b42212859e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-100fe877-9ba9-4d14-bd7a-29696bacbf52,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-3a739a01-af8e-43c9-a071-2f079dd81d15,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-1391c99a-81ed-4985-a1be-5ac00d12a771,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-a4d425c9-796c-4ad7-ba22-62c2cfbc2e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-342cf238-be39-4374-94f0-c52c0f24fc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-a7937a69-9a19-474e-9233-224a5c173765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469067677-172.17.0.4-1595642125554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43383,DS-213a0018-e624-40b9-a27a-7580d39f6b94,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-cce97221-d16d-415d-8a34-c3e2e5abc3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-1ed68750-d0b2-4950-af8f-77562190b84c,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-31237c0c-977b-4e4e-940f-d1590f78ea01,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-e51b7c9d-4fe8-4fb7-b052-30a800fd5e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-786d7e86-b8af-451d-a5df-4ca70eed0e23,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-857250a9-c178-441a-bcd3-e35791af95f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-2e5a493c-4712-45e7-a577-d50c7e7658d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469067677-172.17.0.4-1595642125554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43383,DS-213a0018-e624-40b9-a27a-7580d39f6b94,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-cce97221-d16d-415d-8a34-c3e2e5abc3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-1ed68750-d0b2-4950-af8f-77562190b84c,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-31237c0c-977b-4e4e-940f-d1590f78ea01,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-e51b7c9d-4fe8-4fb7-b052-30a800fd5e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-786d7e86-b8af-451d-a5df-4ca70eed0e23,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-857250a9-c178-441a-bcd3-e35791af95f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-2e5a493c-4712-45e7-a577-d50c7e7658d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 0
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632655503-172.17.0.4-1595642355158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44866,DS-f66563b6-79ab-4756-95aa-3df102f381c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-bbe979e4-b77d-4faa-8d61-8dd3c03b7240,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-4337f863-c71b-404d-bd54-88b10ea120ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-dae4e07e-6a91-460d-a0cd-f4d67c07d80e,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-efa08fa8-a22d-4784-8fba-6fc3a23b4da7,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-31a8edb2-80d0-495b-9f3a-99034102ef82,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-40d6e068-c5fa-45a5-8e21-0db1d57096fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-4074318e-ebbe-4848-ad8a-6ea6184e8c04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1632655503-172.17.0.4-1595642355158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44866,DS-f66563b6-79ab-4756-95aa-3df102f381c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-bbe979e4-b77d-4faa-8d61-8dd3c03b7240,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-4337f863-c71b-404d-bd54-88b10ea120ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-dae4e07e-6a91-460d-a0cd-f4d67c07d80e,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-efa08fa8-a22d-4784-8fba-6fc3a23b4da7,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-31a8edb2-80d0-495b-9f3a-99034102ef82,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-40d6e068-c5fa-45a5-8e21-0db1d57096fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-4074318e-ebbe-4848-ad8a-6ea6184e8c04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5085
