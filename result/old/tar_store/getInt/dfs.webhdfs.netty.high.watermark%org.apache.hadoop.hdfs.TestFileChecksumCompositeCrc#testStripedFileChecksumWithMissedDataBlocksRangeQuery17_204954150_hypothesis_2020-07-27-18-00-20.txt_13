reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003218150-172.17.0.20-1595872992853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42395,DS-e4a2d7e1-e1d7-48a1-8c10-dda1b3d69c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-99456ff3-1dea-4721-9aaa-6737ee85a143,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-c743d241-164a-4174-9614-390b3177bfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-ed02debe-552f-40d4-af45-b06b6445a0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-ea7e773f-8e60-4392-b7d1-00726de6c858,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-84fba2bc-9098-4cd7-a183-9fb6d2a8e73f,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-82fa5d8c-a200-4584-815d-eba0829fbb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-c3a44bd2-e94e-43fa-aa7d-4a79257e88ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003218150-172.17.0.20-1595872992853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42395,DS-e4a2d7e1-e1d7-48a1-8c10-dda1b3d69c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-99456ff3-1dea-4721-9aaa-6737ee85a143,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-c743d241-164a-4174-9614-390b3177bfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-ed02debe-552f-40d4-af45-b06b6445a0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-ea7e773f-8e60-4392-b7d1-00726de6c858,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-84fba2bc-9098-4cd7-a183-9fb6d2a8e73f,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-82fa5d8c-a200-4584-815d-eba0829fbb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-c3a44bd2-e94e-43fa-aa7d-4a79257e88ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373140419-172.17.0.20-1595873396550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43203,DS-cfc5caff-5442-40c6-8b33-5388e5f938e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-f1869687-d984-4ac8-98fe-8fd2243f2528,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-9a146cae-805d-4c44-90fb-5b0bf00767fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-6316805d-aade-4493-8068-5ef2611399e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-08ba484a-1dc0-49c6-af61-9733f799c821,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-fede6921-fed3-4418-a369-a778a46c7bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-9a80b8f1-fb87-45a3-977b-c6ab0b4a5c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-af476bf3-8d6e-44ff-96c4-e14c204d595d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-373140419-172.17.0.20-1595873396550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43203,DS-cfc5caff-5442-40c6-8b33-5388e5f938e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-f1869687-d984-4ac8-98fe-8fd2243f2528,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-9a146cae-805d-4c44-90fb-5b0bf00767fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-6316805d-aade-4493-8068-5ef2611399e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-08ba484a-1dc0-49c6-af61-9733f799c821,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-fede6921-fed3-4418-a369-a778a46c7bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-9a80b8f1-fb87-45a3-977b-c6ab0b4a5c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-af476bf3-8d6e-44ff-96c4-e14c204d595d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449216522-172.17.0.20-1595873437356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33108,DS-f9f6d3dc-558f-4b1f-b687-c73693b98ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-42f90cc2-78cd-4214-9fb1-40410250b7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-16dd6d8d-dcf5-46c7-a0c7-50de5e45e738,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-ab5c4bcf-d152-44c9-a768-223334e5f2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-59fff66e-887f-49ec-a7a9-2f82689c1dda,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-f270ca2e-3a1f-4177-8bbf-3e1e48f73b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-7f7100fa-6133-4aa8-aaa1-f7336f035c01,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-b3b252d5-239b-44ad-9a8d-6f6c970ea6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449216522-172.17.0.20-1595873437356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33108,DS-f9f6d3dc-558f-4b1f-b687-c73693b98ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-42f90cc2-78cd-4214-9fb1-40410250b7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-16dd6d8d-dcf5-46c7-a0c7-50de5e45e738,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-ab5c4bcf-d152-44c9-a768-223334e5f2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-59fff66e-887f-49ec-a7a9-2f82689c1dda,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-f270ca2e-3a1f-4177-8bbf-3e1e48f73b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-7f7100fa-6133-4aa8-aaa1-f7336f035c01,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-b3b252d5-239b-44ad-9a8d-6f6c970ea6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907417448-172.17.0.20-1595873569462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33329,DS-6470a4bc-6698-48b4-9db3-b95c9da5f241,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-bf54c713-5889-495f-b547-4b9f92ae1caf,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-b32a06a5-9f31-4730-be7f-a4d4848cce31,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-28ff9f5e-9535-468b-83f9-997735895df0,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-58d82747-5d83-4ea3-bb28-4684febeeb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-3618624f-c2f1-4602-905e-c7a61660fcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-468c07e5-e6f7-40b8-9da3-2347f2c8771c,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-83fff3a3-340f-478a-8750-55e059366bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907417448-172.17.0.20-1595873569462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33329,DS-6470a4bc-6698-48b4-9db3-b95c9da5f241,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-bf54c713-5889-495f-b547-4b9f92ae1caf,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-b32a06a5-9f31-4730-be7f-a4d4848cce31,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-28ff9f5e-9535-468b-83f9-997735895df0,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-58d82747-5d83-4ea3-bb28-4684febeeb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-3618624f-c2f1-4602-905e-c7a61660fcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-468c07e5-e6f7-40b8-9da3-2347f2c8771c,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-83fff3a3-340f-478a-8750-55e059366bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624868420-172.17.0.20-1595873902979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36735,DS-7141f750-b38e-49a4-887e-54665be45980,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-a6316b93-e722-4f9e-9bc1-63b441358517,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-29c8cac2-c2b6-4d97-a495-d862b6c36980,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-43512f65-9bbe-4221-858b-7c863f0655e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-f2fef0d5-28ab-4137-aee5-fef4c14da6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-246717e8-1a44-4d00-beaa-c3959bd1391a,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-52bcafd7-22d9-4929-8d9a-d66f30bf295f,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-9fd7db2a-3f24-40b3-9daa-5b74abc21c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624868420-172.17.0.20-1595873902979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36735,DS-7141f750-b38e-49a4-887e-54665be45980,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-a6316b93-e722-4f9e-9bc1-63b441358517,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-29c8cac2-c2b6-4d97-a495-d862b6c36980,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-43512f65-9bbe-4221-858b-7c863f0655e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-f2fef0d5-28ab-4137-aee5-fef4c14da6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-246717e8-1a44-4d00-beaa-c3959bd1391a,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-52bcafd7-22d9-4929-8d9a-d66f30bf295f,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-9fd7db2a-3f24-40b3-9daa-5b74abc21c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238944862-172.17.0.20-1595874225864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46748,DS-d679a870-99e5-49fa-b87f-4f53409c18ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-71d847c3-578a-49d6-93ad-ae7d06e05339,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-e8530c02-1616-410a-a26f-6f15657c4711,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-f0744f97-77e2-4d83-8919-5506e4cdc7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-911042dc-20b7-4367-a832-24498edff2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-63e262d3-f456-4605-ab75-da72ecbc3ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-1011600a-7140-493d-b635-295f10b9cadb,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-c1208d68-9dd3-4f7d-b797-2ee34b367b99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238944862-172.17.0.20-1595874225864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46748,DS-d679a870-99e5-49fa-b87f-4f53409c18ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-71d847c3-578a-49d6-93ad-ae7d06e05339,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-e8530c02-1616-410a-a26f-6f15657c4711,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-f0744f97-77e2-4d83-8919-5506e4cdc7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-911042dc-20b7-4367-a832-24498edff2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-63e262d3-f456-4605-ab75-da72ecbc3ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-1011600a-7140-493d-b635-295f10b9cadb,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-c1208d68-9dd3-4f7d-b797-2ee34b367b99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311084109-172.17.0.20-1595874497618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42130,DS-65fa54e7-ab7a-4625-881f-241dd8f7bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-7d5c665a-c614-4919-aaa2-a7cbbde165a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-7d67638e-3726-43b7-993e-02962866b199,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-4416e24e-fcc0-43a1-b9da-23d9c9ebaeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-d2f53f4e-6209-4945-b028-32c849341be5,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-f8cdcbd5-2191-4efa-8b6f-e786d212beea,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-f94b27aa-e6f6-410c-9cba-77d731dcdead,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-10aa624b-fa4c-42cb-b413-18b5ab7bca62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311084109-172.17.0.20-1595874497618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42130,DS-65fa54e7-ab7a-4625-881f-241dd8f7bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-7d5c665a-c614-4919-aaa2-a7cbbde165a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-7d67638e-3726-43b7-993e-02962866b199,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-4416e24e-fcc0-43a1-b9da-23d9c9ebaeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-d2f53f4e-6209-4945-b028-32c849341be5,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-f8cdcbd5-2191-4efa-8b6f-e786d212beea,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-f94b27aa-e6f6-410c-9cba-77d731dcdead,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-10aa624b-fa4c-42cb-b413-18b5ab7bca62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404176277-172.17.0.20-1595874574370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37693,DS-2e325477-cd67-4a7b-981f-b774cc071e31,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-a4b38346-09e2-440e-9592-1a66a6963fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-ef632af1-6a4d-4ec3-b7bb-7f591f847c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-98d1685e-c630-4073-afd4-5f93b1249611,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-8265c91d-cf44-47b0-a2e8-f1d81d522bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-9735d54e-3d1d-47a5-8c08-f53738b6a784,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-d978e275-ed02-45af-9537-8e89348b39d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-cc16f1d0-321b-47d1-8831-54843bc769d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404176277-172.17.0.20-1595874574370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37693,DS-2e325477-cd67-4a7b-981f-b774cc071e31,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-a4b38346-09e2-440e-9592-1a66a6963fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-ef632af1-6a4d-4ec3-b7bb-7f591f847c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-98d1685e-c630-4073-afd4-5f93b1249611,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-8265c91d-cf44-47b0-a2e8-f1d81d522bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-9735d54e-3d1d-47a5-8c08-f53738b6a784,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-d978e275-ed02-45af-9537-8e89348b39d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-cc16f1d0-321b-47d1-8831-54843bc769d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048086990-172.17.0.20-1595874966007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39336,DS-872e7431-80e2-4d3d-b113-bac05553cf46,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-8f35b250-058a-406f-98b5-08c91e68cbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-9930286e-c9c0-4c08-83d1-be50dc8ac126,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-0dd8cf2d-f86d-4dcf-9bf2-67941c6c67c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-5748d3e5-66ea-4521-ac89-a3a3477c7412,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-24a12c67-1c12-42b4-a144-795b5354cfea,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-7d934621-20fb-4c07-a31d-0efab2f30572,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-236914fb-52dd-40da-b36e-bdf492a4a4f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048086990-172.17.0.20-1595874966007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39336,DS-872e7431-80e2-4d3d-b113-bac05553cf46,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-8f35b250-058a-406f-98b5-08c91e68cbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-9930286e-c9c0-4c08-83d1-be50dc8ac126,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-0dd8cf2d-f86d-4dcf-9bf2-67941c6c67c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-5748d3e5-66ea-4521-ac89-a3a3477c7412,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-24a12c67-1c12-42b4-a144-795b5354cfea,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-7d934621-20fb-4c07-a31d-0efab2f30572,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-236914fb-52dd-40da-b36e-bdf492a4a4f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441613300-172.17.0.20-1595875011089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-c3eaf9d8-5ce9-4592-89a4-4259eae9da8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-f7f92b8c-cb42-4df6-b2b3-bcb7e6c33a07,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-d29f4696-075e-4dce-8bed-bd518c68908c,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-282383f7-ef69-40c7-a09f-fcb59181cf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-b26dc12f-e46a-47c2-a430-b1eebdf873a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-aee4bfcd-735e-4a29-b8ef-b721a423f145,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-140885ac-a7b3-4577-a86a-2008699a36b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-ed600986-0a5c-44a7-b176-3ce379dfa230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441613300-172.17.0.20-1595875011089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-c3eaf9d8-5ce9-4592-89a4-4259eae9da8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-f7f92b8c-cb42-4df6-b2b3-bcb7e6c33a07,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-d29f4696-075e-4dce-8bed-bd518c68908c,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-282383f7-ef69-40c7-a09f-fcb59181cf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-b26dc12f-e46a-47c2-a430-b1eebdf873a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-aee4bfcd-735e-4a29-b8ef-b721a423f145,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-140885ac-a7b3-4577-a86a-2008699a36b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-ed600986-0a5c-44a7-b176-3ce379dfa230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038949300-172.17.0.20-1595875095805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45471,DS-464eafd5-d871-4782-aa98-53550061ee00,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-98c4ef2e-b870-4c68-a50c-2fb5c6ac28d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-79574c16-7790-4023-aa4c-45cda836ce9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-298ee53d-41b5-43d6-abd8-6e0a265f8057,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-691c2e7a-1fd2-4e2d-8c38-f1351b1e4f74,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-69df9071-fb54-41e7-be06-0483f654b9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-ef40348f-1cdb-45fa-96b7-0d3d1380c0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-ed983630-ac0c-4372-b63f-976ebd4aa8d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038949300-172.17.0.20-1595875095805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45471,DS-464eafd5-d871-4782-aa98-53550061ee00,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-98c4ef2e-b870-4c68-a50c-2fb5c6ac28d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-79574c16-7790-4023-aa4c-45cda836ce9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-298ee53d-41b5-43d6-abd8-6e0a265f8057,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-691c2e7a-1fd2-4e2d-8c38-f1351b1e4f74,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-69df9071-fb54-41e7-be06-0483f654b9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-ef40348f-1cdb-45fa-96b7-0d3d1380c0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-ed983630-ac0c-4372-b63f-976ebd4aa8d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498572537-172.17.0.20-1595875780810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41078,DS-df1602cc-d606-4170-b29e-44f7b729e32b,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-113259b6-58bc-4d1e-b5bd-5afb1892e926,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-556579ba-dbdf-4d38-a15f-f3f3d747dfef,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-2c7452e8-cf09-4b10-904c-1fa532d16ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-4b0fcd46-139a-4a32-9bd3-76907dbff873,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-a587746a-31fa-459d-ab6d-19b9bb71cd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-3c8ec998-94af-41a2-bd53-547147acaee2,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-87a65cc2-ae4a-4548-9a88-be3f2a01dbcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-498572537-172.17.0.20-1595875780810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41078,DS-df1602cc-d606-4170-b29e-44f7b729e32b,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-113259b6-58bc-4d1e-b5bd-5afb1892e926,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-556579ba-dbdf-4d38-a15f-f3f3d747dfef,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-2c7452e8-cf09-4b10-904c-1fa532d16ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-4b0fcd46-139a-4a32-9bd3-76907dbff873,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-a587746a-31fa-459d-ab6d-19b9bb71cd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-3c8ec998-94af-41a2-bd53-547147acaee2,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-87a65cc2-ae4a-4548-9a88-be3f2a01dbcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839022856-172.17.0.20-1595875912864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37050,DS-65478d5e-8d8a-4ecb-ab16-06826804bbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-d83c1949-cf66-4ace-a4f6-49d4abd8523c,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-2be3d032-3a77-4336-b300-69d6f36b4f26,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-a95e23ad-7433-4013-ae81-c4c9a3efb508,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-084938dd-6ef1-49d7-8096-31d79dec95f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-36261168-154d-4fc2-96f8-90975c5dba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-d2842947-23d3-4ed0-8d2d-4d3f32262925,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-2929fc6d-9844-4c3d-8d16-5ec169f86677,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839022856-172.17.0.20-1595875912864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37050,DS-65478d5e-8d8a-4ecb-ab16-06826804bbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-d83c1949-cf66-4ace-a4f6-49d4abd8523c,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-2be3d032-3a77-4336-b300-69d6f36b4f26,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-a95e23ad-7433-4013-ae81-c4c9a3efb508,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-084938dd-6ef1-49d7-8096-31d79dec95f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-36261168-154d-4fc2-96f8-90975c5dba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-d2842947-23d3-4ed0-8d2d-4d3f32262925,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-2929fc6d-9844-4c3d-8d16-5ec169f86677,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956361926-172.17.0.20-1595876416255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46509,DS-86355fd2-4103-40d4-b193-36d4bcf8a0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-2a70c2a2-141a-4341-8fe6-4d93e4bcff45,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-3f7f1c4e-9b03-4484-874b-f7fad3dc37ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-760f00ff-bb75-4b5f-b691-51e6fa46eb94,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-9364ba87-8993-406e-89b3-b060c8735675,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-58dd486f-0f35-45c4-a6a8-ff3839513f45,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-1335ed8e-0303-4383-ab8d-3fe9beed14eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-445bfb63-9efb-437f-b6b2-6e92c6ba949d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956361926-172.17.0.20-1595876416255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46509,DS-86355fd2-4103-40d4-b193-36d4bcf8a0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-2a70c2a2-141a-4341-8fe6-4d93e4bcff45,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-3f7f1c4e-9b03-4484-874b-f7fad3dc37ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-760f00ff-bb75-4b5f-b691-51e6fa46eb94,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-9364ba87-8993-406e-89b3-b060c8735675,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-58dd486f-0f35-45c4-a6a8-ff3839513f45,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-1335ed8e-0303-4383-ab8d-3fe9beed14eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-445bfb63-9efb-437f-b6b2-6e92c6ba949d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391379215-172.17.0.20-1595876651846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33544,DS-e43a2fb3-4446-4bd1-8753-d07bffd68938,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-f933f014-540b-4dc7-b49b-ed4c2b22275e,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-d2c336e1-9690-4214-9058-6f53b6957602,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-93b06535-20ac-4b3c-8373-1104b7e508b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-88b74187-e19c-4f8a-8e37-dc463944c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-d0c36d06-be46-4e0a-95ef-917c5c028845,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-eef96bf6-7433-4a91-a9be-afed38aa8487,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-4626252a-c2f8-4fea-8783-5330e6bafc9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-391379215-172.17.0.20-1595876651846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33544,DS-e43a2fb3-4446-4bd1-8753-d07bffd68938,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-f933f014-540b-4dc7-b49b-ed4c2b22275e,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-d2c336e1-9690-4214-9058-6f53b6957602,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-93b06535-20ac-4b3c-8373-1104b7e508b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-88b74187-e19c-4f8a-8e37-dc463944c52f,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-d0c36d06-be46-4e0a-95ef-917c5c028845,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-eef96bf6-7433-4a91-a9be-afed38aa8487,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-4626252a-c2f8-4fea-8783-5330e6bafc9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621793423-172.17.0.20-1595876742514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36828,DS-cdae217d-63bc-4717-9e77-0563da3564b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-04d3e4ee-d7be-4412-a1ed-d173a90c4896,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-56cc2b33-9d61-4377-9a1a-180a2d56195f,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-4ee8dff0-aa40-4074-a6ae-d2a22e739c10,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-a7522021-930f-422b-9af2-555591c519ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-da3cf06e-3979-4365-896c-efa619705ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-0c85ac1a-6d0c-44b8-a597-d5385ef52754,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-42675bd2-7b52-4126-b4ab-aa13cc68dc9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621793423-172.17.0.20-1595876742514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36828,DS-cdae217d-63bc-4717-9e77-0563da3564b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-04d3e4ee-d7be-4412-a1ed-d173a90c4896,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-56cc2b33-9d61-4377-9a1a-180a2d56195f,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-4ee8dff0-aa40-4074-a6ae-d2a22e739c10,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-a7522021-930f-422b-9af2-555591c519ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-da3cf06e-3979-4365-896c-efa619705ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-0c85ac1a-6d0c-44b8-a597-d5385ef52754,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-42675bd2-7b52-4126-b4ab-aa13cc68dc9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188717989-172.17.0.20-1595877681374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34160,DS-9b4b21ff-92ee-425e-abfc-76540fbe6281,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-2c5abdd4-ee15-4677-aef0-fc65194700f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-aec20dcd-e94d-41bd-b05e-2df5f7531e56,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-270803ea-2c17-4143-8f35-3cb6691b2c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-bb00fac7-6a14-42fe-b2e4-790f305938e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-968f9542-4f32-4a10-8cc2-5b2116c9124e,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-2dcfd172-ff42-4c01-b2f2-e5010bbe56c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-0ae7c9eb-7167-4cc7-953d-48a78dec1aaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188717989-172.17.0.20-1595877681374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34160,DS-9b4b21ff-92ee-425e-abfc-76540fbe6281,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-2c5abdd4-ee15-4677-aef0-fc65194700f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-aec20dcd-e94d-41bd-b05e-2df5f7531e56,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-270803ea-2c17-4143-8f35-3cb6691b2c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-bb00fac7-6a14-42fe-b2e4-790f305938e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-968f9542-4f32-4a10-8cc2-5b2116c9124e,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-2dcfd172-ff42-4c01-b2f2-e5010bbe56c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-0ae7c9eb-7167-4cc7-953d-48a78dec1aaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311527952-172.17.0.20-1595878166847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-02384ba5-ff21-4639-a168-fd573673613d,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-4129c69a-395c-41e9-bbc7-49e6e1f3e2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-e0529bb1-11b5-4862-a1cf-cfc724c39b87,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-7bd185be-196d-48b1-abb9-7e909bd29fee,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-8b559048-b62a-4ac5-9700-73f645b40551,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-15ef7725-bfaf-4603-bc7d-6482242b0dda,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-159c9a1f-a9d6-4592-99c6-8c4c5c5d2812,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-da0d6a2a-2946-4b52-88da-10b372e8e468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-311527952-172.17.0.20-1595878166847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-02384ba5-ff21-4639-a168-fd573673613d,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-4129c69a-395c-41e9-bbc7-49e6e1f3e2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-e0529bb1-11b5-4862-a1cf-cfc724c39b87,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-7bd185be-196d-48b1-abb9-7e909bd29fee,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-8b559048-b62a-4ac5-9700-73f645b40551,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-15ef7725-bfaf-4603-bc7d-6482242b0dda,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-159c9a1f-a9d6-4592-99c6-8c4c5c5d2812,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-da0d6a2a-2946-4b52-88da-10b372e8e468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555465492-172.17.0.20-1595878213071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43190,DS-e64ed97a-50d8-437b-b4f6-877293a0adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-ccbd25ab-ad76-4351-ba8f-51ac88352113,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-0e74880c-450f-46b0-86ba-aa1be02cccf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-f6feb09e-848a-4f52-ba83-bf380262318c,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-3c3aceed-aac6-4883-a9fb-e8797e72cc56,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-3ea0d26d-3f21-4d78-8dad-c3d1a60da97b,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-f9bdcee0-ac0b-43ff-8284-f154bf6187d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-06b0a528-89fd-473b-8c35-286c6e06a862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555465492-172.17.0.20-1595878213071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43190,DS-e64ed97a-50d8-437b-b4f6-877293a0adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-ccbd25ab-ad76-4351-ba8f-51ac88352113,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-0e74880c-450f-46b0-86ba-aa1be02cccf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-f6feb09e-848a-4f52-ba83-bf380262318c,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-3c3aceed-aac6-4883-a9fb-e8797e72cc56,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-3ea0d26d-3f21-4d78-8dad-c3d1a60da97b,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-f9bdcee0-ac0b-43ff-8284-f154bf6187d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-06b0a528-89fd-473b-8c35-286c6e06a862,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156196599-172.17.0.20-1595878535005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38387,DS-62f68025-69e2-4326-ab7b-9e883e1fd9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-e37f0e65-7016-4040-b4bd-40a18f03a6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-12be811f-574e-42f0-9230-b894b4bbef80,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-bac5d578-10a0-4c66-9fb1-f884ea764646,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-a5356229-3d88-40b0-8791-9348195dfcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-edcad907-0ac9-4b19-8cc3-8a30192b13ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-583b0483-74cf-4faa-b027-1d713fd88e04,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-a09e4197-31af-490c-9bdb-940160613a70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156196599-172.17.0.20-1595878535005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38387,DS-62f68025-69e2-4326-ab7b-9e883e1fd9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-e37f0e65-7016-4040-b4bd-40a18f03a6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-12be811f-574e-42f0-9230-b894b4bbef80,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-bac5d578-10a0-4c66-9fb1-f884ea764646,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-a5356229-3d88-40b0-8791-9348195dfcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-edcad907-0ac9-4b19-8cc3-8a30192b13ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-583b0483-74cf-4faa-b027-1d713fd88e04,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-a09e4197-31af-490c-9bdb-940160613a70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208124251-172.17.0.20-1595878714937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40103,DS-19b64e6b-e7da-4355-9471-a706976a87a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-8ec7514d-6ef6-423f-8acc-5a6cf3fd3e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-c7f8ca1d-6da8-45c7-af77-fab2089dcfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-20117e1f-4cfa-4df8-821e-34e1b3da56b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-fb35b73a-056e-47f6-8350-732b2abde7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-8f4219a9-2a4d-4c1f-b645-96efed79f021,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-9cc87177-a7fa-4fe4-8faa-dad7f46f945b,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-32912fe8-8aa1-4188-a33c-eea436d45d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1208124251-172.17.0.20-1595878714937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40103,DS-19b64e6b-e7da-4355-9471-a706976a87a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-8ec7514d-6ef6-423f-8acc-5a6cf3fd3e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-c7f8ca1d-6da8-45c7-af77-fab2089dcfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35723,DS-20117e1f-4cfa-4df8-821e-34e1b3da56b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-fb35b73a-056e-47f6-8350-732b2abde7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-8f4219a9-2a4d-4c1f-b645-96efed79f021,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-9cc87177-a7fa-4fe4-8faa-dad7f46f945b,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-32912fe8-8aa1-4188-a33c-eea436d45d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028187117-172.17.0.20-1595878800815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44123,DS-3cfcfaa8-86a9-4050-a3c5-04235f936e18,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-4e2dce01-5a98-4c32-aa3f-61b0a68cc7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-0bb50324-3506-44ce-8a77-608af9464e42,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-b9ae1c8f-fd03-4f13-81cd-d0635f250223,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-fe63084f-fd3e-4e41-8b8d-40334efaed25,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-330f87c9-f8af-4ea9-8896-d02a24ddb94d,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-7d6c7341-d490-4d95-93f0-a1ea0d1278ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-4e2e04e2-a204-4fde-9c98-bdfaf8944350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1028187117-172.17.0.20-1595878800815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44123,DS-3cfcfaa8-86a9-4050-a3c5-04235f936e18,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-4e2dce01-5a98-4c32-aa3f-61b0a68cc7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-0bb50324-3506-44ce-8a77-608af9464e42,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-b9ae1c8f-fd03-4f13-81cd-d0635f250223,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-fe63084f-fd3e-4e41-8b8d-40334efaed25,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-330f87c9-f8af-4ea9-8896-d02a24ddb94d,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-7d6c7341-d490-4d95-93f0-a1ea0d1278ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-4e2e04e2-a204-4fde-9c98-bdfaf8944350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733487749-172.17.0.20-1595878988684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43564,DS-954d12e3-bf00-4511-9773-e9955449d80f,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-8fe6e03d-f300-4b6a-abfc-c43c21b23cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-2c268464-d63d-4916-9ca6-dfc835e718c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-1cffeeb7-b41a-4da0-8504-fd58b09215f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-2728dad8-4b20-4259-89a4-2b8f47dd3dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-bd66e2fe-f082-4af9-ac3c-c3961e95b2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-6238dc99-8f4b-497f-82b8-e4f2fe4ddbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-497c48e2-dfae-4695-8fac-383597c8750e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733487749-172.17.0.20-1595878988684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43564,DS-954d12e3-bf00-4511-9773-e9955449d80f,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-8fe6e03d-f300-4b6a-abfc-c43c21b23cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-2c268464-d63d-4916-9ca6-dfc835e718c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-1cffeeb7-b41a-4da0-8504-fd58b09215f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-2728dad8-4b20-4259-89a4-2b8f47dd3dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-bd66e2fe-f082-4af9-ac3c-c3961e95b2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-6238dc99-8f4b-497f-82b8-e4f2fe4ddbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-497c48e2-dfae-4695-8fac-383597c8750e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791015787-172.17.0.20-1595879267246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45797,DS-38d938af-e70f-4eba-8b70-faa738333d78,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-2e0f3966-3b0f-41e6-9d63-379c5e031eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-6e1e3f3a-edd0-4f5b-bf53-143f4077cf10,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-3fc66ff9-1204-4bb8-91e8-a0d6a3b939e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-d9ba3820-1703-4825-b909-183c1684b1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-0f0f279a-bde2-4953-a759-a20901c8e840,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-14de4536-d15a-4839-bb01-1d66d90d94bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-89a64745-00b7-4e21-81c2-4a316a8a89a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791015787-172.17.0.20-1595879267246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45797,DS-38d938af-e70f-4eba-8b70-faa738333d78,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-2e0f3966-3b0f-41e6-9d63-379c5e031eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-6e1e3f3a-edd0-4f5b-bf53-143f4077cf10,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-3fc66ff9-1204-4bb8-91e8-a0d6a3b939e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-d9ba3820-1703-4825-b909-183c1684b1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-0f0f279a-bde2-4953-a759-a20901c8e840,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-14de4536-d15a-4839-bb01-1d66d90d94bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-89a64745-00b7-4e21-81c2-4a316a8a89a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6940
