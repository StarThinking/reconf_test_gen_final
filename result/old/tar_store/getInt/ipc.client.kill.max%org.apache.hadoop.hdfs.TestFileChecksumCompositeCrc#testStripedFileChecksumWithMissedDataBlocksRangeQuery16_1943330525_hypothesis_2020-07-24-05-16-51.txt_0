reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422565973-172.17.0.16-1595568101298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-3cb999cb-9bc7-4203-ab4d-998e3301a1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-26ca1f3a-2685-40b9-b64a-10668c4e7f76,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-126c26e6-e638-4ed1-a2a3-ea98ee66c76a,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-e169ff88-f223-4d91-9981-5c494274cbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-abbd290f-75bb-4e81-9d00-df7c4aeaee46,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-8f14733b-fa43-426b-b20e-6e0b69fd19d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-0fc927b9-4c2d-42a3-aac4-bf2671ef95ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-edab656f-28bc-4e37-b12c-e00079fbec71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422565973-172.17.0.16-1595568101298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-3cb999cb-9bc7-4203-ab4d-998e3301a1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-26ca1f3a-2685-40b9-b64a-10668c4e7f76,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-126c26e6-e638-4ed1-a2a3-ea98ee66c76a,DISK], DatanodeInfoWithStorage[127.0.0.1:34989,DS-e169ff88-f223-4d91-9981-5c494274cbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-abbd290f-75bb-4e81-9d00-df7c4aeaee46,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-8f14733b-fa43-426b-b20e-6e0b69fd19d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-0fc927b9-4c2d-42a3-aac4-bf2671ef95ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-edab656f-28bc-4e37-b12c-e00079fbec71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979011307-172.17.0.16-1595568260762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44663,DS-1ff73826-76a8-48f6-b427-ab957e3ffbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-0aa83ddb-87e7-477e-b2a8-098533da2358,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-bbba020a-30fc-4459-b7af-457068f8aca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-c00334ee-1766-4e80-bb06-aa53f492dfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-c6f90ea0-0868-41d0-8a14-5c29fc79e93f,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-8c0ef486-429c-4ae4-ad5c-dbe41cf725cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-5d37c037-e1b6-4bd1-95df-96196e3140aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-a70c97bf-2e72-48da-97eb-cd7220558846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979011307-172.17.0.16-1595568260762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44663,DS-1ff73826-76a8-48f6-b427-ab957e3ffbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-0aa83ddb-87e7-477e-b2a8-098533da2358,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-bbba020a-30fc-4459-b7af-457068f8aca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-c00334ee-1766-4e80-bb06-aa53f492dfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-c6f90ea0-0868-41d0-8a14-5c29fc79e93f,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-8c0ef486-429c-4ae4-ad5c-dbe41cf725cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-5d37c037-e1b6-4bd1-95df-96196e3140aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-a70c97bf-2e72-48da-97eb-cd7220558846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759219101-172.17.0.16-1595568300516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33367,DS-2e70c89d-e9c6-4eb6-83e9-4b42be2717ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-f1d0504e-cc14-48b2-9cc8-46de2bab1ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-07b9e61d-1dac-4898-bd40-c1a6d2438837,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-dcb51639-1db2-4116-ad2d-8a2621269376,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-f209c2b1-32e7-4024-903f-a6ecd360cbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-ab30c2fc-8347-4ec2-ae51-956da77ab0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-db7738e7-af18-4e26-90a4-56d4a5f75635,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-c38199c0-2a74-43b2-8bbc-105e1bffc77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759219101-172.17.0.16-1595568300516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33367,DS-2e70c89d-e9c6-4eb6-83e9-4b42be2717ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-f1d0504e-cc14-48b2-9cc8-46de2bab1ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-07b9e61d-1dac-4898-bd40-c1a6d2438837,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-dcb51639-1db2-4116-ad2d-8a2621269376,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-f209c2b1-32e7-4024-903f-a6ecd360cbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-ab30c2fc-8347-4ec2-ae51-956da77ab0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-db7738e7-af18-4e26-90a4-56d4a5f75635,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-c38199c0-2a74-43b2-8bbc-105e1bffc77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453313236-172.17.0.16-1595568890497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-1916751e-4289-43ae-90d5-7225e117c0da,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-94284c8f-55a7-4d45-acb2-5cd7486d1f98,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-848f972f-d909-4f45-990c-ce3bb3f8d4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-b1612dce-c9be-454a-8e1f-49e57f18fe9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-1d6c79fb-18bf-418f-87e6-f3b5824556cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-cb00e0f1-c864-4b3d-aff5-5f747a2509ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-0a5a7f20-7281-4cae-bc8e-5a51885c3348,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-beb086e4-7958-4934-8c13-b0f539ed15c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453313236-172.17.0.16-1595568890497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-1916751e-4289-43ae-90d5-7225e117c0da,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-94284c8f-55a7-4d45-acb2-5cd7486d1f98,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-848f972f-d909-4f45-990c-ce3bb3f8d4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-b1612dce-c9be-454a-8e1f-49e57f18fe9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-1d6c79fb-18bf-418f-87e6-f3b5824556cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-cb00e0f1-c864-4b3d-aff5-5f747a2509ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-0a5a7f20-7281-4cae-bc8e-5a51885c3348,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-beb086e4-7958-4934-8c13-b0f539ed15c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719114424-172.17.0.16-1595569499886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33860,DS-6ae9a718-bd67-4b39-8c28-f70f0b06982a,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-5aba45d1-201c-4db0-8f12-83e14a3c48ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-573e76b0-aa8b-46cc-9f2d-09d0c2ac51c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-2a81dfcd-6991-47c6-9d6c-18d32e7eed79,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-ccd54d86-ff20-44d7-a878-ab21dfd07dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-d56aec04-2702-4620-8820-4a8a1190c141,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-37fa6cda-7f8d-46be-943a-7e5dfd214716,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-82e56c76-2a16-46c1-8a51-65dd9219904c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1719114424-172.17.0.16-1595569499886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33860,DS-6ae9a718-bd67-4b39-8c28-f70f0b06982a,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-5aba45d1-201c-4db0-8f12-83e14a3c48ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-573e76b0-aa8b-46cc-9f2d-09d0c2ac51c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-2a81dfcd-6991-47c6-9d6c-18d32e7eed79,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-ccd54d86-ff20-44d7-a878-ab21dfd07dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-d56aec04-2702-4620-8820-4a8a1190c141,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-37fa6cda-7f8d-46be-943a-7e5dfd214716,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-82e56c76-2a16-46c1-8a51-65dd9219904c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268635912-172.17.0.16-1595569573190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-bb4caf96-61d2-4db5-8a68-de19154822de,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-3c2b2525-fc4b-4334-8116-25ca2bbdb853,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-fa06cf41-8e88-4d4a-9c21-0e0d4893ff10,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-b0da086b-34a7-40e2-bdfb-6fdde26287d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-d9acf0c0-15b8-4a8d-bc98-8b39ca9ee27e,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-84483530-e7d6-4473-8c5c-0fd8a417eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-269d97dd-3665-49d3-b928-ad0a42e110a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-8e0e29f8-f36d-4423-9677-803ede4ed463,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268635912-172.17.0.16-1595569573190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-bb4caf96-61d2-4db5-8a68-de19154822de,DISK], DatanodeInfoWithStorage[127.0.0.1:44219,DS-3c2b2525-fc4b-4334-8116-25ca2bbdb853,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-fa06cf41-8e88-4d4a-9c21-0e0d4893ff10,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-b0da086b-34a7-40e2-bdfb-6fdde26287d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-d9acf0c0-15b8-4a8d-bc98-8b39ca9ee27e,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-84483530-e7d6-4473-8c5c-0fd8a417eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-269d97dd-3665-49d3-b928-ad0a42e110a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-8e0e29f8-f36d-4423-9677-803ede4ed463,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422942504-172.17.0.16-1595570012491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42660,DS-d19e6fe8-3a4e-4a0f-bb65-497026a47aab,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-6fb3dbaf-70e8-45be-a54b-3cb772975edf,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-da45475c-1006-476c-9d45-9cdb259e304f,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-657fa833-8783-4c36-adcf-fe04aab0ed2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-a502d11e-aaf2-4a78-af8c-8412f38904de,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-d6d4cb38-a999-407f-a843-662812af5032,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-4f5688b2-7954-4c46-8102-1e4eea7327e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-6a44a1b0-13b1-40e1-8b91-53ecd84d4fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422942504-172.17.0.16-1595570012491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42660,DS-d19e6fe8-3a4e-4a0f-bb65-497026a47aab,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-6fb3dbaf-70e8-45be-a54b-3cb772975edf,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-da45475c-1006-476c-9d45-9cdb259e304f,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-657fa833-8783-4c36-adcf-fe04aab0ed2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-a502d11e-aaf2-4a78-af8c-8412f38904de,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-d6d4cb38-a999-407f-a843-662812af5032,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-4f5688b2-7954-4c46-8102-1e4eea7327e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-6a44a1b0-13b1-40e1-8b91-53ecd84d4fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1248446755-172.17.0.16-1595570050482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43873,DS-c2eb9b11-32c3-4c98-86a1-0020eae0007b,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-8569316f-e78d-44dc-aec8-1f654e098a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-815bdafd-532d-4989-8868-581f7ccba519,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-35eb5037-7455-4c7d-a898-3895401bdb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-3424c0f4-7a72-49eb-afc7-2deaaa65a6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-ad0a4ff1-3919-4346-bef1-ea69448a8a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-5ed8d218-96d9-4380-a59d-a5528279df72,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-bc87d9ce-8cb2-49d8-acde-43b161d2ae9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1248446755-172.17.0.16-1595570050482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43873,DS-c2eb9b11-32c3-4c98-86a1-0020eae0007b,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-8569316f-e78d-44dc-aec8-1f654e098a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-815bdafd-532d-4989-8868-581f7ccba519,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-35eb5037-7455-4c7d-a898-3895401bdb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-3424c0f4-7a72-49eb-afc7-2deaaa65a6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-ad0a4ff1-3919-4346-bef1-ea69448a8a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-5ed8d218-96d9-4380-a59d-a5528279df72,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-bc87d9ce-8cb2-49d8-acde-43b161d2ae9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83643211-172.17.0.16-1595570523360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40556,DS-a2ccfe21-51bc-412e-86f3-1cc2a43af4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-43506e0c-25fd-4508-ba7c-5878b29e42ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-6c1d15b9-b636-41bd-96b9-92397bfd5692,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-351ef7b0-62b3-4520-8e5e-ba5c80690684,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-c2cb84fa-0912-4529-ae02-49c883772eed,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-93b0bc3f-63ed-4ee1-a06d-13871bd817c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-6edbe23f-2562-46c3-9353-081201a76db5,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-87222293-2c1c-4d57-bd93-7b5b3773352d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83643211-172.17.0.16-1595570523360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40556,DS-a2ccfe21-51bc-412e-86f3-1cc2a43af4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-43506e0c-25fd-4508-ba7c-5878b29e42ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-6c1d15b9-b636-41bd-96b9-92397bfd5692,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-351ef7b0-62b3-4520-8e5e-ba5c80690684,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-c2cb84fa-0912-4529-ae02-49c883772eed,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-93b0bc3f-63ed-4ee1-a06d-13871bd817c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-6edbe23f-2562-46c3-9353-081201a76db5,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-87222293-2c1c-4d57-bd93-7b5b3773352d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890215672-172.17.0.16-1595570555092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40929,DS-13753ff3-64d1-4838-b36d-bbb01fbc090a,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-bc302d93-4780-443f-94b6-fef6e8d25aea,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-df9f7654-a850-4211-b9fc-79367cf1d070,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-089fa516-78ca-4671-9c49-f223e920d06a,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-153bedbf-caca-4050-82b1-afae54c3628f,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-2a535769-65c9-479b-9ccf-38b945e9bc10,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-40c99ab2-d3ee-4e11-8686-46e4f5fff5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-efb211da-bd7c-4fa2-96fc-ef6e97b50c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890215672-172.17.0.16-1595570555092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40929,DS-13753ff3-64d1-4838-b36d-bbb01fbc090a,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-bc302d93-4780-443f-94b6-fef6e8d25aea,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-df9f7654-a850-4211-b9fc-79367cf1d070,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-089fa516-78ca-4671-9c49-f223e920d06a,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-153bedbf-caca-4050-82b1-afae54c3628f,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-2a535769-65c9-479b-9ccf-38b945e9bc10,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-40c99ab2-d3ee-4e11-8686-46e4f5fff5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-efb211da-bd7c-4fa2-96fc-ef6e97b50c42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575688193-172.17.0.16-1595570909608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45139,DS-ef83474c-17fe-4ef2-a464-c28b23c526c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-7bda6c62-b0ef-4514-b064-b733ff86b8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-34caed0d-615b-4ea0-a2ba-d80f59805238,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-8c098eb4-8920-4815-884a-bc3fbcafce98,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-9c9e6289-baf3-45cf-bbec-5a8367c8bf61,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-672c0d29-97b5-4cd9-b0a9-3752c8d71b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-67c80bc5-7b87-46cc-874b-1dc0abbd0519,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-18d7d580-1296-42f1-a08e-9f243ea4b8a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575688193-172.17.0.16-1595570909608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45139,DS-ef83474c-17fe-4ef2-a464-c28b23c526c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-7bda6c62-b0ef-4514-b064-b733ff86b8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-34caed0d-615b-4ea0-a2ba-d80f59805238,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-8c098eb4-8920-4815-884a-bc3fbcafce98,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-9c9e6289-baf3-45cf-bbec-5a8367c8bf61,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-672c0d29-97b5-4cd9-b0a9-3752c8d71b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-67c80bc5-7b87-46cc-874b-1dc0abbd0519,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-18d7d580-1296-42f1-a08e-9f243ea4b8a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836707058-172.17.0.16-1595571508280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39843,DS-2674f63a-cdf5-448c-9e68-9f5b4c1b7fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-1f9ea034-6a6f-40be-8231-6a58e467dfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-2d094955-b8f2-4490-ba94-71a8ac5cd5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-e6802752-324b-4303-815e-7a42491c9007,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-5502331e-d47a-42d8-81a7-f68ce4913d46,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-ae81970d-c200-4529-83c0-b112529c22a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-6848bd61-26d2-4c79-b74b-136e427866d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-1cba8cf2-0b01-4773-9c82-15545b8b1263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836707058-172.17.0.16-1595571508280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39843,DS-2674f63a-cdf5-448c-9e68-9f5b4c1b7fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-1f9ea034-6a6f-40be-8231-6a58e467dfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-2d094955-b8f2-4490-ba94-71a8ac5cd5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-e6802752-324b-4303-815e-7a42491c9007,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-5502331e-d47a-42d8-81a7-f68ce4913d46,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-ae81970d-c200-4529-83c0-b112529c22a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-6848bd61-26d2-4c79-b74b-136e427866d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-1cba8cf2-0b01-4773-9c82-15545b8b1263,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050477226-172.17.0.16-1595571618881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39407,DS-d06f012d-b0b4-46d1-882a-2575f6fed40a,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-f67090bd-466e-47d8-a419-37a1b52f61de,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-5bed1b56-633f-4c5c-8525-16f988928548,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-4f6e4c12-af44-4ecb-b6f4-0ffce8a7f649,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-3e090891-be97-4f93-9c0a-42a1a59c01ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-8370c4f3-f9cd-4beb-a12f-89373aead759,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-6a8793b3-cc81-4783-9a13-c5303ee58610,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-5ff9a8f5-f368-4b4c-a516-338ff542884d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050477226-172.17.0.16-1595571618881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39407,DS-d06f012d-b0b4-46d1-882a-2575f6fed40a,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-f67090bd-466e-47d8-a419-37a1b52f61de,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-5bed1b56-633f-4c5c-8525-16f988928548,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-4f6e4c12-af44-4ecb-b6f4-0ffce8a7f649,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-3e090891-be97-4f93-9c0a-42a1a59c01ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-8370c4f3-f9cd-4beb-a12f-89373aead759,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-6a8793b3-cc81-4783-9a13-c5303ee58610,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-5ff9a8f5-f368-4b4c-a516-338ff542884d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999676548-172.17.0.16-1595571697038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39942,DS-0fbe959f-3945-4f3b-bcf1-640ab5b23ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-98c52461-413e-4009-9097-f9ec35dc7b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-1efa6805-4b01-41c8-b173-8ee8b65f0ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-d2698339-46d0-416e-a52c-bfcc84837cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-fcfe36d6-3b72-4191-9660-feedf6f0031f,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-701e2893-b304-4051-8528-3c89c59442a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-19d04723-b294-44d1-9518-a4bb20f50896,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-3d881da1-45fe-4a38-bad2-921d76d3d53a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999676548-172.17.0.16-1595571697038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39942,DS-0fbe959f-3945-4f3b-bcf1-640ab5b23ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-98c52461-413e-4009-9097-f9ec35dc7b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-1efa6805-4b01-41c8-b173-8ee8b65f0ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-d2698339-46d0-416e-a52c-bfcc84837cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-fcfe36d6-3b72-4191-9660-feedf6f0031f,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-701e2893-b304-4051-8528-3c89c59442a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-19d04723-b294-44d1-9518-a4bb20f50896,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-3d881da1-45fe-4a38-bad2-921d76d3d53a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889920478-172.17.0.16-1595571873896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45153,DS-b9edd279-8990-4506-8017-1b5e9b4c4d54,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-f13ef009-8afa-4168-85d7-22ef2026239d,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-5888711d-44b0-4541-949c-35d536197ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-5c1aac4f-86d4-4565-8c27-63688de655d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-9eee2a69-1308-4448-87ca-c17f8dd62ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-704cc3c3-a3a7-4604-a2d9-5951225a7bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-80604b64-b0f4-48da-ae6f-c20d0dabd475,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-a3f3c0f0-8d07-4b5d-a79e-8874aad68f5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889920478-172.17.0.16-1595571873896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45153,DS-b9edd279-8990-4506-8017-1b5e9b4c4d54,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-f13ef009-8afa-4168-85d7-22ef2026239d,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-5888711d-44b0-4541-949c-35d536197ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-5c1aac4f-86d4-4565-8c27-63688de655d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-9eee2a69-1308-4448-87ca-c17f8dd62ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-704cc3c3-a3a7-4604-a2d9-5951225a7bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43715,DS-80604b64-b0f4-48da-ae6f-c20d0dabd475,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-a3f3c0f0-8d07-4b5d-a79e-8874aad68f5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-520015682-172.17.0.16-1595571905527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34701,DS-176b43d9-86bd-49b5-897d-4bbda6306aae,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-649042db-c690-46fa-95a9-9daac64767ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-a1caa720-565b-4385-87fb-84b053e636fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-35d171cc-5f9c-464c-9d1d-4a5e8a561ced,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-d5272261-da89-4c4e-8384-7a9d7b5884c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-4709a52e-f5cb-47c7-b334-3c196caee949,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-4ee710b3-4b65-42e5-b953-ca1c4f9d5541,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-b7149ddc-d48f-445e-b3bd-02e30b0cd6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-520015682-172.17.0.16-1595571905527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34701,DS-176b43d9-86bd-49b5-897d-4bbda6306aae,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-649042db-c690-46fa-95a9-9daac64767ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-a1caa720-565b-4385-87fb-84b053e636fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-35d171cc-5f9c-464c-9d1d-4a5e8a561ced,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-d5272261-da89-4c4e-8384-7a9d7b5884c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-4709a52e-f5cb-47c7-b334-3c196caee949,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-4ee710b3-4b65-42e5-b953-ca1c4f9d5541,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-b7149ddc-d48f-445e-b3bd-02e30b0cd6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197981103-172.17.0.16-1595572051538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35860,DS-c16e5092-af3c-4b7c-9d84-80bc93cac180,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-dfdc5999-c61f-4bec-b1dc-c40309bbed7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-6e30ec0a-6211-4be7-897b-c83f82d7b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-9c046bb9-575c-43aa-910f-90e82f3b060f,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-31450b4e-8e0b-4953-a78d-1b71c7dda834,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-c1bb3ae6-11ca-4370-b90c-7226a9c7f2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-ab900ea7-274f-44b2-914d-94c3bdc1ca05,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-0967c331-d61d-475c-8865-5c6b5dc58b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197981103-172.17.0.16-1595572051538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35860,DS-c16e5092-af3c-4b7c-9d84-80bc93cac180,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-dfdc5999-c61f-4bec-b1dc-c40309bbed7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-6e30ec0a-6211-4be7-897b-c83f82d7b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-9c046bb9-575c-43aa-910f-90e82f3b060f,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-31450b4e-8e0b-4953-a78d-1b71c7dda834,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-c1bb3ae6-11ca-4370-b90c-7226a9c7f2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-ab900ea7-274f-44b2-914d-94c3bdc1ca05,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-0967c331-d61d-475c-8865-5c6b5dc58b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1651297768-172.17.0.16-1595572186150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42894,DS-4b8ae58d-0c74-40ef-9f18-e16946d92b33,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-ecea3569-9e06-45af-9718-bc8c2d65a7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-cd2cbf95-a057-453b-a8a6-fa30010c9bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-a8a241b3-91d1-49a3-b481-1d4695ce7b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-a7367883-64bf-42ef-ab3f-ca6caae4d851,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-3141208e-4420-4532-8a28-013b0e5c07e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-0d6b6e89-c3eb-436b-aba9-f6329a540ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-92e2aa4d-c4a0-43ec-a49e-44cc6ed6cca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1651297768-172.17.0.16-1595572186150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42894,DS-4b8ae58d-0c74-40ef-9f18-e16946d92b33,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-ecea3569-9e06-45af-9718-bc8c2d65a7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-cd2cbf95-a057-453b-a8a6-fa30010c9bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-a8a241b3-91d1-49a3-b481-1d4695ce7b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-a7367883-64bf-42ef-ab3f-ca6caae4d851,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-3141208e-4420-4532-8a28-013b0e5c07e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-0d6b6e89-c3eb-436b-aba9-f6329a540ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-92e2aa4d-c4a0-43ec-a49e-44cc6ed6cca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968878859-172.17.0.16-1595572439600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35856,DS-8be0a3ee-9bd3-41b3-b22e-cef441779e78,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-9144f4b5-a174-49db-abe7-9d1d33fbfa88,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-194e1c08-712c-49f0-9ff7-aa3b916edeba,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-30792278-da01-4993-807a-144ff09830d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-dfcc440b-00d6-4a79-980f-1066b1ffd65a,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-675b1dcd-13b2-4230-846a-4c4de47fd478,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-1ba9952a-34c7-499d-894b-e2c70ff6efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-067b93f2-1cc4-49ea-bd5f-4e51805095db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968878859-172.17.0.16-1595572439600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35856,DS-8be0a3ee-9bd3-41b3-b22e-cef441779e78,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-9144f4b5-a174-49db-abe7-9d1d33fbfa88,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-194e1c08-712c-49f0-9ff7-aa3b916edeba,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-30792278-da01-4993-807a-144ff09830d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-dfcc440b-00d6-4a79-980f-1066b1ffd65a,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-675b1dcd-13b2-4230-846a-4c4de47fd478,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-1ba9952a-34c7-499d-894b-e2c70ff6efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46237,DS-067b93f2-1cc4-49ea-bd5f-4e51805095db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-678700882-172.17.0.16-1595573041381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36434,DS-c2535fa5-decc-4aef-ab7e-8908cd447436,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-71558048-d86f-4803-a2d4-f7d2a394d654,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-fab3cada-ed3a-4b54-8124-5c9eaed85aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-5a85cd4f-d763-40ce-b07b-4e514c597e36,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-24e9de01-c157-44b1-9b2e-7190f4e6ab93,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-fc6651aa-3e0b-4885-827d-60dd9c446087,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-ec01e7ce-73b9-4379-a3f6-58feb05d3769,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-52d9ca0b-6f8c-48eb-b135-1bdef20a54b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-678700882-172.17.0.16-1595573041381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36434,DS-c2535fa5-decc-4aef-ab7e-8908cd447436,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-71558048-d86f-4803-a2d4-f7d2a394d654,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-fab3cada-ed3a-4b54-8124-5c9eaed85aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-5a85cd4f-d763-40ce-b07b-4e514c597e36,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-24e9de01-c157-44b1-9b2e-7190f4e6ab93,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-fc6651aa-3e0b-4885-827d-60dd9c446087,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-ec01e7ce-73b9-4379-a3f6-58feb05d3769,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-52d9ca0b-6f8c-48eb-b135-1bdef20a54b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709308734-172.17.0.16-1595573112072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45118,DS-5fad58b1-c4a4-411b-81d8-8d426530582e,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-3922cc44-dce3-4c2c-859c-58083aa93255,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-746f546f-cd45-4d9c-9534-e261dd4bb3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-5902e8b4-79aa-4c9a-904b-d5964626d006,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-e7a654e2-48dd-4ef7-9e29-b4f7e1d521bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-91a54f95-4163-4db2-be1b-5402243f1d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-4c02132a-cbaf-4e79-af41-b755d95cbfec,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-15a9dd2a-b5d9-4e83-95e3-9ef59adfac86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709308734-172.17.0.16-1595573112072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45118,DS-5fad58b1-c4a4-411b-81d8-8d426530582e,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-3922cc44-dce3-4c2c-859c-58083aa93255,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-746f546f-cd45-4d9c-9534-e261dd4bb3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-5902e8b4-79aa-4c9a-904b-d5964626d006,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-e7a654e2-48dd-4ef7-9e29-b4f7e1d521bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-91a54f95-4163-4db2-be1b-5402243f1d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-4c02132a-cbaf-4e79-af41-b755d95cbfec,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-15a9dd2a-b5d9-4e83-95e3-9ef59adfac86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5348
