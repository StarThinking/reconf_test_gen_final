reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041100745-172.17.0.10-1595831225996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41127,DS-d6c351e2-9be1-4d17-bae4-c6bc54fee780,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-4cb7659a-3071-4e03-b262-fa9590b78fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-e9b7ef6a-7134-49c5-b839-4a47c8233490,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-ffc595bd-bd95-4e4c-bb01-9f737275fcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-329b1671-1122-4545-89e8-a287d970de8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-6054ff26-8039-4928-8412-71acfc900a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-dd4e39a9-51c7-499b-a360-ef44fe2ab43e,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-b7122474-b3e7-41f0-bda7-48d9097fa97b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041100745-172.17.0.10-1595831225996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41127,DS-d6c351e2-9be1-4d17-bae4-c6bc54fee780,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-4cb7659a-3071-4e03-b262-fa9590b78fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-e9b7ef6a-7134-49c5-b839-4a47c8233490,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-ffc595bd-bd95-4e4c-bb01-9f737275fcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-329b1671-1122-4545-89e8-a287d970de8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-6054ff26-8039-4928-8412-71acfc900a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-dd4e39a9-51c7-499b-a360-ef44fe2ab43e,DISK], DatanodeInfoWithStorage[127.0.0.1:34092,DS-b7122474-b3e7-41f0-bda7-48d9097fa97b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237712939-172.17.0.10-1595831290120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33634,DS-2aa457b9-9c7c-47f5-869b-631e18ab62cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-729767d7-4fc7-4f2b-9076-9335cceaefc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-8f4cbc64-85e7-4528-9bbe-a471e683e77f,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-5061c57d-69cc-4da8-82fa-3372d65ba585,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-1020930b-e284-4771-a3df-68cd07c53670,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-ba35e555-4585-4bd9-9780-0421a12a7985,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-597c1e51-2eac-47e2-bbf7-ec4e66847084,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-9836ec12-672a-4361-8748-64730bf9e339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237712939-172.17.0.10-1595831290120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33634,DS-2aa457b9-9c7c-47f5-869b-631e18ab62cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-729767d7-4fc7-4f2b-9076-9335cceaefc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-8f4cbc64-85e7-4528-9bbe-a471e683e77f,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-5061c57d-69cc-4da8-82fa-3372d65ba585,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-1020930b-e284-4771-a3df-68cd07c53670,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-ba35e555-4585-4bd9-9780-0421a12a7985,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-597c1e51-2eac-47e2-bbf7-ec4e66847084,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-9836ec12-672a-4361-8748-64730bf9e339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040048643-172.17.0.10-1595831668267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46419,DS-ca440975-381d-4622-8861-b3c9a2db17a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-c321c859-3229-4aec-b0f5-db30ab02a2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-65714704-b104-4f55-8bb6-642f4a4d5233,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-f9a50c13-2643-4f6e-b3a9-c1147c50f4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-35cfdee8-ab91-4d77-a205-43b03d58802b,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-da703db4-e965-45db-b74d-944eb9c8fa40,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-308ee97b-7ee2-43f0-95e1-a0eae371d6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-18267d40-259e-4353-a91b-497b637d34f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040048643-172.17.0.10-1595831668267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46419,DS-ca440975-381d-4622-8861-b3c9a2db17a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-c321c859-3229-4aec-b0f5-db30ab02a2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-65714704-b104-4f55-8bb6-642f4a4d5233,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-f9a50c13-2643-4f6e-b3a9-c1147c50f4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-35cfdee8-ab91-4d77-a205-43b03d58802b,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-da703db4-e965-45db-b74d-944eb9c8fa40,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-308ee97b-7ee2-43f0-95e1-a0eae371d6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-18267d40-259e-4353-a91b-497b637d34f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581774068-172.17.0.10-1595831764930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45199,DS-02f91767-7198-4ab0-af20-2cc433003606,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-81b2ae9c-1a25-4dd2-a778-43f3e80480c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-199ef392-df59-4e1d-b3c6-a838f582c118,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-fa94df56-bee6-4549-a342-4a0f8006b9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-2527aed4-9090-44a7-9648-41afb1cfed57,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-2c4d8c64-0b71-40ef-884b-b3fd3e13cb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-17cc9a76-8b14-42e6-8f23-8f29c6f711de,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-0b3089f2-e488-4867-a437-9dee83011900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581774068-172.17.0.10-1595831764930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45199,DS-02f91767-7198-4ab0-af20-2cc433003606,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-81b2ae9c-1a25-4dd2-a778-43f3e80480c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-199ef392-df59-4e1d-b3c6-a838f582c118,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-fa94df56-bee6-4549-a342-4a0f8006b9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-2527aed4-9090-44a7-9648-41afb1cfed57,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-2c4d8c64-0b71-40ef-884b-b3fd3e13cb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-17cc9a76-8b14-42e6-8f23-8f29c6f711de,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-0b3089f2-e488-4867-a437-9dee83011900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148164797-172.17.0.10-1595832322466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34547,DS-4a159f89-27a0-4985-bc8e-0c5d55fffebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-96b5ace1-8442-404d-a274-516aef48d900,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-df79e005-6d9b-4c54-8dd3-8c8e95feb1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-1df433a8-3611-4838-a3f4-0cec44aa9be8,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-7b90c8ee-7d99-42c3-9ca0-df24795e79db,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-5033f7b5-ae1f-4b79-aea6-53ed6e5cda4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-46c0001a-f402-4ae9-8beb-d6b48c0575de,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-8c1a735f-9ec5-416a-b353-589470e9b812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148164797-172.17.0.10-1595832322466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34547,DS-4a159f89-27a0-4985-bc8e-0c5d55fffebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-96b5ace1-8442-404d-a274-516aef48d900,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-df79e005-6d9b-4c54-8dd3-8c8e95feb1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-1df433a8-3611-4838-a3f4-0cec44aa9be8,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-7b90c8ee-7d99-42c3-9ca0-df24795e79db,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-5033f7b5-ae1f-4b79-aea6-53ed6e5cda4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-46c0001a-f402-4ae9-8beb-d6b48c0575de,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-8c1a735f-9ec5-416a-b353-589470e9b812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192686370-172.17.0.10-1595833705845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38650,DS-a6df8521-e4ed-44ec-9088-6022042edbde,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-94a83cfa-c8ef-439f-a65a-66f078911fae,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-d96d5aed-fdb8-42af-9362-015405f9ce5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-d3f06a10-32f1-45d1-8ac2-7e617b4e5260,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-791c70f0-5a53-474a-aefa-e7816d9b81af,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-918fd6dd-952b-4b09-b095-95717dc39ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-1cfd8fa8-cf02-46ff-9b0b-2072a5a87567,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-188963e2-ab25-4617-82ca-e22c6208c939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192686370-172.17.0.10-1595833705845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38650,DS-a6df8521-e4ed-44ec-9088-6022042edbde,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-94a83cfa-c8ef-439f-a65a-66f078911fae,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-d96d5aed-fdb8-42af-9362-015405f9ce5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-d3f06a10-32f1-45d1-8ac2-7e617b4e5260,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-791c70f0-5a53-474a-aefa-e7816d9b81af,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-918fd6dd-952b-4b09-b095-95717dc39ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-1cfd8fa8-cf02-46ff-9b0b-2072a5a87567,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-188963e2-ab25-4617-82ca-e22c6208c939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061456158-172.17.0.10-1595834676621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35983,DS-b91b732f-5b81-4905-aa1a-59468c805956,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-a6206bb7-c851-4c78-a22c-f26633928bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-bea1831e-bc39-42fd-9d2b-29f0973742a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-b517234b-58fa-4506-b9a0-d0fb835496e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-367b72a9-de54-41a2-b120-d6eba13b246b,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-48c73bad-e770-451f-a42a-3e9b4f553a89,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-5fa10232-0e47-4136-8933-020e69463e50,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-be6799dd-d397-4746-93d6-d3da21a3ccfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061456158-172.17.0.10-1595834676621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35983,DS-b91b732f-5b81-4905-aa1a-59468c805956,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-a6206bb7-c851-4c78-a22c-f26633928bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-bea1831e-bc39-42fd-9d2b-29f0973742a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-b517234b-58fa-4506-b9a0-d0fb835496e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-367b72a9-de54-41a2-b120-d6eba13b246b,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-48c73bad-e770-451f-a42a-3e9b4f553a89,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-5fa10232-0e47-4136-8933-020e69463e50,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-be6799dd-d397-4746-93d6-d3da21a3ccfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789895784-172.17.0.10-1595834768023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34599,DS-b524c05b-09bb-4497-9bef-95ec97824cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-6816b401-aa19-45e6-9b94-b1dd6b931785,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-c2e6ea66-4559-4433-b003-0e44b478a795,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-059ce43e-c66d-410a-b696-c9a0c6fe0316,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-36a8e21e-9def-4c8a-96ea-d58a953928fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-65724b49-7059-44b4-83dc-7df302655509,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-9841a55c-bd20-40e3-8a8e-d22f77722b75,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-41dd075d-7089-4f93-897e-feb670c421fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789895784-172.17.0.10-1595834768023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34599,DS-b524c05b-09bb-4497-9bef-95ec97824cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-6816b401-aa19-45e6-9b94-b1dd6b931785,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-c2e6ea66-4559-4433-b003-0e44b478a795,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-059ce43e-c66d-410a-b696-c9a0c6fe0316,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-36a8e21e-9def-4c8a-96ea-d58a953928fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-65724b49-7059-44b4-83dc-7df302655509,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-9841a55c-bd20-40e3-8a8e-d22f77722b75,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-41dd075d-7089-4f93-897e-feb670c421fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86679880-172.17.0.10-1595834901136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35908,DS-ec7b05fa-5529-4839-8724-1a0c1109f6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-4b5432ba-5aa4-4397-8729-b77da8a63cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-6a1c8a1c-9186-4894-a620-6336d59d21b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-cde61162-e068-4993-835a-28278bb89433,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-5d6a44d9-dc4d-46df-b7b1-692094a12f96,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-73a5918a-4196-4ece-94d4-d7511b035732,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-31a02083-5fc8-41cc-a012-009ce2a04ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-92e0f45a-6c37-4af9-a56c-20288a1739ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86679880-172.17.0.10-1595834901136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35908,DS-ec7b05fa-5529-4839-8724-1a0c1109f6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-4b5432ba-5aa4-4397-8729-b77da8a63cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-6a1c8a1c-9186-4894-a620-6336d59d21b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-cde61162-e068-4993-835a-28278bb89433,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-5d6a44d9-dc4d-46df-b7b1-692094a12f96,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-73a5918a-4196-4ece-94d4-d7511b035732,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-31a02083-5fc8-41cc-a012-009ce2a04ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-92e0f45a-6c37-4af9-a56c-20288a1739ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.initial.delay.ms
component: hdfs:NameNode
v1: 400
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319381436-172.17.0.10-1595835123572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34986,DS-3145e094-4f48-4d4f-b30e-9cb853455d32,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-84af5938-ab77-475c-8462-66e8b9d09b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-bc6b1c5d-a276-4b92-b886-eaf728d3389d,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-6e10e782-8c95-4c62-ad9c-42e9674674e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-20378495-79f4-4a02-9460-ee0e53631996,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-5b201466-492e-411f-9841-82e6c7ca7018,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-b355c3de-1378-4ba9-8ca9-d6f0f6366d10,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-81d1ac70-43d3-481f-8df0-9e1b2eea8333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319381436-172.17.0.10-1595835123572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34986,DS-3145e094-4f48-4d4f-b30e-9cb853455d32,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-84af5938-ab77-475c-8462-66e8b9d09b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-bc6b1c5d-a276-4b92-b886-eaf728d3389d,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-6e10e782-8c95-4c62-ad9c-42e9674674e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-20378495-79f4-4a02-9460-ee0e53631996,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-5b201466-492e-411f-9841-82e6c7ca7018,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-b355c3de-1378-4ba9-8ca9-d6f0f6366d10,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-81d1ac70-43d3-481f-8df0-9e1b2eea8333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 4928
