reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846505952-172.17.0.15-1595723830647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39935,DS-981039c5-bba9-4321-ab98-1aad2810e933,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-50c0ae50-6d7e-4d7e-9a11-fea2cb99f11b,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-cf26be88-5f53-485e-a42c-d3a0a52ad624,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-35253144-8628-481b-a855-742580f86b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-c8c06435-7461-48a8-825c-76423326a254,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-b23f5699-0095-4dfc-88ba-740186e3f457,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-6e58d67f-1fa8-41ec-b58b-e81dc37b4602,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-727f5011-24bc-4e3b-a246-510287fda236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846505952-172.17.0.15-1595723830647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39935,DS-981039c5-bba9-4321-ab98-1aad2810e933,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-50c0ae50-6d7e-4d7e-9a11-fea2cb99f11b,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-cf26be88-5f53-485e-a42c-d3a0a52ad624,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-35253144-8628-481b-a855-742580f86b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-c8c06435-7461-48a8-825c-76423326a254,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-b23f5699-0095-4dfc-88ba-740186e3f457,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-6e58d67f-1fa8-41ec-b58b-e81dc37b4602,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-727f5011-24bc-4e3b-a246-510287fda236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331651294-172.17.0.15-1595724438571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45451,DS-4edb44f7-975c-4b94-8a58-d5367c1226d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-fe66f81c-9c5b-4f29-a2aa-a11314ecf803,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-ff3db48d-2395-4424-9d6d-d326a294cf98,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-fd704388-2f67-40dc-aa85-23b0ef99c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-596b2a6d-1848-4932-a4ac-4e80687b7c27,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-caa81914-0100-46f2-88f0-2bb59de0364d,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-4faa4ac5-762b-4f0e-ab0d-116ca8152c62,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-533a9b5e-7a8e-4345-8aa6-9c806c55d3ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331651294-172.17.0.15-1595724438571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45451,DS-4edb44f7-975c-4b94-8a58-d5367c1226d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-fe66f81c-9c5b-4f29-a2aa-a11314ecf803,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-ff3db48d-2395-4424-9d6d-d326a294cf98,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-fd704388-2f67-40dc-aa85-23b0ef99c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-596b2a6d-1848-4932-a4ac-4e80687b7c27,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-caa81914-0100-46f2-88f0-2bb59de0364d,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-4faa4ac5-762b-4f0e-ab0d-116ca8152c62,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-533a9b5e-7a8e-4345-8aa6-9c806c55d3ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59226043-172.17.0.15-1595724658434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34459,DS-bcc345c4-d324-42e2-a34d-6368f2b96b27,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-9aef7547-c258-43d3-b9d5-af1a52b5fca0,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-97619983-53c9-4b09-b8b2-40a9634e27be,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-833e469f-5c12-4643-9485-7ef81079f3de,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-50a813e8-e3c1-4592-a011-394c32653555,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-13b5da7b-9f85-4edb-b642-7c7c660058d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-b571ad4b-a1fb-4db1-90db-12e38d0bf23c,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-471ce13d-c509-4947-89e5-92d1a8d7de61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59226043-172.17.0.15-1595724658434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34459,DS-bcc345c4-d324-42e2-a34d-6368f2b96b27,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-9aef7547-c258-43d3-b9d5-af1a52b5fca0,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-97619983-53c9-4b09-b8b2-40a9634e27be,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-833e469f-5c12-4643-9485-7ef81079f3de,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-50a813e8-e3c1-4592-a011-394c32653555,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-13b5da7b-9f85-4edb-b642-7c7c660058d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-b571ad4b-a1fb-4db1-90db-12e38d0bf23c,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-471ce13d-c509-4947-89e5-92d1a8d7de61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552983688-172.17.0.15-1595724899967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40639,DS-e4996d03-79e8-4b34-a5fa-d3635090a937,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-3ff9ac7c-d0db-47f8-9a13-39db11b5e284,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-ed483971-e775-4672-98c3-6fc277c59c21,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-b64ebb80-c4f8-4a29-adb6-7456be62c8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-b4b52a79-1ad5-4001-a053-17d47bfe1a55,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-204fc229-f858-4d14-a10f-f476d1f01353,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-acab312b-dd38-4362-b885-1b4940a57d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-f43755c2-01b6-43c1-8d66-e1e4a134214e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-552983688-172.17.0.15-1595724899967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40639,DS-e4996d03-79e8-4b34-a5fa-d3635090a937,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-3ff9ac7c-d0db-47f8-9a13-39db11b5e284,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-ed483971-e775-4672-98c3-6fc277c59c21,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-b64ebb80-c4f8-4a29-adb6-7456be62c8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-b4b52a79-1ad5-4001-a053-17d47bfe1a55,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-204fc229-f858-4d14-a10f-f476d1f01353,DISK], DatanodeInfoWithStorage[127.0.0.1:37819,DS-acab312b-dd38-4362-b885-1b4940a57d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-f43755c2-01b6-43c1-8d66-e1e4a134214e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267281801-172.17.0.15-1595725334878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-ccf63de7-022c-4e12-a1ca-58b77c91c165,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-5f2bef17-71e2-48be-9246-cb72c6fcde88,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-56e6c54c-0c6c-4c3c-b02b-3471717936e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-ef22b83a-5c14-479b-9a1b-8e891ed965ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-85ee6cc2-e785-46a0-a92c-3c72e5742ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-f1f8c88b-2ee0-49a0-84e3-41db985fed55,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-67b93901-b239-4e4f-a238-e98b0e4162b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-c0f619f2-b6ab-418c-9967-4caa88ae2a48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267281801-172.17.0.15-1595725334878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-ccf63de7-022c-4e12-a1ca-58b77c91c165,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-5f2bef17-71e2-48be-9246-cb72c6fcde88,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-56e6c54c-0c6c-4c3c-b02b-3471717936e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-ef22b83a-5c14-479b-9a1b-8e891ed965ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-85ee6cc2-e785-46a0-a92c-3c72e5742ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-f1f8c88b-2ee0-49a0-84e3-41db985fed55,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-67b93901-b239-4e4f-a238-e98b0e4162b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-c0f619f2-b6ab-418c-9967-4caa88ae2a48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001888403-172.17.0.15-1595726299130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43671,DS-f59e52e3-eb13-42b5-8282-2f333e491b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-1f6fba5c-b374-46e2-a293-ff9e5af9b20a,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-f75615f5-0331-43c2-98bf-c413828dfeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-afcf4143-0bcc-4281-9fe0-240afe91e2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-f3d36a4f-dca8-490b-84d5-6e5d9af52374,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-f76117c5-246a-48e2-85c6-d7bb693d623e,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-9259cb9d-0ec4-4f3d-b74b-acc01c3e35eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-aa97d0ad-b6bb-48f9-b907-b9c427013df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001888403-172.17.0.15-1595726299130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43671,DS-f59e52e3-eb13-42b5-8282-2f333e491b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-1f6fba5c-b374-46e2-a293-ff9e5af9b20a,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-f75615f5-0331-43c2-98bf-c413828dfeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-afcf4143-0bcc-4281-9fe0-240afe91e2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-f3d36a4f-dca8-490b-84d5-6e5d9af52374,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-f76117c5-246a-48e2-85c6-d7bb693d623e,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-9259cb9d-0ec4-4f3d-b74b-acc01c3e35eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-aa97d0ad-b6bb-48f9-b907-b9c427013df3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020369500-172.17.0.15-1595726943921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41049,DS-3066b26f-9d84-4479-8d6b-8bfcc1c75af6,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-61c46d8b-50ce-4af9-bdf6-a87c681c203e,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-0b7c11ab-de58-4d9c-9d9a-e0fe0515dcae,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-098e7de8-7fa1-47e0-8f6e-a9ad2f7f4460,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-b838629e-742a-44e0-90c5-79333debc57b,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-984fe96b-3735-455f-bc5b-60d383a183d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-f05892f0-8acf-4158-b524-d467081db2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-2377d873-5e9e-4244-9f95-d1eaff379694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020369500-172.17.0.15-1595726943921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41049,DS-3066b26f-9d84-4479-8d6b-8bfcc1c75af6,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-61c46d8b-50ce-4af9-bdf6-a87c681c203e,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-0b7c11ab-de58-4d9c-9d9a-e0fe0515dcae,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-098e7de8-7fa1-47e0-8f6e-a9ad2f7f4460,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-b838629e-742a-44e0-90c5-79333debc57b,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-984fe96b-3735-455f-bc5b-60d383a183d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-f05892f0-8acf-4158-b524-d467081db2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-2377d873-5e9e-4244-9f95-d1eaff379694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714018824-172.17.0.15-1595727253749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37429,DS-398c0c92-ec3a-4f1c-adf2-fc0a1d319722,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-4f07d143-6a04-4572-a579-819238e21842,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-1d47044d-9659-49d2-a0cb-3dfa132a9c45,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-e202bb14-4a50-4a80-bcfa-96eaa68b009e,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-e075cfe5-1255-4f45-b606-907cb2220fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-cc96eb5a-6cc7-4fc5-b924-774f750f340d,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-3f8cf4e6-8fe8-4a5b-a910-bc330daf126a,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-40b00d44-3158-428b-8a3a-926693a31f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714018824-172.17.0.15-1595727253749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37429,DS-398c0c92-ec3a-4f1c-adf2-fc0a1d319722,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-4f07d143-6a04-4572-a579-819238e21842,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-1d47044d-9659-49d2-a0cb-3dfa132a9c45,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-e202bb14-4a50-4a80-bcfa-96eaa68b009e,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-e075cfe5-1255-4f45-b606-907cb2220fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39056,DS-cc96eb5a-6cc7-4fc5-b924-774f750f340d,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-3f8cf4e6-8fe8-4a5b-a910-bc330daf126a,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-40b00d44-3158-428b-8a3a-926693a31f51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288154369-172.17.0.15-1595727647269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41096,DS-2470effa-512d-40a1-a183-0fee1edd83f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-f9b63542-89e6-4ea9-8f3d-19c87bd8ab78,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-594f9e19-52e4-490f-806e-163f40cd74d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-53914393-757f-418e-9941-f67e66c37888,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-bfd177aa-47a0-40db-9254-d229ee558520,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-5a9fc82e-1557-43b0-93fc-c55a07d1ae67,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-7a8394fd-2999-4890-8db4-703c8ffeca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-5f827a06-8fc0-4bea-adff-8fded906994c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288154369-172.17.0.15-1595727647269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41096,DS-2470effa-512d-40a1-a183-0fee1edd83f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-f9b63542-89e6-4ea9-8f3d-19c87bd8ab78,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-594f9e19-52e4-490f-806e-163f40cd74d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-53914393-757f-418e-9941-f67e66c37888,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-bfd177aa-47a0-40db-9254-d229ee558520,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-5a9fc82e-1557-43b0-93fc-c55a07d1ae67,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-7a8394fd-2999-4890-8db4-703c8ffeca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-5f827a06-8fc0-4bea-adff-8fded906994c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108999481-172.17.0.15-1595727868639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-eecc66d3-b437-406c-9949-75d6efa6b961,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-c3e8774c-5b6c-46c0-9ee8-1f1d283ecb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-e4aad4ad-e5f2-4958-987e-03be2d258de9,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-8eca1e1c-c4b4-47ee-bc33-ae2f152e5796,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-63c33624-581a-4219-a9b8-d22cc48bb66a,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-e3ded3b1-5509-4ea9-8ae4-f2f688ae246b,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-7b838e35-ff1f-41b0-84ae-cf7b7bb956e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-3af5a43a-8237-4462-a49e-1ebb36c92693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108999481-172.17.0.15-1595727868639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-eecc66d3-b437-406c-9949-75d6efa6b961,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-c3e8774c-5b6c-46c0-9ee8-1f1d283ecb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-e4aad4ad-e5f2-4958-987e-03be2d258de9,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-8eca1e1c-c4b4-47ee-bc33-ae2f152e5796,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-63c33624-581a-4219-a9b8-d22cc48bb66a,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-e3ded3b1-5509-4ea9-8ae4-f2f688ae246b,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-7b838e35-ff1f-41b0-84ae-cf7b7bb956e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-3af5a43a-8237-4462-a49e-1ebb36c92693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186075454-172.17.0.15-1595727997242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44384,DS-53cf0065-475b-4f96-8b3a-45321abd1a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-9ccecd49-83c9-400b-9347-9bc5caa97d50,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-7f859eba-cb0e-48e3-805c-18ea0f8533a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-2fee82e7-5c2d-44fd-83b7-02a2a4a7afc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-117c61e7-6aea-47a6-a82b-939dc2267604,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-8620e12f-1252-4651-96ec-636786d4d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-74323378-80ac-4974-911c-9a561f17ae22,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-54a0812e-4f25-480d-b4b3-9c36128c1f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186075454-172.17.0.15-1595727997242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44384,DS-53cf0065-475b-4f96-8b3a-45321abd1a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-9ccecd49-83c9-400b-9347-9bc5caa97d50,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-7f859eba-cb0e-48e3-805c-18ea0f8533a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-2fee82e7-5c2d-44fd-83b7-02a2a4a7afc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-117c61e7-6aea-47a6-a82b-939dc2267604,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-8620e12f-1252-4651-96ec-636786d4d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-74323378-80ac-4974-911c-9a561f17ae22,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-54a0812e-4f25-480d-b4b3-9c36128c1f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326941542-172.17.0.15-1595728170450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37643,DS-d4018ffd-1763-4efd-b404-a5b005ed4e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-3fc1eaa2-ecca-4854-a1cd-d96c9e827f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-84d83028-4283-407c-85f4-7d11530a3590,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-e10beee5-675e-4204-9ee2-bb1579d8760f,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-fe27afec-e007-48a9-81db-16b225df0d82,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-03a9ebaa-2024-4c30-bbed-4809c84cb84c,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-6d9d9efb-3189-4fe1-b18a-6f36469f0fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-7408fac1-9da1-4edf-8a04-ddb46804657a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326941542-172.17.0.15-1595728170450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37643,DS-d4018ffd-1763-4efd-b404-a5b005ed4e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-3fc1eaa2-ecca-4854-a1cd-d96c9e827f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-84d83028-4283-407c-85f4-7d11530a3590,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-e10beee5-675e-4204-9ee2-bb1579d8760f,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-fe27afec-e007-48a9-81db-16b225df0d82,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-03a9ebaa-2024-4c30-bbed-4809c84cb84c,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-6d9d9efb-3189-4fe1-b18a-6f36469f0fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40865,DS-7408fac1-9da1-4edf-8a04-ddb46804657a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375196442-172.17.0.15-1595728611134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40444,DS-69ac03eb-3fd9-470c-a001-0be9bb1c0d16,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-a737fdbd-33e3-4caa-b7b6-0f4b0c316862,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-d7f284b5-158d-42a8-9f0d-7a3448f704db,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-fad16915-d046-42f0-86a4-9b18c026a1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-878961a8-1f2f-4b16-9b0a-47fce755bfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-4648c274-4799-439d-b8ba-83e0f0d11924,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-8d374018-c974-4d59-bc39-c48abb1c3598,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-9923e1d9-8819-4918-95cb-cd7468484d32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375196442-172.17.0.15-1595728611134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40444,DS-69ac03eb-3fd9-470c-a001-0be9bb1c0d16,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-a737fdbd-33e3-4caa-b7b6-0f4b0c316862,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-d7f284b5-158d-42a8-9f0d-7a3448f704db,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-fad16915-d046-42f0-86a4-9b18c026a1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-878961a8-1f2f-4b16-9b0a-47fce755bfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-4648c274-4799-439d-b8ba-83e0f0d11924,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-8d374018-c974-4d59-bc39-c48abb1c3598,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-9923e1d9-8819-4918-95cb-cd7468484d32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63696960-172.17.0.15-1595728845561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33118,DS-0b5f799c-6017-43d8-af79-e7a00fefbe3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-75794b26-924e-43da-9819-6c6ce6dbac8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-ebe9ad8e-7322-487a-b0a3-00d1310c3f57,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-98b0f5c2-3148-4e24-a949-bafae460587c,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-a986acfd-bbf3-425e-b8b9-d23892bb3806,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-b401d25a-6fdc-4dc9-a2e3-da476c6c89ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-642c4193-9a73-4cb8-8426-6294b76263b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-3d825109-67db-4b8a-96b2-91383866a614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63696960-172.17.0.15-1595728845561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33118,DS-0b5f799c-6017-43d8-af79-e7a00fefbe3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-75794b26-924e-43da-9819-6c6ce6dbac8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-ebe9ad8e-7322-487a-b0a3-00d1310c3f57,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-98b0f5c2-3148-4e24-a949-bafae460587c,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-a986acfd-bbf3-425e-b8b9-d23892bb3806,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-b401d25a-6fdc-4dc9-a2e3-da476c6c89ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-642c4193-9a73-4cb8-8426-6294b76263b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-3d825109-67db-4b8a-96b2-91383866a614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385881778-172.17.0.15-1595729286805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37523,DS-bfa18ec2-79f9-4bd8-b667-97f8d7b3298a,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-e50a90ad-86f6-4c9a-8542-fe0dcc1a31e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-18ed9a2c-0017-419f-99d9-cd2f64a350c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-bd8f531d-f580-428b-9570-4a2a80468a37,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-f437e153-9a79-41aa-9510-cafff7957cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-1dcab19f-5fb7-4a84-be74-6a0f325b9e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-a4b723b9-93e4-4071-9d3f-112ce6355658,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-6aa9352f-67fe-4990-a900-086fb7382450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385881778-172.17.0.15-1595729286805:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37523,DS-bfa18ec2-79f9-4bd8-b667-97f8d7b3298a,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-e50a90ad-86f6-4c9a-8542-fe0dcc1a31e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-18ed9a2c-0017-419f-99d9-cd2f64a350c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-bd8f531d-f580-428b-9570-4a2a80468a37,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-f437e153-9a79-41aa-9510-cafff7957cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-1dcab19f-5fb7-4a84-be74-6a0f325b9e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-a4b723b9-93e4-4071-9d3f-112ce6355658,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-6aa9352f-67fe-4990-a900-086fb7382450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462515348-172.17.0.15-1595729324319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39644,DS-a0aac930-6022-4792-847d-1998ba9d2e74,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-f7c465cd-9613-485e-a150-4c6c821bf114,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-3a8cd4a9-f45c-4932-984a-9b63378d4c85,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-ae997441-ff43-42bf-aee3-3a379098935b,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-043779cb-2b5a-447c-bebe-e610e7ebdaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-229a97b0-69ea-494e-86e1-bc1aba3de8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-35f6b181-5847-4e18-bba5-d09d6038d484,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-6a3c4b4b-dfff-47b3-9d6d-666ce2e992f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462515348-172.17.0.15-1595729324319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39644,DS-a0aac930-6022-4792-847d-1998ba9d2e74,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-f7c465cd-9613-485e-a150-4c6c821bf114,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-3a8cd4a9-f45c-4932-984a-9b63378d4c85,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-ae997441-ff43-42bf-aee3-3a379098935b,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-043779cb-2b5a-447c-bebe-e610e7ebdaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-229a97b0-69ea-494e-86e1-bc1aba3de8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-35f6b181-5847-4e18-bba5-d09d6038d484,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-6a3c4b4b-dfff-47b3-9d6d-666ce2e992f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813976879-172.17.0.15-1595729509143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38399,DS-06777a2a-1543-4159-ac71-86c0f37a96df,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-dd4b477b-ba8d-470c-b712-a01ed910ba64,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-d1799014-1393-464b-9812-b8f0368e7b94,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-cc17f003-b32b-48a6-a11c-4446ae6c6cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-77dabdd4-b533-489c-85e2-81080e383220,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-cbee33f1-6424-4237-89d7-d659bf9c6f71,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-80e5f2e8-8c0e-48c5-8c04-8453a320897d,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-1b9bf878-e979-4f76-81b8-7498fefd0553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813976879-172.17.0.15-1595729509143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38399,DS-06777a2a-1543-4159-ac71-86c0f37a96df,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-dd4b477b-ba8d-470c-b712-a01ed910ba64,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-d1799014-1393-464b-9812-b8f0368e7b94,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-cc17f003-b32b-48a6-a11c-4446ae6c6cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-77dabdd4-b533-489c-85e2-81080e383220,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-cbee33f1-6424-4237-89d7-d659bf9c6f71,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-80e5f2e8-8c0e-48c5-8c04-8453a320897d,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-1b9bf878-e979-4f76-81b8-7498fefd0553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343734215-172.17.0.15-1595729671845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44837,DS-40b5d679-1685-471c-8451-41cfedc071ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-4a2bb5b2-afc1-4bef-af2f-7316c6666df3,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-6963188a-384d-44b4-a00c-74a32255b01f,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-37b45bb4-7550-4a4d-8765-096875b98fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-29236e97-fad8-498e-b803-8aceaa813684,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-b9f46b41-1e60-48d3-bab1-6ede288217f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-7b5d823a-ff01-42a8-a22b-3dea9c0d9b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-999d3c23-cbef-4ee3-8b36-4bbbba9b22ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343734215-172.17.0.15-1595729671845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44837,DS-40b5d679-1685-471c-8451-41cfedc071ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-4a2bb5b2-afc1-4bef-af2f-7316c6666df3,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-6963188a-384d-44b4-a00c-74a32255b01f,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-37b45bb4-7550-4a4d-8765-096875b98fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-29236e97-fad8-498e-b803-8aceaa813684,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-b9f46b41-1e60-48d3-bab1-6ede288217f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-7b5d823a-ff01-42a8-a22b-3dea9c0d9b07,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-999d3c23-cbef-4ee3-8b36-4bbbba9b22ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.reencryption.status.num.responses
component: hdfs:NameNode
v1: 100
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958535779-172.17.0.15-1595729798916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-4e4e66c6-32bf-4830-8deb-282d66fa6b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-1fd86263-a1ea-4afb-9221-f30d4ac2f19c,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-b4b83d21-1ec7-4e5a-adee-b2b29aadbe84,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-85197900-30db-4254-b882-6aa9bf70e659,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-5c376ed1-4bdd-406b-a7c1-d189d45b1078,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-344faf95-46fe-492e-ad49-d7a4a0b1d457,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-476e1bc4-720d-4672-9c5f-15dd121616c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-428a29e0-76d4-4916-8e35-85465d8719cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958535779-172.17.0.15-1595729798916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-4e4e66c6-32bf-4830-8deb-282d66fa6b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-1fd86263-a1ea-4afb-9221-f30d4ac2f19c,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-b4b83d21-1ec7-4e5a-adee-b2b29aadbe84,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-85197900-30db-4254-b882-6aa9bf70e659,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-5c376ed1-4bdd-406b-a7c1-d189d45b1078,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-344faf95-46fe-492e-ad49-d7a4a0b1d457,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-476e1bc4-720d-4672-9c5f-15dd121616c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-428a29e0-76d4-4916-8e35-85465d8719cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6486
