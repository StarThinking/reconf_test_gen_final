reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77500587-172.17.0.4-1595537431370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34436,DS-2ed7c33f-661b-4fbb-bf10-40fe44c7e1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-71138d6e-42e6-4edf-8b59-e17cf2848239,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-79968bc7-b3b7-4a46-b785-c898767e3a63,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-1270a0a6-ef8f-41dd-ba8f-252c7b102a20,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-52f94ddc-bded-4a58-a246-adf2c936364f,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-dc8a346a-82b3-4845-ae15-580a79900b43,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-9babf928-a231-4142-a01c-264f2ba3a0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-53f9a66d-f291-4427-952d-90f8ca3ba3fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77500587-172.17.0.4-1595537431370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34436,DS-2ed7c33f-661b-4fbb-bf10-40fe44c7e1f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-71138d6e-42e6-4edf-8b59-e17cf2848239,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-79968bc7-b3b7-4a46-b785-c898767e3a63,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-1270a0a6-ef8f-41dd-ba8f-252c7b102a20,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-52f94ddc-bded-4a58-a246-adf2c936364f,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-dc8a346a-82b3-4845-ae15-580a79900b43,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-9babf928-a231-4142-a01c-264f2ba3a0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-53f9a66d-f291-4427-952d-90f8ca3ba3fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-927053561-172.17.0.4-1595537479314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44092,DS-a1a0052c-1035-4e49-99ec-c524c47e0456,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-204a84cc-d059-4cca-a555-3af63edef509,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-628c509b-1cdd-440a-af4b-ede2208b84ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-ae91877f-9347-4b46-b876-38847f556e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-51a8dd50-6978-49a3-9da0-d38cf19b85e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-7aadd0c0-0f03-4150-8db7-ab6f25b33df6,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-dce3564c-e561-4028-b89e-f060832020fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-f5512666-acf2-47dc-aef7-3da320940b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-927053561-172.17.0.4-1595537479314:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44092,DS-a1a0052c-1035-4e49-99ec-c524c47e0456,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-204a84cc-d059-4cca-a555-3af63edef509,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-628c509b-1cdd-440a-af4b-ede2208b84ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-ae91877f-9347-4b46-b876-38847f556e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-51a8dd50-6978-49a3-9da0-d38cf19b85e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-7aadd0c0-0f03-4150-8db7-ab6f25b33df6,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-dce3564c-e561-4028-b89e-f060832020fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-f5512666-acf2-47dc-aef7-3da320940b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635570032-172.17.0.4-1595538493019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42270,DS-3cefcf19-cdf7-42ae-b614-a42585ccdb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-905d68b6-64b8-41f8-95e4-1c8a3f3319b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-334bcc99-df78-4462-b9f8-9c37b3ca7d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-644e1854-134b-49b6-9942-db5d6bb6784e,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-1adc1b9c-cd72-4391-8604-b0f0a3ced5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-ed1c2abb-24ae-42b0-b9ff-443695b7cbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-232955d3-ef05-4ec1-a258-c648cc45c748,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-c4fe59fd-1225-48b9-93d3-8fe9b55e5491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635570032-172.17.0.4-1595538493019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42270,DS-3cefcf19-cdf7-42ae-b614-a42585ccdb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-905d68b6-64b8-41f8-95e4-1c8a3f3319b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-334bcc99-df78-4462-b9f8-9c37b3ca7d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-644e1854-134b-49b6-9942-db5d6bb6784e,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-1adc1b9c-cd72-4391-8604-b0f0a3ced5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-ed1c2abb-24ae-42b0-b9ff-443695b7cbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-232955d3-ef05-4ec1-a258-c648cc45c748,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-c4fe59fd-1225-48b9-93d3-8fe9b55e5491,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-50907706-172.17.0.4-1595538671906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42736,DS-422bf5a4-5f9b-4b77-8ea2-bc43e3a501e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-77314eb5-6266-4f47-9a4c-0d4a2ccd7783,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-bf2a1e53-e991-48ac-855b-4384010e3a39,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-46f1f600-68a3-4c1e-b94d-dfada49844ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-afbc51e3-fe2f-4d40-9515-225d683099c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-5d073dd4-4eba-4547-974d-03f18bd9efd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-372f9256-a034-43db-89b8-263ee4b9a146,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-6b870adf-736b-4dc7-ac7f-e238204489cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-50907706-172.17.0.4-1595538671906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42736,DS-422bf5a4-5f9b-4b77-8ea2-bc43e3a501e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-77314eb5-6266-4f47-9a4c-0d4a2ccd7783,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-bf2a1e53-e991-48ac-855b-4384010e3a39,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-46f1f600-68a3-4c1e-b94d-dfada49844ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-afbc51e3-fe2f-4d40-9515-225d683099c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-5d073dd4-4eba-4547-974d-03f18bd9efd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-372f9256-a034-43db-89b8-263ee4b9a146,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-6b870adf-736b-4dc7-ac7f-e238204489cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-564587849-172.17.0.4-1595538983859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37322,DS-da220256-9492-40ba-9090-659ccba1ca57,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-18956bbb-a09c-4443-a2d9-1104fad6d250,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-7cea19a5-4dac-44ac-a36e-fe6e8bbc209a,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-6eb6d9ab-d2d6-4fd8-98eb-f2fd6843a0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-3e64630d-8165-4c78-814b-d0358e68b736,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-352cbc56-6322-44e0-a192-bec99c0ff3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-296914d5-2ce8-417a-a323-30f0a8c70ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-d531a2da-5587-4424-858f-5a0c8d0f5e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-564587849-172.17.0.4-1595538983859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37322,DS-da220256-9492-40ba-9090-659ccba1ca57,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-18956bbb-a09c-4443-a2d9-1104fad6d250,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-7cea19a5-4dac-44ac-a36e-fe6e8bbc209a,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-6eb6d9ab-d2d6-4fd8-98eb-f2fd6843a0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-3e64630d-8165-4c78-814b-d0358e68b736,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-352cbc56-6322-44e0-a192-bec99c0ff3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-296914d5-2ce8-417a-a323-30f0a8c70ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-d531a2da-5587-4424-858f-5a0c8d0f5e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371313669-172.17.0.4-1595539132164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36929,DS-83a9377d-5059-4ce5-90c5-f0e0d6650d12,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-9ade0451-d252-4714-818f-2fc6ff4fc13e,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-c6400f06-d608-4c09-969c-d1a999e2e327,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-9b9308f8-86b5-44d7-a427-3236a8e2e32f,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-e5544415-ec77-49a3-a36c-25b069087972,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-62fa0b4c-802c-41d2-8acf-728da041a28a,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-d6757a4f-3420-40b3-a790-9b6bc6bab893,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-071e9012-dc32-41e6-a6b9-65df79ac3cb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1371313669-172.17.0.4-1595539132164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36929,DS-83a9377d-5059-4ce5-90c5-f0e0d6650d12,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-9ade0451-d252-4714-818f-2fc6ff4fc13e,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-c6400f06-d608-4c09-969c-d1a999e2e327,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-9b9308f8-86b5-44d7-a427-3236a8e2e32f,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-e5544415-ec77-49a3-a36c-25b069087972,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-62fa0b4c-802c-41d2-8acf-728da041a28a,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-d6757a4f-3420-40b3-a790-9b6bc6bab893,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-071e9012-dc32-41e6-a6b9-65df79ac3cb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718061757-172.17.0.4-1595539230085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36571,DS-730c936f-1982-4adc-b171-cfe6f2f8fcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-825d6dee-bf0a-4802-8153-67e091cc77d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-9b5f9477-9806-4222-89da-13e86262c734,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-8149a67f-235e-4218-9d00-66946c644350,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-b61a8157-caae-40ec-9ca1-7f4a36f2b1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-c2fc78a7-dfe6-4347-ab9d-2f85e4c818fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-e216c898-4c73-4cde-907e-a12243b06051,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-360e4190-2107-4ba5-9ee4-6e6b85678705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718061757-172.17.0.4-1595539230085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36571,DS-730c936f-1982-4adc-b171-cfe6f2f8fcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-825d6dee-bf0a-4802-8153-67e091cc77d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-9b5f9477-9806-4222-89da-13e86262c734,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-8149a67f-235e-4218-9d00-66946c644350,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-b61a8157-caae-40ec-9ca1-7f4a36f2b1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-c2fc78a7-dfe6-4347-ab9d-2f85e4c818fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-e216c898-4c73-4cde-907e-a12243b06051,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-360e4190-2107-4ba5-9ee4-6e6b85678705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040901154-172.17.0.4-1595539478141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37681,DS-bbc5233f-a053-42c4-bf24-4897695dc7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-6d5559b7-f748-4228-bc15-4eb4c4daa375,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-397ffa1e-8bc2-449c-baf2-f0804535c4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-8b7c255a-d8be-499e-80c7-d13563ecdbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-5b55fb0e-04fe-47a9-aa10-5cd63df9b96e,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-761f5a51-2d45-4961-9b80-f050269cc0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-ec1cf479-64c2-4e45-a06c-b9af492b39d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-b9260e59-9fa0-4a82-bdbc-22853019e12d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040901154-172.17.0.4-1595539478141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37681,DS-bbc5233f-a053-42c4-bf24-4897695dc7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-6d5559b7-f748-4228-bc15-4eb4c4daa375,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-397ffa1e-8bc2-449c-baf2-f0804535c4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-8b7c255a-d8be-499e-80c7-d13563ecdbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-5b55fb0e-04fe-47a9-aa10-5cd63df9b96e,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-761f5a51-2d45-4961-9b80-f050269cc0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-ec1cf479-64c2-4e45-a06c-b9af492b39d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-b9260e59-9fa0-4a82-bdbc-22853019e12d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-739207144-172.17.0.4-1595539719494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36655,DS-96f83718-712a-47bf-985f-373ee78d9494,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-a4c372e4-ece5-40be-bb33-8d79d564174f,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-cf5aa4e8-328c-4a0a-b360-a4337c8ccfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-b9f00e75-1f7e-4bff-9f1d-dd45bcee1029,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-a8f7fcd7-d427-40d2-b5a2-103a98527f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-ee715eb2-4784-4e47-9409-3a37ac37af53,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-4c6b6819-d9c7-4171-aa91-5be5271cf0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-5dc768c3-dc1e-4ada-9a44-faaffb10b373,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-739207144-172.17.0.4-1595539719494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36655,DS-96f83718-712a-47bf-985f-373ee78d9494,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-a4c372e4-ece5-40be-bb33-8d79d564174f,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-cf5aa4e8-328c-4a0a-b360-a4337c8ccfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-b9f00e75-1f7e-4bff-9f1d-dd45bcee1029,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-a8f7fcd7-d427-40d2-b5a2-103a98527f12,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-ee715eb2-4784-4e47-9409-3a37ac37af53,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-4c6b6819-d9c7-4171-aa91-5be5271cf0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-5dc768c3-dc1e-4ada-9a44-faaffb10b373,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791965786-172.17.0.4-1595539852960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35932,DS-0aae46b8-3a0e-43e7-89dc-debccc24de9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-37b9437f-7d4b-41b9-9860-2a1a89992644,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-538b3414-14c1-4e55-9747-b0949c6c703c,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-e0a5f0f4-70e7-458b-88be-7340c6987ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-6dd9822e-3598-40ce-a9c7-1709f3c15151,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-dc480e7d-d20f-4874-a068-ddef0021da86,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-b6cf1f6f-2168-49f6-9d26-7c7e9cc44ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-bb9ab6e9-ffef-4a02-985f-aa7dbefc08c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1791965786-172.17.0.4-1595539852960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35932,DS-0aae46b8-3a0e-43e7-89dc-debccc24de9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-37b9437f-7d4b-41b9-9860-2a1a89992644,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-538b3414-14c1-4e55-9747-b0949c6c703c,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-e0a5f0f4-70e7-458b-88be-7340c6987ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-6dd9822e-3598-40ce-a9c7-1709f3c15151,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-dc480e7d-d20f-4874-a068-ddef0021da86,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-b6cf1f6f-2168-49f6-9d26-7c7e9cc44ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-bb9ab6e9-ffef-4a02-985f-aa7dbefc08c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104276592-172.17.0.4-1595540040916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45400,DS-833b5c83-5f9c-4dea-9392-77ffd0d8e7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-c4e3b97d-fdf5-4e51-b552-ae48007a067b,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-86d5fe12-1f9d-44be-a41f-71cd9670e3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-7e24b9d3-2ede-4870-b861-3da83772b8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-f197ae39-9d89-4920-ba7f-a14b4f60e5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-5a55c2df-d09e-4de0-bb17-549994b26437,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-b8d9dc03-1388-40b4-8a13-247508b56196,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-f7b68923-0765-4fa2-8df8-e44a21c49e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104276592-172.17.0.4-1595540040916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45400,DS-833b5c83-5f9c-4dea-9392-77ffd0d8e7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-c4e3b97d-fdf5-4e51-b552-ae48007a067b,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-86d5fe12-1f9d-44be-a41f-71cd9670e3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-7e24b9d3-2ede-4870-b861-3da83772b8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-f197ae39-9d89-4920-ba7f-a14b4f60e5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-5a55c2df-d09e-4de0-bb17-549994b26437,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-b8d9dc03-1388-40b4-8a13-247508b56196,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-f7b68923-0765-4fa2-8df8-e44a21c49e30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15353361-172.17.0.4-1595540690915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-995b7782-a559-42ae-b3ec-f4751c93dccc,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-d80c414f-14af-4ed4-a842-bb5b53b05762,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-ce8019c1-7ce1-4c14-a30a-f0b699d169f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-131a9c58-21e2-4534-90fe-ad151b0d9565,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-ae40ec1e-92b4-4137-a38c-74a84a95bb57,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-951c6153-153b-46e4-a308-7d0afd6dddac,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-23cd41f5-8c66-4245-9049-e7e427774ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-6d5d0f2b-c974-4405-9b5e-6583cb4e99d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-15353361-172.17.0.4-1595540690915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-995b7782-a559-42ae-b3ec-f4751c93dccc,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-d80c414f-14af-4ed4-a842-bb5b53b05762,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-ce8019c1-7ce1-4c14-a30a-f0b699d169f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-131a9c58-21e2-4534-90fe-ad151b0d9565,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-ae40ec1e-92b4-4137-a38c-74a84a95bb57,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-951c6153-153b-46e4-a308-7d0afd6dddac,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-23cd41f5-8c66-4245-9049-e7e427774ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-6d5d0f2b-c974-4405-9b5e-6583cb4e99d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671808514-172.17.0.4-1595541024437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40082,DS-6398a270-34d4-4baa-bfc7-2cf2c53efcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-c5f0e43e-13c1-46c4-b476-1cea68763448,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-1ba4d486-9b87-4c51-9508-8b24bd2fdeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-ba4ff000-6803-4b35-87cf-6d3852854352,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-e3f0544e-7b36-482a-a531-bf627e5c9ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-87fc056e-6f09-4db9-8179-b58322fada8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-6b6679dc-78c8-4ad9-ad89-54b4590d0c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-206c1bec-e438-429a-8646-94204ab51c2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671808514-172.17.0.4-1595541024437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40082,DS-6398a270-34d4-4baa-bfc7-2cf2c53efcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-c5f0e43e-13c1-46c4-b476-1cea68763448,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-1ba4d486-9b87-4c51-9508-8b24bd2fdeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-ba4ff000-6803-4b35-87cf-6d3852854352,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-e3f0544e-7b36-482a-a531-bf627e5c9ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-87fc056e-6f09-4db9-8179-b58322fada8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-6b6679dc-78c8-4ad9-ad89-54b4590d0c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-206c1bec-e438-429a-8646-94204ab51c2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117575524-172.17.0.4-1595541115534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38436,DS-2fdbc310-4526-4d26-b1b7-2b105b7b221b,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-47a7a22c-4982-4d3a-9a3f-09549d204ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-3692171c-71d2-42a0-8a73-de0e26b8e6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-a83b4892-94c8-41c4-91ca-589e6b8b5901,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-169d4781-6c33-49d8-bbc0-5413662b1c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-7fd88b1c-9748-4c1f-8f80-3b75ec164b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-81e2ac24-2b83-415e-b54c-cf1a8f370506,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-8cc86d75-8750-4350-9e12-ad92f233272a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117575524-172.17.0.4-1595541115534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38436,DS-2fdbc310-4526-4d26-b1b7-2b105b7b221b,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-47a7a22c-4982-4d3a-9a3f-09549d204ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-3692171c-71d2-42a0-8a73-de0e26b8e6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-a83b4892-94c8-41c4-91ca-589e6b8b5901,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-169d4781-6c33-49d8-bbc0-5413662b1c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38694,DS-7fd88b1c-9748-4c1f-8f80-3b75ec164b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-81e2ac24-2b83-415e-b54c-cf1a8f370506,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-8cc86d75-8750-4350-9e12-ad92f233272a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044981846-172.17.0.4-1595542133978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37087,DS-c97b8d7d-f064-457c-b68f-4d7dcafe4c40,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-a0bac615-0681-4012-8a9e-cb4f24266797,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-b15b0ce9-93bc-43b6-bf6f-35515e4349ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-9606dd56-a0e1-4f3b-96ef-e28553859ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-1f161eb6-ef71-4994-a1dc-6f0547d78554,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-e9faea1c-59a6-4c88-805b-f557ec58a5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-62eec49e-22c3-4433-bc7e-28c4cb38782c,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-3980f1a3-10b7-4842-ab68-edd9350bd816,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044981846-172.17.0.4-1595542133978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37087,DS-c97b8d7d-f064-457c-b68f-4d7dcafe4c40,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-a0bac615-0681-4012-8a9e-cb4f24266797,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-b15b0ce9-93bc-43b6-bf6f-35515e4349ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-9606dd56-a0e1-4f3b-96ef-e28553859ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-1f161eb6-ef71-4994-a1dc-6f0547d78554,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-e9faea1c-59a6-4c88-805b-f557ec58a5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-62eec49e-22c3-4433-bc7e-28c4cb38782c,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-3980f1a3-10b7-4842-ab68-edd9350bd816,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228129356-172.17.0.4-1595542837196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41942,DS-d9982371-c84b-4430-a92b-7f86dc100227,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-95b03a3f-d73e-489f-ae36-141a37ecea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-bfc47146-eb05-4fd4-afdc-98c36d4216dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-bb9fcb6b-a845-4c84-9510-12d90ed7095e,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-fd5db788-8295-4cf6-92df-895902eb8e81,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-721598a3-e1b3-458b-914c-5bea64eddc20,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-15832275-d7bb-4ece-ab7f-f8eed7941f89,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-bd9f813e-0ab1-4caf-b657-e86ebab0c02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228129356-172.17.0.4-1595542837196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41942,DS-d9982371-c84b-4430-a92b-7f86dc100227,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-95b03a3f-d73e-489f-ae36-141a37ecea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-bfc47146-eb05-4fd4-afdc-98c36d4216dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-bb9fcb6b-a845-4c84-9510-12d90ed7095e,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-fd5db788-8295-4cf6-92df-895902eb8e81,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-721598a3-e1b3-458b-914c-5bea64eddc20,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-15832275-d7bb-4ece-ab7f-f8eed7941f89,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-bd9f813e-0ab1-4caf-b657-e86ebab0c02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272384064-172.17.0.4-1595542876770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35896,DS-8e46489b-0f7d-4dbc-bd0a-98d329f2f8de,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-dea81941-5b39-4828-a4d1-4ccb0f2feed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-5e27cd6c-2611-4ba6-a725-fa5dfb14ca9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-7791d66d-b8a3-4f97-8b2a-792eb157900e,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-f51c5d17-0498-48c0-bdc7-3eb7cf00c45e,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-f9fd7a92-6f39-4a6a-9ea0-d8417107c6db,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-d5027969-640c-4a65-a800-912ee6724d79,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-75bddc9d-89bd-4943-8c79-413487960ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272384064-172.17.0.4-1595542876770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35896,DS-8e46489b-0f7d-4dbc-bd0a-98d329f2f8de,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-dea81941-5b39-4828-a4d1-4ccb0f2feed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-5e27cd6c-2611-4ba6-a725-fa5dfb14ca9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-7791d66d-b8a3-4f97-8b2a-792eb157900e,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-f51c5d17-0498-48c0-bdc7-3eb7cf00c45e,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-f9fd7a92-6f39-4a6a-9ea0-d8417107c6db,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-d5027969-640c-4a65-a800-912ee6724d79,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-75bddc9d-89bd-4943-8c79-413487960ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-183160278-172.17.0.4-1595543334805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43103,DS-a27170ab-1088-48d3-8833-ed4bcc988306,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-d4443004-7d20-4ef9-8e72-bb8e1df1f46f,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-2dfea9e7-368a-45c4-82e1-d78cd4a386eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-e6492e35-f5e9-41af-9daf-27961d64f2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-a261f363-95d8-4bbc-914c-6e767091b011,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-17f45a00-c791-469d-ac35-a80d9d8df298,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-e5616c0c-6929-4d82-9aba-c4e1b29d77e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-7a31e656-3b95-4eae-9bf4-e90d4c15e8c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-183160278-172.17.0.4-1595543334805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43103,DS-a27170ab-1088-48d3-8833-ed4bcc988306,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-d4443004-7d20-4ef9-8e72-bb8e1df1f46f,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-2dfea9e7-368a-45c4-82e1-d78cd4a386eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-e6492e35-f5e9-41af-9daf-27961d64f2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-a261f363-95d8-4bbc-914c-6e767091b011,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-17f45a00-c791-469d-ac35-a80d9d8df298,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-e5616c0c-6929-4d82-9aba-c4e1b29d77e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-7a31e656-3b95-4eae-9bf4-e90d4c15e8c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6873
