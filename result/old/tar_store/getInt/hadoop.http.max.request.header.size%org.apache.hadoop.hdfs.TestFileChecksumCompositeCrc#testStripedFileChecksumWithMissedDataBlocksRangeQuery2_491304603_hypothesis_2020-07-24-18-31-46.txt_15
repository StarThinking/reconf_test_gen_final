reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547616773-172.17.0.3-1595615597012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39017,DS-b024db07-8044-40c7-895c-79d0793d3698,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-980e3eee-8e01-49c8-b022-b70f9df1ddcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-591e0a48-a721-4d23-b33f-28c3907a1166,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-3fe3c964-80f3-4708-ba2f-2e41bccee9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-42db3634-529f-419f-a7c9-9548d2aba8de,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-3218ab98-0c3b-468c-a65e-3f72c004555e,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-1a9cd59a-74a1-46d2-8286-fabb63e6c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-fe349aaa-b025-4147-b380-989d67c4a149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547616773-172.17.0.3-1595615597012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39017,DS-b024db07-8044-40c7-895c-79d0793d3698,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-980e3eee-8e01-49c8-b022-b70f9df1ddcc,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-591e0a48-a721-4d23-b33f-28c3907a1166,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-3fe3c964-80f3-4708-ba2f-2e41bccee9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-42db3634-529f-419f-a7c9-9548d2aba8de,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-3218ab98-0c3b-468c-a65e-3f72c004555e,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-1a9cd59a-74a1-46d2-8286-fabb63e6c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-fe349aaa-b025-4147-b380-989d67c4a149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487455089-172.17.0.3-1595615959066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40351,DS-2398c9a5-c5cb-4b32-b005-9f6b4b75f0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-a377befc-9e91-4ef3-86a2-0e0857192129,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-d275e440-e662-4895-84c0-2a423a3915ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-63415311-ade6-42bd-a35b-8eff58614d61,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-a1011a34-983d-4e50-a93f-549b7ab636e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-3b7c1dce-cede-44fe-8432-cab2a25c460c,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-12533162-ae87-431f-a68d-7d08b8993639,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-81f599de-dbaf-4ac3-bdbc-ae3318f13de1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487455089-172.17.0.3-1595615959066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40351,DS-2398c9a5-c5cb-4b32-b005-9f6b4b75f0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-a377befc-9e91-4ef3-86a2-0e0857192129,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-d275e440-e662-4895-84c0-2a423a3915ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-63415311-ade6-42bd-a35b-8eff58614d61,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-a1011a34-983d-4e50-a93f-549b7ab636e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-3b7c1dce-cede-44fe-8432-cab2a25c460c,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-12533162-ae87-431f-a68d-7d08b8993639,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-81f599de-dbaf-4ac3-bdbc-ae3318f13de1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084210699-172.17.0.3-1595616164469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40581,DS-ba12fa4e-6bc1-4a94-a47b-ad526d108612,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-6f3ecd56-35b8-41e4-8634-c439f602bfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-d22107bd-6479-497f-af24-142e64a72d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-7f31402d-58b8-4430-9227-78d4e31a6c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-63843161-84f6-41c3-80d9-a1ade9078b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-820c9aaa-119c-4b66-8b8e-14131edc635d,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-5889de00-660c-4813-9f98-1d93b065cfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-20bbb826-b7e2-4b4f-b5d6-78f75558c858,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084210699-172.17.0.3-1595616164469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40581,DS-ba12fa4e-6bc1-4a94-a47b-ad526d108612,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-6f3ecd56-35b8-41e4-8634-c439f602bfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-d22107bd-6479-497f-af24-142e64a72d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-7f31402d-58b8-4430-9227-78d4e31a6c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-63843161-84f6-41c3-80d9-a1ade9078b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-820c9aaa-119c-4b66-8b8e-14131edc635d,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-5889de00-660c-4813-9f98-1d93b065cfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-20bbb826-b7e2-4b4f-b5d6-78f75558c858,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1075452558-172.17.0.3-1595616538693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40671,DS-965db0cf-a405-4958-8de1-6b80e8330157,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-946e1266-b47e-4d34-a496-5d1c47125c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-ec131e43-179d-4cc0-871a-6fa054eafb71,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-3cb48342-92cf-45d6-9b17-0156747552cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-0023c4f1-1242-45ba-83b4-7ac03b692264,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-0f871456-df44-46d6-b674-b0ec23179788,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-41649b74-93ec-47f5-b422-49fe476309dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-5f73ca98-a467-4885-b8db-5d98a23ecde4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1075452558-172.17.0.3-1595616538693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40671,DS-965db0cf-a405-4958-8de1-6b80e8330157,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-946e1266-b47e-4d34-a496-5d1c47125c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-ec131e43-179d-4cc0-871a-6fa054eafb71,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-3cb48342-92cf-45d6-9b17-0156747552cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-0023c4f1-1242-45ba-83b4-7ac03b692264,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-0f871456-df44-46d6-b674-b0ec23179788,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-41649b74-93ec-47f5-b422-49fe476309dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-5f73ca98-a467-4885-b8db-5d98a23ecde4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568204581-172.17.0.3-1595616649651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35210,DS-f3297021-8ee6-4cd6-b5f9-33fd04214a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-99725642-0d1c-4934-ac61-c24bc2db5a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-4ced0926-caa1-4ce8-b98b-3650940d5d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-574d8674-0cf6-4ad7-955a-9a6b28aaf31a,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-86245552-9f81-4652-a102-096724e96308,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-5cf7dc9c-7874-4b20-9c0b-e9852e1047d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-df1fc02d-ec4d-4567-80e0-8ce47720c421,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-8f22e83e-7646-4808-837d-a1ba5196a356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568204581-172.17.0.3-1595616649651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35210,DS-f3297021-8ee6-4cd6-b5f9-33fd04214a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-99725642-0d1c-4934-ac61-c24bc2db5a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-4ced0926-caa1-4ce8-b98b-3650940d5d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-574d8674-0cf6-4ad7-955a-9a6b28aaf31a,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-86245552-9f81-4652-a102-096724e96308,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-5cf7dc9c-7874-4b20-9c0b-e9852e1047d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-df1fc02d-ec4d-4567-80e0-8ce47720c421,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-8f22e83e-7646-4808-837d-a1ba5196a356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520668554-172.17.0.3-1595616875952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38265,DS-488114ae-4853-44a8-9753-1b791551eee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-fd8a36e3-6eb4-495b-a55c-7bd8ee46be81,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-50056492-5eac-4d0b-b742-0990cebc1986,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-090f0673-2211-4cd7-9048-fc3caef21830,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-379c50ed-0639-453c-bcfc-d75ff152343f,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-2ce2c391-6d2b-413d-866b-f40c980db2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-e00aff78-006c-4d60-99db-74dbd22018b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-25d6bc22-4164-433f-af6b-3fd916e89040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520668554-172.17.0.3-1595616875952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38265,DS-488114ae-4853-44a8-9753-1b791551eee6,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-fd8a36e3-6eb4-495b-a55c-7bd8ee46be81,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-50056492-5eac-4d0b-b742-0990cebc1986,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-090f0673-2211-4cd7-9048-fc3caef21830,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-379c50ed-0639-453c-bcfc-d75ff152343f,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-2ce2c391-6d2b-413d-866b-f40c980db2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-e00aff78-006c-4d60-99db-74dbd22018b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-25d6bc22-4164-433f-af6b-3fd916e89040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498858879-172.17.0.3-1595616912402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41136,DS-5d40d3ac-414b-45fd-9605-6ed242b96604,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-5cf00379-660c-47e9-8b79-ba0e05dee679,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-49b17534-b167-4c56-b852-9622094cb571,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-b23d4761-fe2b-428e-9ef1-1f599a3c73ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-0e0a3a75-e6ca-47ce-ab31-ab37884e3b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-f6bf4fc8-7128-4fb7-abae-47bd3dba39ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-ac366bce-e50b-4c49-b159-55f97fa6cf94,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-bfd25379-90c9-4af7-a600-11bac6a26323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498858879-172.17.0.3-1595616912402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41136,DS-5d40d3ac-414b-45fd-9605-6ed242b96604,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-5cf00379-660c-47e9-8b79-ba0e05dee679,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-49b17534-b167-4c56-b852-9622094cb571,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-b23d4761-fe2b-428e-9ef1-1f599a3c73ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-0e0a3a75-e6ca-47ce-ab31-ab37884e3b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-f6bf4fc8-7128-4fb7-abae-47bd3dba39ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-ac366bce-e50b-4c49-b159-55f97fa6cf94,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-bfd25379-90c9-4af7-a600-11bac6a26323,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207186821-172.17.0.3-1595617035809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45134,DS-d04358b6-a66e-4c55-b7ba-3914176a035e,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-7af85a15-fdb8-4e56-9f56-1bc54981cb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-d41ae962-8412-4e1b-ab32-f1a7820e9535,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-15b72412-59bf-4ed4-a7a9-2e2b66849003,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-03da7b5c-8268-426a-8954-2952397b46e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-63dab348-0c6d-4a6b-93ae-9b4ecdddc770,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-66e09203-11d8-48fa-9196-ee7d15c3cc75,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-c5347ad7-4601-4cab-a1db-dccbcb908feb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207186821-172.17.0.3-1595617035809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45134,DS-d04358b6-a66e-4c55-b7ba-3914176a035e,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-7af85a15-fdb8-4e56-9f56-1bc54981cb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-d41ae962-8412-4e1b-ab32-f1a7820e9535,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-15b72412-59bf-4ed4-a7a9-2e2b66849003,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-03da7b5c-8268-426a-8954-2952397b46e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-63dab348-0c6d-4a6b-93ae-9b4ecdddc770,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-66e09203-11d8-48fa-9196-ee7d15c3cc75,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-c5347ad7-4601-4cab-a1db-dccbcb908feb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317778614-172.17.0.3-1595617258350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38736,DS-e4dab0ee-5de6-4fd6-becc-f85c4641ff2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-d1402ed0-c7b1-4083-8b94-1e3ef26b2a53,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-ca8c59d7-dcf3-4a63-91ca-a3e42b098dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-978b7cc3-ed60-46d3-89ef-c74659835246,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-14454aa1-f41a-4908-bce4-9ee8485f670e,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-1c8c638c-540c-4f96-8d07-1262d60aef53,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-7bfcf875-107c-44d6-a1fe-50b9446f2d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-67f35373-e405-4fb7-b725-f017bd6854af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317778614-172.17.0.3-1595617258350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38736,DS-e4dab0ee-5de6-4fd6-becc-f85c4641ff2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-d1402ed0-c7b1-4083-8b94-1e3ef26b2a53,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-ca8c59d7-dcf3-4a63-91ca-a3e42b098dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-978b7cc3-ed60-46d3-89ef-c74659835246,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-14454aa1-f41a-4908-bce4-9ee8485f670e,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-1c8c638c-540c-4f96-8d07-1262d60aef53,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-7bfcf875-107c-44d6-a1fe-50b9446f2d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-67f35373-e405-4fb7-b725-f017bd6854af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923494126-172.17.0.3-1595617485024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34513,DS-a55b863a-8984-4876-92c1-35539f6eabd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-0c81d640-8949-4796-a2ae-ce983d968d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-56868561-985b-402f-b2f7-4cebd7142f52,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-0427513e-7453-4c71-a86e-4e8d9ec5bab0,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-4e33a38e-f721-4487-81b1-587c1373776f,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-3966f7ef-5fe1-4dec-a51e-d175aeee3c83,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-fb543e44-b602-441f-b566-185c300660d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-b7be349c-54bd-45bb-8499-0720299b1ba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923494126-172.17.0.3-1595617485024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34513,DS-a55b863a-8984-4876-92c1-35539f6eabd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-0c81d640-8949-4796-a2ae-ce983d968d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-56868561-985b-402f-b2f7-4cebd7142f52,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-0427513e-7453-4c71-a86e-4e8d9ec5bab0,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-4e33a38e-f721-4487-81b1-587c1373776f,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-3966f7ef-5fe1-4dec-a51e-d175aeee3c83,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-fb543e44-b602-441f-b566-185c300660d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-b7be349c-54bd-45bb-8499-0720299b1ba4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240388032-172.17.0.3-1595617638866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35513,DS-01767b16-a6bd-4084-8d36-5b9078a3e0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-c8154744-d32c-420c-9b67-8f037a55f479,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-b25154e4-ef1e-4e41-844f-34aa430f2193,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-3d11dded-443c-41ec-b591-987123dabccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-7a5457f5-63c3-4399-898a-30687f02dcec,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-b1bd926b-413f-4b71-bb94-f753886db2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-4b34a072-2eb0-43eb-b303-a78e7cf495dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-cb6e5071-7b6b-4203-b955-3b933bbe1b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240388032-172.17.0.3-1595617638866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35513,DS-01767b16-a6bd-4084-8d36-5b9078a3e0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-c8154744-d32c-420c-9b67-8f037a55f479,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-b25154e4-ef1e-4e41-844f-34aa430f2193,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-3d11dded-443c-41ec-b591-987123dabccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-7a5457f5-63c3-4399-898a-30687f02dcec,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-b1bd926b-413f-4b71-bb94-f753886db2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-4b34a072-2eb0-43eb-b303-a78e7cf495dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-cb6e5071-7b6b-4203-b955-3b933bbe1b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387770704-172.17.0.3-1595618104361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36635,DS-cb2a033d-c441-4708-b9a4-10834fe58cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-fc93f8e7-d0d2-4681-8733-5e6b3b7fec04,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-7338bda6-0dd6-448b-b7cf-03045a28c6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-697e78e3-7427-44e9-9e2b-3e354f9f475b,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-c78aec67-1834-40da-b380-a8fb96d38d00,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-37dd0314-c6c0-41ce-b0a2-5922ba9cb512,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-7310ebc2-e875-4f0d-8bef-228243beb3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-8a026b9d-dd8e-4edd-8718-4869225e3e2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387770704-172.17.0.3-1595618104361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36635,DS-cb2a033d-c441-4708-b9a4-10834fe58cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-fc93f8e7-d0d2-4681-8733-5e6b3b7fec04,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-7338bda6-0dd6-448b-b7cf-03045a28c6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-697e78e3-7427-44e9-9e2b-3e354f9f475b,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-c78aec67-1834-40da-b380-a8fb96d38d00,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-37dd0314-c6c0-41ce-b0a2-5922ba9cb512,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-7310ebc2-e875-4f0d-8bef-228243beb3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-8a026b9d-dd8e-4edd-8718-4869225e3e2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83800830-172.17.0.3-1595618142696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39437,DS-a14d0789-fbe1-4753-961a-88ee9f5679d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-9b198777-c352-4522-90d7-48d2c60017e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-a69a53b2-8563-4779-9733-2bfd7fc717b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-a98124e9-211d-4a77-8674-69189847d94d,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-bd81589b-db96-4eb9-8521-f4793559e34f,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-6836a5fa-6a01-4002-ad3c-e685b5ee5b49,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-95199459-3776-492e-aef8-2b3d1c35ce7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-35845fcd-0292-4e30-8df5-ff36d4050d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83800830-172.17.0.3-1595618142696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39437,DS-a14d0789-fbe1-4753-961a-88ee9f5679d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-9b198777-c352-4522-90d7-48d2c60017e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-a69a53b2-8563-4779-9733-2bfd7fc717b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-a98124e9-211d-4a77-8674-69189847d94d,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-bd81589b-db96-4eb9-8521-f4793559e34f,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-6836a5fa-6a01-4002-ad3c-e685b5ee5b49,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-95199459-3776-492e-aef8-2b3d1c35ce7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-35845fcd-0292-4e30-8df5-ff36d4050d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415387431-172.17.0.3-1595618292750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46405,DS-91571f94-e12d-453f-919b-834a0ad79dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-34a16af7-909d-4412-a860-c0dbc049e868,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-d2cfd07d-437f-4dde-89be-4d52dc87f86a,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-72b5dde2-4a4f-4b92-82d2-ede3d4ecf7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-a7bc9797-cf6f-4380-a163-3e75b198a892,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-bb54f227-0862-4fd3-a9cd-40efe6323bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-92910b31-8c9d-4030-b9b6-fef74fb372cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-2ed82428-d435-4ce5-9d8c-3b9a5c65e53d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-415387431-172.17.0.3-1595618292750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46405,DS-91571f94-e12d-453f-919b-834a0ad79dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-34a16af7-909d-4412-a860-c0dbc049e868,DISK], DatanodeInfoWithStorage[127.0.0.1:42777,DS-d2cfd07d-437f-4dde-89be-4d52dc87f86a,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-72b5dde2-4a4f-4b92-82d2-ede3d4ecf7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-a7bc9797-cf6f-4380-a163-3e75b198a892,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-bb54f227-0862-4fd3-a9cd-40efe6323bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-92910b31-8c9d-4030-b9b6-fef74fb372cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-2ed82428-d435-4ce5-9d8c-3b9a5c65e53d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570116896-172.17.0.3-1595619002205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43432,DS-05ed496b-32bd-448d-8f4c-c90b9ae3c364,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-a9715267-bca3-42b7-a635-eaaf198e832d,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-de9728b8-3721-4725-b856-f019c88e6356,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-48358b88-48c9-42c8-9681-cb045b3d4ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-7ee3ea95-9720-4c1f-8c94-3da0917a6c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-407a3efa-1425-409f-97fe-31f4092a56b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-25c89b0a-1ed8-44e6-bfde-e663c32bce03,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-75927ecc-128c-41b7-9845-9d48a2a397f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-570116896-172.17.0.3-1595619002205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43432,DS-05ed496b-32bd-448d-8f4c-c90b9ae3c364,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-a9715267-bca3-42b7-a635-eaaf198e832d,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-de9728b8-3721-4725-b856-f019c88e6356,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-48358b88-48c9-42c8-9681-cb045b3d4ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-7ee3ea95-9720-4c1f-8c94-3da0917a6c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-407a3efa-1425-409f-97fe-31f4092a56b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-25c89b0a-1ed8-44e6-bfde-e663c32bce03,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-75927ecc-128c-41b7-9845-9d48a2a397f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401587830-172.17.0.3-1595619074169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37014,DS-8656d36b-509d-479f-a4af-6c4c2dd92b16,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-cddbdc5e-5a2f-44b0-9c6c-5ee0911822fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-4e36f110-b8d5-4445-a861-88be79e852c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-5f7c1384-06f6-44f9-816a-903c932d9dea,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-c9778994-32e9-47ab-998c-a9ea122989d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-7d717ceb-18d0-4b47-a461-7699c5c4352b,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-dcdec904-6745-496a-8281-2adc94e7b804,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-b8b2f385-ba2b-4df7-8217-3026c12e9244,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1401587830-172.17.0.3-1595619074169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37014,DS-8656d36b-509d-479f-a4af-6c4c2dd92b16,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-cddbdc5e-5a2f-44b0-9c6c-5ee0911822fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-4e36f110-b8d5-4445-a861-88be79e852c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-5f7c1384-06f6-44f9-816a-903c932d9dea,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-c9778994-32e9-47ab-998c-a9ea122989d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-7d717ceb-18d0-4b47-a461-7699c5c4352b,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-dcdec904-6745-496a-8281-2adc94e7b804,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-b8b2f385-ba2b-4df7-8217-3026c12e9244,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260674011-172.17.0.3-1595619107702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38581,DS-c38bb74d-637f-4beb-afec-1996d63b2c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-278e369c-ff52-48d8-b7f0-641f259c177c,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-99882d1f-75f4-4c52-a860-2aab8712bbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-7418525d-0fc8-4c3e-b756-6e0d576529c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-4af607e1-37ce-486e-8e6a-11c06a30006b,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-749e51ba-a5f1-41ee-b195-b543aa5df1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-55d0f91f-fe2b-4746-9fb7-94f0c64fa0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-78a9ca64-89c3-4fdd-837f-330f5e012ed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260674011-172.17.0.3-1595619107702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38581,DS-c38bb74d-637f-4beb-afec-1996d63b2c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-278e369c-ff52-48d8-b7f0-641f259c177c,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-99882d1f-75f4-4c52-a860-2aab8712bbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-7418525d-0fc8-4c3e-b756-6e0d576529c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-4af607e1-37ce-486e-8e6a-11c06a30006b,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-749e51ba-a5f1-41ee-b195-b543aa5df1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-55d0f91f-fe2b-4746-9fb7-94f0c64fa0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-78a9ca64-89c3-4fdd-837f-330f5e012ed5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694099103-172.17.0.3-1595619514398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37880,DS-856407f4-0e6a-4197-bb34-665be32cd355,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-ccc53a95-b9d0-4a8a-bb1d-b94ee66926aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-44e58827-a3a8-4894-94c3-f0e6fe5f4b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-ac159a5a-1a90-4b3d-bc62-b2d6cea830f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-0815017b-162e-4fd9-85b9-05cfd101d87f,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-f08a8808-cca8-48f7-8266-b4315027844f,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-b07940ee-8cb4-4902-91af-d7912a2b9ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-9ae0926d-ff7b-4017-880d-ab13db89905b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694099103-172.17.0.3-1595619514398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37880,DS-856407f4-0e6a-4197-bb34-665be32cd355,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-ccc53a95-b9d0-4a8a-bb1d-b94ee66926aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-44e58827-a3a8-4894-94c3-f0e6fe5f4b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-ac159a5a-1a90-4b3d-bc62-b2d6cea830f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-0815017b-162e-4fd9-85b9-05cfd101d87f,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-f08a8808-cca8-48f7-8266-b4315027844f,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-b07940ee-8cb4-4902-91af-d7912a2b9ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-9ae0926d-ff7b-4017-880d-ab13db89905b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872256141-172.17.0.3-1595619927392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33973,DS-f8ccc4e1-da93-4e2c-8aa0-b59f99297412,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-2064b19d-925f-428a-b0f2-790b82afe57f,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-49b5830d-9e69-4253-aab8-efd574e53377,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-c39e4cd9-95de-4b88-a63e-c17ebc6e1078,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-3870cf01-b2fe-4cf2-9a73-249c3e9bba31,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-b3f380f9-de84-46be-8be8-5cca7f087959,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-3fcb6f80-ea46-4e53-9ab3-3831a7c6aec7,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-1e6097b1-97cf-47d9-98a7-f9237540367e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872256141-172.17.0.3-1595619927392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33973,DS-f8ccc4e1-da93-4e2c-8aa0-b59f99297412,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-2064b19d-925f-428a-b0f2-790b82afe57f,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-49b5830d-9e69-4253-aab8-efd574e53377,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-c39e4cd9-95de-4b88-a63e-c17ebc6e1078,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-3870cf01-b2fe-4cf2-9a73-249c3e9bba31,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-b3f380f9-de84-46be-8be8-5cca7f087959,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-3fcb6f80-ea46-4e53-9ab3-3831a7c6aec7,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-1e6097b1-97cf-47d9-98a7-f9237540367e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627841636-172.17.0.3-1595620266534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-b827e38e-794f-46f0-9259-baa6c81c6487,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-365312a8-ccd7-4f28-8903-e681de6612b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-1b1e03a2-80f2-46fb-887e-537641ef0658,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-9bc21828-86f8-4f5b-9d76-11621f7740d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-e30e1f81-446c-4316-b02d-4d8cf85aad92,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-0f562e91-ac68-4fdd-86c4-c3b13e770fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-34afab45-657f-4a78-967d-026fb11ffdab,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-901c5b3a-1b76-4ad9-b723-c75067e93e6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627841636-172.17.0.3-1595620266534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-b827e38e-794f-46f0-9259-baa6c81c6487,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-365312a8-ccd7-4f28-8903-e681de6612b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-1b1e03a2-80f2-46fb-887e-537641ef0658,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-9bc21828-86f8-4f5b-9d76-11621f7740d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-e30e1f81-446c-4316-b02d-4d8cf85aad92,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-0f562e91-ac68-4fdd-86c4-c3b13e770fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-34afab45-657f-4a78-967d-026fb11ffdab,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-901c5b3a-1b76-4ad9-b723-c75067e93e6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383184616-172.17.0.3-1595620398205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37556,DS-8a1af2a8-3281-455e-82b9-cb69e9899fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-9dfa46be-fe64-4def-b392-5559d90b8bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-b0a8fbca-a315-428e-a148-3f7e9561dc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-638993f8-0bdd-46db-8fd2-3112517a5dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-7723a506-4482-4d5e-b3c9-40a61573347c,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-d869b1cc-13f3-4db6-8576-1367afa2e96f,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-b4ef767c-b441-4d32-acc5-487ada31b7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-ebd95481-5cfe-4ce5-928a-b835f09e8e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383184616-172.17.0.3-1595620398205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37556,DS-8a1af2a8-3281-455e-82b9-cb69e9899fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-9dfa46be-fe64-4def-b392-5559d90b8bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-b0a8fbca-a315-428e-a148-3f7e9561dc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-638993f8-0bdd-46db-8fd2-3112517a5dea,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-7723a506-4482-4d5e-b3c9-40a61573347c,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-d869b1cc-13f3-4db6-8576-1367afa2e96f,DISK], DatanodeInfoWithStorage[127.0.0.1:45058,DS-b4ef767c-b441-4d32-acc5-487ada31b7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-ebd95481-5cfe-4ce5-928a-b835f09e8e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68098375-172.17.0.3-1595620490599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34206,DS-06cf06c1-007c-4b9a-9805-a557532dc341,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-45d7b3cb-2b5f-461d-a915-d41612d07d47,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-4897d0ac-cf25-4a8e-be48-6cd305ed027f,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-0aeb6f05-6a9c-4cb5-a347-495decd0a81a,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-d7da4571-0380-44af-8180-1d2bb4731b40,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-b94d005d-b511-4608-afad-1c3aee9b9def,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-7629d7b8-9a95-4c5d-b371-1ec1f614d5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-a79c8305-0ed4-4d6a-a4ed-5bf36ea85ae1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-68098375-172.17.0.3-1595620490599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34206,DS-06cf06c1-007c-4b9a-9805-a557532dc341,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-45d7b3cb-2b5f-461d-a915-d41612d07d47,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-4897d0ac-cf25-4a8e-be48-6cd305ed027f,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-0aeb6f05-6a9c-4cb5-a347-495decd0a81a,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-d7da4571-0380-44af-8180-1d2bb4731b40,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-b94d005d-b511-4608-afad-1c3aee9b9def,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-7629d7b8-9a95-4c5d-b371-1ec1f614d5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-a79c8305-0ed4-4d6a-a4ed-5bf36ea85ae1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978939691-172.17.0.3-1595620526466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41528,DS-0d66a57e-b0b2-42db-a30d-38da4e8a2444,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-ac99efbe-8711-484f-977e-8c0b794cfac5,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-b1bc379c-60dc-4976-9002-57e3b7e9258f,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-83955556-eaf2-4b13-8269-6b9a21aeebc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-01a3503a-f8df-4c84-8c99-43fa3b06b1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-53ac3436-277a-43f0-9ecc-e8e9738cf98f,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-96531a68-bd27-4e5c-96d2-c8512a92c3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-0fa3b823-d3c0-4580-8141-adf71be574e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978939691-172.17.0.3-1595620526466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41528,DS-0d66a57e-b0b2-42db-a30d-38da4e8a2444,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-ac99efbe-8711-484f-977e-8c0b794cfac5,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-b1bc379c-60dc-4976-9002-57e3b7e9258f,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-83955556-eaf2-4b13-8269-6b9a21aeebc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-01a3503a-f8df-4c84-8c99-43fa3b06b1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-53ac3436-277a-43f0-9ecc-e8e9738cf98f,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-96531a68-bd27-4e5c-96d2-c8512a92c3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-0fa3b823-d3c0-4580-8141-adf71be574e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132638669-172.17.0.3-1595620664154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39722,DS-487fcf1a-e24c-4f04-898c-39dbf8a9a4da,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-df908aa3-ef67-4258-b6be-6cdd93a082a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-49443bbf-e035-4c08-aca1-828fca544c59,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-9df897c4-bae0-42f4-97f0-b024820d252b,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-00e44a14-1ae0-49cc-9e0d-3b86e5560935,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-ad1e9a66-60d1-445c-85af-f3b2b0737d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-1a9bea52-6214-43ed-8b41-8dbf623455a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-92b96589-0c89-41e9-ab2e-07e49b33624d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132638669-172.17.0.3-1595620664154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39722,DS-487fcf1a-e24c-4f04-898c-39dbf8a9a4da,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-df908aa3-ef67-4258-b6be-6cdd93a082a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-49443bbf-e035-4c08-aca1-828fca544c59,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-9df897c4-bae0-42f4-97f0-b024820d252b,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-00e44a14-1ae0-49cc-9e0d-3b86e5560935,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-ad1e9a66-60d1-445c-85af-f3b2b0737d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-1a9bea52-6214-43ed-8b41-8dbf623455a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-92b96589-0c89-41e9-ab2e-07e49b33624d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892851400-172.17.0.3-1595620833896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42212,DS-1dbb6b9a-6be7-4617-b1ca-af982de6d63e,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-6b4b1861-f781-4d0d-aaf8-9a6970000b34,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-44cd8817-6445-4119-9709-1e33c4658eff,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-ff4ea6e9-c7c3-4a58-9706-77064e2bafe5,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-45ec561d-28a2-4c6a-94e7-1f85911ac688,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-5f41b813-a7e8-41e2-afdc-ba2667a640b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-5f75f99d-ec06-4b35-80bb-4cc4ee6abeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-ef15dbe1-596e-442e-8940-8e0cc11f8c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892851400-172.17.0.3-1595620833896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42212,DS-1dbb6b9a-6be7-4617-b1ca-af982de6d63e,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-6b4b1861-f781-4d0d-aaf8-9a6970000b34,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-44cd8817-6445-4119-9709-1e33c4658eff,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-ff4ea6e9-c7c3-4a58-9706-77064e2bafe5,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-45ec561d-28a2-4c6a-94e7-1f85911ac688,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-5f41b813-a7e8-41e2-afdc-ba2667a640b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-5f75f99d-ec06-4b35-80bb-4cc4ee6abeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-ef15dbe1-596e-442e-8940-8e0cc11f8c15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491736211-172.17.0.3-1595620862786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39696,DS-405fa387-18b7-4258-9239-dccf22003d82,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-e49b0551-6f69-4ab5-abab-bd3cffa8785a,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-33d3c54e-1970-48d5-9237-7d5946cd4678,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-d8dd7bee-a1b8-4573-bd90-a154384fec14,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-d15b4efc-28e2-4076-9292-47fb8e609c07,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-ea77c334-e4d3-4d20-8298-b23ce93d1430,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-bce79555-5336-4109-9579-50a53fc1c4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-1bfdd64c-9f05-471f-bec8-1139afdbea41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491736211-172.17.0.3-1595620862786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39696,DS-405fa387-18b7-4258-9239-dccf22003d82,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-e49b0551-6f69-4ab5-abab-bd3cffa8785a,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-33d3c54e-1970-48d5-9237-7d5946cd4678,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-d8dd7bee-a1b8-4573-bd90-a154384fec14,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-d15b4efc-28e2-4076-9292-47fb8e609c07,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-ea77c334-e4d3-4d20-8298-b23ce93d1430,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-bce79555-5336-4109-9579-50a53fc1c4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-1bfdd64c-9f05-471f-bec8-1139afdbea41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567067276-172.17.0.3-1595620930154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33965,DS-ca17f458-e1dd-4f70-8385-6c168123330f,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-fe77be49-6353-459f-947b-7314c594137c,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-5349d7c2-cc5c-41e5-8c1f-6d4b0eb02ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-2e6ad782-eff9-4244-a23f-84f9d9c4efc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-81c6c5da-3a81-43a6-abc3-14a30d5ba164,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-34039691-fc2f-400a-9547-195cdcaebe54,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-3f55e0b1-1d96-49bd-bf81-55d840946d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-f037bba9-65ba-4579-ac0b-a79493bf2c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567067276-172.17.0.3-1595620930154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33965,DS-ca17f458-e1dd-4f70-8385-6c168123330f,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-fe77be49-6353-459f-947b-7314c594137c,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-5349d7c2-cc5c-41e5-8c1f-6d4b0eb02ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-2e6ad782-eff9-4244-a23f-84f9d9c4efc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-81c6c5da-3a81-43a6-abc3-14a30d5ba164,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-34039691-fc2f-400a-9547-195cdcaebe54,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-3f55e0b1-1d96-49bd-bf81-55d840946d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-f037bba9-65ba-4579-ac0b-a79493bf2c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5444
