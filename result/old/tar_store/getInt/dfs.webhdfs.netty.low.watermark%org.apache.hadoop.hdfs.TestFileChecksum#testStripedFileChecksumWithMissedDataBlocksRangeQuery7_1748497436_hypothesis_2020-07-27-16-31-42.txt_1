reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530487561-172.17.0.20-1595867522045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45210,DS-5626bff6-a17d-4c3a-b9e0-6d11cb9acbde,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-07cc5447-c9f0-4404-aaf3-b6a0d5796243,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-2f51ad12-d5de-4a47-bcf7-351c495dce26,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-048633a4-bb2d-46f7-9700-36e71bf77efc,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-d8bca6ee-8ced-42de-858c-d759c638bb59,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-4a50f132-b0e6-42e0-a98a-57b223a99c32,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-0312b4f2-09b4-465e-87a1-c53175a13429,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-365bfaea-55d2-4fe4-b254-c8548a0fbfe9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530487561-172.17.0.20-1595867522045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45210,DS-5626bff6-a17d-4c3a-b9e0-6d11cb9acbde,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-07cc5447-c9f0-4404-aaf3-b6a0d5796243,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-2f51ad12-d5de-4a47-bcf7-351c495dce26,DISK], DatanodeInfoWithStorage[127.0.0.1:41882,DS-048633a4-bb2d-46f7-9700-36e71bf77efc,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-d8bca6ee-8ced-42de-858c-d759c638bb59,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-4a50f132-b0e6-42e0-a98a-57b223a99c32,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-0312b4f2-09b4-465e-87a1-c53175a13429,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-365bfaea-55d2-4fe4-b254-c8548a0fbfe9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221920085-172.17.0.20-1595867695049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42715,DS-512f3cf2-d268-4c3d-bf29-7304ad198e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-278b8ced-4ff0-4532-bcbb-6ba5a93c6860,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-267f7283-f672-4f94-8ac5-9c6f4bee89ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-727a8962-bbaf-435c-8671-41cf731fe7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-944e0d88-3c1c-481a-8daa-a1705a13e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-a14a9226-6a1b-4e95-9a23-9c727a6574a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-02f90452-f2a5-49f1-95f7-1e1597f0e768,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-0e930988-0947-4326-b027-cf6de65dbefa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221920085-172.17.0.20-1595867695049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42715,DS-512f3cf2-d268-4c3d-bf29-7304ad198e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-278b8ced-4ff0-4532-bcbb-6ba5a93c6860,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-267f7283-f672-4f94-8ac5-9c6f4bee89ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-727a8962-bbaf-435c-8671-41cf731fe7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-944e0d88-3c1c-481a-8daa-a1705a13e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-a14a9226-6a1b-4e95-9a23-9c727a6574a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-02f90452-f2a5-49f1-95f7-1e1597f0e768,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-0e930988-0947-4326-b027-cf6de65dbefa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361995393-172.17.0.20-1595868008282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34167,DS-8c58d5c0-bb08-4723-9e67-b20c48671a68,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-c59c5e67-6ae4-458a-b90a-4c479244a35e,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-a282a4b6-44bf-4a42-878d-7d754990c0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-349be270-98f9-49aa-817f-93d79f403a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-39a97199-bbad-4c2f-b3c4-9a7dac499453,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-53dc3121-9bbe-4150-878f-10114bb6e178,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-a8dd5d9f-cdee-4021-a0eb-c1b71dde55b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-9a2b5ec4-eeb0-4ef7-9205-e94800395125,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361995393-172.17.0.20-1595868008282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34167,DS-8c58d5c0-bb08-4723-9e67-b20c48671a68,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-c59c5e67-6ae4-458a-b90a-4c479244a35e,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-a282a4b6-44bf-4a42-878d-7d754990c0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-349be270-98f9-49aa-817f-93d79f403a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-39a97199-bbad-4c2f-b3c4-9a7dac499453,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-53dc3121-9bbe-4150-878f-10114bb6e178,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-a8dd5d9f-cdee-4021-a0eb-c1b71dde55b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-9a2b5ec4-eeb0-4ef7-9205-e94800395125,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673564448-172.17.0.20-1595868196248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42918,DS-71390b5e-89e9-4c6e-9da7-f3df6d196fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-72070943-b831-4a4b-aaca-3c3eb3d760c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-e553cfdd-ea5b-4015-a12a-19c83b2c1620,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-baa62b4c-2344-453e-b239-f317e1409c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-a7a12e55-e1ba-4dfa-8d5f-a6569c3d17fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-caaca962-dd20-44c2-b844-e929c07ef46e,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-2815965a-6f73-4352-8f4b-77501f77a3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-6a6a57c5-47e4-4f25-a756-7176515827e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673564448-172.17.0.20-1595868196248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42918,DS-71390b5e-89e9-4c6e-9da7-f3df6d196fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-72070943-b831-4a4b-aaca-3c3eb3d760c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-e553cfdd-ea5b-4015-a12a-19c83b2c1620,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-baa62b4c-2344-453e-b239-f317e1409c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-a7a12e55-e1ba-4dfa-8d5f-a6569c3d17fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-caaca962-dd20-44c2-b844-e929c07ef46e,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-2815965a-6f73-4352-8f4b-77501f77a3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-6a6a57c5-47e4-4f25-a756-7176515827e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23242608-172.17.0.20-1595868436474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37144,DS-d34b98d2-2bf4-4c47-8eaa-fd5d708d7ace,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-18a49b4b-bfec-4ec0-b8dd-0a1930996ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-723ad6f2-3006-44bf-b623-a9d6df430661,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-fa2e74c9-1ad0-4b2a-822a-29194de4ad18,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-b019cb58-af03-49b4-84bf-9d9bd9d3c8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-9f06b107-b8db-49b4-b7af-0e1b4498e421,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-eb8384c5-9689-4779-b9a6-201f96102963,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-9bd8c784-eeac-4b5c-80d1-817d11a9f7e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23242608-172.17.0.20-1595868436474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37144,DS-d34b98d2-2bf4-4c47-8eaa-fd5d708d7ace,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-18a49b4b-bfec-4ec0-b8dd-0a1930996ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-723ad6f2-3006-44bf-b623-a9d6df430661,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-fa2e74c9-1ad0-4b2a-822a-29194de4ad18,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-b019cb58-af03-49b4-84bf-9d9bd9d3c8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-9f06b107-b8db-49b4-b7af-0e1b4498e421,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-eb8384c5-9689-4779-b9a6-201f96102963,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-9bd8c784-eeac-4b5c-80d1-817d11a9f7e5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088001059-172.17.0.20-1595868474462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-ed194fc6-1bfa-4dbc-939d-3f120e45a99a,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-9a70135d-26c0-4737-94ad-73e3f784ad19,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-50fd2ea9-802b-453d-bdf5-35b8363533e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-66e32ed9-6c13-49f3-ac99-5530a12cfbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-7d094484-5230-4ee8-a5cb-796e14d723b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-daf93118-f10d-4954-a3f7-f06d70066e32,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-e029298a-9ef5-4be7-8dcc-8d7caa87c181,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-6c057d65-df27-43c5-8807-00d72622b476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088001059-172.17.0.20-1595868474462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36947,DS-ed194fc6-1bfa-4dbc-939d-3f120e45a99a,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-9a70135d-26c0-4737-94ad-73e3f784ad19,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-50fd2ea9-802b-453d-bdf5-35b8363533e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-66e32ed9-6c13-49f3-ac99-5530a12cfbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-7d094484-5230-4ee8-a5cb-796e14d723b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-daf93118-f10d-4954-a3f7-f06d70066e32,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-e029298a-9ef5-4be7-8dcc-8d7caa87c181,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-6c057d65-df27-43c5-8807-00d72622b476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519269476-172.17.0.20-1595868571562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43876,DS-c4d18d0f-ac18-49f4-8ff8-16d36d5a6923,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-cdb591b4-7a47-4f9f-bf68-999427902ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-5a5d021a-5389-49e4-af58-fc21b3224f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-a0d33df2-ae4e-4f51-9797-a4ad09651e15,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-d189752b-d371-49fa-bb2e-b9c05d90d64b,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-5eed9c96-4f31-4ebe-a6a7-2e701dbfd773,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-6aaa22d1-a48e-40cf-9446-815c0ed1d259,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-a524d341-73c0-4c80-9c69-d2bf1657b9f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519269476-172.17.0.20-1595868571562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43876,DS-c4d18d0f-ac18-49f4-8ff8-16d36d5a6923,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-cdb591b4-7a47-4f9f-bf68-999427902ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-5a5d021a-5389-49e4-af58-fc21b3224f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-a0d33df2-ae4e-4f51-9797-a4ad09651e15,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-d189752b-d371-49fa-bb2e-b9c05d90d64b,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-5eed9c96-4f31-4ebe-a6a7-2e701dbfd773,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-6aaa22d1-a48e-40cf-9446-815c0ed1d259,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-a524d341-73c0-4c80-9c69-d2bf1657b9f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901524633-172.17.0.20-1595868653208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38986,DS-1107d92e-8f46-4da7-9027-0bc93cde4560,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-db6f4992-f655-45ea-9a86-bcdc03fed0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-7ecf48ab-ede7-4b69-8406-6b782b1e79a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-172edfb2-70c0-4e03-9adc-2315159efee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-3d071598-5598-4d69-9902-dd6618fe0369,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-71db643c-a047-4fe0-bac8-5e1ce821924f,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-ab5942c8-6aff-49d6-a882-e665280427aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-b4e87d67-a9e4-47a2-8c91-08796af6797a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901524633-172.17.0.20-1595868653208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38986,DS-1107d92e-8f46-4da7-9027-0bc93cde4560,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-db6f4992-f655-45ea-9a86-bcdc03fed0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-7ecf48ab-ede7-4b69-8406-6b782b1e79a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-172edfb2-70c0-4e03-9adc-2315159efee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-3d071598-5598-4d69-9902-dd6618fe0369,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-71db643c-a047-4fe0-bac8-5e1ce821924f,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-ab5942c8-6aff-49d6-a882-e665280427aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-b4e87d67-a9e4-47a2-8c91-08796af6797a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008267331-172.17.0.20-1595868999003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33163,DS-dbbe892c-6da4-4036-a23c-91397365bdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-da1b1dfa-e8d2-4c41-b068-391f01f08ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-1ee3bd92-60bd-4ae3-af77-5f531b8a5021,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-17c60743-7cfb-436f-8c3c-41eedecd32e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-9dc4c10b-0416-413a-9aa8-4121dca1cb92,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-f268a4c7-171b-4bb1-9272-d19795bb97f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-ccdc4a87-1216-48b1-a8bd-9f5b49e9383d,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-b17adeff-a91f-4958-b0e0-20cbece80f49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008267331-172.17.0.20-1595868999003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33163,DS-dbbe892c-6da4-4036-a23c-91397365bdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-da1b1dfa-e8d2-4c41-b068-391f01f08ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:33062,DS-1ee3bd92-60bd-4ae3-af77-5f531b8a5021,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-17c60743-7cfb-436f-8c3c-41eedecd32e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-9dc4c10b-0416-413a-9aa8-4121dca1cb92,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-f268a4c7-171b-4bb1-9272-d19795bb97f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-ccdc4a87-1216-48b1-a8bd-9f5b49e9383d,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-b17adeff-a91f-4958-b0e0-20cbece80f49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636331027-172.17.0.20-1595869128065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33103,DS-3f342c6d-7b5d-4521-86bb-873c895a280d,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-2d6310e2-6ca2-4bfe-bda1-aa787e7d13a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-86d6b8f4-1e70-4946-be24-d1079acb8e42,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-84920ced-e421-4e33-9749-e036763d70bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-21c128be-f093-4fb4-98c4-c52b0846591b,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-9eb1d54b-94ea-47b9-b4c1-9dc84464d07d,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-1e6a54c8-681d-4f82-ab15-10ac6c4472ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-d482a2ff-bc96-4d06-ac09-1a598494aa7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636331027-172.17.0.20-1595869128065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33103,DS-3f342c6d-7b5d-4521-86bb-873c895a280d,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-2d6310e2-6ca2-4bfe-bda1-aa787e7d13a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-86d6b8f4-1e70-4946-be24-d1079acb8e42,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-84920ced-e421-4e33-9749-e036763d70bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-21c128be-f093-4fb4-98c4-c52b0846591b,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-9eb1d54b-94ea-47b9-b4c1-9dc84464d07d,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-1e6a54c8-681d-4f82-ab15-10ac6c4472ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-d482a2ff-bc96-4d06-ac09-1a598494aa7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397429827-172.17.0.20-1595869226223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34928,DS-56c293c0-e5f8-4c11-98c8-c59561be3fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-4b43ff3e-b6c1-4ea0-be06-995e5536924c,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-dbb92e8b-dd5c-4b48-af56-7ef31d9516dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-3f8a520f-a19a-4eed-a06f-98ed2cebadc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-043b5c94-0d2e-42a5-95a7-b89abec3297c,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-2a58570e-b4a1-43e7-9d85-bf3c2079370a,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-e5c5509d-581e-4c8f-a398-c08143e88f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-2e69a33f-1867-4f1b-8731-563ac6b47aa3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397429827-172.17.0.20-1595869226223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34928,DS-56c293c0-e5f8-4c11-98c8-c59561be3fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-4b43ff3e-b6c1-4ea0-be06-995e5536924c,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-dbb92e8b-dd5c-4b48-af56-7ef31d9516dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-3f8a520f-a19a-4eed-a06f-98ed2cebadc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-043b5c94-0d2e-42a5-95a7-b89abec3297c,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-2a58570e-b4a1-43e7-9d85-bf3c2079370a,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-e5c5509d-581e-4c8f-a398-c08143e88f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-2e69a33f-1867-4f1b-8731-563ac6b47aa3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105260840-172.17.0.20-1595869388466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34737,DS-78de4c1f-b758-4e60-9888-aa8c3e0e5818,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-7417d9e7-9723-4bfc-bf1e-d5c7bb38a745,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-2c38d2be-1f59-4f81-96f9-64cecfc08dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-6d35dd65-af4c-4baf-a6d0-f43558f1c123,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-3e4e0ab6-1ec4-4dc8-87a5-f91b28612d24,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-25f010fa-f64a-46ee-a0b6-bf282cad24f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-bafa8879-a81e-4d3a-940a-cf5e9f4c1491,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-748a6547-3aec-4259-957c-297d3ca07863,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105260840-172.17.0.20-1595869388466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34737,DS-78de4c1f-b758-4e60-9888-aa8c3e0e5818,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-7417d9e7-9723-4bfc-bf1e-d5c7bb38a745,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-2c38d2be-1f59-4f81-96f9-64cecfc08dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-6d35dd65-af4c-4baf-a6d0-f43558f1c123,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-3e4e0ab6-1ec4-4dc8-87a5-f91b28612d24,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-25f010fa-f64a-46ee-a0b6-bf282cad24f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-bafa8879-a81e-4d3a-940a-cf5e9f4c1491,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-748a6547-3aec-4259-957c-297d3ca07863,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717978598-172.17.0.20-1595869436166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36048,DS-dee70172-f2f7-4fa1-b102-ed32fdd79298,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-de0c87d7-52d2-41d2-934f-2d68450a6495,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-d63ac50a-affa-4e20-afcc-6e32dc3e6120,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-2c01ea4c-dcdb-4bd2-9067-f5ceba108a90,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-c5a566f6-0fcd-4eb9-9e04-ac8050caae72,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-79aff71e-1c3b-4188-abb8-38f6d8de7c34,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-345eb682-878f-43fa-b23e-0505930efda7,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-484ab929-1991-4c90-8b07-cc1ed0b73b43,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-717978598-172.17.0.20-1595869436166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36048,DS-dee70172-f2f7-4fa1-b102-ed32fdd79298,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-de0c87d7-52d2-41d2-934f-2d68450a6495,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-d63ac50a-affa-4e20-afcc-6e32dc3e6120,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-2c01ea4c-dcdb-4bd2-9067-f5ceba108a90,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-c5a566f6-0fcd-4eb9-9e04-ac8050caae72,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-79aff71e-1c3b-4188-abb8-38f6d8de7c34,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-345eb682-878f-43fa-b23e-0505930efda7,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-484ab929-1991-4c90-8b07-cc1ed0b73b43,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862284819-172.17.0.20-1595869479231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39514,DS-3d938dff-c5dd-4b45-b634-15f3797ca5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-e9a43074-c029-42b2-b67b-da76bdef84fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-6e256de1-9803-450a-a50f-320db7a2efb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-f1dab7d3-c653-44ac-8ece-daa2d658f638,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-5ca1cd53-e9b7-4694-a178-e26c9966a5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-c689325a-59f9-45fb-b4d0-4d4d8f970c56,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-27eed8ac-986d-4abe-bc12-af47f7e18b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-23ab139e-7d02-4b53-aecd-3249fbaa0709,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862284819-172.17.0.20-1595869479231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39514,DS-3d938dff-c5dd-4b45-b634-15f3797ca5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-e9a43074-c029-42b2-b67b-da76bdef84fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-6e256de1-9803-450a-a50f-320db7a2efb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-f1dab7d3-c653-44ac-8ece-daa2d658f638,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-5ca1cd53-e9b7-4694-a178-e26c9966a5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-c689325a-59f9-45fb-b4d0-4d4d8f970c56,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-27eed8ac-986d-4abe-bc12-af47f7e18b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-23ab139e-7d02-4b53-aecd-3249fbaa0709,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675449860-172.17.0.20-1595869829908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34242,DS-2f8d6265-60cd-4f22-ab11-f0b8a4b923b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-279de69b-11e2-4888-b42e-15b91e48d8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-be37e348-82aa-41ed-a9dd-b68937e2dbee,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-80038432-7c6e-4a06-9236-1949ab5a747d,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-44dd33e9-9d8f-4fbf-9da1-6ee2be126572,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-29e67fbc-839f-4567-980d-08aebc5f6ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-3aab2c01-0e29-467f-ad4f-451d75604f73,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-a65d6caa-386b-4adf-a9ea-e546b5112076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675449860-172.17.0.20-1595869829908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34242,DS-2f8d6265-60cd-4f22-ab11-f0b8a4b923b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-279de69b-11e2-4888-b42e-15b91e48d8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-be37e348-82aa-41ed-a9dd-b68937e2dbee,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-80038432-7c6e-4a06-9236-1949ab5a747d,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-44dd33e9-9d8f-4fbf-9da1-6ee2be126572,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-29e67fbc-839f-4567-980d-08aebc5f6ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-3aab2c01-0e29-467f-ad4f-451d75604f73,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-a65d6caa-386b-4adf-a9ea-e546b5112076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223881599-172.17.0.20-1595869952240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34195,DS-4a3a263f-ef77-4f16-8be5-4508470b8c90,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-2665e176-3012-449a-8765-92643d80f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-184db687-1c42-44f1-be4c-db2fc64bb93a,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-a3bdf646-ae25-4f65-ad2d-66a695762b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-2e02177e-bb52-4382-937d-6a72d17f6112,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-433dd47b-4ae2-4dde-a1d7-700f4632728b,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-97612d82-1299-430a-958d-ccff626aac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-01c22c76-42ed-4a9d-b832-1528f02412c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223881599-172.17.0.20-1595869952240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34195,DS-4a3a263f-ef77-4f16-8be5-4508470b8c90,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-2665e176-3012-449a-8765-92643d80f6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-184db687-1c42-44f1-be4c-db2fc64bb93a,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-a3bdf646-ae25-4f65-ad2d-66a695762b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-2e02177e-bb52-4382-937d-6a72d17f6112,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-433dd47b-4ae2-4dde-a1d7-700f4632728b,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-97612d82-1299-430a-958d-ccff626aac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-01c22c76-42ed-4a9d-b832-1528f02412c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572659915-172.17.0.20-1595870515033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39274,DS-3cdb37a9-89ac-4645-a1b9-513b0546a350,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-befaa04c-4941-4ecb-8b3e-a119c8c59d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-ec13a2b2-4fa3-41aa-8a11-5b22d16a6735,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-bd896529-d2fc-4341-baaf-95f8b4bc8783,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-9f019946-2f36-4806-9215-31523a64458b,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-1afe4c63-7178-423f-a784-9a8eef75253c,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-b138e156-29ea-417f-9832-b1e11038503f,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-7c2e15a8-a561-453f-b266-140ad0d4d5ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572659915-172.17.0.20-1595870515033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39274,DS-3cdb37a9-89ac-4645-a1b9-513b0546a350,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-befaa04c-4941-4ecb-8b3e-a119c8c59d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-ec13a2b2-4fa3-41aa-8a11-5b22d16a6735,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-bd896529-d2fc-4341-baaf-95f8b4bc8783,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-9f019946-2f36-4806-9215-31523a64458b,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-1afe4c63-7178-423f-a784-9a8eef75253c,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-b138e156-29ea-417f-9832-b1e11038503f,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-7c2e15a8-a561-453f-b266-140ad0d4d5ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413895472-172.17.0.20-1595871179294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46442,DS-c6b1c0ee-129f-46db-832d-ce73622bdb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-74b97ad2-febc-4a19-b9eb-0ef014f6b6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-871ea658-f0ba-4a07-b25c-f1ea949f78f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-c15d4a17-4b2c-4e02-942d-07c823d2037f,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-ad1bfc3d-f026-4a88-bd50-58499f67a9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-28165e03-eb3e-45f9-88b3-c552e3c2a245,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-970703d4-da7c-4489-996a-4d51d21e170e,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-3576f79e-6dd1-46e0-bb0a-ece4345a6bed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413895472-172.17.0.20-1595871179294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46442,DS-c6b1c0ee-129f-46db-832d-ce73622bdb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-74b97ad2-febc-4a19-b9eb-0ef014f6b6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-871ea658-f0ba-4a07-b25c-f1ea949f78f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-c15d4a17-4b2c-4e02-942d-07c823d2037f,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-ad1bfc3d-f026-4a88-bd50-58499f67a9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-28165e03-eb3e-45f9-88b3-c552e3c2a245,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-970703d4-da7c-4489-996a-4d51d21e170e,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-3576f79e-6dd1-46e0-bb0a-ece4345a6bed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523437081-172.17.0.20-1595871275365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37398,DS-26c0bca9-4575-4de1-9c14-632e33192c15,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-5ef7016a-5ebc-4af4-86fb-adbc7aafdb67,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-28c8ecc9-3ef6-4454-b178-d7d52ddf0c83,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-909af4e5-bdc3-4a94-b6f3-fde4f9ab71a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-351968bc-5090-43a8-ac09-d42d4da41cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-ff750e42-1c9a-41bb-ac11-49985f911a71,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-38982545-c837-4aec-9889-7f37ec46e4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-f278c768-883a-43df-8ef6-2f86d0a727fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523437081-172.17.0.20-1595871275365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37398,DS-26c0bca9-4575-4de1-9c14-632e33192c15,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-5ef7016a-5ebc-4af4-86fb-adbc7aafdb67,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-28c8ecc9-3ef6-4454-b178-d7d52ddf0c83,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-909af4e5-bdc3-4a94-b6f3-fde4f9ab71a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-351968bc-5090-43a8-ac09-d42d4da41cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-ff750e42-1c9a-41bb-ac11-49985f911a71,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-38982545-c837-4aec-9889-7f37ec46e4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-f278c768-883a-43df-8ef6-2f86d0a727fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94364375-172.17.0.20-1595871322508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42755,DS-0b768cc7-b201-4359-9bde-4abc8f3dd5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-5dad716c-b4ef-41fa-8e2f-a8a03d700123,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-9dd7fb2f-213a-4b78-9f95-cb3ca0d5413f,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-d3d46415-c50d-45bf-adb2-83000ffc1e90,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-c5b692ae-6492-437b-b262-62596646144d,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-049d5e5e-43c6-44dd-aee3-d09e4fb5a7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-4e27a372-e50e-4ae3-afd5-8708bda2d6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-31a7fad1-5d0e-4746-817a-9bbb7b2915c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94364375-172.17.0.20-1595871322508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42755,DS-0b768cc7-b201-4359-9bde-4abc8f3dd5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-5dad716c-b4ef-41fa-8e2f-a8a03d700123,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-9dd7fb2f-213a-4b78-9f95-cb3ca0d5413f,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-d3d46415-c50d-45bf-adb2-83000ffc1e90,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-c5b692ae-6492-437b-b262-62596646144d,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-049d5e5e-43c6-44dd-aee3-d09e4fb5a7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-4e27a372-e50e-4ae3-afd5-8708bda2d6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-31a7fad1-5d0e-4746-817a-9bbb7b2915c2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976277644-172.17.0.20-1595871461607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46405,DS-714a6859-5185-4a71-963f-0b2e836aadef,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-87c34aca-6ef0-46bf-a072-ef58f72f738b,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-a0b15549-a6c5-4c35-a011-5abb5f30c929,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-67f5bc00-6d41-46f4-9d8a-409f24bb3b65,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-e7c89fbd-48fe-40c1-a153-ff5680e6f90d,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-0d581611-b4bb-4e4a-8490-d2cea604a2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-10890b6c-9485-4479-8bf9-dccb4b72fdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-4ca7ecb9-c21e-4f94-9f14-628df98d5f71,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-976277644-172.17.0.20-1595871461607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46405,DS-714a6859-5185-4a71-963f-0b2e836aadef,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-87c34aca-6ef0-46bf-a072-ef58f72f738b,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-a0b15549-a6c5-4c35-a011-5abb5f30c929,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-67f5bc00-6d41-46f4-9d8a-409f24bb3b65,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-e7c89fbd-48fe-40c1-a153-ff5680e6f90d,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-0d581611-b4bb-4e4a-8490-d2cea604a2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-10890b6c-9485-4479-8bf9-dccb4b72fdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-4ca7ecb9-c21e-4f94-9f14-628df98d5f71,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432977671-172.17.0.20-1595871545262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45056,DS-00a784ff-1f8e-486d-a20e-045b7dcad523,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-cc2bd99f-978e-44b9-bd02-42746f168d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-924172bc-39ba-427d-a6ea-5a44c3119dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-94b7de8b-957d-4d8c-9224-26138f616fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-b8606b06-c945-4854-b43e-c92f6620b550,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-86adc2d7-446e-4dfa-8266-71e8beb77a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-0f4b2db6-337d-4230-9417-20303cab2f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-d1ad9083-2ff9-4a41-9902-9dfbfa4fabbd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432977671-172.17.0.20-1595871545262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45056,DS-00a784ff-1f8e-486d-a20e-045b7dcad523,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-cc2bd99f-978e-44b9-bd02-42746f168d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-924172bc-39ba-427d-a6ea-5a44c3119dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-94b7de8b-957d-4d8c-9224-26138f616fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-b8606b06-c945-4854-b43e-c92f6620b550,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-86adc2d7-446e-4dfa-8266-71e8beb77a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-0f4b2db6-337d-4230-9417-20303cab2f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-d1ad9083-2ff9-4a41-9902-9dfbfa4fabbd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061052585-172.17.0.20-1595871587033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44863,DS-6a56affa-3855-4fba-a6c9-0ebed0d1f816,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-fb15c5d2-d2d0-4cbf-8545-1fdc96e4596b,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-0b2d2cf3-8e9e-4e37-b897-bb69b61a42a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-e42af367-5c97-4f0f-a1c9-ccd44c8c6df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-137e5687-00e6-46a5-9b10-753342efba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-121aaaa5-5e67-4d62-ad4c-b6e660990dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-3ec7afdc-2a48-406c-a27f-da6734d5a9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-ce1a916a-1de2-4af4-9756-ba2446c83170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061052585-172.17.0.20-1595871587033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44863,DS-6a56affa-3855-4fba-a6c9-0ebed0d1f816,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-fb15c5d2-d2d0-4cbf-8545-1fdc96e4596b,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-0b2d2cf3-8e9e-4e37-b897-bb69b61a42a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-e42af367-5c97-4f0f-a1c9-ccd44c8c6df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-137e5687-00e6-46a5-9b10-753342efba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-121aaaa5-5e67-4d62-ad4c-b6e660990dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-3ec7afdc-2a48-406c-a27f-da6734d5a9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-ce1a916a-1de2-4af4-9756-ba2446c83170,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988254337-172.17.0.20-1595871637565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38383,DS-07426b6f-4759-4f62-b62c-5fe798cde8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-7695dad3-da5e-485c-b93a-6778784f98e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-c7c8eacb-2cff-4fbb-88a1-ef737b50f39d,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-67be2cf5-79b2-4b84-ad69-93e66e534cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-e8e3719d-3c2f-4b39-bce1-36c6da0d3c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-0bd49bf4-093d-4821-ad92-8d7a6974ef33,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-dbdb5c7c-0fea-4aa0-84f0-5d6e93b30676,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-37e923fa-3703-47a1-9854-d9dd9f2beeba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988254337-172.17.0.20-1595871637565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38383,DS-07426b6f-4759-4f62-b62c-5fe798cde8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-7695dad3-da5e-485c-b93a-6778784f98e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-c7c8eacb-2cff-4fbb-88a1-ef737b50f39d,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-67be2cf5-79b2-4b84-ad69-93e66e534cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-e8e3719d-3c2f-4b39-bce1-36c6da0d3c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-0bd49bf4-093d-4821-ad92-8d7a6974ef33,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-dbdb5c7c-0fea-4aa0-84f0-5d6e93b30676,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-37e923fa-3703-47a1-9854-d9dd9f2beeba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690465098-172.17.0.20-1595871774575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43328,DS-e124aefb-bcad-4372-8d18-edbf1957f065,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-24a80332-f303-4da0-9cc3-275f51f1872c,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-80b14687-d65d-4ffa-a044-088e3abad4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-6d3dcf55-b027-4a75-bc72-a451383e99a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-921893b9-1f28-412c-9b0e-79b8517ecad9,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-a86694b6-2f2f-406f-b9fc-8e14b473bb39,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-948f469d-7c63-48f8-84f9-56f48fcb2e33,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-847268b4-bd9d-4bde-91d7-747ed11800bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690465098-172.17.0.20-1595871774575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43328,DS-e124aefb-bcad-4372-8d18-edbf1957f065,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-24a80332-f303-4da0-9cc3-275f51f1872c,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-80b14687-d65d-4ffa-a044-088e3abad4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-6d3dcf55-b027-4a75-bc72-a451383e99a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-921893b9-1f28-412c-9b0e-79b8517ecad9,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-a86694b6-2f2f-406f-b9fc-8e14b473bb39,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-948f469d-7c63-48f8-84f9-56f48fcb2e33,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-847268b4-bd9d-4bde-91d7-747ed11800bc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961410396-172.17.0.20-1595871952274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42498,DS-5e104299-b822-4dcc-97c8-5651d84ef220,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-f3dc0585-9053-4fdc-b8df-31712f8e9404,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-c4ae4875-9e4e-4edd-9104-a6f3aca808a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-e4da02d7-66cd-4fc7-b378-3d1248b6db1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-7be51975-8169-456a-aa94-5de69b7f74b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-92327e30-d739-41a2-8320-3504a91bf8db,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-cacbc351-cdd1-411c-906a-0675d5d115d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-eac02054-9e88-43be-9dce-08decdc90d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961410396-172.17.0.20-1595871952274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42498,DS-5e104299-b822-4dcc-97c8-5651d84ef220,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-f3dc0585-9053-4fdc-b8df-31712f8e9404,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-c4ae4875-9e4e-4edd-9104-a6f3aca808a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-e4da02d7-66cd-4fc7-b378-3d1248b6db1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-7be51975-8169-456a-aa94-5de69b7f74b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-92327e30-d739-41a2-8320-3504a91bf8db,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-cacbc351-cdd1-411c-906a-0675d5d115d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-eac02054-9e88-43be-9dce-08decdc90d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950819254-172.17.0.20-1595872027423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-e6fc84f8-de1e-4349-8848-b6d697cc2359,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-ce7ba165-79d0-46df-bce8-15270179905b,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-0cde2234-016f-45b9-8977-cc939c37058e,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-3a98fc19-4c14-4637-85e8-64e030acaf36,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-b72dc83a-489b-46da-8d53-bc4537c41616,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-ce247de1-c81b-47fa-9a06-12bb08e827a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-a257c036-c0ce-47bd-8151-b4da5b7e7e79,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-cf99a59d-0145-4916-88b6-00e8162b359b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950819254-172.17.0.20-1595872027423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41804,DS-e6fc84f8-de1e-4349-8848-b6d697cc2359,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-ce7ba165-79d0-46df-bce8-15270179905b,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-0cde2234-016f-45b9-8977-cc939c37058e,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-3a98fc19-4c14-4637-85e8-64e030acaf36,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-b72dc83a-489b-46da-8d53-bc4537c41616,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-ce247de1-c81b-47fa-9a06-12bb08e827a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36235,DS-a257c036-c0ce-47bd-8151-b4da5b7e7e79,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-cf99a59d-0145-4916-88b6-00e8162b359b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557068323-172.17.0.20-1595872309386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39350,DS-9f2d83d1-85d3-4286-83b7-09fb52c0c052,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-abc472a1-a7de-439a-ae08-b239a0cabf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-aac1bef4-826f-4524-8960-8c2a4fe87d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-8d6dec96-522f-407c-865c-9656f4ba6aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-d93e482b-6739-4bc8-9e82-49035b119c99,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-a4fb020a-9a23-404f-adc3-f2d014b538ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-5e1efd2d-5f0c-41d2-9ea6-2889ca67d988,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-b81e0736-f01c-4c39-8733-4e8fcddd7955,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557068323-172.17.0.20-1595872309386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39350,DS-9f2d83d1-85d3-4286-83b7-09fb52c0c052,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-abc472a1-a7de-439a-ae08-b239a0cabf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-aac1bef4-826f-4524-8960-8c2a4fe87d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-8d6dec96-522f-407c-865c-9656f4ba6aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-d93e482b-6739-4bc8-9e82-49035b119c99,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-a4fb020a-9a23-404f-adc3-f2d014b538ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-5e1efd2d-5f0c-41d2-9ea6-2889ca67d988,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-b81e0736-f01c-4c39-8733-4e8fcddd7955,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343462019-172.17.0.20-1595872516879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34263,DS-d105c946-e0cd-449e-8844-6df0db657545,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-d9cda74b-e767-4b75-8d01-85c3549e0e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-a9b30640-d406-45d2-b663-8c3229fcfe05,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-c3549654-3c80-4a2b-bbbb-7987013a9260,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-839b9b8c-0e2a-423f-a584-298a0947fd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-58be86df-88ff-4985-9db7-a860359a7971,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-ff0224de-318c-4ddc-9c4d-ded5d7612e30,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-9fdfaecf-7e83-4048-93da-1f33a3679590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343462019-172.17.0.20-1595872516879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34263,DS-d105c946-e0cd-449e-8844-6df0db657545,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-d9cda74b-e767-4b75-8d01-85c3549e0e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-a9b30640-d406-45d2-b663-8c3229fcfe05,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-c3549654-3c80-4a2b-bbbb-7987013a9260,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-839b9b8c-0e2a-423f-a584-298a0947fd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-58be86df-88ff-4985-9db7-a860359a7971,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-ff0224de-318c-4ddc-9c4d-ded5d7612e30,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-9fdfaecf-7e83-4048-93da-1f33a3679590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873144367-172.17.0.20-1595873050259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45889,DS-51d8ee6a-1d43-4caa-bf3e-bdf9ed1a96c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-f2a776cb-f7dd-43cd-908e-9d5b2d3bf485,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-ccbb96e7-732b-4da9-9ad7-a25ef40bb966,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-e336fb54-fdc6-4adf-91b4-e594e5b6a694,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-72145188-419f-4996-beb7-01146e3d80c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-c09bf77b-d700-4199-889f-d11cbaad4d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-4e64a094-35ed-41fd-a689-4f312f47bcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-27c9cb48-3f08-47d8-bfa0-47ade57e1990,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-873144367-172.17.0.20-1595873050259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45889,DS-51d8ee6a-1d43-4caa-bf3e-bdf9ed1a96c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-f2a776cb-f7dd-43cd-908e-9d5b2d3bf485,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-ccbb96e7-732b-4da9-9ad7-a25ef40bb966,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-e336fb54-fdc6-4adf-91b4-e594e5b6a694,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-72145188-419f-4996-beb7-01146e3d80c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-c09bf77b-d700-4199-889f-d11cbaad4d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-4e64a094-35ed-41fd-a689-4f312f47bcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-27c9cb48-3f08-47d8-bfa0-47ade57e1990,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942097463-172.17.0.20-1595873081847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44622,DS-fef9e261-c3ea-45e9-a3d8-2c3e24c15fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-83b2ba41-62f8-4d3b-ac1e-1ed74a7989b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-7ea46683-7058-421c-b6f7-3ac1dfe3fe13,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-cf1de11a-bf49-4c88-9184-de13afa0230c,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-f6710576-c753-4ba9-95df-a9729b5cae79,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-d1c167dc-9654-4774-b03e-0cb059c846ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-711008ff-d877-403f-a78a-df9206615abc,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-b87997a9-9289-4ae7-b071-b0bdac538a19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942097463-172.17.0.20-1595873081847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44622,DS-fef9e261-c3ea-45e9-a3d8-2c3e24c15fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-83b2ba41-62f8-4d3b-ac1e-1ed74a7989b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-7ea46683-7058-421c-b6f7-3ac1dfe3fe13,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-cf1de11a-bf49-4c88-9184-de13afa0230c,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-f6710576-c753-4ba9-95df-a9729b5cae79,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-d1c167dc-9654-4774-b03e-0cb059c846ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-711008ff-d877-403f-a78a-df9206615abc,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-b87997a9-9289-4ae7-b071-b0bdac538a19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290403662-172.17.0.20-1595873708887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33968,DS-2fe82cbb-77f4-44d8-8797-fdf7b16159af,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-3431c64e-dc36-4ea0-b7c1-cba2c0609e16,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-8257a2ab-1801-4e54-bcd0-944d1207e25c,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-bcedcf41-b1a6-415f-9c47-528cb323ae79,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-d0dc7582-f7d7-446f-99be-a6ce265d6814,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-9e30bbe8-2562-4c61-afb6-adf3f0825102,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-bffd46d3-6452-4fa4-8648-81fc5e7c9b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-0f89824b-7189-4a15-90da-18ffdcec0b69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290403662-172.17.0.20-1595873708887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33968,DS-2fe82cbb-77f4-44d8-8797-fdf7b16159af,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-3431c64e-dc36-4ea0-b7c1-cba2c0609e16,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-8257a2ab-1801-4e54-bcd0-944d1207e25c,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-bcedcf41-b1a6-415f-9c47-528cb323ae79,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-d0dc7582-f7d7-446f-99be-a6ce265d6814,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-9e30bbe8-2562-4c61-afb6-adf3f0825102,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-bffd46d3-6452-4fa4-8648-81fc5e7c9b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-0f89824b-7189-4a15-90da-18ffdcec0b69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 128
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922239046-172.17.0.20-1595873968662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46716,DS-a8edfbd9-ce54-49f3-b3f6-557c8585ab10,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-b058d1e7-c9ff-4cc2-956d-e6701ec91bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-4a0d78b8-247e-46b9-8a37-bac9632d034c,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-ae9499a4-4301-4225-b68e-51cf024069a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-3205d38d-e73f-482e-b735-69580bda42aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-e373210f-7808-4b1c-a352-e81fa658327a,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-54ebf765-5a39-4ce0-be6d-7a89887859b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-5007a49a-164a-4690-a79b-a54ffa78ad15,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922239046-172.17.0.20-1595873968662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46716,DS-a8edfbd9-ce54-49f3-b3f6-557c8585ab10,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-b058d1e7-c9ff-4cc2-956d-e6701ec91bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-4a0d78b8-247e-46b9-8a37-bac9632d034c,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-ae9499a4-4301-4225-b68e-51cf024069a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-3205d38d-e73f-482e-b735-69580bda42aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-e373210f-7808-4b1c-a352-e81fa658327a,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-54ebf765-5a39-4ce0-be6d-7a89887859b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-5007a49a-164a-4690-a79b-a54ffa78ad15,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 6529
