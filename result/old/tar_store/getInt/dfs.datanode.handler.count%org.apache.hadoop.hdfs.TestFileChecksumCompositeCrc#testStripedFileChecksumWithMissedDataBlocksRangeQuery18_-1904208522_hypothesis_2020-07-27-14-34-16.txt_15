reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61725155-172.17.0.10-1595860770398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39096,DS-4f918d94-9dc4-431b-98ea-c156674462d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-87a12c8c-f096-45be-a8bd-4fc09dd54499,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-134df3b5-db21-4aab-8eed-3b64a0133fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-26950e5e-7c0d-4f01-8152-f2304f86b3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-8944ba1f-001d-4afc-a83d-f766a975d39c,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-e9679475-1020-4501-98a4-6e8d4cf4b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-a4990171-711e-44ce-9ffa-49c0304996b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-ff348c0b-957a-40c7-ab26-3f607f521d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61725155-172.17.0.10-1595860770398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39096,DS-4f918d94-9dc4-431b-98ea-c156674462d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-87a12c8c-f096-45be-a8bd-4fc09dd54499,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-134df3b5-db21-4aab-8eed-3b64a0133fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-26950e5e-7c0d-4f01-8152-f2304f86b3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-8944ba1f-001d-4afc-a83d-f766a975d39c,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-e9679475-1020-4501-98a4-6e8d4cf4b61f,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-a4990171-711e-44ce-9ffa-49c0304996b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-ff348c0b-957a-40c7-ab26-3f607f521d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070443263-172.17.0.10-1595861067298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43579,DS-fdc90d81-0988-4e79-bfad-7c88c5bab87c,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-fab949c6-567e-485d-b595-9e6bad6792f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-c3714b59-b421-41b9-bb9e-11b84d9ba428,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-502c90f8-dc02-45d7-9bd8-fd51764a715b,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-824aa5fe-5829-4a79-95b9-e95111992c42,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-550fc9cc-1fc4-49ac-a129-f6f82f442e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-000d7fd2-b0ff-4407-b2e4-dd197846771d,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-318339d3-9695-4036-a8f6-1685382e546c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070443263-172.17.0.10-1595861067298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43579,DS-fdc90d81-0988-4e79-bfad-7c88c5bab87c,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-fab949c6-567e-485d-b595-9e6bad6792f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-c3714b59-b421-41b9-bb9e-11b84d9ba428,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-502c90f8-dc02-45d7-9bd8-fd51764a715b,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-824aa5fe-5829-4a79-95b9-e95111992c42,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-550fc9cc-1fc4-49ac-a129-f6f82f442e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-000d7fd2-b0ff-4407-b2e4-dd197846771d,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-318339d3-9695-4036-a8f6-1685382e546c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593014763-172.17.0.10-1595861174207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-e38114be-e9c5-41e0-9212-c5294be1167d,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-688401ee-4634-4415-aab5-9a76b17947d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-d82bb650-fddd-42b6-b1b5-96124f77586a,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-ada10c80-f788-4d2d-9ffa-0880c2140ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-33eedb5c-136b-4cc4-8afc-e40ddf07ffe8,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-4a5f37ad-2135-4ca9-9aba-728883a5372a,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-77c53cde-f4b1-42b1-a301-a148bcd5431a,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-4b5e173f-f752-424d-acd1-fd9f06e9ce18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593014763-172.17.0.10-1595861174207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-e38114be-e9c5-41e0-9212-c5294be1167d,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-688401ee-4634-4415-aab5-9a76b17947d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-d82bb650-fddd-42b6-b1b5-96124f77586a,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-ada10c80-f788-4d2d-9ffa-0880c2140ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-33eedb5c-136b-4cc4-8afc-e40ddf07ffe8,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-4a5f37ad-2135-4ca9-9aba-728883a5372a,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-77c53cde-f4b1-42b1-a301-a148bcd5431a,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-4b5e173f-f752-424d-acd1-fd9f06e9ce18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38901108-172.17.0.10-1595861406648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46189,DS-59df8cb5-d126-404b-9f25-c21bfb0157d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-5d7a6ead-1698-43a3-9326-6a1eef7669a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-58ccad61-79a3-4fb5-a59c-52d778b292ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-e3bff37a-0c3b-4e73-bbc5-34f94a505f94,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-63fcbd0c-65d3-40b3-9d67-31a953578981,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-eea114e1-f9a0-4f1e-b41b-71c2393009a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-7243a340-d312-48ad-8fce-fbbf83573a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-45d212c4-bc03-4ba5-a561-67b8c19c8bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-38901108-172.17.0.10-1595861406648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46189,DS-59df8cb5-d126-404b-9f25-c21bfb0157d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-5d7a6ead-1698-43a3-9326-6a1eef7669a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-58ccad61-79a3-4fb5-a59c-52d778b292ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-e3bff37a-0c3b-4e73-bbc5-34f94a505f94,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-63fcbd0c-65d3-40b3-9d67-31a953578981,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-eea114e1-f9a0-4f1e-b41b-71c2393009a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-7243a340-d312-48ad-8fce-fbbf83573a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-45d212c4-bc03-4ba5-a561-67b8c19c8bde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401639970-172.17.0.10-1595861644387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35711,DS-a52c7be8-18f1-4c05-9719-7dd704964457,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-aaad2ebc-0917-404c-8fe4-1ec991759ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-702a7f1c-ea94-4fb8-914a-77cd6a24a7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-0f138d65-3a29-4a89-b749-c6f10b3e07c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-fbc39378-f439-4faf-9fb0-378fe6f7acd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-edeca47f-87ad-4aba-9cd8-8e1b25c1be73,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-5f945c51-d0bf-462a-9f7a-537f03f00b71,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-d3b5b9d0-15e4-4711-921e-5fe48131f02e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401639970-172.17.0.10-1595861644387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35711,DS-a52c7be8-18f1-4c05-9719-7dd704964457,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-aaad2ebc-0917-404c-8fe4-1ec991759ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-702a7f1c-ea94-4fb8-914a-77cd6a24a7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-0f138d65-3a29-4a89-b749-c6f10b3e07c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-fbc39378-f439-4faf-9fb0-378fe6f7acd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-edeca47f-87ad-4aba-9cd8-8e1b25c1be73,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-5f945c51-d0bf-462a-9f7a-537f03f00b71,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-d3b5b9d0-15e4-4711-921e-5fe48131f02e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1850159359-172.17.0.10-1595861757213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41781,DS-4dca8f55-4cf0-4698-b9c9-41fe95399d37,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-e022756f-a95d-4440-88d0-4327167a1e34,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-54aa6920-631e-49c6-9b02-63bb7a96c652,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-84393b85-2c9c-4037-9f03-a81e6fd9dadf,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-6a140610-1441-4d66-9c06-d5c2677def20,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-a611000e-3c83-4038-8410-3b6217a95c91,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-4675c189-fe7a-4cf3-9628-962a8f62339b,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-e93194ab-5afd-4e21-a6ce-2b57eb6f5824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1850159359-172.17.0.10-1595861757213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41781,DS-4dca8f55-4cf0-4698-b9c9-41fe95399d37,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-e022756f-a95d-4440-88d0-4327167a1e34,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-54aa6920-631e-49c6-9b02-63bb7a96c652,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-84393b85-2c9c-4037-9f03-a81e6fd9dadf,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-6a140610-1441-4d66-9c06-d5c2677def20,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-a611000e-3c83-4038-8410-3b6217a95c91,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-4675c189-fe7a-4cf3-9628-962a8f62339b,DISK], DatanodeInfoWithStorage[127.0.0.1:41442,DS-e93194ab-5afd-4e21-a6ce-2b57eb6f5824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826386766-172.17.0.10-1595862002490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45627,DS-b0172ba7-703a-4351-b4f1-4ac7898cccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-3fd2f36d-d478-4129-a0bb-bfd73c55608d,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-e0409da2-2ce3-4fb8-856a-2e1a2fafed15,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-cf85e96a-9a50-4ba6-999d-0a6381800c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-e35e9ee5-c9bc-4bd1-b2fb-b9584fc69ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-b645ce42-d5b4-4f37-b7fe-a37865ef1ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-5dd69b87-b552-4210-bd72-a86b24cecc99,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-d8b4c2e0-102d-4923-9adc-a671e8248b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826386766-172.17.0.10-1595862002490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45627,DS-b0172ba7-703a-4351-b4f1-4ac7898cccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-3fd2f36d-d478-4129-a0bb-bfd73c55608d,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-e0409da2-2ce3-4fb8-856a-2e1a2fafed15,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-cf85e96a-9a50-4ba6-999d-0a6381800c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-e35e9ee5-c9bc-4bd1-b2fb-b9584fc69ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-b645ce42-d5b4-4f37-b7fe-a37865ef1ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-5dd69b87-b552-4210-bd72-a86b24cecc99,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-d8b4c2e0-102d-4923-9adc-a671e8248b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96708833-172.17.0.10-1595862033236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38632,DS-8a823bb3-8d9c-42b9-8160-65c19e073c62,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-e7795c04-5c5b-4b8e-9842-a0fd1a36e504,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-98be698b-dfbe-463f-b144-78867e2f4f34,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-72da27b6-d83d-43d6-84d5-18820ba93a64,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-4801078a-b87d-4960-b75f-65d9cdd36b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-173541f3-c3fe-4d8c-af3a-4bf8690e93a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-7674d424-49a4-4f51-8429-ff0d18452151,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-7222eeae-df6b-4b46-8540-2c9acfe83d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-96708833-172.17.0.10-1595862033236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38632,DS-8a823bb3-8d9c-42b9-8160-65c19e073c62,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-e7795c04-5c5b-4b8e-9842-a0fd1a36e504,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-98be698b-dfbe-463f-b144-78867e2f4f34,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-72da27b6-d83d-43d6-84d5-18820ba93a64,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-4801078a-b87d-4960-b75f-65d9cdd36b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-173541f3-c3fe-4d8c-af3a-4bf8690e93a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-7674d424-49a4-4f51-8429-ff0d18452151,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-7222eeae-df6b-4b46-8540-2c9acfe83d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1772454265-172.17.0.10-1595862452725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46718,DS-c3e0fc64-3cff-4f0b-b511-c115a72a515a,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-e27f49e4-b10d-48cf-bc7b-fb5070b28bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-eaae2ce7-d79e-4d86-ab7f-93807e630b71,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-4f7fb9ed-8325-43f9-8d8e-757ab21d9e29,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-20039c6e-663f-4291-9d5c-97197a13ac43,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-e91a2fd3-60ca-4326-9428-29c905d8aca4,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-08a91d9d-8991-4421-93e2-c0d5878e50b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-6712ba8d-1acd-416b-bd10-3a8a6e68b2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1772454265-172.17.0.10-1595862452725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46718,DS-c3e0fc64-3cff-4f0b-b511-c115a72a515a,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-e27f49e4-b10d-48cf-bc7b-fb5070b28bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-eaae2ce7-d79e-4d86-ab7f-93807e630b71,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-4f7fb9ed-8325-43f9-8d8e-757ab21d9e29,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-20039c6e-663f-4291-9d5c-97197a13ac43,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-e91a2fd3-60ca-4326-9428-29c905d8aca4,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-08a91d9d-8991-4421-93e2-c0d5878e50b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-6712ba8d-1acd-416b-bd10-3a8a6e68b2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914432765-172.17.0.10-1595862596421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38198,DS-3ed7f9cb-ade3-4301-a977-3e4bbab0372c,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-f577583b-317f-4f67-92c0-186702fbdf89,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-67041993-4c13-4704-97e7-d36b6049b6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-335af109-4e25-4677-9d0d-5a03314834e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-96f0aff1-e0ee-46da-bb55-f09927fd0ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-f30fed93-cee6-4176-8216-8d58ae18abe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-5f13eef8-a92e-4eb2-b89f-3ebc572af8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-fb69d79f-1271-4372-96ba-c663b5dcf89d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914432765-172.17.0.10-1595862596421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38198,DS-3ed7f9cb-ade3-4301-a977-3e4bbab0372c,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-f577583b-317f-4f67-92c0-186702fbdf89,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-67041993-4c13-4704-97e7-d36b6049b6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-335af109-4e25-4677-9d0d-5a03314834e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-96f0aff1-e0ee-46da-bb55-f09927fd0ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-f30fed93-cee6-4176-8216-8d58ae18abe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-5f13eef8-a92e-4eb2-b89f-3ebc572af8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-fb69d79f-1271-4372-96ba-c663b5dcf89d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752330132-172.17.0.10-1595863397313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46649,DS-e23817c4-3ab8-4918-ab6d-265e09edc2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-f18511fb-9390-464d-be0a-0d3e8ea2f309,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-21db82fd-0395-4330-b920-c2096f9a899a,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-fbc943f2-e742-4279-bd85-d6ce5c83801b,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-c81628e2-8d87-4229-8e8f-299cfe86d240,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-59364b7f-4317-40fe-b50b-ed8b523a9cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-27eec1aa-fbc4-4346-8b74-e76d01c80f50,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-c084c7f8-1a07-48c2-93be-0e2204304432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752330132-172.17.0.10-1595863397313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46649,DS-e23817c4-3ab8-4918-ab6d-265e09edc2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-f18511fb-9390-464d-be0a-0d3e8ea2f309,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-21db82fd-0395-4330-b920-c2096f9a899a,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-fbc943f2-e742-4279-bd85-d6ce5c83801b,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-c81628e2-8d87-4229-8e8f-299cfe86d240,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-59364b7f-4317-40fe-b50b-ed8b523a9cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-27eec1aa-fbc4-4346-8b74-e76d01c80f50,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-c084c7f8-1a07-48c2-93be-0e2204304432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422866095-172.17.0.10-1595863477164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39781,DS-565e823f-141d-40af-b608-3a5bf0ffcceb,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-82429c9c-5480-48cd-85db-afb616843353,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-d6ee3e02-d42d-4be9-98fc-c592c742c86c,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-1e2db730-2422-4a5a-811d-16a61fc7b442,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-3161c511-b94a-4f17-9766-32eef42078f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-ec49f8bb-71ee-4ce9-8dc2-d0555a978bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-2775901c-fa11-4bb8-abab-f7ba1a137385,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-bd0a4c5e-b931-4262-b360-159261cca511,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422866095-172.17.0.10-1595863477164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39781,DS-565e823f-141d-40af-b608-3a5bf0ffcceb,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-82429c9c-5480-48cd-85db-afb616843353,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-d6ee3e02-d42d-4be9-98fc-c592c742c86c,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-1e2db730-2422-4a5a-811d-16a61fc7b442,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-3161c511-b94a-4f17-9766-32eef42078f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-ec49f8bb-71ee-4ce9-8dc2-d0555a978bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-2775901c-fa11-4bb8-abab-f7ba1a137385,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-bd0a4c5e-b931-4262-b360-159261cca511,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656241142-172.17.0.10-1595863668496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37053,DS-6d2319fe-4f4a-4800-bed7-460b707a961f,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-9c0f93db-de5b-4ef6-be3c-c6f12f95cb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-9d3a49b5-22de-4508-b879-572674cdddb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-3fadd8fb-5d83-4784-979d-3c676b030fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-a89d4891-7dc9-420c-bfd3-2b0b5c83c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-97984ab8-c33e-472e-a4c2-06e0d1c98d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-9ca419cb-866d-4d5d-910f-4879c704023b,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-de76d29c-b7f4-4bdc-9c90-75cdf86973c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656241142-172.17.0.10-1595863668496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37053,DS-6d2319fe-4f4a-4800-bed7-460b707a961f,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-9c0f93db-de5b-4ef6-be3c-c6f12f95cb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-9d3a49b5-22de-4508-b879-572674cdddb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-3fadd8fb-5d83-4784-979d-3c676b030fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-a89d4891-7dc9-420c-bfd3-2b0b5c83c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-97984ab8-c33e-472e-a4c2-06e0d1c98d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-9ca419cb-866d-4d5d-910f-4879c704023b,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-de76d29c-b7f4-4bdc-9c90-75cdf86973c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740026967-172.17.0.10-1595864401295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37133,DS-061b5ac1-dd73-42cb-90bb-6e4856611bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-35c9e385-e404-4bf2-85db-459308b14077,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-3e96a2b9-aa15-40ee-9c69-0297ba64cff5,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-d16cf47b-dbb1-4a9e-8139-7ff3372562b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-2185e2cc-4174-4756-971b-6e22094c4f46,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-baf705b3-f94e-4f99-bd21-c8b6d6a5ac4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-5560adaa-25a9-4b62-ba1e-2e5f0e2cddad,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-fefc9921-286a-4cdf-8720-c3daf651780f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740026967-172.17.0.10-1595864401295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37133,DS-061b5ac1-dd73-42cb-90bb-6e4856611bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-35c9e385-e404-4bf2-85db-459308b14077,DISK], DatanodeInfoWithStorage[127.0.0.1:34492,DS-3e96a2b9-aa15-40ee-9c69-0297ba64cff5,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-d16cf47b-dbb1-4a9e-8139-7ff3372562b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-2185e2cc-4174-4756-971b-6e22094c4f46,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-baf705b3-f94e-4f99-bd21-c8b6d6a5ac4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-5560adaa-25a9-4b62-ba1e-2e5f0e2cddad,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-fefc9921-286a-4cdf-8720-c3daf651780f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664933322-172.17.0.10-1595864608219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36409,DS-b77bc014-b418-40c6-9e5a-29d44b69eaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-6622c885-b534-42a5-8d5b-2257a33d44ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-2400c044-33a4-4f35-8b71-e09713766b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-b320d870-15a2-4ecc-9d1b-4485c4cc7966,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-1c8a363c-5fad-46cc-9e7d-00bf1c400377,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-c5b06f9d-df6b-4305-a458-b6547245091a,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-cccbd5b0-bdd6-4051-85ed-cb97b796fe6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-13498874-b413-4506-a0d4-238e86220405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1664933322-172.17.0.10-1595864608219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36409,DS-b77bc014-b418-40c6-9e5a-29d44b69eaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-6622c885-b534-42a5-8d5b-2257a33d44ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-2400c044-33a4-4f35-8b71-e09713766b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-b320d870-15a2-4ecc-9d1b-4485c4cc7966,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-1c8a363c-5fad-46cc-9e7d-00bf1c400377,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-c5b06f9d-df6b-4305-a458-b6547245091a,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-cccbd5b0-bdd6-4051-85ed-cb97b796fe6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-13498874-b413-4506-a0d4-238e86220405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362566225-172.17.0.10-1595864846793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32859,DS-f40b4d9b-a25a-4b62-b560-ca94ac2c2dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-a2b096b8-003a-48b1-a248-9a07447eb845,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-1aaf8ed5-2e3d-4184-80bd-5f1dad57ae09,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-6d9be48e-998e-421a-aced-948d8ac5f7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-ff8cca3f-7260-4557-9521-9b3c3478961a,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-0a501727-588d-4211-9be5-94b3806b889e,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-1311f5a7-71c6-48dc-bf17-d4584b5dcbce,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-28d06a01-169b-472d-8473-7d93d2e30729,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362566225-172.17.0.10-1595864846793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32859,DS-f40b4d9b-a25a-4b62-b560-ca94ac2c2dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-a2b096b8-003a-48b1-a248-9a07447eb845,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-1aaf8ed5-2e3d-4184-80bd-5f1dad57ae09,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-6d9be48e-998e-421a-aced-948d8ac5f7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-ff8cca3f-7260-4557-9521-9b3c3478961a,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-0a501727-588d-4211-9be5-94b3806b889e,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-1311f5a7-71c6-48dc-bf17-d4584b5dcbce,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-28d06a01-169b-472d-8473-7d93d2e30729,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908330040-172.17.0.10-1595864887485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36671,DS-8d29bf8e-52c7-49c7-9a39-7dfc4748a198,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-83395f36-3180-4ca9-abbe-63f00e4ed385,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-8a89c36a-4418-4a6b-b1cd-a380a218fbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-fa55b96c-4199-4e95-966a-f2f9989e4710,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-886a7688-40cc-40f5-9118-51104e1ca98a,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-8491e417-71eb-49f9-8833-d06239f62129,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-46faed1c-4195-479f-8344-f92b68c19a75,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-1b117262-522e-421a-b20e-14b86455233e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908330040-172.17.0.10-1595864887485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36671,DS-8d29bf8e-52c7-49c7-9a39-7dfc4748a198,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-83395f36-3180-4ca9-abbe-63f00e4ed385,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-8a89c36a-4418-4a6b-b1cd-a380a218fbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-fa55b96c-4199-4e95-966a-f2f9989e4710,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-886a7688-40cc-40f5-9118-51104e1ca98a,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-8491e417-71eb-49f9-8833-d06239f62129,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-46faed1c-4195-479f-8344-f92b68c19a75,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-1b117262-522e-421a-b20e-14b86455233e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-903536372-172.17.0.10-1595865026294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34872,DS-d302cd97-383a-4243-8ee9-db632f4f535e,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-da10d9be-7573-4270-8e63-bad268d036a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-358f8237-6f6b-4bb4-a41c-8cac5e39573b,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-718283a9-7c11-4fea-94ae-ca6ac7c8ff2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-248e5bbe-7ccf-4bee-bb08-7918743541fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-6ed98847-6f9f-4499-a56c-7c6775c6d432,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-62b5759d-6cfd-4bfd-9e29-4052a1f5d9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-543794df-2b56-4263-89bd-4983d2dc09ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-903536372-172.17.0.10-1595865026294:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34872,DS-d302cd97-383a-4243-8ee9-db632f4f535e,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-da10d9be-7573-4270-8e63-bad268d036a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-358f8237-6f6b-4bb4-a41c-8cac5e39573b,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-718283a9-7c11-4fea-94ae-ca6ac7c8ff2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-248e5bbe-7ccf-4bee-bb08-7918743541fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-6ed98847-6f9f-4499-a56c-7c6775c6d432,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-62b5759d-6cfd-4bfd-9e29-4052a1f5d9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-543794df-2b56-4263-89bd-4983d2dc09ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553981893-172.17.0.10-1595865428799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40972,DS-23c6d48f-9eaf-4fbd-9bda-60c08141fea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-42474b42-7d57-4a11-ae63-48234008a972,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-82e6f6c0-683c-49b0-8b6f-b61374c337a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-f13f9c5b-d001-415f-a3b7-bb6e62a3a407,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-14e3c4f5-2fd6-474c-8896-482731b87851,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-ac2c0290-3c94-41c6-83e3-d1f3063e08cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-abd4a8ee-3d73-4b89-8edf-71f1b3cbafd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-f3e0c02d-b23d-4993-a9c1-ee6bedb317ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553981893-172.17.0.10-1595865428799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40972,DS-23c6d48f-9eaf-4fbd-9bda-60c08141fea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-42474b42-7d57-4a11-ae63-48234008a972,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-82e6f6c0-683c-49b0-8b6f-b61374c337a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-f13f9c5b-d001-415f-a3b7-bb6e62a3a407,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-14e3c4f5-2fd6-474c-8896-482731b87851,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-ac2c0290-3c94-41c6-83e3-d1f3063e08cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-abd4a8ee-3d73-4b89-8edf-71f1b3cbafd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-f3e0c02d-b23d-4993-a9c1-ee6bedb317ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889423118-172.17.0.10-1595866018336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36887,DS-3cbc4b8c-8f89-4ae9-8f6e-1b2e2186ae48,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-9c23a7e8-d073-465e-a054-f12e5eb9a6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-db2c61a9-abf4-43e1-8142-16f8792e44ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-a34d9d2a-36aa-4dd5-b66c-b8783057db05,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-9bfa8a5d-8600-4ec4-b6b7-9795e125b53e,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-9d24b874-6a16-4a73-bf5b-d5217c7f1278,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-3cc2f332-7ad5-45eb-89ec-c52587548506,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-071f2119-60d7-4542-b1a1-8bfc73560c97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889423118-172.17.0.10-1595866018336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36887,DS-3cbc4b8c-8f89-4ae9-8f6e-1b2e2186ae48,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-9c23a7e8-d073-465e-a054-f12e5eb9a6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-db2c61a9-abf4-43e1-8142-16f8792e44ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-a34d9d2a-36aa-4dd5-b66c-b8783057db05,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-9bfa8a5d-8600-4ec4-b6b7-9795e125b53e,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-9d24b874-6a16-4a73-bf5b-d5217c7f1278,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-3cc2f332-7ad5-45eb-89ec-c52587548506,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-071f2119-60d7-4542-b1a1-8bfc73560c97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5616
