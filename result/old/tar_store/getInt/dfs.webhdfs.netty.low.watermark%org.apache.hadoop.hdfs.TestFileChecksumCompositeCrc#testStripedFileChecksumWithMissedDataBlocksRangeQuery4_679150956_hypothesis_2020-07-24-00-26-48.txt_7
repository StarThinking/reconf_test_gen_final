reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316688962-172.17.0.21-1595550531787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36649,DS-268e290b-c767-4def-9db7-6e39ba7d2c45,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-ca1fcfc9-5560-4225-834c-960104931c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-58c56b0e-7ec0-4868-bdb5-f6ebaae88d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-5160836f-23ca-40ba-a62d-a910a4d935e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-9254c299-036f-421d-8871-16c6649ebf29,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-7787a3dd-4e37-41a0-ad7b-a71ebbf19c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-388b6a29-9e74-48bb-ac8e-8485383afe80,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-72cbfc0a-d6b7-4883-8bba-21cccfebeab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316688962-172.17.0.21-1595550531787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36649,DS-268e290b-c767-4def-9db7-6e39ba7d2c45,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-ca1fcfc9-5560-4225-834c-960104931c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-58c56b0e-7ec0-4868-bdb5-f6ebaae88d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-5160836f-23ca-40ba-a62d-a910a4d935e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-9254c299-036f-421d-8871-16c6649ebf29,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-7787a3dd-4e37-41a0-ad7b-a71ebbf19c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-388b6a29-9e74-48bb-ac8e-8485383afe80,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-72cbfc0a-d6b7-4883-8bba-21cccfebeab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448497178-172.17.0.21-1595551092536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41235,DS-c0528be6-a3ba-4f45-849c-53d99226bbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-b20aeafc-ccd4-4df0-a32a-1517cf0b0bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-4298f851-dd1a-41c8-ba26-e931b729c17f,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-c4ec5ff4-5d46-41aa-a9d3-d67c86da4094,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-d3d478c4-2a21-49cf-863d-f018869c91f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-17f25e0e-8d6a-4166-a145-e9f613e8b99f,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-d670b629-2c5b-46f3-ba6e-d6ea5bb0ac43,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-cca0724b-dc84-4867-bec8-18a6901edba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448497178-172.17.0.21-1595551092536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41235,DS-c0528be6-a3ba-4f45-849c-53d99226bbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-b20aeafc-ccd4-4df0-a32a-1517cf0b0bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-4298f851-dd1a-41c8-ba26-e931b729c17f,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-c4ec5ff4-5d46-41aa-a9d3-d67c86da4094,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-d3d478c4-2a21-49cf-863d-f018869c91f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-17f25e0e-8d6a-4166-a145-e9f613e8b99f,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-d670b629-2c5b-46f3-ba6e-d6ea5bb0ac43,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-cca0724b-dc84-4867-bec8-18a6901edba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028143528-172.17.0.21-1595551316561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33371,DS-246df551-6440-4dac-b7b2-05261480dac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-23ba3e02-2013-4248-8f12-964497efcd48,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-71550323-7bdd-40b5-a7e7-3d1aa675cd30,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-69ef8c3b-b5ca-42e4-b28c-a275021ffc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-de85e6a8-93d3-466e-98de-bfc597d0c1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-699579d5-5303-4295-9238-2ee55ca53017,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-99796e50-8036-4780-9ff9-ce339f88f8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-1912cf40-e177-4371-9bda-1a69a7c12e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2028143528-172.17.0.21-1595551316561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33371,DS-246df551-6440-4dac-b7b2-05261480dac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-23ba3e02-2013-4248-8f12-964497efcd48,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-71550323-7bdd-40b5-a7e7-3d1aa675cd30,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-69ef8c3b-b5ca-42e4-b28c-a275021ffc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-de85e6a8-93d3-466e-98de-bfc597d0c1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-699579d5-5303-4295-9238-2ee55ca53017,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-99796e50-8036-4780-9ff9-ce339f88f8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-1912cf40-e177-4371-9bda-1a69a7c12e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452762217-172.17.0.21-1595551833057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43186,DS-48884466-d1f8-4e2b-856d-7d920ab95b23,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-1249d050-7b85-4b73-93f4-99dc6bfda4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-7d95cb0c-ba8b-49e3-9143-7005dc4323f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-323f298c-1d82-4231-aaff-411c74474a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-e6c608ef-a414-4aef-9f18-34c1eaaf5e87,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-d9d12dde-41d3-4aa6-88e4-c1eb7e07f814,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-f8deef20-abab-4e55-af33-c91784e7d3af,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-31ced406-b513-4744-b9dc-66dd0104efd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452762217-172.17.0.21-1595551833057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43186,DS-48884466-d1f8-4e2b-856d-7d920ab95b23,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-1249d050-7b85-4b73-93f4-99dc6bfda4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-7d95cb0c-ba8b-49e3-9143-7005dc4323f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-323f298c-1d82-4231-aaff-411c74474a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-e6c608ef-a414-4aef-9f18-34c1eaaf5e87,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-d9d12dde-41d3-4aa6-88e4-c1eb7e07f814,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-f8deef20-abab-4e55-af33-c91784e7d3af,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-31ced406-b513-4744-b9dc-66dd0104efd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550785036-172.17.0.21-1595551862770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44375,DS-11c23133-c848-4596-9183-594796f45ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-a749f0f8-fab5-4351-b978-a0904a80d3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-18bacad0-822b-444b-893e-a9582e971333,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-d08fc503-c02f-4177-a721-811a88c4b6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-5fe450fe-4836-4605-8399-66d8e3578113,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-01dc018e-a231-4107-9552-dc10147068d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-597c578e-0ebd-498c-9b44-c0caedf2ace9,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-b1626b08-32e1-4eae-ab0c-7c7cc2a3bc3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550785036-172.17.0.21-1595551862770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44375,DS-11c23133-c848-4596-9183-594796f45ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-a749f0f8-fab5-4351-b978-a0904a80d3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-18bacad0-822b-444b-893e-a9582e971333,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-d08fc503-c02f-4177-a721-811a88c4b6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-5fe450fe-4836-4605-8399-66d8e3578113,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-01dc018e-a231-4107-9552-dc10147068d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-597c578e-0ebd-498c-9b44-c0caedf2ace9,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-b1626b08-32e1-4eae-ab0c-7c7cc2a3bc3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847829855-172.17.0.21-1595552576153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39883,DS-c925af04-c169-45b1-b6bf-50cbb6c991f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-2eda4998-b85e-4bbc-a635-590adf11a7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-f668d656-fea8-43ec-abbb-5a4460ff8716,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-65bd5b73-f890-49e1-b753-da9f479198ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-13e6e8d5-a82d-4b42-b7b5-5dd500ea541f,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-76185489-f143-4e01-bc40-a3db521a42d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-4d3766d0-0b06-46c9-ab3a-8eaa0baad2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-d911f03a-074f-4e14-82b2-be9a0fb42fc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-847829855-172.17.0.21-1595552576153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39883,DS-c925af04-c169-45b1-b6bf-50cbb6c991f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-2eda4998-b85e-4bbc-a635-590adf11a7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-f668d656-fea8-43ec-abbb-5a4460ff8716,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-65bd5b73-f890-49e1-b753-da9f479198ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-13e6e8d5-a82d-4b42-b7b5-5dd500ea541f,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-76185489-f143-4e01-bc40-a3db521a42d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-4d3766d0-0b06-46c9-ab3a-8eaa0baad2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-d911f03a-074f-4e14-82b2-be9a0fb42fc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917530500-172.17.0.21-1595552609709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37493,DS-08d45f20-f7e4-4454-b8e4-9127f6626d29,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-8a1fc964-7fc0-4925-880a-afd0d88b7f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-a0d1ba94-b98f-41af-91ad-ad38cd9cfe10,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-724c352c-f632-4f36-aeca-ac27947b6152,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-ff30b5ed-c777-4fb0-a360-b84fddfb5089,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-17399aef-0ce9-497d-a116-31d1d42c9b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-3d43b1dc-a6a0-46d9-aac7-4d32e2fbc47d,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-495252a4-868c-4f0b-8f4f-833ec3862edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917530500-172.17.0.21-1595552609709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37493,DS-08d45f20-f7e4-4454-b8e4-9127f6626d29,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-8a1fc964-7fc0-4925-880a-afd0d88b7f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-a0d1ba94-b98f-41af-91ad-ad38cd9cfe10,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-724c352c-f632-4f36-aeca-ac27947b6152,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-ff30b5ed-c777-4fb0-a360-b84fddfb5089,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-17399aef-0ce9-497d-a116-31d1d42c9b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-3d43b1dc-a6a0-46d9-aac7-4d32e2fbc47d,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-495252a4-868c-4f0b-8f4f-833ec3862edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589747623-172.17.0.21-1595552958240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-03b68234-d724-4e82-8dd6-cb4fbe6bfcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-5f452bca-c980-42a8-9782-d8c137fe2660,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-37e1e9ac-9973-4408-a868-6791e284877d,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-b18c7c1d-7e0d-410f-8912-5a16bad9d2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-4c985359-76a7-4548-9890-faf737fb5464,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-46de607a-2228-4022-ade6-05b50a6c548c,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-166180fc-0fc3-4c52-b059-d7ee644ba709,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-52db7397-4675-4cf5-a588-66808b21e554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589747623-172.17.0.21-1595552958240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-03b68234-d724-4e82-8dd6-cb4fbe6bfcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-5f452bca-c980-42a8-9782-d8c137fe2660,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-37e1e9ac-9973-4408-a868-6791e284877d,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-b18c7c1d-7e0d-410f-8912-5a16bad9d2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-4c985359-76a7-4548-9890-faf737fb5464,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-46de607a-2228-4022-ade6-05b50a6c548c,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-166180fc-0fc3-4c52-b059-d7ee644ba709,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-52db7397-4675-4cf5-a588-66808b21e554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938071219-172.17.0.21-1595553744033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33169,DS-efc830f8-164e-4c0f-a9af-8d014cff21cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-587b95ba-32a0-49d8-8801-d6f80af46f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-6a919ded-b17b-47df-a8da-c2451fb16d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-f6b9de44-1c04-4d20-bd60-937cda299b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-373e4e8c-75a0-4488-95ca-2640474ee7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-2c6af9e5-0db8-4493-9983-7e29ba46023a,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-426866fa-cae1-410c-a91d-fd5714f795da,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-a096c00d-750c-46a7-bcc0-be1290ef34a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938071219-172.17.0.21-1595553744033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33169,DS-efc830f8-164e-4c0f-a9af-8d014cff21cb,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-587b95ba-32a0-49d8-8801-d6f80af46f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-6a919ded-b17b-47df-a8da-c2451fb16d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-f6b9de44-1c04-4d20-bd60-937cda299b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-373e4e8c-75a0-4488-95ca-2640474ee7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-2c6af9e5-0db8-4493-9983-7e29ba46023a,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-426866fa-cae1-410c-a91d-fd5714f795da,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-a096c00d-750c-46a7-bcc0-be1290ef34a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10820789-172.17.0.21-1595554598614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36895,DS-ea299292-b220-4512-bff3-08849618ec54,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-7ab693ad-a0ad-492d-845d-d291bc96e8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-f6b720f3-d792-46b2-b307-614fcf7fd034,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-f9a3cfab-10f5-4b9a-9059-6aeb2f0e1eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-c2f998f2-02ce-433f-bb28-4628963b945b,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-bb013784-9ab9-4401-b2ad-7ddcb2e6749a,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-bec7807a-2bcf-4f52-a99c-19d11896f3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-b53e27ea-fe5c-4007-85ff-2e5f5b9d27cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10820789-172.17.0.21-1595554598614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36895,DS-ea299292-b220-4512-bff3-08849618ec54,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-7ab693ad-a0ad-492d-845d-d291bc96e8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-f6b720f3-d792-46b2-b307-614fcf7fd034,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-f9a3cfab-10f5-4b9a-9059-6aeb2f0e1eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-c2f998f2-02ce-433f-bb28-4628963b945b,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-bb013784-9ab9-4401-b2ad-7ddcb2e6749a,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-bec7807a-2bcf-4f52-a99c-19d11896f3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-b53e27ea-fe5c-4007-85ff-2e5f5b9d27cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444642141-172.17.0.21-1595554936589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34335,DS-af3f7e89-e1f4-4893-979b-d9e5033a8718,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-069a0a0a-e130-41c2-ba3a-2bec9bc2e840,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-cfee582f-b47f-4a12-ab36-ce3156736350,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-93b2c745-662f-4adb-92f4-33471a3a3973,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-afa89351-71c9-49db-9228-acc200887ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-877559ee-670a-4795-ae97-972324757d84,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-b8b3aa7c-a24c-4596-9cf1-dfeda06b4152,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-95fe7ff3-e8f8-4c38-92fb-8d422fee924c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-444642141-172.17.0.21-1595554936589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34335,DS-af3f7e89-e1f4-4893-979b-d9e5033a8718,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-069a0a0a-e130-41c2-ba3a-2bec9bc2e840,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-cfee582f-b47f-4a12-ab36-ce3156736350,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-93b2c745-662f-4adb-92f4-33471a3a3973,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-afa89351-71c9-49db-9228-acc200887ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-877559ee-670a-4795-ae97-972324757d84,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-b8b3aa7c-a24c-4596-9cf1-dfeda06b4152,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-95fe7ff3-e8f8-4c38-92fb-8d422fee924c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88265318-172.17.0.21-1595555114379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41989,DS-07bfcac3-17b8-48d9-aca4-42c0ed43a74c,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-f8f1f81e-2c05-4889-903b-9fac39e010be,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-5db518a1-a538-4948-b9db-17f09f125d22,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-942cb89c-20f8-40ba-97c6-dfeae7a15c40,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-6a6a817a-cfb5-4e5e-8615-b5642c15b861,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-b2f54153-ce32-45e9-b8cc-6db639b5c335,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-bb074e8b-7380-4a21-b3e2-6134afaa82cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-6d9aa681-741c-4bbd-badb-2c746ea9ddee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88265318-172.17.0.21-1595555114379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41989,DS-07bfcac3-17b8-48d9-aca4-42c0ed43a74c,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-f8f1f81e-2c05-4889-903b-9fac39e010be,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-5db518a1-a538-4948-b9db-17f09f125d22,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-942cb89c-20f8-40ba-97c6-dfeae7a15c40,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-6a6a817a-cfb5-4e5e-8615-b5642c15b861,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-b2f54153-ce32-45e9-b8cc-6db639b5c335,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-bb074e8b-7380-4a21-b3e2-6134afaa82cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-6d9aa681-741c-4bbd-badb-2c746ea9ddee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91962528-172.17.0.21-1595555191029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40335,DS-5cc76d78-333c-4dd0-9d11-54fd53d02d85,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-025528db-be1a-4f4f-bb2e-7b17896dbc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-491beecf-d12b-406d-9a31-5b0321a90f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-9fa35d4c-470e-4357-b191-4cc8ff6c67ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-4bb3737f-4af1-4706-b55b-ef3a7a8eb289,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-2f5d0631-1d89-450e-bce5-dac910cd59dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-9f3db5f6-1357-49f2-bcc5-de46b47f5c18,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-a986a02d-ecfc-4fbb-bfc3-cda2a905b954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-91962528-172.17.0.21-1595555191029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40335,DS-5cc76d78-333c-4dd0-9d11-54fd53d02d85,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-025528db-be1a-4f4f-bb2e-7b17896dbc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-491beecf-d12b-406d-9a31-5b0321a90f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-9fa35d4c-470e-4357-b191-4cc8ff6c67ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-4bb3737f-4af1-4706-b55b-ef3a7a8eb289,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-2f5d0631-1d89-450e-bce5-dac910cd59dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-9f3db5f6-1357-49f2-bcc5-de46b47f5c18,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-a986a02d-ecfc-4fbb-bfc3-cda2a905b954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595668809-172.17.0.21-1595555300041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34758,DS-35a6c658-1b59-414c-9271-815534687971,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-39a45967-4b8e-4236-b640-6aabd3370935,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-fafca701-4ac7-46ac-b630-8cdf8a0e54ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-43047cb9-33e0-4255-9fec-4c9c29ea685b,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-50388bff-5156-4f8d-a829-2d77128d56da,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-e716d8da-2846-495b-a039-19c5ea6f1aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-3d001da2-e70a-41a7-8d05-87a0c6011072,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-25f0e54d-cc90-4399-aa14-bb3d7dd0f66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595668809-172.17.0.21-1595555300041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34758,DS-35a6c658-1b59-414c-9271-815534687971,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-39a45967-4b8e-4236-b640-6aabd3370935,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-fafca701-4ac7-46ac-b630-8cdf8a0e54ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-43047cb9-33e0-4255-9fec-4c9c29ea685b,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-50388bff-5156-4f8d-a829-2d77128d56da,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-e716d8da-2846-495b-a039-19c5ea6f1aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-3d001da2-e70a-41a7-8d05-87a0c6011072,DISK], DatanodeInfoWithStorage[127.0.0.1:33734,DS-25f0e54d-cc90-4399-aa14-bb3d7dd0f66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 32768
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875612828-172.17.0.21-1595555341013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40071,DS-10fef2eb-3642-4dc0-a83f-bd7c1d1748d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-4483b503-0ec4-4a69-8291-f8c903f8631b,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-e6a624f9-e322-422b-8db5-32439862598e,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-6d2eac13-af49-4fbc-98f3-2476689c6a14,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-f67fb9f1-6962-460c-9226-19e2ea6e7b02,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-73f6db75-b1b3-4c53-aceb-b62a2cc4fddb,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-3c40d5ce-31f8-4bf7-aa06-dda6fd303650,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-7e3919f5-28d1-442f-a7bd-92708b4a3373,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875612828-172.17.0.21-1595555341013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40071,DS-10fef2eb-3642-4dc0-a83f-bd7c1d1748d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-4483b503-0ec4-4a69-8291-f8c903f8631b,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-e6a624f9-e322-422b-8db5-32439862598e,DISK], DatanodeInfoWithStorage[127.0.0.1:35177,DS-6d2eac13-af49-4fbc-98f3-2476689c6a14,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-f67fb9f1-6962-460c-9226-19e2ea6e7b02,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-73f6db75-b1b3-4c53-aceb-b62a2cc4fddb,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-3c40d5ce-31f8-4bf7-aa06-dda6fd303650,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-7e3919f5-28d1-442f-a7bd-92708b4a3373,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5266
