reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5981917-172.17.0.4-1596019374688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33247,DS-6a5db893-1b40-48ea-81bf-43c7a139bdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-5ef78b06-075d-4392-8dd9-8e0796ba6a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-fe21b91f-85f3-48bc-93c5-ae2bf2ce6299,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-d9596f07-1c4d-4272-b9ca-64190796aa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-1ba26531-9b0e-455e-b7df-eae96f1abb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-47fb409c-8347-49c0-b571-08590fa81f29,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-44525caf-f060-4c18-9825-a87571ebdb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-af2c312c-c17c-4b44-a3cc-14394a38cde4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-5981917-172.17.0.4-1596019374688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33247,DS-6a5db893-1b40-48ea-81bf-43c7a139bdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-5ef78b06-075d-4392-8dd9-8e0796ba6a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-fe21b91f-85f3-48bc-93c5-ae2bf2ce6299,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-d9596f07-1c4d-4272-b9ca-64190796aa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-1ba26531-9b0e-455e-b7df-eae96f1abb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-47fb409c-8347-49c0-b571-08590fa81f29,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-44525caf-f060-4c18-9825-a87571ebdb9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-af2c312c-c17c-4b44-a3cc-14394a38cde4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642391836-172.17.0.4-1596019411465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46351,DS-9a55224e-261e-4605-ba0e-63233e9e7645,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-e2250148-0eb6-4d4b-9671-375cb025d8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-fb17774f-5fc0-4ddc-af47-a056a358693a,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-03a243d8-a24c-473a-b3fe-be2860bfa4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-c07f7de5-393f-439b-b608-8f746293d88d,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-cfc5543b-fc68-4d02-bf1d-4a4f4f3f60e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-e4af1441-73f4-4b94-8b1a-49b2d3bd76f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-38b2942f-38df-48ac-b8ce-a29c495790b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642391836-172.17.0.4-1596019411465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46351,DS-9a55224e-261e-4605-ba0e-63233e9e7645,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-e2250148-0eb6-4d4b-9671-375cb025d8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-fb17774f-5fc0-4ddc-af47-a056a358693a,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-03a243d8-a24c-473a-b3fe-be2860bfa4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-c07f7de5-393f-439b-b608-8f746293d88d,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-cfc5543b-fc68-4d02-bf1d-4a4f4f3f60e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-e4af1441-73f4-4b94-8b1a-49b2d3bd76f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-38b2942f-38df-48ac-b8ce-a29c495790b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603164899-172.17.0.4-1596019529851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40928,DS-e52680a7-7e24-4dfa-b411-4f33c60efad9,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-3fe631b6-fe6a-4b20-ad7e-53f5ce6f1d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-99757c93-c1ed-4f1d-9ced-026f33a0db21,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-70090b07-f601-4550-878a-1f8e1a0c8041,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-d327980c-841d-4c1a-b549-14c54e964706,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-914be773-260b-4b70-b943-4ce8e1ce8cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-a469a074-91da-4102-810f-56b91d8cf124,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-44d1604b-b06b-484a-8015-94396f42fb78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603164899-172.17.0.4-1596019529851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40928,DS-e52680a7-7e24-4dfa-b411-4f33c60efad9,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-3fe631b6-fe6a-4b20-ad7e-53f5ce6f1d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-99757c93-c1ed-4f1d-9ced-026f33a0db21,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-70090b07-f601-4550-878a-1f8e1a0c8041,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-d327980c-841d-4c1a-b549-14c54e964706,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-914be773-260b-4b70-b943-4ce8e1ce8cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-a469a074-91da-4102-810f-56b91d8cf124,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-44d1604b-b06b-484a-8015-94396f42fb78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527888509-172.17.0.4-1596019609312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35166,DS-aae44b52-2e7e-4620-9e8e-46b014d22fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-3cbc1b49-5f31-4dcc-8119-b39b6f87e8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-bac886fb-dc6c-4722-a858-16e7b093d27a,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-2f270f06-278f-474d-ad25-0297ae838dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-427af4e8-f5e6-4bd7-8fac-09308829b818,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-d4e36d6b-db1f-4802-b753-d31f14dad0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-e5e73023-6e6c-41ff-9b9a-00a64cfef388,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-7c20d867-6642-4d9b-8749-81b17a345ce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527888509-172.17.0.4-1596019609312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35166,DS-aae44b52-2e7e-4620-9e8e-46b014d22fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-3cbc1b49-5f31-4dcc-8119-b39b6f87e8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-bac886fb-dc6c-4722-a858-16e7b093d27a,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-2f270f06-278f-474d-ad25-0297ae838dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-427af4e8-f5e6-4bd7-8fac-09308829b818,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-d4e36d6b-db1f-4802-b753-d31f14dad0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-e5e73023-6e6c-41ff-9b9a-00a64cfef388,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-7c20d867-6642-4d9b-8749-81b17a345ce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078467474-172.17.0.4-1596019680635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37946,DS-709b0a13-609c-43c6-933c-8d4e3b679bee,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-dc117024-da67-45f7-a3d6-1f11d3ddd464,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-458c6d01-2857-445a-87d4-723ce4223852,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-df80a7bb-a469-4a55-bbfe-8b14866a8fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-0851c7ef-edf0-46e1-9d4c-177177780bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-287f5d10-598e-4c82-b53c-a82ba987db87,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-78d7f7df-2288-4a1a-b5df-c2c84146dcca,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-726a5291-2093-4aee-9231-d94e90e97272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078467474-172.17.0.4-1596019680635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37946,DS-709b0a13-609c-43c6-933c-8d4e3b679bee,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-dc117024-da67-45f7-a3d6-1f11d3ddd464,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-458c6d01-2857-445a-87d4-723ce4223852,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-df80a7bb-a469-4a55-bbfe-8b14866a8fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-0851c7ef-edf0-46e1-9d4c-177177780bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-287f5d10-598e-4c82-b53c-a82ba987db87,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-78d7f7df-2288-4a1a-b5df-c2c84146dcca,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-726a5291-2093-4aee-9231-d94e90e97272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814181850-172.17.0.4-1596019856329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35208,DS-d85b02f7-0323-487c-be0f-05e9639ff49b,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-bbb99c16-25e7-4934-a0e8-bfb2ff06e58f,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-cda3c970-2d89-4057-aef3-3317d4ead918,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-71519742-7df6-459a-b5ac-56120f049334,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-145d3094-0835-4d43-aec5-dfac3db7022d,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-38386403-d4ac-4c57-9dc6-cc4702b379af,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-e619cc7c-9c5a-4791-a20e-a1e8ac5fed86,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-59baa97d-747f-4d83-b839-c68f2572d260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814181850-172.17.0.4-1596019856329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35208,DS-d85b02f7-0323-487c-be0f-05e9639ff49b,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-bbb99c16-25e7-4934-a0e8-bfb2ff06e58f,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-cda3c970-2d89-4057-aef3-3317d4ead918,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-71519742-7df6-459a-b5ac-56120f049334,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-145d3094-0835-4d43-aec5-dfac3db7022d,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-38386403-d4ac-4c57-9dc6-cc4702b379af,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-e619cc7c-9c5a-4791-a20e-a1e8ac5fed86,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-59baa97d-747f-4d83-b839-c68f2572d260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738922934-172.17.0.4-1596019895787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-a92c1ce5-6d62-41fd-bdcc-64ad6a64e8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-07b1f1ea-8be7-4d34-aead-8f5887785690,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-2ecb3cee-f3e6-4219-a05a-99f58e3d2d43,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-fc56f74e-5df3-4beb-97cd-514de2b5bd69,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-ffd04f5a-b876-4eab-bf2c-527549705b48,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-ef93782f-3ff3-4f20-8289-57c8a5c87d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-fa7ee3c1-f1c7-4809-a805-a3162ca109cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-319b7aa4-92bf-4957-bf10-d5d8f990e02c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-738922934-172.17.0.4-1596019895787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-a92c1ce5-6d62-41fd-bdcc-64ad6a64e8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-07b1f1ea-8be7-4d34-aead-8f5887785690,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-2ecb3cee-f3e6-4219-a05a-99f58e3d2d43,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-fc56f74e-5df3-4beb-97cd-514de2b5bd69,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-ffd04f5a-b876-4eab-bf2c-527549705b48,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-ef93782f-3ff3-4f20-8289-57c8a5c87d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-fa7ee3c1-f1c7-4809-a805-a3162ca109cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-319b7aa4-92bf-4957-bf10-d5d8f990e02c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838657606-172.17.0.4-1596020501717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36349,DS-a91b9517-488f-4f7f-9c2d-c3f802fc36c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-365fb251-13d4-48df-a527-c99b619a8301,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-779b9f14-e1aa-4107-9039-408b9a5d302e,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-e3766de4-1b7c-4345-9a10-a4398c41715a,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-962a20c3-7b69-4dcb-85c0-7337cb854cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-dffefee8-0e66-4d19-be1a-59dc7f1d3e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-4f89b9c8-3506-4c0c-b6c9-d103162f77dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-8483b913-b1ea-4708-9206-7eac7b76e17b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838657606-172.17.0.4-1596020501717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36349,DS-a91b9517-488f-4f7f-9c2d-c3f802fc36c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-365fb251-13d4-48df-a527-c99b619a8301,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-779b9f14-e1aa-4107-9039-408b9a5d302e,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-e3766de4-1b7c-4345-9a10-a4398c41715a,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-962a20c3-7b69-4dcb-85c0-7337cb854cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-dffefee8-0e66-4d19-be1a-59dc7f1d3e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-4f89b9c8-3506-4c0c-b6c9-d103162f77dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-8483b913-b1ea-4708-9206-7eac7b76e17b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977991189-172.17.0.4-1596021254634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46851,DS-509c1792-ea02-4801-a19e-6d9f9dfba739,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-7e0274b1-c46e-4afd-a62c-1d61f35d6b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-f086d616-e9d4-4f71-ae8e-66b0f3c0ac28,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-c269c0e7-3335-4061-b85b-9a6fe5d40f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-9862b537-aef0-4cce-a811-ba30bfc23a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-b838e049-d94e-48fa-a621-e3bad9fa3af7,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-6c0f1c36-2d49-43e4-8b41-1c61b29f3ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-51fe4b04-a67e-4884-8a37-7a98b07cc57c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977991189-172.17.0.4-1596021254634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46851,DS-509c1792-ea02-4801-a19e-6d9f9dfba739,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-7e0274b1-c46e-4afd-a62c-1d61f35d6b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-f086d616-e9d4-4f71-ae8e-66b0f3c0ac28,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-c269c0e7-3335-4061-b85b-9a6fe5d40f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-9862b537-aef0-4cce-a811-ba30bfc23a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-b838e049-d94e-48fa-a621-e3bad9fa3af7,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-6c0f1c36-2d49-43e4-8b41-1c61b29f3ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-51fe4b04-a67e-4884-8a37-7a98b07cc57c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325411243-172.17.0.4-1596021334968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-74d80aeb-09df-42a7-9baf-cad65ad340b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-2bb96ea9-0e36-42e2-8afd-ed0b635aa175,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-d9fbcbdc-2e0e-4661-8ab5-a6266b262e35,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-09150e24-9e69-43bd-b66b-a6b36b017c20,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-7a9ca9c2-7961-4971-9801-cacbc1d262e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-ac810c44-c6b0-492f-b9b2-69e30ceed079,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-45a91c32-31b7-4f03-b6e4-7c20363ff1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-8e7a9843-1e0c-4233-b9e5-baf5701ec7c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325411243-172.17.0.4-1596021334968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-74d80aeb-09df-42a7-9baf-cad65ad340b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-2bb96ea9-0e36-42e2-8afd-ed0b635aa175,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-d9fbcbdc-2e0e-4661-8ab5-a6266b262e35,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-09150e24-9e69-43bd-b66b-a6b36b017c20,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-7a9ca9c2-7961-4971-9801-cacbc1d262e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-ac810c44-c6b0-492f-b9b2-69e30ceed079,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-45a91c32-31b7-4f03-b6e4-7c20363ff1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-8e7a9843-1e0c-4233-b9e5-baf5701ec7c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871662030-172.17.0.4-1596021436610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46205,DS-5bce1fe6-3f83-462d-8d08-86577fdb099e,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-97aa53f8-db20-4c0b-a9d7-17bcf584a254,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-b8ec5eb8-6c49-4808-9fbd-fa76f75b52c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-137eaeb0-eb14-4e08-a660-30561b59c8af,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-7d5c792e-6dc6-4bd5-9867-97129952c4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-4b4b9e24-13d7-4fb8-b091-c8e327774b15,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-4669e50e-4d29-45ad-ae29-74f5cea88b27,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-21bd9e11-012b-4fc1-8366-1d967bee5a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871662030-172.17.0.4-1596021436610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46205,DS-5bce1fe6-3f83-462d-8d08-86577fdb099e,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-97aa53f8-db20-4c0b-a9d7-17bcf584a254,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-b8ec5eb8-6c49-4808-9fbd-fa76f75b52c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-137eaeb0-eb14-4e08-a660-30561b59c8af,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-7d5c792e-6dc6-4bd5-9867-97129952c4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-4b4b9e24-13d7-4fb8-b091-c8e327774b15,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-4669e50e-4d29-45ad-ae29-74f5cea88b27,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-21bd9e11-012b-4fc1-8366-1d967bee5a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1591340426-172.17.0.4-1596021655551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46737,DS-997ff984-445a-4827-8781-3889406b755d,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-530e6641-953e-4a77-b6c0-ab6a376430b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-9e45e818-c209-4f7e-8b3d-e5add20834d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-5c41a1ea-cdac-4e1e-b306-d755715442c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-7316d806-56b9-40d3-94a0-29b39eccab8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-ceafdc1c-62ad-4482-8146-ef7fe4fe720b,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-a93bc06f-9520-4f43-a471-484b838b7289,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-0fcd1709-ba15-4163-a9a1-dc5614bc3c06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1591340426-172.17.0.4-1596021655551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46737,DS-997ff984-445a-4827-8781-3889406b755d,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-530e6641-953e-4a77-b6c0-ab6a376430b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-9e45e818-c209-4f7e-8b3d-e5add20834d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-5c41a1ea-cdac-4e1e-b306-d755715442c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-7316d806-56b9-40d3-94a0-29b39eccab8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44692,DS-ceafdc1c-62ad-4482-8146-ef7fe4fe720b,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-a93bc06f-9520-4f43-a471-484b838b7289,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-0fcd1709-ba15-4163-a9a1-dc5614bc3c06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503774451-172.17.0.4-1596021799332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-506657dd-9e67-459e-8576-2581792f42b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-d4c01dae-d4b3-4725-99a9-927c99f79d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-1ef7aa28-2d5e-492d-8195-2e0e2389191c,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-5e0828af-e281-422f-98c1-8f2b372cf332,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-7659deae-90b0-4873-a319-6b9343e7df24,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-ce418138-e5c4-4250-9cd7-296d46f9851d,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-35a6904c-616e-43de-8d90-634e648d1c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-5c598365-6ec3-4f2b-b6c9-99ee75309a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503774451-172.17.0.4-1596021799332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-506657dd-9e67-459e-8576-2581792f42b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-d4c01dae-d4b3-4725-99a9-927c99f79d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-1ef7aa28-2d5e-492d-8195-2e0e2389191c,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-5e0828af-e281-422f-98c1-8f2b372cf332,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-7659deae-90b0-4873-a319-6b9343e7df24,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-ce418138-e5c4-4250-9cd7-296d46f9851d,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-35a6904c-616e-43de-8d90-634e648d1c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-5c598365-6ec3-4f2b-b6c9-99ee75309a00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215349958-172.17.0.4-1596021832013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41034,DS-c28f7c74-359d-4d1c-99c7-b05694777984,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-85ff1908-1c4b-4993-9e55-036b7722adee,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-61a1c12a-93ee-4656-a971-cac8a5187402,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-d7a356f3-a4b0-460a-842b-aec0bbc8557c,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-e7b62291-db02-4ac5-8a0c-4d5bb25c776c,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-9cdae47b-d074-4548-ac7a-f3c2c85de610,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-1dba56d5-b96b-4922-9e7f-4f6744282584,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-2ba14e04-c354-4e85-be28-b1f900ed5a11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215349958-172.17.0.4-1596021832013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41034,DS-c28f7c74-359d-4d1c-99c7-b05694777984,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-85ff1908-1c4b-4993-9e55-036b7722adee,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-61a1c12a-93ee-4656-a971-cac8a5187402,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-d7a356f3-a4b0-460a-842b-aec0bbc8557c,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-e7b62291-db02-4ac5-8a0c-4d5bb25c776c,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-9cdae47b-d074-4548-ac7a-f3c2c85de610,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-1dba56d5-b96b-4922-9e7f-4f6744282584,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-2ba14e04-c354-4e85-be28-b1f900ed5a11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832204829-172.17.0.4-1596021984855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40069,DS-b8e50660-5b0f-4199-9e92-23bf790f6216,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-237c1f40-784b-4998-b91c-d4a281d478b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-3649793e-7b71-4ed5-a4c8-b11354eb59f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-d08cc9fc-fc28-4bc8-93ea-4957091ee0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-3045ac85-ae8e-4f61-9078-54fae6da462e,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-b6d662ef-2b98-41b9-a077-e6ad2aa64ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-639cfaf8-8fef-4f82-884d-141afa553628,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-28da3184-6cd4-4973-8d41-507491942b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-832204829-172.17.0.4-1596021984855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40069,DS-b8e50660-5b0f-4199-9e92-23bf790f6216,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-237c1f40-784b-4998-b91c-d4a281d478b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-3649793e-7b71-4ed5-a4c8-b11354eb59f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-d08cc9fc-fc28-4bc8-93ea-4957091ee0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-3045ac85-ae8e-4f61-9078-54fae6da462e,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-b6d662ef-2b98-41b9-a077-e6ad2aa64ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-639cfaf8-8fef-4f82-884d-141afa553628,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-28da3184-6cd4-4973-8d41-507491942b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786314838-172.17.0.4-1596022237759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-1f275a7c-5e05-4bef-8f22-72841dee4414,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-39962fb8-e75d-45a4-bed6-b2b3f21d5f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-e67e70f6-50eb-44a3-8019-6c6478ffe25a,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-0c926c02-9bfb-464e-b4f0-0d2a32b3044c,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-af166f43-b0f3-4ade-9d11-e5b4f3289907,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-c6d7a15e-b1cb-49f3-a3ac-9f77fd698362,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-764e8afa-ea15-4074-9bd6-31f8b9466879,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-f662c28b-0c93-45b8-b3f1-74e6b3b661f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786314838-172.17.0.4-1596022237759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-1f275a7c-5e05-4bef-8f22-72841dee4414,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-39962fb8-e75d-45a4-bed6-b2b3f21d5f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-e67e70f6-50eb-44a3-8019-6c6478ffe25a,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-0c926c02-9bfb-464e-b4f0-0d2a32b3044c,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-af166f43-b0f3-4ade-9d11-e5b4f3289907,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-c6d7a15e-b1cb-49f3-a3ac-9f77fd698362,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-764e8afa-ea15-4074-9bd6-31f8b9466879,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-f662c28b-0c93-45b8-b3f1-74e6b3b661f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790214033-172.17.0.4-1596022266534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34261,DS-3fbf6c5a-8ecc-4df2-bbfb-9eed21f1431b,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-7ffa082a-648a-4bbf-b00b-642724edbd36,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-5475b712-2925-4274-bb7a-a64167ee8aef,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-e1b66ca0-d45c-4e5c-8e27-a9d196ddabc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-ece25392-77c2-4965-8a21-07680d776149,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-5e015ce2-861b-4670-99d2-1a2b26ba285b,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-d262296d-3301-4635-8169-3cae80d453b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-c8c0a718-711c-4886-9cdd-c7720f17e7ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790214033-172.17.0.4-1596022266534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34261,DS-3fbf6c5a-8ecc-4df2-bbfb-9eed21f1431b,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-7ffa082a-648a-4bbf-b00b-642724edbd36,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-5475b712-2925-4274-bb7a-a64167ee8aef,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-e1b66ca0-d45c-4e5c-8e27-a9d196ddabc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-ece25392-77c2-4965-8a21-07680d776149,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-5e015ce2-861b-4670-99d2-1a2b26ba285b,DISK], DatanodeInfoWithStorage[127.0.0.1:36947,DS-d262296d-3301-4635-8169-3cae80d453b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-c8c0a718-711c-4886-9cdd-c7720f17e7ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517046716-172.17.0.4-1596022335993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41028,DS-a099a42e-403f-498e-a607-097817949019,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-28600246-ce66-40b0-933b-b146fc0d139b,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-e825dafc-a533-41b9-9e7a-4d6c095ab4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-826042f0-3ed6-471c-b0c2-b9d3d93edb43,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-d3b6e5cf-0730-4231-a6df-2a367458c87d,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-04358045-643a-4df9-9e41-f5d9442bd6de,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-3d4bc465-d4fd-4edf-bca1-166e16788454,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-f38dd23e-e925-4218-ab51-9aaa4af8e619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517046716-172.17.0.4-1596022335993:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41028,DS-a099a42e-403f-498e-a607-097817949019,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-28600246-ce66-40b0-933b-b146fc0d139b,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-e825dafc-a533-41b9-9e7a-4d6c095ab4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-826042f0-3ed6-471c-b0c2-b9d3d93edb43,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-d3b6e5cf-0730-4231-a6df-2a367458c87d,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-04358045-643a-4df9-9e41-f5d9442bd6de,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-3d4bc465-d4fd-4edf-bca1-166e16788454,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-f38dd23e-e925-4218-ab51-9aaa4af8e619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337914862-172.17.0.4-1596022661720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41337,DS-8ebdac40-48be-4444-9b45-8dcd2f5247db,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-198ee588-6412-4db3-9ffb-2e5a2c66bdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-851d09c7-dbc8-4fda-8eab-3f41c56a99de,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-cafe3629-23b1-41ef-9e1e-fbbf2e154af0,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-7994a14a-625a-4c53-88ee-3de3aa053fce,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-4037dcf7-b5dd-4fb3-bf27-6347e8baae9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-f4b02885-053f-407e-bb26-b1a7cae558bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-b704237c-599f-4410-ad1e-56cb0ffb0842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337914862-172.17.0.4-1596022661720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41337,DS-8ebdac40-48be-4444-9b45-8dcd2f5247db,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-198ee588-6412-4db3-9ffb-2e5a2c66bdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-851d09c7-dbc8-4fda-8eab-3f41c56a99de,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-cafe3629-23b1-41ef-9e1e-fbbf2e154af0,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-7994a14a-625a-4c53-88ee-3de3aa053fce,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-4037dcf7-b5dd-4fb3-bf27-6347e8baae9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-f4b02885-053f-407e-bb26-b1a7cae558bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-b704237c-599f-4410-ad1e-56cb0ffb0842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832506422-172.17.0.4-1596022884758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34521,DS-894b252c-5327-45ef-8947-4393e4659513,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-662cc662-a7b6-495c-a048-ab2c96a51aac,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-57ee15ec-b3e1-4d65-989b-08106560c692,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-04517594-6f1d-478b-a890-7f5617316e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-b1cd6bf2-3565-4d32-9516-02e6ea5392b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-da530404-4d72-429a-ba10-25ba9faa6342,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-268b5f8f-3454-42f9-9eb7-f8258b59ee89,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-f7e9ef6d-c3fb-43e9-b773-7ef91f94c699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832506422-172.17.0.4-1596022884758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34521,DS-894b252c-5327-45ef-8947-4393e4659513,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-662cc662-a7b6-495c-a048-ab2c96a51aac,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-57ee15ec-b3e1-4d65-989b-08106560c692,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-04517594-6f1d-478b-a890-7f5617316e43,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-b1cd6bf2-3565-4d32-9516-02e6ea5392b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-da530404-4d72-429a-ba10-25ba9faa6342,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-268b5f8f-3454-42f9-9eb7-f8258b59ee89,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-f7e9ef6d-c3fb-43e9-b773-7ef91f94c699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614340822-172.17.0.4-1596023072437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39286,DS-660792df-b651-4baa-9674-00147ff408a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-06ce512d-89ea-4fca-8e5c-29d9de008842,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-e1225d0c-0c0e-4e61-8217-a243225ab9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-331c13a3-b2ff-469c-82df-d9e8fa4b98fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-2c51bbb7-fca4-4d53-858d-e38a7b0bc676,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-8a8390f8-5069-4480-9eea-d2a86f87930a,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-db7841d7-345a-4f6e-a9bc-4cb0edc5a8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-00fa664c-b406-4df6-b394-082862a52946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614340822-172.17.0.4-1596023072437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39286,DS-660792df-b651-4baa-9674-00147ff408a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-06ce512d-89ea-4fca-8e5c-29d9de008842,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-e1225d0c-0c0e-4e61-8217-a243225ab9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-331c13a3-b2ff-469c-82df-d9e8fa4b98fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-2c51bbb7-fca4-4d53-858d-e38a7b0bc676,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-8a8390f8-5069-4480-9eea-d2a86f87930a,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-db7841d7-345a-4f6e-a9bc-4cb0edc5a8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-00fa664c-b406-4df6-b394-082862a52946,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320833818-172.17.0.4-1596023734575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36720,DS-85085931-56ce-49fd-9c3c-b009dd800b94,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-05f7ea81-8036-433b-95b2-3dab8aa8e57d,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-e1db4ae5-e54a-4ea6-a2d4-e65407c9b556,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-f2d63b8a-d907-4fbc-8d32-0b40a1c7a243,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-7f9c366f-a9df-4316-b067-74f4e2dba0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-b51fee1a-8e92-456b-b01d-78701be11453,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-b9026243-2c9c-40ff-a9c0-a0dddcbd6f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-afc6d16a-0adb-489f-a7ec-2c20a737ef73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1320833818-172.17.0.4-1596023734575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36720,DS-85085931-56ce-49fd-9c3c-b009dd800b94,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-05f7ea81-8036-433b-95b2-3dab8aa8e57d,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-e1db4ae5-e54a-4ea6-a2d4-e65407c9b556,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-f2d63b8a-d907-4fbc-8d32-0b40a1c7a243,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-7f9c366f-a9df-4316-b067-74f4e2dba0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-b51fee1a-8e92-456b-b01d-78701be11453,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-b9026243-2c9c-40ff-a9c0-a0dddcbd6f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-afc6d16a-0adb-489f-a7ec-2c20a737ef73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841869153-172.17.0.4-1596024068728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36040,DS-00ec26bb-c66b-4c2b-a737-da28dc8eb127,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-2d89b8a3-b1d6-4f78-ab42-3a6fdd21cea6,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-ffae442e-a17a-477c-8680-71e5bab3265d,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-b86ed6d2-6a39-4ef8-9ca9-13a59b82e15c,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-83a84145-57b6-40ee-b464-457b5d7130d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-a2359974-0b6f-4ea3-ae5f-b711329cbe47,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-aa52a1eb-babb-4ec0-8f72-b4cfe20a5e06,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-49fdcdc1-4d0f-46e9-abf4-f2e785deacb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841869153-172.17.0.4-1596024068728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36040,DS-00ec26bb-c66b-4c2b-a737-da28dc8eb127,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-2d89b8a3-b1d6-4f78-ab42-3a6fdd21cea6,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-ffae442e-a17a-477c-8680-71e5bab3265d,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-b86ed6d2-6a39-4ef8-9ca9-13a59b82e15c,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-83a84145-57b6-40ee-b464-457b5d7130d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-a2359974-0b6f-4ea3-ae5f-b711329cbe47,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-aa52a1eb-babb-4ec0-8f72-b4cfe20a5e06,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-49fdcdc1-4d0f-46e9-abf4-f2e785deacb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 2
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571019160-172.17.0.4-1596024362986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34156,DS-cba9b02e-b546-4eb6-9bbd-4080e685149c,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-97ede46f-ba89-42e6-9f43-8a74bc0e5108,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-a3c14d8f-4ccf-4b58-838b-f357ada340a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-09f43536-039a-4f08-8079-fc19db00cd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-ae1f11f2-ba32-4912-9a68-e5756cd72496,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-81f8ed69-e27b-4ab2-a1e0-fd55ede21f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-36863766-b592-4693-a8d9-bd89b280dc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-b838bb45-00a6-488a-ad2c-8af9a037d53c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571019160-172.17.0.4-1596024362986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34156,DS-cba9b02e-b546-4eb6-9bbd-4080e685149c,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-97ede46f-ba89-42e6-9f43-8a74bc0e5108,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-a3c14d8f-4ccf-4b58-838b-f357ada340a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-09f43536-039a-4f08-8079-fc19db00cd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-ae1f11f2-ba32-4912-9a68-e5756cd72496,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-81f8ed69-e27b-4ab2-a1e0-fd55ede21f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-36863766-b592-4693-a8d9-bd89b280dc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-b838bb45-00a6-488a-ad2c-8af9a037d53c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5414
