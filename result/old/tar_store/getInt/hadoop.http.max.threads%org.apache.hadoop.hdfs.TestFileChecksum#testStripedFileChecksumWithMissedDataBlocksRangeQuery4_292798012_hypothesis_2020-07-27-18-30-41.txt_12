reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671529887-172.17.0.10-1595875643121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42358,DS-3fad9130-0534-4b6f-9b8c-859a1440e8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-f355a37c-0ec9-40ca-a369-45d24233a527,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-9147d2f9-a0c8-4886-87e3-b4e63954d1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-189df771-3d10-4b06-9050-907b10d37f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-c3e5e355-379d-4edf-9d93-a99c545c3b60,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-abf58b07-2625-4123-82fe-f001f9d061f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-a829afa3-0aee-43af-a1b7-8fc0002242d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-d3356055-2b66-4ef5-a982-1e7b93f3627a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671529887-172.17.0.10-1595875643121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42358,DS-3fad9130-0534-4b6f-9b8c-859a1440e8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-f355a37c-0ec9-40ca-a369-45d24233a527,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-9147d2f9-a0c8-4886-87e3-b4e63954d1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-189df771-3d10-4b06-9050-907b10d37f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-c3e5e355-379d-4edf-9d93-a99c545c3b60,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-abf58b07-2625-4123-82fe-f001f9d061f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-a829afa3-0aee-43af-a1b7-8fc0002242d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-d3356055-2b66-4ef5-a982-1e7b93f3627a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928392404-172.17.0.10-1595875678226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44353,DS-eac8bf76-9e48-455e-905d-2da726a03675,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-d7cb2192-1f1e-4a55-90c8-573e2234aa78,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-f3838e36-8b1e-4ce9-8d8e-c8a7feee4bea,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-de4aa035-2b88-4efa-81f7-bd07a0b1b571,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-33f34373-28ea-4143-b344-05b9d8f3e8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-9948653a-af59-49c2-a3f4-c27a2cf92d46,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-8f6baf40-c7a4-4bbd-bd2d-aff52701d787,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-34343cb7-9498-4eff-8bac-a44ed86345a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928392404-172.17.0.10-1595875678226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44353,DS-eac8bf76-9e48-455e-905d-2da726a03675,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-d7cb2192-1f1e-4a55-90c8-573e2234aa78,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-f3838e36-8b1e-4ce9-8d8e-c8a7feee4bea,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-de4aa035-2b88-4efa-81f7-bd07a0b1b571,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-33f34373-28ea-4143-b344-05b9d8f3e8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-9948653a-af59-49c2-a3f4-c27a2cf92d46,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-8f6baf40-c7a4-4bbd-bd2d-aff52701d787,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-34343cb7-9498-4eff-8bac-a44ed86345a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2101547890-172.17.0.10-1595876940277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42941,DS-9e84b592-649c-4a97-9a33-8363b995cb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-1275dbbe-75c4-4cd1-bf4f-86305e675614,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-6f7a7f68-0463-4eed-8dfd-0ddd5d6b2765,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-7ef85793-2538-4f6f-ae81-62e04af67947,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-bac837b5-522a-4b4e-bbe6-846f398edc66,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-61dcef59-1ad4-4141-b06d-b2f5f9f487f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-2d9e6002-b683-4220-8229-63a9eb65a96b,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-dd108b33-d38c-4e8b-a170-5ed8001000ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2101547890-172.17.0.10-1595876940277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42941,DS-9e84b592-649c-4a97-9a33-8363b995cb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-1275dbbe-75c4-4cd1-bf4f-86305e675614,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-6f7a7f68-0463-4eed-8dfd-0ddd5d6b2765,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-7ef85793-2538-4f6f-ae81-62e04af67947,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-bac837b5-522a-4b4e-bbe6-846f398edc66,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-61dcef59-1ad4-4141-b06d-b2f5f9f487f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-2d9e6002-b683-4220-8229-63a9eb65a96b,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-dd108b33-d38c-4e8b-a170-5ed8001000ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791697388-172.17.0.10-1595877159855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33871,DS-86c7da08-c341-439e-9ddb-835469ae8e48,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-3731e373-a60d-48a3-8171-314396fa0260,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-13eeb66a-9a6c-4fbc-96cb-f906bfa75bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-170201ad-f685-4f78-b6c4-56fd979228f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-ec988231-0936-4eb7-ac4f-262fb8a0b0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-52649283-8c2e-4e75-8433-b5c28222d1de,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-eb1ba81a-e00e-4e7c-b15f-351b4a328c17,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-4ee5d74e-0b16-4661-919e-7a8d2e77cd61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791697388-172.17.0.10-1595877159855:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33871,DS-86c7da08-c341-439e-9ddb-835469ae8e48,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-3731e373-a60d-48a3-8171-314396fa0260,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-13eeb66a-9a6c-4fbc-96cb-f906bfa75bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-170201ad-f685-4f78-b6c4-56fd979228f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-ec988231-0936-4eb7-ac4f-262fb8a0b0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-52649283-8c2e-4e75-8433-b5c28222d1de,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-eb1ba81a-e00e-4e7c-b15f-351b4a328c17,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-4ee5d74e-0b16-4661-919e-7a8d2e77cd61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576941390-172.17.0.10-1595877429423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43454,DS-7a31aec4-48d9-4559-890a-eb0b2b64672d,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-72d58f96-3a9b-4571-be98-eb0b8c4bec93,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-56f2c8fa-3f01-43df-96f3-074fbce36d14,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-26cc0404-e829-4a79-b04d-2ae301b9da83,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-a9708268-ccdd-4070-9638-2a5abeb17cab,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-66f3b8f5-57f4-4c2a-8bd6-923aa8a9d635,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-1f13d199-61aa-48aa-ba28-50bfbc385a63,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-69bd3c2e-2b7d-4e5d-ad0b-d5a54dd2ef7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576941390-172.17.0.10-1595877429423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43454,DS-7a31aec4-48d9-4559-890a-eb0b2b64672d,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-72d58f96-3a9b-4571-be98-eb0b8c4bec93,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-56f2c8fa-3f01-43df-96f3-074fbce36d14,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-26cc0404-e829-4a79-b04d-2ae301b9da83,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-a9708268-ccdd-4070-9638-2a5abeb17cab,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-66f3b8f5-57f4-4c2a-8bd6-923aa8a9d635,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-1f13d199-61aa-48aa-ba28-50bfbc385a63,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-69bd3c2e-2b7d-4e5d-ad0b-d5a54dd2ef7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123420187-172.17.0.10-1595877461523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44512,DS-b344557d-9ecc-47ad-b14e-eb25b29d0017,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-db66afc6-beb9-4cda-aa27-a86f6d159c81,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-f494b7c8-56ff-4e71-918f-9c84dcc3b9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-13c8b3f4-2c0b-47cc-b433-c563c52fe759,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-2f970500-0351-41b2-bdcf-dbff4704db16,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-662e64ea-4ed3-490d-bfde-f4c71122b960,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-36cebbd9-da26-4312-9f28-fe8f8946d8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-adf4c55d-d5c3-4492-a93d-5bd7d694d222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123420187-172.17.0.10-1595877461523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44512,DS-b344557d-9ecc-47ad-b14e-eb25b29d0017,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-db66afc6-beb9-4cda-aa27-a86f6d159c81,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-f494b7c8-56ff-4e71-918f-9c84dcc3b9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-13c8b3f4-2c0b-47cc-b433-c563c52fe759,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-2f970500-0351-41b2-bdcf-dbff4704db16,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-662e64ea-4ed3-490d-bfde-f4c71122b960,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-36cebbd9-da26-4312-9f28-fe8f8946d8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-adf4c55d-d5c3-4492-a93d-5bd7d694d222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092512139-172.17.0.10-1595877941528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38537,DS-253f825a-273e-4105-ae54-0717e47ec2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-7ad3807a-d4c0-4c44-bf8a-a0d9a62bacc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-c9cf2752-5c3c-410b-8b52-7c8d94fd3ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-ce444a13-b5b2-46bc-8cab-04dd0cd341d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-acb16bf7-3b37-4c90-bdf4-28b526f6acfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-4d5c56c6-2b77-4633-9df0-77405be837cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-4b1fcc1e-9e3d-4fee-91de-33035d7402f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-465421ca-0109-4c51-bd55-907c4fc832b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092512139-172.17.0.10-1595877941528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38537,DS-253f825a-273e-4105-ae54-0717e47ec2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-7ad3807a-d4c0-4c44-bf8a-a0d9a62bacc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-c9cf2752-5c3c-410b-8b52-7c8d94fd3ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43357,DS-ce444a13-b5b2-46bc-8cab-04dd0cd341d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-acb16bf7-3b37-4c90-bdf4-28b526f6acfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-4d5c56c6-2b77-4633-9df0-77405be837cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-4b1fcc1e-9e3d-4fee-91de-33035d7402f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-465421ca-0109-4c51-bd55-907c4fc832b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251915388-172.17.0.10-1595878207353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34552,DS-c2b8e5fb-823a-46aa-85e5-878d6e3ff775,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-36fe491a-a976-45b4-be31-c70d755d3ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-abf243c0-e94b-4fd2-8d3c-8ea899cc2c27,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-5492fbc6-173a-41f1-a25f-89938e52652d,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-839fbb71-afa8-4447-8925-49a2ee18fd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-c02674b3-6b16-42fd-a9fc-c21a74982a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-ead5adfd-0738-4258-b405-4da018075751,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-15e2c750-a15b-4790-9d6f-cc35cc5382d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251915388-172.17.0.10-1595878207353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34552,DS-c2b8e5fb-823a-46aa-85e5-878d6e3ff775,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-36fe491a-a976-45b4-be31-c70d755d3ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-abf243c0-e94b-4fd2-8d3c-8ea899cc2c27,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-5492fbc6-173a-41f1-a25f-89938e52652d,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-839fbb71-afa8-4447-8925-49a2ee18fd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-c02674b3-6b16-42fd-a9fc-c21a74982a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-ead5adfd-0738-4258-b405-4da018075751,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-15e2c750-a15b-4790-9d6f-cc35cc5382d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834408998-172.17.0.10-1595878384466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36099,DS-2dee3133-206b-42d1-9405-47f59da37fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-b4ee721a-18e7-485e-a17b-770326eda0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-d4843fdc-c4f9-4961-b9b1-7448b112ba8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-82d63297-bf8d-427b-9649-a98719285fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-1eeeaffa-1fa6-4f10-994d-8d3c0fe56689,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-701e0d34-56eb-4531-a91f-2b553158418d,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-8702ae01-5ad7-4216-9657-d4c5cbfd6436,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-049af3fa-1f53-4e83-a991-fb60a63dc626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834408998-172.17.0.10-1595878384466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36099,DS-2dee3133-206b-42d1-9405-47f59da37fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-b4ee721a-18e7-485e-a17b-770326eda0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-d4843fdc-c4f9-4961-b9b1-7448b112ba8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-82d63297-bf8d-427b-9649-a98719285fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-1eeeaffa-1fa6-4f10-994d-8d3c0fe56689,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-701e0d34-56eb-4531-a91f-2b553158418d,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-8702ae01-5ad7-4216-9657-d4c5cbfd6436,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-049af3fa-1f53-4e83-a991-fb60a63dc626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190236786-172.17.0.10-1595878520067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34686,DS-e89dd814-4596-4807-af55-502792b72a25,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-2bb80f5d-023f-484c-aa0d-fc009e30d9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-66a05232-7af1-440c-af0d-945af2153793,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-f4f5e152-8354-498a-b145-5a0f3535322f,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-ff0372be-f7a5-4927-928a-428486a69309,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-2fed3ccb-70dc-4948-a042-958199e603ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-884c53a5-e4a3-42bc-be6d-f7baa90f6c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-7359f347-f28b-494a-b27f-d64ce4226b2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190236786-172.17.0.10-1595878520067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34686,DS-e89dd814-4596-4807-af55-502792b72a25,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-2bb80f5d-023f-484c-aa0d-fc009e30d9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-66a05232-7af1-440c-af0d-945af2153793,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-f4f5e152-8354-498a-b145-5a0f3535322f,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-ff0372be-f7a5-4927-928a-428486a69309,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-2fed3ccb-70dc-4948-a042-958199e603ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-884c53a5-e4a3-42bc-be6d-f7baa90f6c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-7359f347-f28b-494a-b27f-d64ce4226b2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831300001-172.17.0.10-1595878593306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35660,DS-63d312ad-0eaa-4074-9f0e-ec09c3300e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-a41eaa39-a3ce-4ae7-9e3c-6572db558cea,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-72496824-9b52-435f-a241-d2e4f8f657d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-a4566221-2406-4505-b54b-cb8d41bb9445,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-37163b91-0992-4663-a6c6-26ff7961523b,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-95c5158b-be07-43b1-b16c-0b1abc65b775,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-cfcf286c-c336-42af-a912-d885e89b2e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-7d6d9fc5-dfee-4c26-be32-9809f3e8443d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831300001-172.17.0.10-1595878593306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35660,DS-63d312ad-0eaa-4074-9f0e-ec09c3300e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-a41eaa39-a3ce-4ae7-9e3c-6572db558cea,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-72496824-9b52-435f-a241-d2e4f8f657d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-a4566221-2406-4505-b54b-cb8d41bb9445,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-37163b91-0992-4663-a6c6-26ff7961523b,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-95c5158b-be07-43b1-b16c-0b1abc65b775,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-cfcf286c-c336-42af-a912-d885e89b2e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-7d6d9fc5-dfee-4c26-be32-9809f3e8443d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910133487-172.17.0.10-1595878655152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38446,DS-20c582de-3c58-48e1-98da-b90df0eedf88,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-30b51a62-4e16-4cc5-b670-e35c4dd89163,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-3cfa02ff-debe-4c97-a739-99ce7f66720e,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-28fb5a4c-5792-400e-bbaf-61ec627ec1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-619cae56-0b4c-4976-a042-44ddb65d62e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-0bccf38f-00ee-49e1-b73b-88487a4e7a11,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-15357e21-a1c3-462e-a323-9a39b33eb058,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-06a96884-a40b-46e0-abb3-dce652854d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910133487-172.17.0.10-1595878655152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38446,DS-20c582de-3c58-48e1-98da-b90df0eedf88,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-30b51a62-4e16-4cc5-b670-e35c4dd89163,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-3cfa02ff-debe-4c97-a739-99ce7f66720e,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-28fb5a4c-5792-400e-bbaf-61ec627ec1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-619cae56-0b4c-4976-a042-44ddb65d62e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-0bccf38f-00ee-49e1-b73b-88487a4e7a11,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-15357e21-a1c3-462e-a323-9a39b33eb058,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-06a96884-a40b-46e0-abb3-dce652854d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882727170-172.17.0.10-1595878687139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35500,DS-10dd8e87-c60d-4fa5-acdd-bb2dd1174d47,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-0732a01c-eee7-4ef5-baf9-0e2652902900,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-8dbd6b58-dfc4-459e-b211-5b9e4268ffaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-0310c933-3f48-4a74-ac9a-f58aaf290105,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-d552f8ce-24c3-4d2b-9520-ba9fd0cd976f,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-45ff8f34-0851-4733-a853-3e5dd943fbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-551e0d65-f100-401e-bc0a-c32d853af6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-12351d21-b236-484d-b7a5-1bcbb724f222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882727170-172.17.0.10-1595878687139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35500,DS-10dd8e87-c60d-4fa5-acdd-bb2dd1174d47,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-0732a01c-eee7-4ef5-baf9-0e2652902900,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-8dbd6b58-dfc4-459e-b211-5b9e4268ffaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-0310c933-3f48-4a74-ac9a-f58aaf290105,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-d552f8ce-24c3-4d2b-9520-ba9fd0cd976f,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-45ff8f34-0851-4733-a853-3e5dd943fbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-551e0d65-f100-401e-bc0a-c32d853af6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-12351d21-b236-484d-b7a5-1bcbb724f222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087569046-172.17.0.10-1595878891559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37445,DS-6dff0212-a4af-407a-810e-1546e80d8a86,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-5b262c9e-0a51-4d8d-b3e7-80a87c45600a,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-818a9d9d-e905-453d-837e-3f2fcdf59039,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-73db229c-aa42-4354-a307-1d6c27e179d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-1ea42fac-d2a6-4d1b-93d0-8f39a7942f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-c86398ce-5ea6-48d0-8344-b5a1eddac466,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-7d62e921-7790-4979-a591-ed18c415eda3,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-4f4c5f43-d4f2-4592-a81e-9b5acf551214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087569046-172.17.0.10-1595878891559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37445,DS-6dff0212-a4af-407a-810e-1546e80d8a86,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-5b262c9e-0a51-4d8d-b3e7-80a87c45600a,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-818a9d9d-e905-453d-837e-3f2fcdf59039,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-73db229c-aa42-4354-a307-1d6c27e179d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-1ea42fac-d2a6-4d1b-93d0-8f39a7942f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-c86398ce-5ea6-48d0-8344-b5a1eddac466,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-7d62e921-7790-4979-a591-ed18c415eda3,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-4f4c5f43-d4f2-4592-a81e-9b5acf551214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884705875-172.17.0.10-1595878922329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43540,DS-855b6684-a220-421f-bd91-fb81e4456c03,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-77a5f209-af0a-4b54-a0cd-ae929670c1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-9e0398db-a5cd-4537-9e20-a31b20678c18,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-6340599b-3dc9-4fd0-a1ef-d871585e3c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-b69e0aff-3769-47ed-9849-9e6e9a9f06e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-d2f1b906-5023-417c-a0b1-ced478825afd,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-5eab0074-beff-4612-8427-d1a6962fc888,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-8d0e51ef-1394-48b1-b373-91bcd7efcdb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884705875-172.17.0.10-1595878922329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43540,DS-855b6684-a220-421f-bd91-fb81e4456c03,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-77a5f209-af0a-4b54-a0cd-ae929670c1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-9e0398db-a5cd-4537-9e20-a31b20678c18,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-6340599b-3dc9-4fd0-a1ef-d871585e3c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-b69e0aff-3769-47ed-9849-9e6e9a9f06e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-d2f1b906-5023-417c-a0b1-ced478825afd,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-5eab0074-beff-4612-8427-d1a6962fc888,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-8d0e51ef-1394-48b1-b373-91bcd7efcdb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301171707-172.17.0.10-1595879295808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32993,DS-7f002247-aea5-4f24-b969-ac85e866c5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-b2d85a5a-4465-426b-8ca5-e8bf56b6fec1,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-5fd81ada-a04c-49d9-8b6f-eeaf0dccb4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-c23de27e-c99c-42c2-a617-e2bbce76ca58,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-071aa4a3-0594-46fe-b978-3312691cba81,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-8e0c87fb-d3fd-4ade-b948-517c63177daa,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-e42e9602-e2b4-48c3-b023-45ccf1410b90,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-521df06b-f949-40e8-9367-2817146587b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301171707-172.17.0.10-1595879295808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32993,DS-7f002247-aea5-4f24-b969-ac85e866c5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-b2d85a5a-4465-426b-8ca5-e8bf56b6fec1,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-5fd81ada-a04c-49d9-8b6f-eeaf0dccb4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-c23de27e-c99c-42c2-a617-e2bbce76ca58,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-071aa4a3-0594-46fe-b978-3312691cba81,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-8e0c87fb-d3fd-4ade-b948-517c63177daa,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-e42e9602-e2b4-48c3-b023-45ccf1410b90,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-521df06b-f949-40e8-9367-2817146587b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389948503-172.17.0.10-1595879566629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35877,DS-0b3d490a-bd9a-4eb4-bc41-0c7554cd32e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-11071c18-d220-4989-8d19-66f8315d83c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-86d31ec8-c9be-4c1d-95c4-af5fbd69d4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-ebf02cf4-c597-4071-8d09-65c6583d0761,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-6c2e0b7f-6fd8-4f9f-ac5f-e987a3bb91d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-42a71d07-3daf-4ef9-9984-d7e29c38a8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-07e0e3cd-59c5-4800-9ba5-5dabcf97200c,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-b881a4b4-9251-464b-999c-03b2fa45b830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389948503-172.17.0.10-1595879566629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35877,DS-0b3d490a-bd9a-4eb4-bc41-0c7554cd32e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46187,DS-11071c18-d220-4989-8d19-66f8315d83c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-86d31ec8-c9be-4c1d-95c4-af5fbd69d4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-ebf02cf4-c597-4071-8d09-65c6583d0761,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-6c2e0b7f-6fd8-4f9f-ac5f-e987a3bb91d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-42a71d07-3daf-4ef9-9984-d7e29c38a8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-07e0e3cd-59c5-4800-9ba5-5dabcf97200c,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-b881a4b4-9251-464b-999c-03b2fa45b830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5078
