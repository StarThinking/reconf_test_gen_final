reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293249448-172.17.0.7-1595802962494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41578,DS-5932be11-a306-4298-96c6-96bff9873db6,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-225fef40-3ba7-4d0e-9b73-40d296fd3e53,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-23f3def0-f57b-4cfc-aa6c-1f6b664e16e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-3b8f18d1-9cd9-4a97-98af-4b158f857d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-ebb4def6-20e9-421a-8be7-37aff041b6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-5fa80b46-cfcd-4b4f-af2e-76e92c90d869,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-f27a59aa-3b6d-4ad9-8e94-ae9f63df0543,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-34eeec94-b12c-4a21-8f9a-41c5084f41b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293249448-172.17.0.7-1595802962494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41578,DS-5932be11-a306-4298-96c6-96bff9873db6,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-225fef40-3ba7-4d0e-9b73-40d296fd3e53,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-23f3def0-f57b-4cfc-aa6c-1f6b664e16e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-3b8f18d1-9cd9-4a97-98af-4b158f857d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-ebb4def6-20e9-421a-8be7-37aff041b6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-5fa80b46-cfcd-4b4f-af2e-76e92c90d869,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-f27a59aa-3b6d-4ad9-8e94-ae9f63df0543,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-34eeec94-b12c-4a21-8f9a-41c5084f41b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322656195-172.17.0.7-1595803070221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42594,DS-73fa621b-da87-4251-8b2c-34f24709fa80,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-0cd3b39c-2896-453c-a754-e45b11ec8fba,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-40bea9ab-99b6-4399-a301-1c1f5cc73e60,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-a4acb4ef-7985-443f-bc5d-e535a1a79932,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-5c8d3eab-ffb2-41d6-bb40-7f4c3889b763,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-9b39844e-e009-4398-be47-37bd3bd6801a,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-7f7953f1-53ed-4a8b-bcc9-2aa1682c4b75,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-c1030e8e-46b2-4ff2-b024-d8835c4a850b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322656195-172.17.0.7-1595803070221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42594,DS-73fa621b-da87-4251-8b2c-34f24709fa80,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-0cd3b39c-2896-453c-a754-e45b11ec8fba,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-40bea9ab-99b6-4399-a301-1c1f5cc73e60,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-a4acb4ef-7985-443f-bc5d-e535a1a79932,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-5c8d3eab-ffb2-41d6-bb40-7f4c3889b763,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-9b39844e-e009-4398-be47-37bd3bd6801a,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-7f7953f1-53ed-4a8b-bcc9-2aa1682c4b75,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-c1030e8e-46b2-4ff2-b024-d8835c4a850b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-985841024-172.17.0.7-1595804131818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36906,DS-71f1175e-9e89-4afe-9a89-871a0122089f,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-20475dd0-7d96-40bd-a89e-05e88dcf506f,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-e4b4e241-c1df-410a-90ae-320b3ffb58e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-de7ef131-faef-41f5-a6d4-875452d9f8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-8f1a3750-9f1b-40de-a3e6-a8ee24527419,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-11844472-1bd9-427a-b8b8-689c89ee5cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-a9d86414-52ad-4a06-a32c-d56bb67ddad9,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-48657120-44d3-4622-8686-fcd5dcaa67c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-985841024-172.17.0.7-1595804131818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36906,DS-71f1175e-9e89-4afe-9a89-871a0122089f,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-20475dd0-7d96-40bd-a89e-05e88dcf506f,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-e4b4e241-c1df-410a-90ae-320b3ffb58e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-de7ef131-faef-41f5-a6d4-875452d9f8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-8f1a3750-9f1b-40de-a3e6-a8ee24527419,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-11844472-1bd9-427a-b8b8-689c89ee5cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-a9d86414-52ad-4a06-a32c-d56bb67ddad9,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-48657120-44d3-4622-8686-fcd5dcaa67c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-21190386-172.17.0.7-1595804176404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42234,DS-30749728-1209-42ba-afa6-af0de4e6edf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-5262920a-7aa2-400c-9866-a88128fb9312,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-b02132bf-887b-425a-8504-8fa6856652b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-ec1870c9-66aa-4313-b771-c721de73e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-ac01ddd7-6e51-49de-ac4b-9284b577cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-286bc74a-887d-4aa7-863e-c8a67aedc7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-d63b4da6-f480-4613-b196-3af0f7e19c61,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-5514f33c-34d3-4f70-9e67-a5b446c9ba27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-21190386-172.17.0.7-1595804176404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42234,DS-30749728-1209-42ba-afa6-af0de4e6edf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-5262920a-7aa2-400c-9866-a88128fb9312,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-b02132bf-887b-425a-8504-8fa6856652b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-ec1870c9-66aa-4313-b771-c721de73e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-ac01ddd7-6e51-49de-ac4b-9284b577cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-286bc74a-887d-4aa7-863e-c8a67aedc7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-d63b4da6-f480-4613-b196-3af0f7e19c61,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-5514f33c-34d3-4f70-9e67-a5b446c9ba27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1240565467-172.17.0.7-1595804207752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35233,DS-e906953e-b9fc-4f75-af21-4400accb683e,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-60ba9c95-849a-494a-9575-3ec770fe836a,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-8f386f38-c0d3-4bd8-892a-375ed913fa66,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-5cde1486-cae3-4fd7-a703-d92684034619,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-9679baa9-b0c2-48aa-af6f-5c0a5c35638d,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-3f796192-2bef-44ce-83fd-be3b6f99a218,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-83a30486-00eb-4597-9b45-ea0a3f1eb196,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-03c8c229-8fa5-4682-abe6-cb4bed007367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1240565467-172.17.0.7-1595804207752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35233,DS-e906953e-b9fc-4f75-af21-4400accb683e,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-60ba9c95-849a-494a-9575-3ec770fe836a,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-8f386f38-c0d3-4bd8-892a-375ed913fa66,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-5cde1486-cae3-4fd7-a703-d92684034619,DISK], DatanodeInfoWithStorage[127.0.0.1:34651,DS-9679baa9-b0c2-48aa-af6f-5c0a5c35638d,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-3f796192-2bef-44ce-83fd-be3b6f99a218,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-83a30486-00eb-4597-9b45-ea0a3f1eb196,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-03c8c229-8fa5-4682-abe6-cb4bed007367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340454974-172.17.0.7-1595804401557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40744,DS-576183b1-520a-40d9-8f4f-22b0e2b8660e,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-20c34956-3096-4324-95ec-7c846c2266ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-3bdc2c80-c3d3-4c21-b5d2-9bedacf63c92,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-6aef017d-a153-4af2-9c9b-36baffb8a3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-c38071a5-4ef5-43d0-9518-ed9b3bff6624,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-0b9e3860-c612-4974-bac6-47176a14154c,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-11a25d7d-5670-4d9d-bcb4-7f0af619a9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-28d5e3e4-8381-4c32-9022-fe440b098c2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340454974-172.17.0.7-1595804401557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40744,DS-576183b1-520a-40d9-8f4f-22b0e2b8660e,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-20c34956-3096-4324-95ec-7c846c2266ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-3bdc2c80-c3d3-4c21-b5d2-9bedacf63c92,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-6aef017d-a153-4af2-9c9b-36baffb8a3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-c38071a5-4ef5-43d0-9518-ed9b3bff6624,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-0b9e3860-c612-4974-bac6-47176a14154c,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-11a25d7d-5670-4d9d-bcb4-7f0af619a9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-28d5e3e4-8381-4c32-9022-fe440b098c2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1621663198-172.17.0.7-1595804434345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46592,DS-bc5b9c14-a139-43f3-a8c9-27113b8d4284,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-6a584dcd-5a81-4bda-ad64-33e9048fba63,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-e2929bc8-03af-4104-8f0c-c7e36598e275,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-9ad16820-070e-4fda-a3ff-fa973d59e373,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-6edec42e-f5fe-41a0-a943-a93cbe96c78e,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-cca21fcd-20fc-492c-8df9-0b33c34bdc24,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-525988ed-1541-494f-b657-453fd3eb0e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-39702bca-1976-45f5-9a1e-cffc49f22979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1621663198-172.17.0.7-1595804434345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46592,DS-bc5b9c14-a139-43f3-a8c9-27113b8d4284,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-6a584dcd-5a81-4bda-ad64-33e9048fba63,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-e2929bc8-03af-4104-8f0c-c7e36598e275,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-9ad16820-070e-4fda-a3ff-fa973d59e373,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-6edec42e-f5fe-41a0-a943-a93cbe96c78e,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-cca21fcd-20fc-492c-8df9-0b33c34bdc24,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-525988ed-1541-494f-b657-453fd3eb0e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-39702bca-1976-45f5-9a1e-cffc49f22979,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064790021-172.17.0.7-1595804789000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35053,DS-99a0061e-9f61-4ed1-8280-441f620324f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-b4dcdf25-e2f3-4d54-a34c-d62a456fa5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-a8ddfee6-6bc7-4422-8598-2f520216ad19,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-248c7df7-c9ae-4f32-90e6-384755ec515d,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-d189e0cb-6d22-4fd7-b309-5512837b38e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-2341525f-bbc3-45f8-89be-6453eb22380d,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-97cbac83-5023-419c-a697-69350916245a,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-42ecee67-c678-49dd-b74b-968858494770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064790021-172.17.0.7-1595804789000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35053,DS-99a0061e-9f61-4ed1-8280-441f620324f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-b4dcdf25-e2f3-4d54-a34c-d62a456fa5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-a8ddfee6-6bc7-4422-8598-2f520216ad19,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-248c7df7-c9ae-4f32-90e6-384755ec515d,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-d189e0cb-6d22-4fd7-b309-5512837b38e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-2341525f-bbc3-45f8-89be-6453eb22380d,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-97cbac83-5023-419c-a697-69350916245a,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-42ecee67-c678-49dd-b74b-968858494770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1403610056-172.17.0.7-1595805451033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37811,DS-9eba8821-dde4-46ab-a32c-ec4400bafc28,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-36a0066a-e0e5-4382-995e-b7ee8501d3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-5aab48a8-384c-496b-97e8-84af04816766,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-89f48693-b05f-4c97-a601-68b4b1e58887,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-853a3da7-88ef-456e-9923-dce0d6984bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-52c4718b-7af6-4d01-aef1-f54693712c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-43f76d83-6955-4634-bd81-854293a2e8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-c634ac22-38a3-4e73-8dab-1d2b85491446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1403610056-172.17.0.7-1595805451033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37811,DS-9eba8821-dde4-46ab-a32c-ec4400bafc28,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-36a0066a-e0e5-4382-995e-b7ee8501d3f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-5aab48a8-384c-496b-97e8-84af04816766,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-89f48693-b05f-4c97-a601-68b4b1e58887,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-853a3da7-88ef-456e-9923-dce0d6984bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-52c4718b-7af6-4d01-aef1-f54693712c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-43f76d83-6955-4634-bd81-854293a2e8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-c634ac22-38a3-4e73-8dab-1d2b85491446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500316409-172.17.0.7-1595805569447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44781,DS-e61d6f35-cc11-4c27-9d46-726f45ed03a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-f48dfed1-75e9-4854-83db-29990119ca46,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-2e06f7f9-e2a7-46d8-b047-50a8fd57de45,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-1c56bffe-184e-496d-9dce-b1e03a5b9c38,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-8e378b38-04b1-4ee7-b489-90c534e8c4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-c39d5f56-e81f-49dd-8940-533bf6d1f90a,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-c05b907f-98f3-44f8-bf59-3f514b144ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-524bed1e-7839-4db0-8f7e-c7c9c053fc63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1500316409-172.17.0.7-1595805569447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44781,DS-e61d6f35-cc11-4c27-9d46-726f45ed03a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-f48dfed1-75e9-4854-83db-29990119ca46,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-2e06f7f9-e2a7-46d8-b047-50a8fd57de45,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-1c56bffe-184e-496d-9dce-b1e03a5b9c38,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-8e378b38-04b1-4ee7-b489-90c534e8c4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-c39d5f56-e81f-49dd-8940-533bf6d1f90a,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-c05b907f-98f3-44f8-bf59-3f514b144ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-524bed1e-7839-4db0-8f7e-c7c9c053fc63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138563083-172.17.0.7-1595805793808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36354,DS-6e7aab17-03ae-4d25-ae78-54c8548f307d,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-b9ec8144-e5b8-4955-b2a8-d0671ebccaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-bd40b07d-8dee-4694-8362-c3b84ce9aed2,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-1256e5d0-a3ff-4e2f-9a26-375a2fc66441,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-87bb1d56-5071-4496-bfc9-7475235c8dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-d363a927-d61a-40a1-9132-171ebf90a7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-250eafbd-87da-4202-a291-1bc3cfa32a89,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-3206cca2-aeca-4e42-886e-bd81a825484c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138563083-172.17.0.7-1595805793808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36354,DS-6e7aab17-03ae-4d25-ae78-54c8548f307d,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-b9ec8144-e5b8-4955-b2a8-d0671ebccaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-bd40b07d-8dee-4694-8362-c3b84ce9aed2,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-1256e5d0-a3ff-4e2f-9a26-375a2fc66441,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-87bb1d56-5071-4496-bfc9-7475235c8dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-d363a927-d61a-40a1-9132-171ebf90a7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-250eafbd-87da-4202-a291-1bc3cfa32a89,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-3206cca2-aeca-4e42-886e-bd81a825484c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11392068-172.17.0.7-1595805979954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-8e5aa23c-de5c-4f18-8315-322dd18f116a,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-3d8c8992-bb2a-4d13-8418-f599f7cd094a,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-70b1352e-12b6-4c02-ae47-017b6cb5a51a,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-5c655da9-b814-440b-8261-32c9842dbd61,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-ff0bda59-7bbb-4877-bf5f-dded8ed1500d,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-b7ee7227-94b6-4c6f-b81d-676f88ed507c,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-dd78bc76-63a7-44e4-8372-271e6bbb6808,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-00eddd92-f1ba-41e9-b9bb-a517aacd0897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11392068-172.17.0.7-1595805979954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-8e5aa23c-de5c-4f18-8315-322dd18f116a,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-3d8c8992-bb2a-4d13-8418-f599f7cd094a,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-70b1352e-12b6-4c02-ae47-017b6cb5a51a,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-5c655da9-b814-440b-8261-32c9842dbd61,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-ff0bda59-7bbb-4877-bf5f-dded8ed1500d,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-b7ee7227-94b6-4c6f-b81d-676f88ed507c,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-dd78bc76-63a7-44e4-8372-271e6bbb6808,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-00eddd92-f1ba-41e9-b9bb-a517aacd0897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027744186-172.17.0.7-1595806055780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42666,DS-de795cc9-893b-4934-ba6a-89df8c1685e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-ec7931b8-fa79-4883-b455-a724d6bf9303,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-de404bce-8a03-43e6-8325-dc6e8bbede13,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-f63e3550-739b-4e81-aff0-52f20c33397d,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-d66f1d53-8ab6-4d5e-a0ef-133a86b835a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-d93b576d-4fea-4736-8ea4-62ded52b0909,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-aa101190-1ed3-4d83-8338-274251c9a715,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-4fa650f9-850b-4287-82fb-49bae6d41e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1027744186-172.17.0.7-1595806055780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42666,DS-de795cc9-893b-4934-ba6a-89df8c1685e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-ec7931b8-fa79-4883-b455-a724d6bf9303,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-de404bce-8a03-43e6-8325-dc6e8bbede13,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-f63e3550-739b-4e81-aff0-52f20c33397d,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-d66f1d53-8ab6-4d5e-a0ef-133a86b835a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-d93b576d-4fea-4736-8ea4-62ded52b0909,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-aa101190-1ed3-4d83-8338-274251c9a715,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-4fa650f9-850b-4287-82fb-49bae6d41e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720061832-172.17.0.7-1595806504939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-1dc3bc45-910a-4d3b-8388-a77e005588df,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-533d40f6-eb77-49b4-8a7d-716fcc6e9796,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-6538fc08-e91c-4166-aebd-69e730489ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-1147141f-2bd2-4aaa-aa6b-3e25febffcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-6b24859a-6e47-422c-a413-68660897bee8,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-972f321c-4d93-4178-8bb9-f8af10ec4ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-ecbcfe83-6159-4b2b-b48d-e4004b64edc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-2d698770-3f93-49ca-ac47-511b11de6015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720061832-172.17.0.7-1595806504939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-1dc3bc45-910a-4d3b-8388-a77e005588df,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-533d40f6-eb77-49b4-8a7d-716fcc6e9796,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-6538fc08-e91c-4166-aebd-69e730489ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-1147141f-2bd2-4aaa-aa6b-3e25febffcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-6b24859a-6e47-422c-a413-68660897bee8,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-972f321c-4d93-4178-8bb9-f8af10ec4ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-ecbcfe83-6159-4b2b-b48d-e4004b64edc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-2d698770-3f93-49ca-ac47-511b11de6015,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646856128-172.17.0.7-1595806740567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44308,DS-b63d0cc0-bc28-411f-9c5d-3e57dbd50dab,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-c48e757e-b535-4458-9ed5-e58c1eca658c,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-6e84fad5-e1eb-4c05-8b86-f7fcd44b90d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-2db4e18b-eaf7-48cc-a3af-301dd9275061,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-ee8f007d-909b-4d92-93f6-8c73787ed126,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-f37315f7-3573-4b94-8a8c-5d24dbb79d32,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-47d316ec-e4e7-4ff4-9ad4-cdaf3316b6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-89a1525b-c2ed-404e-a1c9-f89afe6fcddb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646856128-172.17.0.7-1595806740567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44308,DS-b63d0cc0-bc28-411f-9c5d-3e57dbd50dab,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-c48e757e-b535-4458-9ed5-e58c1eca658c,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-6e84fad5-e1eb-4c05-8b86-f7fcd44b90d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-2db4e18b-eaf7-48cc-a3af-301dd9275061,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-ee8f007d-909b-4d92-93f6-8c73787ed126,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-f37315f7-3573-4b94-8a8c-5d24dbb79d32,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-47d316ec-e4e7-4ff4-9ad4-cdaf3316b6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-89a1525b-c2ed-404e-a1c9-f89afe6fcddb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273712848-172.17.0.7-1595807037871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42583,DS-7d6ee315-9437-4d47-ad1f-f5ba3c3ff081,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-1f7f0eb2-2407-4f33-bfcb-e2465c5f40e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-3356ea9a-1ad3-4319-9db8-f1551f7994b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-635c28b9-6cd1-406d-9d01-75181fd8616a,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-a5bf619d-92cc-4137-8566-baf3242c7474,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-e27dc8c1-bdfc-426e-9764-67485ef23e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-4d7f3f61-2e03-4c57-a8c9-78bce1ac855c,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-eec27a3f-29df-41e8-8eb1-6c662c3a94d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273712848-172.17.0.7-1595807037871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42583,DS-7d6ee315-9437-4d47-ad1f-f5ba3c3ff081,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-1f7f0eb2-2407-4f33-bfcb-e2465c5f40e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34320,DS-3356ea9a-1ad3-4319-9db8-f1551f7994b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-635c28b9-6cd1-406d-9d01-75181fd8616a,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-a5bf619d-92cc-4137-8566-baf3242c7474,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-e27dc8c1-bdfc-426e-9764-67485ef23e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46241,DS-4d7f3f61-2e03-4c57-a8c9-78bce1ac855c,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-eec27a3f-29df-41e8-8eb1-6c662c3a94d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022633548-172.17.0.7-1595807356851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45645,DS-78ef49df-e5d3-4d86-83eb-86bcfd515ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-ae2702cd-6001-4fad-96fc-46a6a8217bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-b51f287c-7776-4b69-ab74-b0b8aca69f56,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-9bccec86-36a1-488c-801f-2c92ab5c5f85,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-b4488d62-3eb5-46dd-ad1f-6558a03b9960,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-b71a8e16-e101-4719-bfb6-5bd46aababb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-7e0e4372-3d1c-4b6a-a92d-669acd1d095a,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-2ced172d-b7ba-49d0-bed7-2d12406b504e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022633548-172.17.0.7-1595807356851:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45645,DS-78ef49df-e5d3-4d86-83eb-86bcfd515ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-ae2702cd-6001-4fad-96fc-46a6a8217bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-b51f287c-7776-4b69-ab74-b0b8aca69f56,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-9bccec86-36a1-488c-801f-2c92ab5c5f85,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-b4488d62-3eb5-46dd-ad1f-6558a03b9960,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-b71a8e16-e101-4719-bfb6-5bd46aababb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-7e0e4372-3d1c-4b6a-a92d-669acd1d095a,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-2ced172d-b7ba-49d0-bed7-2d12406b504e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762840644-172.17.0.7-1595807591590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38731,DS-3bee85ca-003f-49af-8a8b-44f896b00407,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-6083eb83-a28e-4f09-b042-da62ff028193,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-5ed816ae-7769-4406-b951-6808dbf947e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-2aa55496-13ea-45bf-9f2a-c08366b67216,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-9db890a7-ccdd-4c86-86bb-a97e5798e7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-6a43465f-690f-4278-8ae2-61e9258f5f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-2f714830-e4ea-4219-a093-dee9e31895d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-53da7620-8c3f-48c4-941e-fb77a36d12ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-762840644-172.17.0.7-1595807591590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38731,DS-3bee85ca-003f-49af-8a8b-44f896b00407,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-6083eb83-a28e-4f09-b042-da62ff028193,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-5ed816ae-7769-4406-b951-6808dbf947e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-2aa55496-13ea-45bf-9f2a-c08366b67216,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-9db890a7-ccdd-4c86-86bb-a97e5798e7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-6a43465f-690f-4278-8ae2-61e9258f5f92,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-2f714830-e4ea-4219-a093-dee9e31895d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-53da7620-8c3f-48c4-941e-fb77a36d12ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2072834959-172.17.0.7-1595807712198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36578,DS-00acc7f1-d8fe-4737-b90b-b1744f3635f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-349dfccb-5ed2-4622-a173-c5d9a064cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-1bfbd57a-0c69-4e0d-8045-b1d810460d01,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-a3d9680a-6d5b-4a7d-b2c1-ad02c591b8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-987c6e0f-fc53-4889-bb8d-2b431457f5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-072a06f3-5305-4f2b-9d7a-9b47a71cb09a,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-5913cca4-2d7e-4876-bd4e-906806ade8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-5af3c9ce-d037-43d5-afc7-397af726ea57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2072834959-172.17.0.7-1595807712198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36578,DS-00acc7f1-d8fe-4737-b90b-b1744f3635f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-349dfccb-5ed2-4622-a173-c5d9a064cb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-1bfbd57a-0c69-4e0d-8045-b1d810460d01,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-a3d9680a-6d5b-4a7d-b2c1-ad02c591b8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-987c6e0f-fc53-4889-bb8d-2b431457f5e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-072a06f3-5305-4f2b-9d7a-9b47a71cb09a,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-5913cca4-2d7e-4876-bd4e-906806ade8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-5af3c9ce-d037-43d5-afc7-397af726ea57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5940
