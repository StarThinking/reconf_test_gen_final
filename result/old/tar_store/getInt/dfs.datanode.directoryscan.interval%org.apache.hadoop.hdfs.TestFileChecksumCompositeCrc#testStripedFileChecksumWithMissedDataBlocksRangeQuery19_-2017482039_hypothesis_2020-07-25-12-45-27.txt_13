reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587517601-172.17.0.21-1595682177557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42483,DS-2051ae8c-0f6d-4426-ada2-9fe507743db1,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-5ca4b9e1-18d0-469e-b937-9ec1def68cca,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-4f0d3277-ce04-4c8e-b33d-9a6405ec1b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-4ad44a72-ff2f-4bb5-b54c-32a8b0037ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-1c107b69-2d89-48e9-b0c0-8f12a273e800,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-400433da-24c4-4368-8140-0ab169bb5d04,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-276605a2-6365-43dc-b485-842b68758711,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-2d40433b-5c45-4135-9834-042498176416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587517601-172.17.0.21-1595682177557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42483,DS-2051ae8c-0f6d-4426-ada2-9fe507743db1,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-5ca4b9e1-18d0-469e-b937-9ec1def68cca,DISK], DatanodeInfoWithStorage[127.0.0.1:44170,DS-4f0d3277-ce04-4c8e-b33d-9a6405ec1b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-4ad44a72-ff2f-4bb5-b54c-32a8b0037ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-1c107b69-2d89-48e9-b0c0-8f12a273e800,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-400433da-24c4-4368-8140-0ab169bb5d04,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-276605a2-6365-43dc-b485-842b68758711,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-2d40433b-5c45-4135-9834-042498176416,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87677518-172.17.0.21-1595682220848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43651,DS-c176d64f-e2b8-4eae-a1b2-1c6a793a5eda,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-6883f59d-5bc9-4062-a7f9-902db6c95bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-8cb2b46b-64bc-42b7-96cb-6f024b409758,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-66c87fb8-77f1-4931-a859-2a8505e11a34,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-dfa79e4c-63c4-4b4a-aacd-6547f194760b,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-10618527-7c49-475e-b56d-f34f1b793efb,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-a883471b-abfb-412a-aeb0-04a25b6733a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-83a1fe23-6c26-41c6-b6fc-751f4f2356f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87677518-172.17.0.21-1595682220848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43651,DS-c176d64f-e2b8-4eae-a1b2-1c6a793a5eda,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-6883f59d-5bc9-4062-a7f9-902db6c95bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-8cb2b46b-64bc-42b7-96cb-6f024b409758,DISK], DatanodeInfoWithStorage[127.0.0.1:39072,DS-66c87fb8-77f1-4931-a859-2a8505e11a34,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-dfa79e4c-63c4-4b4a-aacd-6547f194760b,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-10618527-7c49-475e-b56d-f34f1b793efb,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-a883471b-abfb-412a-aeb0-04a25b6733a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-83a1fe23-6c26-41c6-b6fc-751f4f2356f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757702343-172.17.0.21-1595683012614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34876,DS-257f2385-534d-41ed-9e74-3f780e895ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-9c7da72d-a1f4-4aa5-a079-20627341fb35,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-7df4e54d-6260-420d-bf27-39be6bb6b3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-89e4fbbd-fe0a-4915-b7b3-8ca2b0c5d13a,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-2ce0c543-91ef-472c-b9e7-1da62509adab,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-694b05c3-66dc-4d1c-8463-8b923e87b0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-0faaaa73-3aae-46b8-be66-fb5b515c5759,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-82c78498-1469-4c60-a4d1-07eb637480f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757702343-172.17.0.21-1595683012614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34876,DS-257f2385-534d-41ed-9e74-3f780e895ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-9c7da72d-a1f4-4aa5-a079-20627341fb35,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-7df4e54d-6260-420d-bf27-39be6bb6b3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-89e4fbbd-fe0a-4915-b7b3-8ca2b0c5d13a,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-2ce0c543-91ef-472c-b9e7-1da62509adab,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-694b05c3-66dc-4d1c-8463-8b923e87b0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-0faaaa73-3aae-46b8-be66-fb5b515c5759,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-82c78498-1469-4c60-a4d1-07eb637480f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2052595408-172.17.0.21-1595683792834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35891,DS-36679b21-07be-47b2-a103-877ef954d406,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-7819e603-df0e-42f3-b361-fdb959e28530,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-2fbacf57-00e6-4baf-b14f-c8442ccebba0,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-fc053816-853e-4423-8b41-07155725c71e,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-4592bf82-da69-4f0f-a996-afaad87f8862,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-4da62a3e-8332-4597-bd64-806f1c151604,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-d5a58c51-bb69-4f14-ad8a-3c181a2ffe31,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-76a205ec-541a-4a4b-8b17-e357d32537ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2052595408-172.17.0.21-1595683792834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35891,DS-36679b21-07be-47b2-a103-877ef954d406,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-7819e603-df0e-42f3-b361-fdb959e28530,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-2fbacf57-00e6-4baf-b14f-c8442ccebba0,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-fc053816-853e-4423-8b41-07155725c71e,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-4592bf82-da69-4f0f-a996-afaad87f8862,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-4da62a3e-8332-4597-bd64-806f1c151604,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-d5a58c51-bb69-4f14-ad8a-3c181a2ffe31,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-76a205ec-541a-4a4b-8b17-e357d32537ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-112369962-172.17.0.21-1595684609723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35760,DS-8c8109e4-f2cc-4f2f-9853-a53c516e7c73,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-2540055a-33e8-4d28-80fc-8bdef198b857,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-b754c28d-d13a-4e4b-9c38-623e4770029e,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-a90d9fe2-b993-4d1a-b96d-fc2c29753e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-f2a3ed2a-1298-431f-b03d-7c4f38988e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-46b73914-796d-46d3-9757-72e0eaca42b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-9eaaa458-8f16-4132-b799-e1aed858b3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-42f40a45-fac3-410d-bfc5-8b925d1ab0d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-112369962-172.17.0.21-1595684609723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35760,DS-8c8109e4-f2cc-4f2f-9853-a53c516e7c73,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-2540055a-33e8-4d28-80fc-8bdef198b857,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-b754c28d-d13a-4e4b-9c38-623e4770029e,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-a90d9fe2-b993-4d1a-b96d-fc2c29753e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-f2a3ed2a-1298-431f-b03d-7c4f38988e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-46b73914-796d-46d3-9757-72e0eaca42b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-9eaaa458-8f16-4132-b799-e1aed858b3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-42f40a45-fac3-410d-bfc5-8b925d1ab0d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195590894-172.17.0.21-1595684854454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39007,DS-2added52-3994-4ae2-8f94-689d124fe69f,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-03778d35-4645-4d28-9182-e934a1dca13e,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-39425318-87d3-4e0a-badd-d968600ae5af,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-b7922191-7e7e-49e6-9685-f9e45952090b,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-51846344-e107-4934-8216-8c9e2f333b78,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-5ea939da-5060-472b-8c02-3cf61ba0bb85,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-bc86038e-4670-4a9c-99a9-6289534623e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-5e9c36d5-ce3c-4a5d-9d5e-2d70c7fb30a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195590894-172.17.0.21-1595684854454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39007,DS-2added52-3994-4ae2-8f94-689d124fe69f,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-03778d35-4645-4d28-9182-e934a1dca13e,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-39425318-87d3-4e0a-badd-d968600ae5af,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-b7922191-7e7e-49e6-9685-f9e45952090b,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-51846344-e107-4934-8216-8c9e2f333b78,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-5ea939da-5060-472b-8c02-3cf61ba0bb85,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-bc86038e-4670-4a9c-99a9-6289534623e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-5e9c36d5-ce3c-4a5d-9d5e-2d70c7fb30a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320926235-172.17.0.21-1595685017343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43858,DS-ad3e707a-94e8-463e-bda3-0e65ec955399,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-8b9aef5f-ad30-4c06-b14a-87d622c71466,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-2f0fead8-4abf-4f62-b2f3-be9948b3b958,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-c235a1dc-a606-4750-9dd4-89b95c837f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-e26bf815-dbb9-4ad9-9419-bd0e21e52bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-2042b569-e487-4b17-be7c-2a5f2440f2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-ab034d11-fa13-41e8-8cde-c24c1bef7d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-4c60641c-cdf3-455c-8f04-fdf96a970253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320926235-172.17.0.21-1595685017343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43858,DS-ad3e707a-94e8-463e-bda3-0e65ec955399,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-8b9aef5f-ad30-4c06-b14a-87d622c71466,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-2f0fead8-4abf-4f62-b2f3-be9948b3b958,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-c235a1dc-a606-4750-9dd4-89b95c837f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-e26bf815-dbb9-4ad9-9419-bd0e21e52bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-2042b569-e487-4b17-be7c-2a5f2440f2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-ab034d11-fa13-41e8-8cde-c24c1bef7d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-4c60641c-cdf3-455c-8f04-fdf96a970253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778439763-172.17.0.21-1595685071105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36875,DS-08a1e035-eee9-4b92-8622-bc5446cce547,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-8e998fa4-9ff5-49e4-9512-9d118ee46c70,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-44d12955-5795-4fc8-b67d-73c5ba81ecc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-3d6462a4-ee0e-41fb-9ccf-ef3453f551e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-479ed0c1-e42a-414d-9157-286dc175cb97,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-232120c9-88d4-4a29-a7ab-2140fb8e25fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-500a55ac-7896-4750-9e9e-59baae43db01,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-a745351f-bfda-4638-b3d8-7ebfa53eb167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778439763-172.17.0.21-1595685071105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36875,DS-08a1e035-eee9-4b92-8622-bc5446cce547,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-8e998fa4-9ff5-49e4-9512-9d118ee46c70,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-44d12955-5795-4fc8-b67d-73c5ba81ecc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-3d6462a4-ee0e-41fb-9ccf-ef3453f551e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-479ed0c1-e42a-414d-9157-286dc175cb97,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-232120c9-88d4-4a29-a7ab-2140fb8e25fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-500a55ac-7896-4750-9e9e-59baae43db01,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-a745351f-bfda-4638-b3d8-7ebfa53eb167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863861665-172.17.0.21-1595685190999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37894,DS-71c7cdf1-4968-4eb0-a507-4e9603786760,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-1fc6bc10-9f7a-439c-bd9e-35e721f65c74,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-af17286c-8095-468d-afda-4159ab01afe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-96a6f78c-3c3d-4a08-9b67-af306d28e6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-f8816ed6-ac93-4d8d-aaea-438706ac27b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-b1dc61ff-0ea0-4c96-a2f6-e81f4859e58d,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-344fac28-e55b-41b8-bd12-d8beb2ab4990,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-0f3d280e-336a-42c8-a64a-42e38c1ef869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863861665-172.17.0.21-1595685190999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37894,DS-71c7cdf1-4968-4eb0-a507-4e9603786760,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-1fc6bc10-9f7a-439c-bd9e-35e721f65c74,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-af17286c-8095-468d-afda-4159ab01afe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-96a6f78c-3c3d-4a08-9b67-af306d28e6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-f8816ed6-ac93-4d8d-aaea-438706ac27b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-b1dc61ff-0ea0-4c96-a2f6-e81f4859e58d,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-344fac28-e55b-41b8-bd12-d8beb2ab4990,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-0f3d280e-336a-42c8-a64a-42e38c1ef869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593119691-172.17.0.21-1595685422002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41202,DS-7f61981b-033a-40f0-957c-abde33afc97b,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-fadc706a-3722-46da-be05-6be4a2d0c76c,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-1c1afd58-f2fe-4080-abf7-f391f3c7d283,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-69a5f3e0-9ca6-4ef4-bf23-e21667487c62,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-ba0b31f5-5e2d-4db7-8735-b011780de2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-1b4774a7-bd7c-43ec-a3ed-ee953eead61c,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-52d6bfd1-50d5-43a1-97d5-e86274467958,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-fffe879b-6c18-42d0-8def-ddc0b97c839a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593119691-172.17.0.21-1595685422002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41202,DS-7f61981b-033a-40f0-957c-abde33afc97b,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-fadc706a-3722-46da-be05-6be4a2d0c76c,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-1c1afd58-f2fe-4080-abf7-f391f3c7d283,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-69a5f3e0-9ca6-4ef4-bf23-e21667487c62,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-ba0b31f5-5e2d-4db7-8735-b011780de2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-1b4774a7-bd7c-43ec-a3ed-ee953eead61c,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-52d6bfd1-50d5-43a1-97d5-e86274467958,DISK], DatanodeInfoWithStorage[127.0.0.1:41766,DS-fffe879b-6c18-42d0-8def-ddc0b97c839a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198156216-172.17.0.21-1595685798076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37743,DS-e4914267-55ef-46ec-b60c-95c0932fe31c,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-2b14fcc3-e1f5-4e04-ab57-4b68c6ecc557,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-75091cd3-3833-4bd8-92a6-762b33a1c601,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-e900e2fa-0ffa-4903-9108-a21916435400,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-631afd94-6dd7-4096-abcc-0580941d3500,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-d4bb386d-1945-48e3-9427-3bb62061e6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-2eb3a4d2-55f2-4cfd-a6ec-1a9f49d00472,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-ba037782-7500-4dc1-acbd-5c1e3910eb93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198156216-172.17.0.21-1595685798076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37743,DS-e4914267-55ef-46ec-b60c-95c0932fe31c,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-2b14fcc3-e1f5-4e04-ab57-4b68c6ecc557,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-75091cd3-3833-4bd8-92a6-762b33a1c601,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-e900e2fa-0ffa-4903-9108-a21916435400,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-631afd94-6dd7-4096-abcc-0580941d3500,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-d4bb386d-1945-48e3-9427-3bb62061e6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-2eb3a4d2-55f2-4cfd-a6ec-1a9f49d00472,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-ba037782-7500-4dc1-acbd-5c1e3910eb93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271940306-172.17.0.21-1595685975125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36658,DS-9398ebc8-6992-4932-92f1-d44b02cbd7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-e9b24480-2dc7-4a61-a1cf-5678bedc0f40,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-cc963e81-efd7-4b30-86be-895d2f8299e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-75dafcbe-c0fa-4f4b-a714-2d09aaa62bee,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-280bfa8d-9970-4daa-b8be-07a0b88fce4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-107695b2-97f0-431f-a57a-36e24d56b2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-a85f59cd-81be-43b8-8f2f-52acc3983f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-c2db6fd3-d87d-44df-93ef-94217e3967ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271940306-172.17.0.21-1595685975125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36658,DS-9398ebc8-6992-4932-92f1-d44b02cbd7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-e9b24480-2dc7-4a61-a1cf-5678bedc0f40,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-cc963e81-efd7-4b30-86be-895d2f8299e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-75dafcbe-c0fa-4f4b-a714-2d09aaa62bee,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-280bfa8d-9970-4daa-b8be-07a0b88fce4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-107695b2-97f0-431f-a57a-36e24d56b2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-a85f59cd-81be-43b8-8f2f-52acc3983f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-c2db6fd3-d87d-44df-93ef-94217e3967ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507242054-172.17.0.21-1595686021339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43830,DS-4c867e60-999d-4c32-a341-cf540488562a,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-05e45958-2b7c-48f6-9f89-d6d671089de4,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-d562b761-46dc-4cc9-a44a-74e83f8ff750,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-103d1c30-f3e4-4ba4-b9d1-1be78debc1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-daf70ad4-d32b-40c8-8e27-0ed05974daa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-c9349c7d-1d91-42ac-a999-c2fc2bb2017c,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-7ba85dc1-7a21-432d-9ec2-fa82ac715823,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-8bcebb7f-fb34-44ea-9de0-b008dfbc9ae4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507242054-172.17.0.21-1595686021339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43830,DS-4c867e60-999d-4c32-a341-cf540488562a,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-05e45958-2b7c-48f6-9f89-d6d671089de4,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-d562b761-46dc-4cc9-a44a-74e83f8ff750,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-103d1c30-f3e4-4ba4-b9d1-1be78debc1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-daf70ad4-d32b-40c8-8e27-0ed05974daa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-c9349c7d-1d91-42ac-a999-c2fc2bb2017c,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-7ba85dc1-7a21-432d-9ec2-fa82ac715823,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-8bcebb7f-fb34-44ea-9de0-b008dfbc9ae4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913954029-172.17.0.21-1595686184109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46192,DS-afe3d9c4-cecb-482b-82ec-fe7b1553a910,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-9114df3f-232e-4320-902b-2d8707cec684,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-c9a7ff28-9d80-4b33-b15f-7de5997b0bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-837b8e55-c2b8-4f75-91f0-a308e37f8c26,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-738c7ee1-e4b7-419b-8e15-a21c2c14c683,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-f6055f5f-19da-45c3-8914-22e42fb17878,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-7d39c615-eb01-485a-9c37-da488f431a28,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-d6d83ed4-6df0-428a-8257-6ae6a1714585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913954029-172.17.0.21-1595686184109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46192,DS-afe3d9c4-cecb-482b-82ec-fe7b1553a910,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-9114df3f-232e-4320-902b-2d8707cec684,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-c9a7ff28-9d80-4b33-b15f-7de5997b0bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-837b8e55-c2b8-4f75-91f0-a308e37f8c26,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-738c7ee1-e4b7-419b-8e15-a21c2c14c683,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-f6055f5f-19da-45c3-8914-22e42fb17878,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-7d39c615-eb01-485a-9c37-da488f431a28,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-d6d83ed4-6df0-428a-8257-6ae6a1714585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575868313-172.17.0.21-1595686270617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38682,DS-3beb8a6d-946e-46ac-9c50-b6515716173a,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-7a130bc3-8b2e-4de9-96ec-b351b8d8a5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-a2955589-d41d-4b58-99ad-7065ce02d3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-d1415d98-7bda-4477-832d-ca54bfbfc9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-5d2ca9b2-cb97-416e-acec-50d62d28f382,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-4523f586-bcef-4467-a7cd-d3e150a00373,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-8e654960-8d85-4e39-9a62-1e5db4dddaca,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-0b0e430a-e8e2-4850-a2cd-b66ca0df5868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575868313-172.17.0.21-1595686270617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38682,DS-3beb8a6d-946e-46ac-9c50-b6515716173a,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-7a130bc3-8b2e-4de9-96ec-b351b8d8a5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-a2955589-d41d-4b58-99ad-7065ce02d3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-d1415d98-7bda-4477-832d-ca54bfbfc9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-5d2ca9b2-cb97-416e-acec-50d62d28f382,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-4523f586-bcef-4467-a7cd-d3e150a00373,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-8e654960-8d85-4e39-9a62-1e5db4dddaca,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-0b0e430a-e8e2-4850-a2cd-b66ca0df5868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117429431-172.17.0.21-1595686410263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41171,DS-ad868ec9-4c3a-4d01-b3a1-3a4d1c1e9194,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-65f9ed11-8308-4c63-87e3-fbc811defaad,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-537f4b10-9728-43e7-9726-1f1446a75be4,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-8b0d50aa-b940-434c-a329-a1d4fc0be835,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-b07ed21b-aa4d-479b-ab70-3374c8af1fed,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-488e0de4-a9ca-42be-92e7-97e5e745f501,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-94fc1e04-95ac-4393-a8ab-59eb3d48c54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-e5a27985-e1a1-43b1-bd7c-38ecdc2804c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117429431-172.17.0.21-1595686410263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41171,DS-ad868ec9-4c3a-4d01-b3a1-3a4d1c1e9194,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-65f9ed11-8308-4c63-87e3-fbc811defaad,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-537f4b10-9728-43e7-9726-1f1446a75be4,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-8b0d50aa-b940-434c-a329-a1d4fc0be835,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-b07ed21b-aa4d-479b-ab70-3374c8af1fed,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-488e0de4-a9ca-42be-92e7-97e5e745f501,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-94fc1e04-95ac-4393-a8ab-59eb3d48c54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-e5a27985-e1a1-43b1-bd7c-38ecdc2804c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709407606-172.17.0.21-1595686502287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42421,DS-9973fbaa-0f71-452d-810a-cf8d2660d004,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-143e4d10-ba8d-4cb2-a3f2-b12a5c71e2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-ac4fd265-5d23-446e-8138-86b14ce008dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-eeed6614-eb68-4fee-9a61-c2d7c662b6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-82e3f37e-801f-4188-b7a1-0d642e419f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-125124fb-2376-4f1f-b2b4-3b1409010027,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-d6e108c7-8f93-4c60-9aed-76b796732dba,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-21421ecb-64e4-494f-8782-33a1802226d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709407606-172.17.0.21-1595686502287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42421,DS-9973fbaa-0f71-452d-810a-cf8d2660d004,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-143e4d10-ba8d-4cb2-a3f2-b12a5c71e2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-ac4fd265-5d23-446e-8138-86b14ce008dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-eeed6614-eb68-4fee-9a61-c2d7c662b6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-82e3f37e-801f-4188-b7a1-0d642e419f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-125124fb-2376-4f1f-b2b4-3b1409010027,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-d6e108c7-8f93-4c60-9aed-76b796732dba,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-21421ecb-64e4-494f-8782-33a1802226d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411511035-172.17.0.21-1595686640959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39891,DS-aea265d7-7f76-4116-a203-6244d2f0e901,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-b6f47372-fe73-4658-9c23-8923f2fc8217,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-50305f05-8fae-4b98-8683-79f461a5ff32,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-3eeb2da3-fa43-4784-b6dc-76fa8ef78c62,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-9eb25818-1e5d-4eaf-bc8b-0a098c99e677,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-066f783e-8bc0-42b3-abf2-b0473a9a4d93,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-2ec7fe6f-ce83-4be1-8f62-f21beee58822,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-f61cd136-909f-4c6c-9d70-dfd4ef7a718f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411511035-172.17.0.21-1595686640959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39891,DS-aea265d7-7f76-4116-a203-6244d2f0e901,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-b6f47372-fe73-4658-9c23-8923f2fc8217,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-50305f05-8fae-4b98-8683-79f461a5ff32,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-3eeb2da3-fa43-4784-b6dc-76fa8ef78c62,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-9eb25818-1e5d-4eaf-bc8b-0a098c99e677,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-066f783e-8bc0-42b3-abf2-b0473a9a4d93,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-2ec7fe6f-ce83-4be1-8f62-f21beee58822,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-f61cd136-909f-4c6c-9d70-dfd4ef7a718f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-122749507-172.17.0.21-1595686679248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-054add54-c78e-42e6-8165-2e87ae729586,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-c893df5b-784b-436f-a40a-0da7acf3d002,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-414aa7bd-4e38-4e8a-8588-8456889542bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-9bfaeeb9-beec-4254-a6f9-26a3cb21b4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-c2031dcc-4c1c-4098-b5bc-3cf9bb83735c,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-7d27c6e2-2b37-4339-880d-8cb5ec4cbb22,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-60dea93a-80a3-48ec-a3ca-33c4df25c26f,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-d654685e-1926-413d-844c-b3efa11c9e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-122749507-172.17.0.21-1595686679248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-054add54-c78e-42e6-8165-2e87ae729586,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-c893df5b-784b-436f-a40a-0da7acf3d002,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-414aa7bd-4e38-4e8a-8588-8456889542bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-9bfaeeb9-beec-4254-a6f9-26a3cb21b4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-c2031dcc-4c1c-4098-b5bc-3cf9bb83735c,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-7d27c6e2-2b37-4339-880d-8cb5ec4cbb22,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-60dea93a-80a3-48ec-a3ca-33c4df25c26f,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-d654685e-1926-413d-844c-b3efa11c9e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769266236-172.17.0.21-1595687651670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-083687dc-ec6a-4da1-bd1a-ced419820549,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-a6b4685c-acef-433c-893f-d59dc73015fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-f30df9ab-aa17-4e92-979e-a667e379ebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-daa6178b-56b3-41f8-8a5a-21bcd5fa9c43,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-03a9339b-3f76-4ddf-8d89-56745763aba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-b6070ae7-8417-4ba0-b69d-c489fcbcb3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-736d9bdb-cc87-47ab-bd0c-e2768fbed6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-7f9db502-664d-408b-9899-13b0bacc4035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769266236-172.17.0.21-1595687651670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-083687dc-ec6a-4da1-bd1a-ced419820549,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-a6b4685c-acef-433c-893f-d59dc73015fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-f30df9ab-aa17-4e92-979e-a667e379ebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-daa6178b-56b3-41f8-8a5a-21bcd5fa9c43,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-03a9339b-3f76-4ddf-8d89-56745763aba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-b6070ae7-8417-4ba0-b69d-c489fcbcb3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-736d9bdb-cc87-47ab-bd0c-e2768fbed6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-7f9db502-664d-408b-9899-13b0bacc4035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934782506-172.17.0.21-1595687697953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36582,DS-4334d1c4-e991-4522-95a1-5c970b91f045,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-c6ecf5d8-5b87-4a1b-b322-38dd4dd98dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-36353c81-bf19-4f04-a4cf-e4802106da1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-395040b8-4c27-432d-926b-1e9838042142,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-ffcb9b50-f5f1-46e6-87e5-46a06aefd78b,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-ea2ed494-a4ad-4b3b-8382-52a4fd89db7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-992e04c5-195a-4ea3-ae98-5cfce88de76b,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-de76e3df-4cec-4c15-9235-8eb37bb16c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934782506-172.17.0.21-1595687697953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36582,DS-4334d1c4-e991-4522-95a1-5c970b91f045,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-c6ecf5d8-5b87-4a1b-b322-38dd4dd98dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-36353c81-bf19-4f04-a4cf-e4802106da1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-395040b8-4c27-432d-926b-1e9838042142,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-ffcb9b50-f5f1-46e6-87e5-46a06aefd78b,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-ea2ed494-a4ad-4b3b-8382-52a4fd89db7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-992e04c5-195a-4ea3-ae98-5cfce88de76b,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-de76e3df-4cec-4c15-9235-8eb37bb16c38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6593
