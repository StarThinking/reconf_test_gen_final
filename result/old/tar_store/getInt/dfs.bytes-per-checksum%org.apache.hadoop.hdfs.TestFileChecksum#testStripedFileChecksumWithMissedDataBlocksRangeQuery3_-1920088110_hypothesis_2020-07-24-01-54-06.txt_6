reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871221426-172.17.0.9-1595556729197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44990,DS-ab03f336-a311-4827-b252-ab3190201fff,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-e014646e-bd21-4d13-a3cd-98e1dcbd9d33,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-33661f35-9464-4ae8-b4d0-f194e790bf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-e8976ab7-6fbc-4f85-a1f6-78cf33cf7960,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-fbbeea16-97cc-43e3-bc58-5311d6013fef,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-08e962a0-8010-4fbf-bdae-70ebb15f5a30,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-23a5c49a-7f49-4d5d-9cbd-bd440fc3c718,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-7d9568d5-ce8e-4401-9abe-054813b68f53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-871221426-172.17.0.9-1595556729197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44990,DS-ab03f336-a311-4827-b252-ab3190201fff,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-e014646e-bd21-4d13-a3cd-98e1dcbd9d33,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-33661f35-9464-4ae8-b4d0-f194e790bf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-e8976ab7-6fbc-4f85-a1f6-78cf33cf7960,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-fbbeea16-97cc-43e3-bc58-5311d6013fef,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-08e962a0-8010-4fbf-bdae-70ebb15f5a30,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-23a5c49a-7f49-4d5d-9cbd-bd440fc3c718,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-7d9568d5-ce8e-4401-9abe-054813b68f53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264490048-172.17.0.9-1595557357166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45510,DS-80932c82-d5f6-42c8-8450-e98c52bf17f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-5ad20a39-272f-435c-9813-82ac11d17153,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-6ff4545c-7b00-4323-9ab6-fd0279dbafc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-63a1f6fe-fac7-425f-8970-15b102d5d775,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-7d10936f-f059-4a2e-b484-4d2290cc658b,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-a3265a98-5166-4b54-b85e-6466bd7e6aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-bcf6acfa-7779-40f7-b73d-c93ec45d164e,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-96164b9b-fc23-4f8e-8f44-8998c01d5a23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-264490048-172.17.0.9-1595557357166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45510,DS-80932c82-d5f6-42c8-8450-e98c52bf17f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-5ad20a39-272f-435c-9813-82ac11d17153,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-6ff4545c-7b00-4323-9ab6-fd0279dbafc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-63a1f6fe-fac7-425f-8970-15b102d5d775,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-7d10936f-f059-4a2e-b484-4d2290cc658b,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-a3265a98-5166-4b54-b85e-6466bd7e6aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-bcf6acfa-7779-40f7-b73d-c93ec45d164e,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-96164b9b-fc23-4f8e-8f44-8998c01d5a23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042237778-172.17.0.9-1595557520968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38272,DS-f1f4c82b-2dac-42bb-82c8-92d08b6691d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-7ece0430-ed5e-458d-b732-81fda61b1e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-e5f6b048-f012-430d-820c-1b9299dfddbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-9bb30769-2b5f-4a58-a4ab-c4a7923134fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-4aa072a7-03c4-4fd4-bebd-9291b4a3ef3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-af10baff-fba0-4fb6-aad7-07e01ec8f9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-0fe03b3b-debe-44f1-8851-37bd329ba002,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-214ff9f4-eddd-41d9-8677-cade6b34f36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042237778-172.17.0.9-1595557520968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38272,DS-f1f4c82b-2dac-42bb-82c8-92d08b6691d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-7ece0430-ed5e-458d-b732-81fda61b1e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-e5f6b048-f012-430d-820c-1b9299dfddbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-9bb30769-2b5f-4a58-a4ab-c4a7923134fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-4aa072a7-03c4-4fd4-bebd-9291b4a3ef3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-af10baff-fba0-4fb6-aad7-07e01ec8f9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-0fe03b3b-debe-44f1-8851-37bd329ba002,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-214ff9f4-eddd-41d9-8677-cade6b34f36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402789567-172.17.0.9-1595557610214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45028,DS-f95a309a-20ab-48fa-bf77-d2a109fe7fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-12bb1ab0-66e7-41e1-a44f-6e134959b5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-9c95ed91-75e1-4c43-804a-c08dbed45c34,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-2cad37ca-53c9-4f0b-8c75-3e87d95fca5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-43389311-91dc-4b19-bc79-8629355f18de,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-c0639e40-e420-4f32-93f0-f3436ba523d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-dafabaae-08b5-4674-b0a8-e4e1e43107ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-1f5160bc-138c-4d21-b660-c72fd1415216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-402789567-172.17.0.9-1595557610214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45028,DS-f95a309a-20ab-48fa-bf77-d2a109fe7fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-12bb1ab0-66e7-41e1-a44f-6e134959b5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-9c95ed91-75e1-4c43-804a-c08dbed45c34,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-2cad37ca-53c9-4f0b-8c75-3e87d95fca5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-43389311-91dc-4b19-bc79-8629355f18de,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-c0639e40-e420-4f32-93f0-f3436ba523d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-dafabaae-08b5-4674-b0a8-e4e1e43107ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-1f5160bc-138c-4d21-b660-c72fd1415216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737824853-172.17.0.9-1595557922228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34190,DS-1756bc84-6c17-4f1a-964a-b839b0b1815e,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-ccc5c010-4066-48e4-9e26-0de4823a437c,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-1833cf72-5cbb-40af-9bc9-85d22ac41265,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-9a301acf-50de-4f99-968b-38161df478b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-5b609ddb-db90-48bd-8306-723111f5c8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-728d4adf-ffb2-4e98-b219-693df18e78d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-6509bb13-91d6-4b21-9f1b-6f79ba39076b,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-c3029b59-68b8-496e-98b8-c75864e29538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737824853-172.17.0.9-1595557922228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34190,DS-1756bc84-6c17-4f1a-964a-b839b0b1815e,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-ccc5c010-4066-48e4-9e26-0de4823a437c,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-1833cf72-5cbb-40af-9bc9-85d22ac41265,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-9a301acf-50de-4f99-968b-38161df478b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-5b609ddb-db90-48bd-8306-723111f5c8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-728d4adf-ffb2-4e98-b219-693df18e78d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-6509bb13-91d6-4b21-9f1b-6f79ba39076b,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-c3029b59-68b8-496e-98b8-c75864e29538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927267336-172.17.0.9-1595558085027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37195,DS-f85fa6de-33ee-4293-b7a8-05581db877e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-a13d2f21-6da8-4334-a242-b4e2664e3c61,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-707aef25-1124-4170-b3af-ff904dd2d081,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-17eb7210-76aa-486d-94fc-9d8a247de454,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-189f4368-6834-4bf3-a3ee-b195d66ed64b,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-619702f2-a13f-4833-bc36-a998b10620f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-1c5845b2-0b5d-4fdd-8202-0e45b9cdf9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-92f6ffa5-9eb4-419a-be85-1b869e42581e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927267336-172.17.0.9-1595558085027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37195,DS-f85fa6de-33ee-4293-b7a8-05581db877e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-a13d2f21-6da8-4334-a242-b4e2664e3c61,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-707aef25-1124-4170-b3af-ff904dd2d081,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-17eb7210-76aa-486d-94fc-9d8a247de454,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-189f4368-6834-4bf3-a3ee-b195d66ed64b,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-619702f2-a13f-4833-bc36-a998b10620f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-1c5845b2-0b5d-4fdd-8202-0e45b9cdf9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-92f6ffa5-9eb4-419a-be85-1b869e42581e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732694755-172.17.0.9-1595558169470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32961,DS-4df24afc-1f6c-498b-9529-1baf028d98ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-d68a8522-db41-416c-838a-b9f4a4163da2,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-38f63208-b490-40c2-ad89-a0a79366e7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-5441e9e0-4047-42b7-9732-2db41e9b39aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-4589380f-6f86-4754-96e0-3259c24798ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-c5091919-b1a1-4c4c-b5dc-1f3368b8be9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-9b3f9214-329a-4337-8d12-533841e29497,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-c3b27c05-ca31-44cb-8928-cb38f6831720,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732694755-172.17.0.9-1595558169470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32961,DS-4df24afc-1f6c-498b-9529-1baf028d98ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-d68a8522-db41-416c-838a-b9f4a4163da2,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-38f63208-b490-40c2-ad89-a0a79366e7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-5441e9e0-4047-42b7-9732-2db41e9b39aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-4589380f-6f86-4754-96e0-3259c24798ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-c5091919-b1a1-4c4c-b5dc-1f3368b8be9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-9b3f9214-329a-4337-8d12-533841e29497,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-c3b27c05-ca31-44cb-8928-cb38f6831720,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105005558-172.17.0.9-1595558576782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40774,DS-3e77d7ab-a3bf-4ec6-8f46-7027d8da789b,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-6b5cb9c9-8cd0-42f7-91bf-4b378277f3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-7ed801bd-732e-4984-9781-5e40abb9c9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-d85e12ab-760b-4cd7-bbba-985d4df7c340,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-93bb0435-daa4-4116-b2e6-43c17f1bf324,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-3e11bb73-490d-4bcd-bae2-382adb99494c,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-bb4c63b7-0511-4b8f-a501-45aa8ee2bd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-38ff07c5-3c64-45ef-a66a-44baffd74521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105005558-172.17.0.9-1595558576782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40774,DS-3e77d7ab-a3bf-4ec6-8f46-7027d8da789b,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-6b5cb9c9-8cd0-42f7-91bf-4b378277f3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-7ed801bd-732e-4984-9781-5e40abb9c9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-d85e12ab-760b-4cd7-bbba-985d4df7c340,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-93bb0435-daa4-4116-b2e6-43c17f1bf324,DISK], DatanodeInfoWithStorage[127.0.0.1:33782,DS-3e11bb73-490d-4bcd-bae2-382adb99494c,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-bb4c63b7-0511-4b8f-a501-45aa8ee2bd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-38ff07c5-3c64-45ef-a66a-44baffd74521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909177925-172.17.0.9-1595559017715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46831,DS-cbcd9d39-e969-4254-9a0e-60d5bcdc0118,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-2658cd5e-a372-4d92-94f4-19e129a9cbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-5bb6b6fa-1298-4aff-9570-b3d88454e833,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-9dcffd3b-db8e-4068-bf10-9318af03edbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-82e5219d-bc68-4667-976a-869a5f1068cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-6910e877-9dae-4496-80a4-d52c153968c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-873ceffa-58bc-4b6f-9055-da9591df6a75,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-c7ab89ce-e381-4c6b-9a14-dae1c785269e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909177925-172.17.0.9-1595559017715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46831,DS-cbcd9d39-e969-4254-9a0e-60d5bcdc0118,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-2658cd5e-a372-4d92-94f4-19e129a9cbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-5bb6b6fa-1298-4aff-9570-b3d88454e833,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-9dcffd3b-db8e-4068-bf10-9318af03edbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-82e5219d-bc68-4667-976a-869a5f1068cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-6910e877-9dae-4496-80a4-d52c153968c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-873ceffa-58bc-4b6f-9055-da9591df6a75,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-c7ab89ce-e381-4c6b-9a14-dae1c785269e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174027015-172.17.0.9-1595559110589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34752,DS-bb37f5ac-2201-4846-86bb-dc2ddd598e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-de7d3aaa-c8b9-4fbc-90da-3ec739adc5df,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-7b6c7ee3-b700-47fa-bc39-f8b51b3079e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-0e240ef0-cb3e-4d4b-ad35-7f81edf8c0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-340a1415-5f18-4b34-814b-ef3c555a07e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-9346430a-c90c-46bb-99df-a51e3fb82d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-be6415cc-e543-4d23-95f5-ff10da2a8b54,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-62e69df6-2ac1-4aff-ac3a-516447643254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174027015-172.17.0.9-1595559110589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34752,DS-bb37f5ac-2201-4846-86bb-dc2ddd598e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-de7d3aaa-c8b9-4fbc-90da-3ec739adc5df,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-7b6c7ee3-b700-47fa-bc39-f8b51b3079e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-0e240ef0-cb3e-4d4b-ad35-7f81edf8c0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-340a1415-5f18-4b34-814b-ef3c555a07e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-9346430a-c90c-46bb-99df-a51e3fb82d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-be6415cc-e543-4d23-95f5-ff10da2a8b54,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-62e69df6-2ac1-4aff-ac3a-516447643254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123885479-172.17.0.9-1595559195093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34944,DS-2c181de1-38c9-49d6-9c24-435abc09c72c,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-f9fc47e7-a88a-4807-9cc2-f7daf1fca4db,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-523fe0fe-7621-4766-b923-293589945160,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-87b13280-2977-42fa-ab03-0189218100ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-e3414e34-a1a0-4d32-971d-c3a4925a0e99,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-4e70284b-3975-40e7-8131-16cb4a7407ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-ec64f62e-cdf9-4397-b675-e397abb50b45,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-1c7470fa-fdd6-44c2-8302-ce198ee87f65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123885479-172.17.0.9-1595559195093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34944,DS-2c181de1-38c9-49d6-9c24-435abc09c72c,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-f9fc47e7-a88a-4807-9cc2-f7daf1fca4db,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-523fe0fe-7621-4766-b923-293589945160,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-87b13280-2977-42fa-ab03-0189218100ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-e3414e34-a1a0-4d32-971d-c3a4925a0e99,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-4e70284b-3975-40e7-8131-16cb4a7407ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-ec64f62e-cdf9-4397-b675-e397abb50b45,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-1c7470fa-fdd6-44c2-8302-ce198ee87f65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255731713-172.17.0.9-1595560150603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39251,DS-0d01b43f-6337-4d98-85b9-0850ba0c33b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-9d6d66b9-5ebf-4957-aeb8-b35e95d8e2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-1a7878d5-29ba-4652-a4d4-8723ccceea0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-330f3e7f-e5c4-448f-9197-0925928e0beb,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-52ea536a-bc4f-4576-afac-3155b306ef27,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-92c9c509-ab37-4d07-bd69-4d8e6bc7d1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-62c5f90d-d36f-4b47-be89-04bbe6cb50a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-36a955eb-2036-4f45-8902-daed1d5d405b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255731713-172.17.0.9-1595560150603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39251,DS-0d01b43f-6337-4d98-85b9-0850ba0c33b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-9d6d66b9-5ebf-4957-aeb8-b35e95d8e2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-1a7878d5-29ba-4652-a4d4-8723ccceea0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-330f3e7f-e5c4-448f-9197-0925928e0beb,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-52ea536a-bc4f-4576-afac-3155b306ef27,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-92c9c509-ab37-4d07-bd69-4d8e6bc7d1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-62c5f90d-d36f-4b47-be89-04bbe6cb50a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-36a955eb-2036-4f45-8902-daed1d5d405b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311262634-172.17.0.9-1595560279879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43000,DS-77c6c748-8dc1-429f-bbcc-ffe4e4f92396,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-7308047a-e4a0-44f0-b838-202e98c7eadf,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-9b56f5b3-0594-488b-8ccf-c25cd2f27790,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-a6f9d0d2-071c-4a4f-9bd4-de6dc6d0660a,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-061b0b51-b18f-4ded-b798-1b193bd49fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-83139531-da8e-4e2c-aa0d-835aee52b312,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-8ac319f9-16c5-454b-a363-6a2b305cbdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-1e2d4dee-ba58-4960-bb62-967ea8088d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311262634-172.17.0.9-1595560279879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43000,DS-77c6c748-8dc1-429f-bbcc-ffe4e4f92396,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-7308047a-e4a0-44f0-b838-202e98c7eadf,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-9b56f5b3-0594-488b-8ccf-c25cd2f27790,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-a6f9d0d2-071c-4a4f-9bd4-de6dc6d0660a,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-061b0b51-b18f-4ded-b798-1b193bd49fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-83139531-da8e-4e2c-aa0d-835aee52b312,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-8ac319f9-16c5-454b-a363-6a2b305cbdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-1e2d4dee-ba58-4960-bb62-967ea8088d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269211192-172.17.0.9-1595560366662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35091,DS-5c1d9687-292f-40b0-bccf-15fe43b4dfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-827ea6c9-bd44-4799-a4f0-b05947e8eecd,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-b4c20765-0eaa-47fb-aa5a-c2f1f9645d47,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-d6fcc1db-a7ae-4b4c-8152-66417cca733a,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-0142af4d-9be5-4996-a39d-de94c9434c78,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-79f97de9-92bb-4175-8192-4523d85863c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-ba28f2f5-1d3c-45f7-ab69-da65fb5e503e,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-23988321-21c6-4fa8-a262-4ac1d0acce9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269211192-172.17.0.9-1595560366662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35091,DS-5c1d9687-292f-40b0-bccf-15fe43b4dfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-827ea6c9-bd44-4799-a4f0-b05947e8eecd,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-b4c20765-0eaa-47fb-aa5a-c2f1f9645d47,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-d6fcc1db-a7ae-4b4c-8152-66417cca733a,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-0142af4d-9be5-4996-a39d-de94c9434c78,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-79f97de9-92bb-4175-8192-4523d85863c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-ba28f2f5-1d3c-45f7-ab69-da65fb5e503e,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-23988321-21c6-4fa8-a262-4ac1d0acce9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956664561-172.17.0.9-1595560497359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36777,DS-560635ea-085a-4139-b0a3-53e14d6ca8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-abdf111c-fcbc-438a-958e-da2f5d7452f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-456aa2aa-1ee8-433b-a73e-f93db47dd3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-3cbeed94-3f4b-4f61-a8a5-4ecad86c701a,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-b6620820-c8c2-4a7b-af3d-6e96dd90e0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-0b7906f9-3a02-4366-9056-15af43817001,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-e21a4776-3300-4372-b724-19581f8de437,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-37c6826b-de4c-4936-9036-dc432b217178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956664561-172.17.0.9-1595560497359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36777,DS-560635ea-085a-4139-b0a3-53e14d6ca8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-abdf111c-fcbc-438a-958e-da2f5d7452f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-456aa2aa-1ee8-433b-a73e-f93db47dd3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-3cbeed94-3f4b-4f61-a8a5-4ecad86c701a,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-b6620820-c8c2-4a7b-af3d-6e96dd90e0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-0b7906f9-3a02-4366-9056-15af43817001,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-e21a4776-3300-4372-b724-19581f8de437,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-37c6826b-de4c-4936-9036-dc432b217178,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509708202-172.17.0.9-1595560538550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34177,DS-5d6b580f-b16c-4307-8d07-4ad93521b883,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-948c2d8b-934d-4583-a194-ba49cd00e9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-714993b3-e9b9-4bc7-90e6-96f14f34ec9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-3e243734-30bc-4042-885c-cca83e9991e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-31c29c1c-9dfc-43cf-81ab-98435f838f93,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-cf0e1312-7148-416d-bada-57f60d2236a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-2cdab0e1-d82d-4796-a9d1-d2366c1f0621,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-60bf4277-f48f-4eb1-9525-649f70b71d05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509708202-172.17.0.9-1595560538550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34177,DS-5d6b580f-b16c-4307-8d07-4ad93521b883,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-948c2d8b-934d-4583-a194-ba49cd00e9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-714993b3-e9b9-4bc7-90e6-96f14f34ec9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-3e243734-30bc-4042-885c-cca83e9991e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-31c29c1c-9dfc-43cf-81ab-98435f838f93,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-cf0e1312-7148-416d-bada-57f60d2236a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-2cdab0e1-d82d-4796-a9d1-d2366c1f0621,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-60bf4277-f48f-4eb1-9525-649f70b71d05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37720205-172.17.0.9-1595561149953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40995,DS-2b4447e3-8350-4841-b09a-8ca52cd79460,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-bd0c0d33-2558-47f2-b3fb-2eb3d2aafd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-556d1b44-e657-4fe9-a96b-7f27a1cc269d,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-93e35044-ffa9-4fe8-98d8-a6b53bf3f0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-901de0d2-6c09-42a1-a623-dfb265cfa470,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-77df1eaf-44ab-4940-a8a7-58626091ba22,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-84ed8761-a6ee-49cb-bc1b-73dddfcaf8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-1599ad08-d599-456d-936e-e0c8dc577120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-37720205-172.17.0.9-1595561149953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40995,DS-2b4447e3-8350-4841-b09a-8ca52cd79460,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-bd0c0d33-2558-47f2-b3fb-2eb3d2aafd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-556d1b44-e657-4fe9-a96b-7f27a1cc269d,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-93e35044-ffa9-4fe8-98d8-a6b53bf3f0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-901de0d2-6c09-42a1-a623-dfb265cfa470,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-77df1eaf-44ab-4940-a8a7-58626091ba22,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-84ed8761-a6ee-49cb-bc1b-73dddfcaf8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-1599ad08-d599-456d-936e-e0c8dc577120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150781240-172.17.0.9-1595561232666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38450,DS-8b11aeb2-f54b-4369-a658-31d79b9d9ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-dd3268de-fad6-46f1-9fe5-b90c32f20d66,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-4c72b86c-07fb-4aa3-993a-5683d1cbc6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-1f2c6805-44c4-407e-b904-083a7bf1efa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-aeb3c1be-2532-4276-b51c-48b13b2dfb40,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-8be90e43-4cc6-46aa-8b01-0aa22c3f45da,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-64df12b3-89de-4fb0-a8ed-9a0f2ca16ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-c0b2af6c-5de5-4405-879c-44421471bcec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150781240-172.17.0.9-1595561232666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38450,DS-8b11aeb2-f54b-4369-a658-31d79b9d9ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-dd3268de-fad6-46f1-9fe5-b90c32f20d66,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-4c72b86c-07fb-4aa3-993a-5683d1cbc6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-1f2c6805-44c4-407e-b904-083a7bf1efa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-aeb3c1be-2532-4276-b51c-48b13b2dfb40,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-8be90e43-4cc6-46aa-8b01-0aa22c3f45da,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-64df12b3-89de-4fb0-a8ed-9a0f2ca16ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-c0b2af6c-5de5-4405-879c-44421471bcec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 512
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341315657-172.17.0.9-1595562021352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43689,DS-5b3af88f-018c-4ef5-b428-232419a8c676,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-067221d0-2530-4c3a-ae42-2a0c9c720a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-0958e6c8-d784-4cb2-955f-2944c5aa651c,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-1ac3d094-f956-410e-a1b9-9544571a22d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-90632dda-2312-457f-9e53-f7a0a2af0381,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-8d3d9b6c-4604-4d6c-8ba7-a4b255e3909c,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-47af5979-02c4-455b-a99a-04d86c26493f,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-2bbfbec3-40db-44ab-b173-bfcb49f23fa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341315657-172.17.0.9-1595562021352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43689,DS-5b3af88f-018c-4ef5-b428-232419a8c676,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-067221d0-2530-4c3a-ae42-2a0c9c720a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-0958e6c8-d784-4cb2-955f-2944c5aa651c,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-1ac3d094-f956-410e-a1b9-9544571a22d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-90632dda-2312-457f-9e53-f7a0a2af0381,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-8d3d9b6c-4604-4d6c-8ba7-a4b255e3909c,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-47af5979-02c4-455b-a99a-04d86c26493f,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-2bbfbec3-40db-44ab-b173-bfcb49f23fa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6404
