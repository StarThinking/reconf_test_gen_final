reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157448382-172.17.0.19-1595702124613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35296,DS-398deff5-97ac-42dc-a1d4-dec2ec306080,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-041e832d-722e-4865-bee6-a542b1c1d692,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-adda5966-ba2f-4081-ade6-6c19d3f8470f,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-c31858f1-0190-413d-86d2-1b198b5ab7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-d7145e06-b3cb-46f1-a087-5dc5340898ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-b7f37b09-3c97-4e4d-8586-ec664f1a9c36,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-0dd0a313-a56d-480c-aa3f-2f7e0c2c2c07,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-703562f7-1c54-4fba-b0da-628f90b975fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157448382-172.17.0.19-1595702124613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35296,DS-398deff5-97ac-42dc-a1d4-dec2ec306080,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-041e832d-722e-4865-bee6-a542b1c1d692,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-adda5966-ba2f-4081-ade6-6c19d3f8470f,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-c31858f1-0190-413d-86d2-1b198b5ab7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-d7145e06-b3cb-46f1-a087-5dc5340898ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-b7f37b09-3c97-4e4d-8586-ec664f1a9c36,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-0dd0a313-a56d-480c-aa3f-2f7e0c2c2c07,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-703562f7-1c54-4fba-b0da-628f90b975fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750800662-172.17.0.19-1595702227396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36828,DS-8b46f6fb-a6e1-4882-ba38-dce7d18e6270,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-3d57e937-5764-4879-9cc9-958a1ca4dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-3011da02-cead-4302-aa43-455c15406f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-4fb3cdb4-866e-4941-9179-5d4077bd0321,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-2bb27ebb-bae4-4e56-9477-1e01be55abe6,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-d693a568-bf19-48dd-8c5d-9ed63b029012,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-c6477c62-ddb9-48ba-af26-62922baaa208,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-dc70c9c2-67f4-4dd0-99cd-23ad91a12a02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750800662-172.17.0.19-1595702227396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36828,DS-8b46f6fb-a6e1-4882-ba38-dce7d18e6270,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-3d57e937-5764-4879-9cc9-958a1ca4dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-3011da02-cead-4302-aa43-455c15406f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-4fb3cdb4-866e-4941-9179-5d4077bd0321,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-2bb27ebb-bae4-4e56-9477-1e01be55abe6,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-d693a568-bf19-48dd-8c5d-9ed63b029012,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-c6477c62-ddb9-48ba-af26-62922baaa208,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-dc70c9c2-67f4-4dd0-99cd-23ad91a12a02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-450512998-172.17.0.19-1595702729818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46630,DS-f45dfc6e-6852-4d45-81d2-436402981cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-96d5ad1e-45a8-4053-b69e-bd39ec383c48,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-e5a88667-16dc-43b6-90e5-a748ac40c01d,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-9016fef3-f26c-42bd-8b5b-8b729b0e9f44,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-0e7da3e0-46b9-4bba-b1bc-2ffbb2934ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-61a9f81d-8fb4-4d2f-9260-75906a98c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-7744bf77-b1fb-4c42-848b-eddd59abb03b,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-abc76413-3205-443c-92ac-2a794b892adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-450512998-172.17.0.19-1595702729818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46630,DS-f45dfc6e-6852-4d45-81d2-436402981cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-96d5ad1e-45a8-4053-b69e-bd39ec383c48,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-e5a88667-16dc-43b6-90e5-a748ac40c01d,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-9016fef3-f26c-42bd-8b5b-8b729b0e9f44,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-0e7da3e0-46b9-4bba-b1bc-2ffbb2934ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-61a9f81d-8fb4-4d2f-9260-75906a98c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-7744bf77-b1fb-4c42-848b-eddd59abb03b,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-abc76413-3205-443c-92ac-2a794b892adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219559154-172.17.0.19-1595703096494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37952,DS-f8eba3b8-2097-462b-8c67-f38096d1ebce,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-65a4b66b-6b9f-4e7a-b34d-3bb7fb7ec569,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-228bfdbf-f14e-47f2-97f6-bf03d19cf176,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-b1a0a97f-1e5a-41b6-98d6-3dc4cabd849d,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-9a59659c-4519-406f-98d8-80e637628384,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-ba191219-256e-459b-b4e0-2085afc82521,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-6d7d0d69-74e6-4b82-ac6b-951dc2acc22e,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-d2cd8c92-246d-4f25-b1d5-47e5d53b68d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219559154-172.17.0.19-1595703096494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37952,DS-f8eba3b8-2097-462b-8c67-f38096d1ebce,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-65a4b66b-6b9f-4e7a-b34d-3bb7fb7ec569,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-228bfdbf-f14e-47f2-97f6-bf03d19cf176,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-b1a0a97f-1e5a-41b6-98d6-3dc4cabd849d,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-9a59659c-4519-406f-98d8-80e637628384,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-ba191219-256e-459b-b4e0-2085afc82521,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-6d7d0d69-74e6-4b82-ac6b-951dc2acc22e,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-d2cd8c92-246d-4f25-b1d5-47e5d53b68d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-536506214-172.17.0.19-1595703461297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43558,DS-1cc8f487-241d-486b-9775-06d48e28335a,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-975dd37c-e372-484c-9462-40c2f76afa9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-67965ab6-7db3-4320-b822-61e301772e17,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-cba8e7e5-af47-43de-b5cb-1ad3275bbf48,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-07d3efff-a24c-41a2-9e86-4247072b8d50,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-9a10265e-280a-437e-acf2-b9d81c5a21e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-a45571f2-5aae-4821-8653-40bc8d1923b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-983cf9d1-7fa0-4c5b-ae62-a9b6b2b05537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-536506214-172.17.0.19-1595703461297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43558,DS-1cc8f487-241d-486b-9775-06d48e28335a,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-975dd37c-e372-484c-9462-40c2f76afa9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-67965ab6-7db3-4320-b822-61e301772e17,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-cba8e7e5-af47-43de-b5cb-1ad3275bbf48,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-07d3efff-a24c-41a2-9e86-4247072b8d50,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-9a10265e-280a-437e-acf2-b9d81c5a21e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-a45571f2-5aae-4821-8653-40bc8d1923b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-983cf9d1-7fa0-4c5b-ae62-a9b6b2b05537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216122722-172.17.0.19-1595703608517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46178,DS-79110792-d955-4828-8925-fc2b661e38b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-70a0aae0-4930-417f-b5a7-98413d533384,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-8e054831-e5da-47ff-b621-b68f5e83770e,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-ff63a9a3-acc2-4dfe-ad5c-464fa7b0e0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-e1d1c264-3066-41ed-b954-027116c4597b,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-dec188e4-9e5e-4d2d-ae1a-70f81a267e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-ddf2ccc6-6704-40d7-a584-e526f5a8af23,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-ffdf4b9d-9b22-463c-bd33-3ced9dad2db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216122722-172.17.0.19-1595703608517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46178,DS-79110792-d955-4828-8925-fc2b661e38b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-70a0aae0-4930-417f-b5a7-98413d533384,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-8e054831-e5da-47ff-b621-b68f5e83770e,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-ff63a9a3-acc2-4dfe-ad5c-464fa7b0e0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-e1d1c264-3066-41ed-b954-027116c4597b,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-dec188e4-9e5e-4d2d-ae1a-70f81a267e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-ddf2ccc6-6704-40d7-a584-e526f5a8af23,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-ffdf4b9d-9b22-463c-bd33-3ced9dad2db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000528474-172.17.0.19-1595704149200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39105,DS-527cf44c-e4f1-4775-a86f-2b15ef985c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-3ce2ab3a-fce0-4cca-aaf5-5a2f752a0f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-c996124a-cdaa-4448-b977-a508b5fd1101,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-6131d02a-d8f6-4044-9f8d-d4d803216f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-53f24d41-9b4c-423e-a309-31a530b5695c,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-0ba00ea0-adc5-4e05-aa49-e5ec7f87f09d,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-a0eaac27-fe00-494e-9f15-562d41e723cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-582eaf8d-eee5-41ec-841a-729e0f4fd313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000528474-172.17.0.19-1595704149200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39105,DS-527cf44c-e4f1-4775-a86f-2b15ef985c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-3ce2ab3a-fce0-4cca-aaf5-5a2f752a0f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-c996124a-cdaa-4448-b977-a508b5fd1101,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-6131d02a-d8f6-4044-9f8d-d4d803216f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-53f24d41-9b4c-423e-a309-31a530b5695c,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-0ba00ea0-adc5-4e05-aa49-e5ec7f87f09d,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-a0eaac27-fe00-494e-9f15-562d41e723cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-582eaf8d-eee5-41ec-841a-729e0f4fd313,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1331839447-172.17.0.19-1595704715671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38243,DS-04614f20-d015-4373-94ec-50683e47b906,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-22a962b7-c84f-4cdc-812c-28528fc46ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-5a32469c-9226-4989-9c39-2629aebd4897,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-c87534f2-f464-40a2-a0f3-e63b3b3959ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-e16a17b8-ba7e-4533-9ef1-91d7822ab6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-79f9190b-f7b1-4711-9cc1-512e4f386a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-346db1b6-4ace-446a-a994-9b06baa628e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-0fd8784d-a5ff-41c6-92d9-811283bd1db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1331839447-172.17.0.19-1595704715671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38243,DS-04614f20-d015-4373-94ec-50683e47b906,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-22a962b7-c84f-4cdc-812c-28528fc46ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-5a32469c-9226-4989-9c39-2629aebd4897,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-c87534f2-f464-40a2-a0f3-e63b3b3959ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-e16a17b8-ba7e-4533-9ef1-91d7822ab6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-79f9190b-f7b1-4711-9cc1-512e4f386a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-346db1b6-4ace-446a-a994-9b06baa628e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-0fd8784d-a5ff-41c6-92d9-811283bd1db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300437070-172.17.0.19-1595704757914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35669,DS-1376c873-4686-4838-a978-f44b29eebb69,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-3485b0f7-1600-428b-a63f-15e149266ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-8db2d02f-3bfb-4e9d-8634-b36356be1962,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-2f3cdfc4-b13a-4ad3-ae9d-106f5ab11d47,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-d1c737aa-5f59-445f-a698-ec6b63e7e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-b0d91af2-6ae9-4aa0-abc3-ca18039c8da3,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-435a5d8c-fa04-4dd6-8840-d61aa2f850ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-2c3f2d81-0c90-49c4-92fd-2b7da81e0d77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300437070-172.17.0.19-1595704757914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35669,DS-1376c873-4686-4838-a978-f44b29eebb69,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-3485b0f7-1600-428b-a63f-15e149266ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-8db2d02f-3bfb-4e9d-8634-b36356be1962,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-2f3cdfc4-b13a-4ad3-ae9d-106f5ab11d47,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-d1c737aa-5f59-445f-a698-ec6b63e7e6b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-b0d91af2-6ae9-4aa0-abc3-ca18039c8da3,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-435a5d8c-fa04-4dd6-8840-d61aa2f850ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-2c3f2d81-0c90-49c4-92fd-2b7da81e0d77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1886619322-172.17.0.19-1595705021862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43266,DS-8833bc76-81b5-4e03-8318-e6250278acd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-243348ff-7914-4686-a894-c980d39b121c,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-47d2fec0-3b96-4930-99ac-210ae0ee4b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-267c8dd2-ca38-4294-9473-5291cb2bbd28,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-cf1cb5d1-a654-4857-b459-a895c05a28d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-5042ed28-1d7c-4686-8fb6-07f17a0b1d93,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-2c219082-de74-4fae-b5c4-c892545b8498,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-fecc7bc3-39d6-461b-876d-233063454f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1886619322-172.17.0.19-1595705021862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43266,DS-8833bc76-81b5-4e03-8318-e6250278acd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-243348ff-7914-4686-a894-c980d39b121c,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-47d2fec0-3b96-4930-99ac-210ae0ee4b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-267c8dd2-ca38-4294-9473-5291cb2bbd28,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-cf1cb5d1-a654-4857-b459-a895c05a28d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-5042ed28-1d7c-4686-8fb6-07f17a0b1d93,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-2c219082-de74-4fae-b5c4-c892545b8498,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-fecc7bc3-39d6-461b-876d-233063454f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264085537-172.17.0.19-1595705128149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43128,DS-db2f836d-41bc-4c47-a8e2-882595e573fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-133f6535-9103-4dec-bc56-b3513aa4f8de,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-a82d5a67-3564-403c-a687-f9a64ea64ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-70e4728a-e37c-456d-94fb-e5250c313b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-ddda19ce-ad4c-4164-a011-9cf0fcf6d572,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-dfd6d932-263c-47bc-a621-2321a249ae0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-2b90bf22-da7a-43f3-b35d-e9fc78a952b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-31fca268-ad00-4435-8687-384a22266732,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264085537-172.17.0.19-1595705128149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43128,DS-db2f836d-41bc-4c47-a8e2-882595e573fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-133f6535-9103-4dec-bc56-b3513aa4f8de,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-a82d5a67-3564-403c-a687-f9a64ea64ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-70e4728a-e37c-456d-94fb-e5250c313b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-ddda19ce-ad4c-4164-a011-9cf0fcf6d572,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-dfd6d932-263c-47bc-a621-2321a249ae0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-2b90bf22-da7a-43f3-b35d-e9fc78a952b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-31fca268-ad00-4435-8687-384a22266732,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551631350-172.17.0.19-1595705174876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41350,DS-39454585-69b8-4c3a-9527-28e5f15f4bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-48d7bcfb-bb45-4308-b96d-fc1b73993535,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-821838a6-b771-4219-9c92-da908bb855ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-c4d3c26e-01bf-4229-a014-fee900360011,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-55a1e12a-a07a-4037-b3fd-2eac1da2bf38,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-e3bd6b7e-3238-4b93-ae0f-3b6071a39e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-8ea08b3a-edd1-47d7-b40c-943e3ed6cfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-4733de63-1166-41ec-873a-8aa366793fa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1551631350-172.17.0.19-1595705174876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41350,DS-39454585-69b8-4c3a-9527-28e5f15f4bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-48d7bcfb-bb45-4308-b96d-fc1b73993535,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-821838a6-b771-4219-9c92-da908bb855ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33745,DS-c4d3c26e-01bf-4229-a014-fee900360011,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-55a1e12a-a07a-4037-b3fd-2eac1da2bf38,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-e3bd6b7e-3238-4b93-ae0f-3b6071a39e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-8ea08b3a-edd1-47d7-b40c-943e3ed6cfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-4733de63-1166-41ec-873a-8aa366793fa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780592310-172.17.0.19-1595705858418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41531,DS-07821807-7c2e-473f-bb30-a6de8ee09b71,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-0cab6089-46d0-4fa3-ad2d-e580a0391072,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-114e6a75-73ad-4a12-a499-6bd3ae5d4647,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-0e411172-b099-4927-857f-8924b478d67c,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-bfe5b905-f23c-4245-b70c-fac3f797b4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-bcb425f3-1e7c-43d5-9264-3c7ccf66d873,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-e926dad4-c59f-4859-9764-a34d15a2e353,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-31e75ed0-a600-4b0b-b54b-37bb331d95f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780592310-172.17.0.19-1595705858418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41531,DS-07821807-7c2e-473f-bb30-a6de8ee09b71,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-0cab6089-46d0-4fa3-ad2d-e580a0391072,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-114e6a75-73ad-4a12-a499-6bd3ae5d4647,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-0e411172-b099-4927-857f-8924b478d67c,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-bfe5b905-f23c-4245-b70c-fac3f797b4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-bcb425f3-1e7c-43d5-9264-3c7ccf66d873,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-e926dad4-c59f-4859-9764-a34d15a2e353,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-31e75ed0-a600-4b0b-b54b-37bb331d95f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1542863650-172.17.0.19-1595706372892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38709,DS-c2acd794-1c25-4551-9e82-e2ad333d4ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-e7c777c4-3408-4b3c-92e1-0a00fbe53e33,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-411929c0-48cb-434c-a906-d154ac1fed03,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-9df6840c-61d3-410a-a292-8a0deafb3d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-570820ba-8852-4b0d-8484-1f852bdb5e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-6e548649-2a24-4545-a12e-6ec1d54040b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-569f7174-9b1f-4168-abc5-7f1a0c23d1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-56e67a83-dda2-4ec0-b09d-1b6daf49a0ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1542863650-172.17.0.19-1595706372892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38709,DS-c2acd794-1c25-4551-9e82-e2ad333d4ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-e7c777c4-3408-4b3c-92e1-0a00fbe53e33,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-411929c0-48cb-434c-a906-d154ac1fed03,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-9df6840c-61d3-410a-a292-8a0deafb3d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-570820ba-8852-4b0d-8484-1f852bdb5e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-6e548649-2a24-4545-a12e-6ec1d54040b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-569f7174-9b1f-4168-abc5-7f1a0c23d1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-56e67a83-dda2-4ec0-b09d-1b6daf49a0ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923793702-172.17.0.19-1595706607144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41415,DS-7c9d6032-cb09-4886-a506-cfc3dc7a29e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-e6872d42-b1fb-4d6c-83eb-fcc545c72c48,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-28449c8d-b120-4237-903b-6abf46afd92e,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-65a39ad5-c5d6-4497-aede-67720e2d657b,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-fc79f463-a70f-4e5d-a4ab-71f2864f4176,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-68e8243f-507d-46bf-a57b-67fdc5e5ec51,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-cbb59c4e-9904-4965-b876-aa162b92875d,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-bc64ca0d-cf98-42e4-959c-58666aeb228c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1923793702-172.17.0.19-1595706607144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41415,DS-7c9d6032-cb09-4886-a506-cfc3dc7a29e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-e6872d42-b1fb-4d6c-83eb-fcc545c72c48,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-28449c8d-b120-4237-903b-6abf46afd92e,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-65a39ad5-c5d6-4497-aede-67720e2d657b,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-fc79f463-a70f-4e5d-a4ab-71f2864f4176,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-68e8243f-507d-46bf-a57b-67fdc5e5ec51,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-cbb59c4e-9904-4965-b876-aa162b92875d,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-bc64ca0d-cf98-42e4-959c-58666aeb228c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-145802548-172.17.0.19-1595706730459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45598,DS-63bc54d1-4d70-419b-a0bb-2de3dbebfddb,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-125dc4b6-3de8-4eb2-9ced-d1ca00ffa52c,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-5745e291-2e5b-4130-b991-4f363aff9f95,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-8b12f6a7-6648-40af-b984-4d659b1a12c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-5337783f-9eed-42eb-8cad-5b331f6217b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-3d1b242f-66a6-4538-bdb2-7c5cc5599d96,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-b780a642-d3f7-4801-bd81-69f3b4fe2ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-9c38f016-254b-4c19-a8c0-826b623fcba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-145802548-172.17.0.19-1595706730459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45598,DS-63bc54d1-4d70-419b-a0bb-2de3dbebfddb,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-125dc4b6-3de8-4eb2-9ced-d1ca00ffa52c,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-5745e291-2e5b-4130-b991-4f363aff9f95,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-8b12f6a7-6648-40af-b984-4d659b1a12c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-5337783f-9eed-42eb-8cad-5b331f6217b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-3d1b242f-66a6-4538-bdb2-7c5cc5599d96,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-b780a642-d3f7-4801-bd81-69f3b4fe2ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-9c38f016-254b-4c19-a8c0-826b623fcba6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103404570-172.17.0.19-1595707163044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45819,DS-63406ca4-51fc-43f3-ac83-dc590227ae45,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-9ad21f30-9f84-4e17-b444-008ab1e3cbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-20162cda-0af3-476d-b10e-78bf20eb9029,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-87fd0880-1ed2-4d10-bd17-16fef2569c50,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-ff0042d6-7f1e-4dd6-96d8-e66e4d25f034,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-aef08bf3-80e3-4264-8919-bf23fcf15a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-85c63e95-592d-4818-afee-1379c2983ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-edb72916-d144-4aa9-b424-5ec0e9ab692d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2103404570-172.17.0.19-1595707163044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45819,DS-63406ca4-51fc-43f3-ac83-dc590227ae45,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-9ad21f30-9f84-4e17-b444-008ab1e3cbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-20162cda-0af3-476d-b10e-78bf20eb9029,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-87fd0880-1ed2-4d10-bd17-16fef2569c50,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-ff0042d6-7f1e-4dd6-96d8-e66e4d25f034,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-aef08bf3-80e3-4264-8919-bf23fcf15a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-85c63e95-592d-4818-afee-1379c2983ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-edb72916-d144-4aa9-b424-5ec0e9ab692d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1570640838-172.17.0.19-1595707495253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36525,DS-9ddc7289-e7f1-475b-8288-f1ac10475958,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-a830aa71-5b47-4bda-ad65-650bb58da976,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-a79ffc8b-1bf9-4448-af6c-ac293b1b899b,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-3319a365-eb61-4711-ad08-ba7a715fd908,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-a610167c-3beb-48fd-9781-63d98566c584,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-d42b4181-a627-4836-955a-6935c921574b,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-c2e92c91-89f0-4a80-bbb7-0d2dd39523bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-f1a6069b-b0ed-4d3c-95d7-8359b920b58a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1570640838-172.17.0.19-1595707495253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36525,DS-9ddc7289-e7f1-475b-8288-f1ac10475958,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-a830aa71-5b47-4bda-ad65-650bb58da976,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-a79ffc8b-1bf9-4448-af6c-ac293b1b899b,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-3319a365-eb61-4711-ad08-ba7a715fd908,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-a610167c-3beb-48fd-9781-63d98566c584,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-d42b4181-a627-4836-955a-6935c921574b,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-c2e92c91-89f0-4a80-bbb7-0d2dd39523bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-f1a6069b-b0ed-4d3c-95d7-8359b920b58a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6800
