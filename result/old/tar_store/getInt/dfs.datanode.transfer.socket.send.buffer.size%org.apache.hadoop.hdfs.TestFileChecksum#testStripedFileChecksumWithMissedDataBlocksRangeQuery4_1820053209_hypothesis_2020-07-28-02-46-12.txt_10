reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056902633-172.17.0.6-1595904506683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46242,DS-8526a72c-52d9-4212-94ce-7fda69cab5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-1b32d5d8-daf5-4adf-b2d3-dc66e7b31d32,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-833553c8-cbb5-4b0c-ad5d-0f9074339a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-c34a3268-4335-4ae1-b6e4-805093f983ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-4e6e22b6-f7c5-4355-a55d-f6b42ca871ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-8c54ff47-3784-4b61-ae4c-0abfb68b4728,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-232403e1-1daa-43f7-858d-51284d3a2ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-4b4aeb5e-5aa0-40a8-9715-88b4312cffb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056902633-172.17.0.6-1595904506683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46242,DS-8526a72c-52d9-4212-94ce-7fda69cab5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-1b32d5d8-daf5-4adf-b2d3-dc66e7b31d32,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-833553c8-cbb5-4b0c-ad5d-0f9074339a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-c34a3268-4335-4ae1-b6e4-805093f983ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-4e6e22b6-f7c5-4355-a55d-f6b42ca871ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-8c54ff47-3784-4b61-ae4c-0abfb68b4728,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-232403e1-1daa-43f7-858d-51284d3a2ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-4b4aeb5e-5aa0-40a8-9715-88b4312cffb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557026430-172.17.0.6-1595904597470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-8263a9eb-1c5d-4c9e-80a5-e73136d492da,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-8957a6ba-57b8-4645-af7c-7c2a7515aeab,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-63712d98-faf8-4462-8814-bcfe6e4ad1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-0cf257fd-b22f-4654-8911-0010e6ee0d12,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-8c9769f2-6786-4adb-988b-dc6a8ea2f155,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-7070a1ef-3096-406a-ad43-c9929c7d55e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-ae92ac6b-69c1-4fb7-a43b-e2830a896604,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-4f33a866-9fc4-43bd-87e1-dbe4d93addee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557026430-172.17.0.6-1595904597470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39797,DS-8263a9eb-1c5d-4c9e-80a5-e73136d492da,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-8957a6ba-57b8-4645-af7c-7c2a7515aeab,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-63712d98-faf8-4462-8814-bcfe6e4ad1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-0cf257fd-b22f-4654-8911-0010e6ee0d12,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-8c9769f2-6786-4adb-988b-dc6a8ea2f155,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-7070a1ef-3096-406a-ad43-c9929c7d55e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-ae92ac6b-69c1-4fb7-a43b-e2830a896604,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-4f33a866-9fc4-43bd-87e1-dbe4d93addee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553217382-172.17.0.6-1595905215922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38613,DS-0f20e72e-a805-48d2-a9f4-696cfbce589f,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-9ba90d42-5b2a-43e0-9897-adeed3200bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-8e50f3c8-bf4c-4a7a-ac42-895a7f7efb07,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-48c51bcc-d7a5-4ca0-ad21-f5ffbee0163c,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-3ff7df86-8be2-4a0d-bc90-599c58d099bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-8da1d4bb-2192-472b-b5b9-3047ba7cf362,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-043bc0fa-add8-437b-9d78-306776394399,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-a0ef9a63-2a62-4971-9955-afe916679a5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553217382-172.17.0.6-1595905215922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38613,DS-0f20e72e-a805-48d2-a9f4-696cfbce589f,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-9ba90d42-5b2a-43e0-9897-adeed3200bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-8e50f3c8-bf4c-4a7a-ac42-895a7f7efb07,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-48c51bcc-d7a5-4ca0-ad21-f5ffbee0163c,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-3ff7df86-8be2-4a0d-bc90-599c58d099bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-8da1d4bb-2192-472b-b5b9-3047ba7cf362,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-043bc0fa-add8-437b-9d78-306776394399,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-a0ef9a63-2a62-4971-9955-afe916679a5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650973071-172.17.0.6-1595905318303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38809,DS-82a2453f-39f4-4f4c-8654-662ebab1a3af,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-9a2559fb-e5ac-4d94-bb75-a49f665bb636,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-1a05f56e-0d87-4d26-8fcd-dff644bfce29,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-a8c64a02-1584-4714-8ace-d1cbed8f88e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-2454adf4-8c02-41e4-8509-e0ca6f5bf11c,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-9dde0f89-d279-4bd9-aace-cfc0aa5a5027,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-037981d0-b4bd-49a6-bd95-ed6b2b683790,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-5cfacd02-377e-46de-8a6b-946eba4883ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1650973071-172.17.0.6-1595905318303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38809,DS-82a2453f-39f4-4f4c-8654-662ebab1a3af,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-9a2559fb-e5ac-4d94-bb75-a49f665bb636,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-1a05f56e-0d87-4d26-8fcd-dff644bfce29,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-a8c64a02-1584-4714-8ace-d1cbed8f88e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-2454adf4-8c02-41e4-8509-e0ca6f5bf11c,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-9dde0f89-d279-4bd9-aace-cfc0aa5a5027,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-037981d0-b4bd-49a6-bd95-ed6b2b683790,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-5cfacd02-377e-46de-8a6b-946eba4883ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353015285-172.17.0.6-1595905877728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37653,DS-50ae42b1-f62a-47ed-855c-8b4fcbf8e705,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-4b86b077-4eb1-4fa3-bb7a-11e08e1b88c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-628a414f-a87e-43df-b7ac-86c05997a24d,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-68e2b067-5982-47a6-bda7-0ace31ec528f,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-f7b0aef2-094d-4f68-b609-d733febbe933,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-ddb506bb-bfe0-404f-9309-6eb54e91c1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-1ed4065d-4bef-4636-950f-d3696fca312e,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-cdeeb426-8627-455c-aaed-f57cb3774baa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353015285-172.17.0.6-1595905877728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37653,DS-50ae42b1-f62a-47ed-855c-8b4fcbf8e705,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-4b86b077-4eb1-4fa3-bb7a-11e08e1b88c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-628a414f-a87e-43df-b7ac-86c05997a24d,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-68e2b067-5982-47a6-bda7-0ace31ec528f,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-f7b0aef2-094d-4f68-b609-d733febbe933,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-ddb506bb-bfe0-404f-9309-6eb54e91c1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-1ed4065d-4bef-4636-950f-d3696fca312e,DISK], DatanodeInfoWithStorage[127.0.0.1:45301,DS-cdeeb426-8627-455c-aaed-f57cb3774baa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641982379-172.17.0.6-1595906454557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41258,DS-b549b92f-319f-478a-848d-cb7e0305782c,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-3e3bfb7a-fd80-487e-8227-ee69aaeedbec,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-21ab04f5-2e6c-46bd-a99f-a1eed0d736b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-0540b751-2ee8-4e03-8bf2-41224bff67ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-d309a3e7-024a-4b48-9c0e-1ec565a1716b,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-c3137a38-18ad-4cdb-970f-dc0dfe0a2d37,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-94ace2ca-dea9-4544-9cd9-a2cc65e2a014,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-79328fd0-cf0c-4f6a-b3f5-5c3da3106e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641982379-172.17.0.6-1595906454557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41258,DS-b549b92f-319f-478a-848d-cb7e0305782c,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-3e3bfb7a-fd80-487e-8227-ee69aaeedbec,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-21ab04f5-2e6c-46bd-a99f-a1eed0d736b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-0540b751-2ee8-4e03-8bf2-41224bff67ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-d309a3e7-024a-4b48-9c0e-1ec565a1716b,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-c3137a38-18ad-4cdb-970f-dc0dfe0a2d37,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-94ace2ca-dea9-4544-9cd9-a2cc65e2a014,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-79328fd0-cf0c-4f6a-b3f5-5c3da3106e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220109179-172.17.0.6-1595906490656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43030,DS-e7b5f4b9-623e-4e01-9d9a-d5d6d235122f,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-7879961e-62bb-4abe-8cec-bfc7f8560f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-c6f9b401-d87c-4131-9eff-5d8cb1ac10ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-042c3c1d-d52f-43e1-9a4a-8ee0031cc5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-2f2d6e10-67c5-41fc-ba53-46e58eb0bf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-571e214a-fd0f-4f17-bfd2-dd99a8012f43,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-8837cd49-3dea-45e8-b52a-2d496ff3e54d,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-5eca572f-b5ab-4dcc-a999-3cb5fa82fda7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220109179-172.17.0.6-1595906490656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43030,DS-e7b5f4b9-623e-4e01-9d9a-d5d6d235122f,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-7879961e-62bb-4abe-8cec-bfc7f8560f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-c6f9b401-d87c-4131-9eff-5d8cb1ac10ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-042c3c1d-d52f-43e1-9a4a-8ee0031cc5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-2f2d6e10-67c5-41fc-ba53-46e58eb0bf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-571e214a-fd0f-4f17-bfd2-dd99a8012f43,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-8837cd49-3dea-45e8-b52a-2d496ff3e54d,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-5eca572f-b5ab-4dcc-a999-3cb5fa82fda7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677579131-172.17.0.6-1595906739436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43644,DS-77836f7e-8780-48b8-add2-9e9ad9978f32,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-3c4a9a8b-9898-4785-88d3-672b780593ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-7e42113f-2193-4802-bd5d-0bc5cd5327dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-405db0f6-5c2d-406e-8ead-4e2d22f4fe35,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-ec4f492d-e987-4f40-bb3e-58a7097e139c,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-196414b4-0e87-4c6e-a03c-aed3d7b7e48d,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-fea2a6a2-cbce-4929-9614-88bf18741cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-d9ac783c-7484-4ecd-9dd9-1829d0edd7de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677579131-172.17.0.6-1595906739436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43644,DS-77836f7e-8780-48b8-add2-9e9ad9978f32,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-3c4a9a8b-9898-4785-88d3-672b780593ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-7e42113f-2193-4802-bd5d-0bc5cd5327dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-405db0f6-5c2d-406e-8ead-4e2d22f4fe35,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-ec4f492d-e987-4f40-bb3e-58a7097e139c,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-196414b4-0e87-4c6e-a03c-aed3d7b7e48d,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-fea2a6a2-cbce-4929-9614-88bf18741cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-d9ac783c-7484-4ecd-9dd9-1829d0edd7de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731034313-172.17.0.6-1595907444456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43065,DS-61ef6485-e7a9-4166-aa63-1be7b459aa8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-70556b90-a21a-407a-8ba3-f45118d07267,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-df4c69e0-41c4-4bd3-9629-5f55b4ce2e26,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-b15b43b1-547f-45c7-a0d4-8f8939f1aa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-2577df14-d008-448c-abde-5aa4e38ff98f,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-b4b7071e-6942-42a6-95e3-a9ab681094f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-ec2f1f60-3ee9-4534-bf9b-f91fc11601eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-3a2f1dcf-875c-403b-b417-07d792a8c258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731034313-172.17.0.6-1595907444456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43065,DS-61ef6485-e7a9-4166-aa63-1be7b459aa8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-70556b90-a21a-407a-8ba3-f45118d07267,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-df4c69e0-41c4-4bd3-9629-5f55b4ce2e26,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-b15b43b1-547f-45c7-a0d4-8f8939f1aa3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-2577df14-d008-448c-abde-5aa4e38ff98f,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-b4b7071e-6942-42a6-95e3-a9ab681094f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-ec2f1f60-3ee9-4534-bf9b-f91fc11601eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-3a2f1dcf-875c-403b-b417-07d792a8c258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42331494-172.17.0.6-1595907869174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43590,DS-81c9564f-71c1-4e24-9e85-1eb6f667de48,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-359dc053-6090-46e8-8017-51bf5f85866f,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-cfaf4480-cb66-422c-9f4d-2245fe11aa01,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-8169a74c-58c8-41bc-a19e-419fdac7cd19,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-1215337a-3fbc-4221-a1ec-0261e4b538b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-0a56874d-d420-4c58-8f4b-a3055f6a70ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-1ac56045-5554-4db0-82ca-532904f58d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-18c75c11-ab40-41be-9958-e4cfc652cb31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42331494-172.17.0.6-1595907869174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43590,DS-81c9564f-71c1-4e24-9e85-1eb6f667de48,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-359dc053-6090-46e8-8017-51bf5f85866f,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-cfaf4480-cb66-422c-9f4d-2245fe11aa01,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-8169a74c-58c8-41bc-a19e-419fdac7cd19,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-1215337a-3fbc-4221-a1ec-0261e4b538b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-0a56874d-d420-4c58-8f4b-a3055f6a70ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-1ac56045-5554-4db0-82ca-532904f58d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-18c75c11-ab40-41be-9958-e4cfc652cb31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234018572-172.17.0.6-1595908923164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36995,DS-bdc41d28-200e-40c6-8a67-dc447b4bd90b,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-776eafde-5be4-4c87-bbef-92b3eb0d39bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-8c37be16-d8de-4bc4-bddf-a54a3d1c18d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-7056932e-ef31-4484-8e8f-6dcef23c6946,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-2bf217fd-6681-4f72-be28-eb63514513bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-31a22944-c1e3-4ea5-b0a0-4564f6154f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-e490c5d0-5f10-4a59-9c11-327533366a78,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-4b8e3f14-aa25-4d89-b0fa-85533e329536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234018572-172.17.0.6-1595908923164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36995,DS-bdc41d28-200e-40c6-8a67-dc447b4bd90b,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-776eafde-5be4-4c87-bbef-92b3eb0d39bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-8c37be16-d8de-4bc4-bddf-a54a3d1c18d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-7056932e-ef31-4484-8e8f-6dcef23c6946,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-2bf217fd-6681-4f72-be28-eb63514513bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-31a22944-c1e3-4ea5-b0a0-4564f6154f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-e490c5d0-5f10-4a59-9c11-327533366a78,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-4b8e3f14-aa25-4d89-b0fa-85533e329536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114055644-172.17.0.6-1595909003648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42565,DS-89c0870c-d610-4678-9c52-21a0b681f40a,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-39a8ac14-4a00-403b-b5ef-fc5f804720f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-c58a359b-90c5-4e68-be32-f9b4d0e477eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-12ef3909-64a1-41e1-b746-d6fbb00f1f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-17aca7cc-aa9b-4583-8cbb-eadbfe3d4be3,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-fc969fc1-1b08-426e-a590-9cedff46cc59,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-d08be853-2339-40b4-9ed1-33a1f07ed7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-ad68ddd9-7f61-4ce4-bb5c-867275a6ad08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114055644-172.17.0.6-1595909003648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42565,DS-89c0870c-d610-4678-9c52-21a0b681f40a,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-39a8ac14-4a00-403b-b5ef-fc5f804720f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-c58a359b-90c5-4e68-be32-f9b4d0e477eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-12ef3909-64a1-41e1-b746-d6fbb00f1f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-17aca7cc-aa9b-4583-8cbb-eadbfe3d4be3,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-fc969fc1-1b08-426e-a590-9cedff46cc59,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-d08be853-2339-40b4-9ed1-33a1f07ed7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-ad68ddd9-7f61-4ce4-bb5c-867275a6ad08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448124654-172.17.0.6-1595909351077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-a5b39988-eb3c-4bfc-a0a6-98c237118639,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-a6f06ba1-80dd-4598-92c5-100d0dd1d69b,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-2946a6eb-f26f-4bb2-8307-d54e3b4d9393,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-50340816-02de-4874-aa92-3205351221dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-1972ac99-73d9-4e66-91c7-87c6ceb1bb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-a1c694d9-2d99-4c11-bc13-fa77ee08b730,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-ef58a873-cb47-487d-ba9b-7551ffb3c4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-0402c537-316e-4d6b-b91b-8345ad550e2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448124654-172.17.0.6-1595909351077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-a5b39988-eb3c-4bfc-a0a6-98c237118639,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-a6f06ba1-80dd-4598-92c5-100d0dd1d69b,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-2946a6eb-f26f-4bb2-8307-d54e3b4d9393,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-50340816-02de-4874-aa92-3205351221dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-1972ac99-73d9-4e66-91c7-87c6ceb1bb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-a1c694d9-2d99-4c11-bc13-fa77ee08b730,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-ef58a873-cb47-487d-ba9b-7551ffb3c4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-0402c537-316e-4d6b-b91b-8345ad550e2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248441509-172.17.0.6-1595910331327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40635,DS-ac8df174-7467-43c1-8ab3-4a840e03e5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-3ffe543a-2286-414d-ae57-38fd2ea6850c,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-a35c4c40-e0b7-4ced-b99f-feb33ec68ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-e429bca7-3d9b-4be6-9ff9-c858aa7f7ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-902e99d1-7726-43df-a7e5-d79d3974ab28,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-001eaa9d-2d00-4624-97c9-9893fcf9672a,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-781be02f-5755-48ee-843f-a9db06acbbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-88699815-39f4-4acf-954a-e06331dac6a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248441509-172.17.0.6-1595910331327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40635,DS-ac8df174-7467-43c1-8ab3-4a840e03e5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-3ffe543a-2286-414d-ae57-38fd2ea6850c,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-a35c4c40-e0b7-4ced-b99f-feb33ec68ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-e429bca7-3d9b-4be6-9ff9-c858aa7f7ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-902e99d1-7726-43df-a7e5-d79d3974ab28,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-001eaa9d-2d00-4624-97c9-9893fcf9672a,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-781be02f-5755-48ee-843f-a9db06acbbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-88699815-39f4-4acf-954a-e06331dac6a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6283
