reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882244767-172.17.0.14-1595537849032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42685,DS-7e200413-52e1-46ce-9af0-18ea10af8253,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-31db2842-9926-4304-ba8d-dfa8690d22fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-7e527c86-b83a-43ff-ab23-1b8f6b24d577,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-e2ca3a39-5e09-4cdf-ad46-83b9ef185c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-561c0b4c-78d1-400a-a866-79e3c9b22c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-5eba9274-a127-4d24-9a71-cc2344987391,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-c09fcd3d-b63a-496a-afe2-3982c77009a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-b3e7e9c8-3759-474e-ba86-c5ee43094044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882244767-172.17.0.14-1595537849032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42685,DS-7e200413-52e1-46ce-9af0-18ea10af8253,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-31db2842-9926-4304-ba8d-dfa8690d22fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-7e527c86-b83a-43ff-ab23-1b8f6b24d577,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-e2ca3a39-5e09-4cdf-ad46-83b9ef185c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-561c0b4c-78d1-400a-a866-79e3c9b22c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-5eba9274-a127-4d24-9a71-cc2344987391,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-c09fcd3d-b63a-496a-afe2-3982c77009a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-b3e7e9c8-3759-474e-ba86-c5ee43094044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802013984-172.17.0.14-1595537919306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34177,DS-078f28ae-b1a1-4c5e-87bd-0f2a4e728944,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-0bbe7c31-a71e-4262-9411-acee5a9a84b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-1ffb80a4-d3da-4596-bcc7-b80bfbe1bf23,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-27e6b40e-3913-4dcb-a94c-2e7c7a44b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-9dc7e182-bda9-462b-ba47-575413ec6e51,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-209bc468-ceea-4c11-94ac-02153a95866e,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-4be8f797-fe34-46f3-a80f-8e1c134a79a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-e5360e17-637f-495d-b89a-7802de40cb15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802013984-172.17.0.14-1595537919306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34177,DS-078f28ae-b1a1-4c5e-87bd-0f2a4e728944,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-0bbe7c31-a71e-4262-9411-acee5a9a84b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-1ffb80a4-d3da-4596-bcc7-b80bfbe1bf23,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-27e6b40e-3913-4dcb-a94c-2e7c7a44b5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-9dc7e182-bda9-462b-ba47-575413ec6e51,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-209bc468-ceea-4c11-94ac-02153a95866e,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-4be8f797-fe34-46f3-a80f-8e1c134a79a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-e5360e17-637f-495d-b89a-7802de40cb15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2072120088-172.17.0.14-1595537983047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42303,DS-d2b73c50-0bb9-4dd0-9cf7-d6c598de6c30,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-c54fee18-77d6-435c-a6e5-106a51bae3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-a97d694a-3584-462a-8d29-ea995fbec8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-bd7786a0-5be1-47f2-bbe0-4bc5495b5051,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-23fd0f4f-5df1-43c2-860b-cfd455b61cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-9c2c396d-761f-4e03-b0a8-443c3f1935ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-eb00510f-8e8b-49c6-8a5f-833cf1581480,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-d7d2da00-f110-4e81-b064-22e4e4fa2b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2072120088-172.17.0.14-1595537983047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42303,DS-d2b73c50-0bb9-4dd0-9cf7-d6c598de6c30,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-c54fee18-77d6-435c-a6e5-106a51bae3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-a97d694a-3584-462a-8d29-ea995fbec8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-bd7786a0-5be1-47f2-bbe0-4bc5495b5051,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-23fd0f4f-5df1-43c2-860b-cfd455b61cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-9c2c396d-761f-4e03-b0a8-443c3f1935ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-eb00510f-8e8b-49c6-8a5f-833cf1581480,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-d7d2da00-f110-4e81-b064-22e4e4fa2b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1844981329-172.17.0.14-1595538202560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37381,DS-907c0dee-769d-4cb9-be1a-1d5c9127d59e,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-243d4533-4496-4199-bd00-73d730a27888,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-394e9f6c-6570-4055-b500-97068f10f91d,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-c60737b3-57b5-4767-80c5-6905933eebd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-0d1e5e7f-2df7-4ded-b2d7-e224123cc019,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-decb74f1-e5b0-404f-a5c9-805eea6e61cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-eaee917c-a84f-4dfe-82ee-85e2a44e7b42,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-35cdb0ae-69b3-44d7-a431-d09e86663605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1844981329-172.17.0.14-1595538202560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37381,DS-907c0dee-769d-4cb9-be1a-1d5c9127d59e,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-243d4533-4496-4199-bd00-73d730a27888,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-394e9f6c-6570-4055-b500-97068f10f91d,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-c60737b3-57b5-4767-80c5-6905933eebd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-0d1e5e7f-2df7-4ded-b2d7-e224123cc019,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-decb74f1-e5b0-404f-a5c9-805eea6e61cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-eaee917c-a84f-4dfe-82ee-85e2a44e7b42,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-35cdb0ae-69b3-44d7-a431-d09e86663605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341771747-172.17.0.14-1595538384408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40998,DS-9200d685-601b-4958-bb6f-52cc6304ae05,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-a9ff41d0-690d-4718-9a75-9da411d21272,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-5e7838ce-7672-4349-8744-45b336f9bae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-44f8af3b-766f-41fc-8c94-46243c8449cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-8b127cd4-1326-448d-8769-13805cc3b892,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-3e6327ad-95c2-4690-8d3e-bb21d4bf395b,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-0a6817b9-989e-4a3c-ae0a-0e2c586fcafc,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-bc9de83c-cd4d-4455-a01d-f97bddb44665,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341771747-172.17.0.14-1595538384408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40998,DS-9200d685-601b-4958-bb6f-52cc6304ae05,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-a9ff41d0-690d-4718-9a75-9da411d21272,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-5e7838ce-7672-4349-8744-45b336f9bae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-44f8af3b-766f-41fc-8c94-46243c8449cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-8b127cd4-1326-448d-8769-13805cc3b892,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-3e6327ad-95c2-4690-8d3e-bb21d4bf395b,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-0a6817b9-989e-4a3c-ae0a-0e2c586fcafc,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-bc9de83c-cd4d-4455-a01d-f97bddb44665,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100060970-172.17.0.14-1595538463216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38554,DS-6cd42b34-4afa-450e-91eb-a883a4b8d7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-b2e63a3e-3f77-48e4-8621-3b645fa4ce05,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-421e2bb4-d50c-49b4-bcd3-3624d247fb84,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-02a2c6e0-0001-4fae-ae1c-9fb8bf3b8678,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-3828c5e5-3b8f-4b6b-8b0f-5457702f5422,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-44208727-9e74-482d-b1d8-39ef5d00647f,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-5e4f5c33-96da-4737-bbb2-58f19c5d2f69,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-8b0b1bf7-b49a-4880-803b-bc4155c7d7a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100060970-172.17.0.14-1595538463216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38554,DS-6cd42b34-4afa-450e-91eb-a883a4b8d7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-b2e63a3e-3f77-48e4-8621-3b645fa4ce05,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-421e2bb4-d50c-49b4-bcd3-3624d247fb84,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-02a2c6e0-0001-4fae-ae1c-9fb8bf3b8678,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-3828c5e5-3b8f-4b6b-8b0f-5457702f5422,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-44208727-9e74-482d-b1d8-39ef5d00647f,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-5e4f5c33-96da-4737-bbb2-58f19c5d2f69,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-8b0b1bf7-b49a-4880-803b-bc4155c7d7a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512722569-172.17.0.14-1595538923115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39986,DS-981b7195-6bc4-441f-a7f5-9d35b64b1b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-feceb981-16e6-4915-b788-0eb5ccd67638,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-f6e41e6f-7d7d-490d-b508-0c5c2aa2353c,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-3c43c385-63d0-47e2-bb1a-76a68020c2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-0d42e26c-8a4f-46e4-acd8-31783af7025c,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-334073e6-e690-494d-bc58-02cdb2e9a7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-37be04ff-77fc-4eb3-bcf7-82de153e0d68,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-e5f6ce97-fdc6-4b79-a192-f325ef3715f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-512722569-172.17.0.14-1595538923115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39986,DS-981b7195-6bc4-441f-a7f5-9d35b64b1b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-feceb981-16e6-4915-b788-0eb5ccd67638,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-f6e41e6f-7d7d-490d-b508-0c5c2aa2353c,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-3c43c385-63d0-47e2-bb1a-76a68020c2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-0d42e26c-8a4f-46e4-acd8-31783af7025c,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-334073e6-e690-494d-bc58-02cdb2e9a7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-37be04ff-77fc-4eb3-bcf7-82de153e0d68,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-e5f6ce97-fdc6-4b79-a192-f325ef3715f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1711233673-172.17.0.14-1595539826885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37314,DS-e9dc9616-8b47-4600-aed6-cfd91643d4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-6a77096e-a702-41d7-a550-3adaecafe8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-8dbad466-e6eb-44cb-8a71-fb2c86e2fdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-a196a51c-4fe7-495e-81e2-ba4fd2779687,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-a75175a5-0598-457a-90ff-ac990ce5dee4,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-912d6b5d-b882-4909-a041-56088fafdc85,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-4bea4b40-e293-494b-93f9-2a86d91195e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-ac906299-b66b-41a7-90e7-5283d5515fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1711233673-172.17.0.14-1595539826885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37314,DS-e9dc9616-8b47-4600-aed6-cfd91643d4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-6a77096e-a702-41d7-a550-3adaecafe8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-8dbad466-e6eb-44cb-8a71-fb2c86e2fdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-a196a51c-4fe7-495e-81e2-ba4fd2779687,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-a75175a5-0598-457a-90ff-ac990ce5dee4,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-912d6b5d-b882-4909-a041-56088fafdc85,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-4bea4b40-e293-494b-93f9-2a86d91195e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-ac906299-b66b-41a7-90e7-5283d5515fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742251940-172.17.0.14-1595540085540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38400,DS-1ac5d72a-35db-4187-831e-11a17c89f7be,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-f0414775-74ce-400e-9323-dbc001de85dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-988e2894-7dfe-450a-91eb-fd762572f473,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-5d5eee79-ef07-41c0-b85f-368ff8d55ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-b8184b58-a62f-4a5c-858b-922dc2774dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-399eba62-562d-4829-b6b2-4a0b0fc1a03c,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-a9f77f1d-c715-4984-87bd-2c5ea625bf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-115c0aca-9543-472e-9e8c-7a1da5b3cac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742251940-172.17.0.14-1595540085540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38400,DS-1ac5d72a-35db-4187-831e-11a17c89f7be,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-f0414775-74ce-400e-9323-dbc001de85dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-988e2894-7dfe-450a-91eb-fd762572f473,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-5d5eee79-ef07-41c0-b85f-368ff8d55ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-b8184b58-a62f-4a5c-858b-922dc2774dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-399eba62-562d-4829-b6b2-4a0b0fc1a03c,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-a9f77f1d-c715-4984-87bd-2c5ea625bf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-115c0aca-9543-472e-9e8c-7a1da5b3cac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453206837-172.17.0.14-1595540461166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41172,DS-f3b8ec0d-fd24-4752-a853-be994fe98682,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-c7045818-6641-43e9-b099-5c64840f8df8,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-0ef62425-c8ac-4bf7-8ca2-27d28015db87,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-25b4caab-c0d9-4b1b-9cff-98bd239f492b,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-4daba00b-2859-497f-8ef1-2e87c2df50cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-8062217f-b765-48a7-85b8-68f2d36abd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-37dd95c8-b463-43f6-8ba3-99fbbd8e75eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-26eb7ab9-d368-44fe-af14-d8a302a691d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-453206837-172.17.0.14-1595540461166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41172,DS-f3b8ec0d-fd24-4752-a853-be994fe98682,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-c7045818-6641-43e9-b099-5c64840f8df8,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-0ef62425-c8ac-4bf7-8ca2-27d28015db87,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-25b4caab-c0d9-4b1b-9cff-98bd239f492b,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-4daba00b-2859-497f-8ef1-2e87c2df50cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-8062217f-b765-48a7-85b8-68f2d36abd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-37dd95c8-b463-43f6-8ba3-99fbbd8e75eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-26eb7ab9-d368-44fe-af14-d8a302a691d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-94052845-172.17.0.14-1595540828651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34659,DS-4535d70c-79bf-418d-b35e-833def2248b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-6d1e7a77-88f4-4f02-b043-3346a9fd9b51,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-3b4dbad2-6f70-46e9-939b-4cd8c919c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-761b72fb-9d3f-45cd-af5f-c847dc9364e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-98c0d83b-1c88-4446-8ce3-7ddc361b53bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-af7bf8d1-505d-4562-b82b-359644e9457d,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-a9a95d84-28da-4461-b0d2-58de1473522b,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-203e9388-9c06-4363-9c21-a688727a48ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-94052845-172.17.0.14-1595540828651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34659,DS-4535d70c-79bf-418d-b35e-833def2248b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38205,DS-6d1e7a77-88f4-4f02-b043-3346a9fd9b51,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-3b4dbad2-6f70-46e9-939b-4cd8c919c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-761b72fb-9d3f-45cd-af5f-c847dc9364e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-98c0d83b-1c88-4446-8ce3-7ddc361b53bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-af7bf8d1-505d-4562-b82b-359644e9457d,DISK], DatanodeInfoWithStorage[127.0.0.1:42803,DS-a9a95d84-28da-4461-b0d2-58de1473522b,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-203e9388-9c06-4363-9c21-a688727a48ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269677681-172.17.0.14-1595541083883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33376,DS-080aa2a7-7233-49f0-81b8-2aa2a13b3023,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-5fa1125d-eb50-42a9-81a2-ded60b136cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-ef8511c6-7919-4d31-b4d3-6b49abb0d75a,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-c17bcd3c-ec41-4d04-aeef-f8dd472f5317,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-cb336ade-6130-437e-914e-7fea22d7a85b,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-9f92b2ee-b052-4a1a-a9a4-c46926cda281,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-9dd4c1f5-f8f5-4db8-bf82-d31aff076971,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-07d3d130-89e3-4b06-a0c9-39c6b1bf0830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269677681-172.17.0.14-1595541083883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33376,DS-080aa2a7-7233-49f0-81b8-2aa2a13b3023,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-5fa1125d-eb50-42a9-81a2-ded60b136cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-ef8511c6-7919-4d31-b4d3-6b49abb0d75a,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-c17bcd3c-ec41-4d04-aeef-f8dd472f5317,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-cb336ade-6130-437e-914e-7fea22d7a85b,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-9f92b2ee-b052-4a1a-a9a4-c46926cda281,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-9dd4c1f5-f8f5-4db8-bf82-d31aff076971,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-07d3d130-89e3-4b06-a0c9-39c6b1bf0830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410595204-172.17.0.14-1595541159219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38605,DS-16b652e6-4d79-4446-b856-8f400e397c62,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-4583a265-9787-4f03-90c9-19e0fc6bff7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-53e7f7c5-69dc-4400-b50e-daceced03421,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-19e10316-9e25-46e8-be84-48c732bed85f,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-b894edcd-71bc-4ebe-bce5-de2a6f17caa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-7d5a8ba5-7367-48b1-a0f5-48f0a632fa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-73c9a2cf-e759-4adb-8591-34165b8a5256,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-258b00f6-6562-4ee8-b6a8-e9dce64d2ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410595204-172.17.0.14-1595541159219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38605,DS-16b652e6-4d79-4446-b856-8f400e397c62,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-4583a265-9787-4f03-90c9-19e0fc6bff7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-53e7f7c5-69dc-4400-b50e-daceced03421,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-19e10316-9e25-46e8-be84-48c732bed85f,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-b894edcd-71bc-4ebe-bce5-de2a6f17caa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-7d5a8ba5-7367-48b1-a0f5-48f0a632fa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-73c9a2cf-e759-4adb-8591-34165b8a5256,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-258b00f6-6562-4ee8-b6a8-e9dce64d2ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117308107-172.17.0.14-1595542070009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40034,DS-7c7175a3-949f-4b97-b4c3-65c1f6183deb,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-b75066c7-0e4f-4d1a-946f-ab554e4b9764,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-33f1cb3d-0398-4d67-b552-72b0e983008f,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-985afe63-c610-4fb7-9727-d55772db877b,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-0161a1d3-238f-4b14-afc1-49515a178cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-ed8e0082-0888-4792-b499-617c88b6527f,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-d60b163a-c2e3-4463-bfbe-aa72b3279f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-cfe2fd0d-63cc-4d37-972a-d530746b1c53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117308107-172.17.0.14-1595542070009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40034,DS-7c7175a3-949f-4b97-b4c3-65c1f6183deb,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-b75066c7-0e4f-4d1a-946f-ab554e4b9764,DISK], DatanodeInfoWithStorage[127.0.0.1:35590,DS-33f1cb3d-0398-4d67-b552-72b0e983008f,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-985afe63-c610-4fb7-9727-d55772db877b,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-0161a1d3-238f-4b14-afc1-49515a178cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-ed8e0082-0888-4792-b499-617c88b6527f,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-d60b163a-c2e3-4463-bfbe-aa72b3279f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-cfe2fd0d-63cc-4d37-972a-d530746b1c53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039225772-172.17.0.14-1595542111256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36023,DS-ffcca647-dd61-45c7-af49-23d7bfbcbe40,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-877fca60-201f-492c-837c-6003213e7ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-e606429b-c027-4474-bae6-3390b0b79915,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-689b8680-70d3-4c0d-8543-134386f922a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-3b3f6668-e94f-4e54-9e27-fd6b5fa10689,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-ecb50d33-27d6-4436-9238-32c092f95465,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-506b31bf-2694-48a6-83ce-ae0c880474f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-d265811f-fc20-418a-a0a9-964de9a8e66c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039225772-172.17.0.14-1595542111256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36023,DS-ffcca647-dd61-45c7-af49-23d7bfbcbe40,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-877fca60-201f-492c-837c-6003213e7ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-e606429b-c027-4474-bae6-3390b0b79915,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-689b8680-70d3-4c0d-8543-134386f922a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-3b3f6668-e94f-4e54-9e27-fd6b5fa10689,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-ecb50d33-27d6-4436-9238-32c092f95465,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-506b31bf-2694-48a6-83ce-ae0c880474f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-d265811f-fc20-418a-a0a9-964de9a8e66c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304608705-172.17.0.14-1595542435016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42858,DS-341b5c66-ff65-4d71-950a-21b7c51e6c67,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-b5a834e1-56f1-4a63-b922-91ab17ac3bba,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-6509b83c-1016-415f-aa88-82a024942b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-f3336451-8a6d-4118-8f5d-d8dfca57e44c,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-b34f875f-1008-431a-8a1e-e378687ae585,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-8f67853a-b386-4329-91a2-74971a478ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-a0f5b155-45f6-4eb2-a673-5a2202016098,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-88fabfdc-1125-487e-ab54-15910222034b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304608705-172.17.0.14-1595542435016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42858,DS-341b5c66-ff65-4d71-950a-21b7c51e6c67,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-b5a834e1-56f1-4a63-b922-91ab17ac3bba,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-6509b83c-1016-415f-aa88-82a024942b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-f3336451-8a6d-4118-8f5d-d8dfca57e44c,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-b34f875f-1008-431a-8a1e-e378687ae585,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-8f67853a-b386-4329-91a2-74971a478ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-a0f5b155-45f6-4eb2-a673-5a2202016098,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-88fabfdc-1125-487e-ab54-15910222034b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1406507382-172.17.0.14-1595542763692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37665,DS-14f4c8c0-d31a-4bd7-94cd-81d04e9cdb49,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-9c3052dd-37d5-42f0-8c22-d302413c1013,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-abb926bc-f627-4718-ad2e-ec607db95267,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-7ffbc28c-3f63-4bc2-b27b-a8d37e9ba13a,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-ac27f92a-00e8-4d57-937f-3921f8777ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-bb5dfdf2-d193-4afa-a44b-deca2010fe54,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-7f24d362-59e1-459f-99ab-3ffffc9d6400,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-e55c4446-cd93-49bb-8747-28a3c0dff58d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1406507382-172.17.0.14-1595542763692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37665,DS-14f4c8c0-d31a-4bd7-94cd-81d04e9cdb49,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-9c3052dd-37d5-42f0-8c22-d302413c1013,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-abb926bc-f627-4718-ad2e-ec607db95267,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-7ffbc28c-3f63-4bc2-b27b-a8d37e9ba13a,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-ac27f92a-00e8-4d57-937f-3921f8777ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-bb5dfdf2-d193-4afa-a44b-deca2010fe54,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-7f24d362-59e1-459f-99ab-3ffffc9d6400,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-e55c4446-cd93-49bb-8747-28a3c0dff58d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5302
