reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380308105-172.17.0.12-1595849384379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33113,DS-ffd88c23-e1f2-4d87-a736-8bce80c58963,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-677d06f5-fa09-4c25-ae52-682e350d4cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-cba85cbe-fa40-4b62-bfff-211cec5287e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-7c2389e5-5a60-436e-95f8-173c27c1bcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-662d6d13-f610-4287-ae92-2a2ad43ca723,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-b52666bf-cd61-49d4-b3cc-df73fad4dda2,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-f5633d39-2336-4ad0-95b8-ac6603dae136,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-db5d5f5e-05d2-470b-8913-3c3b76d090e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380308105-172.17.0.12-1595849384379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33113,DS-ffd88c23-e1f2-4d87-a736-8bce80c58963,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-677d06f5-fa09-4c25-ae52-682e350d4cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-cba85cbe-fa40-4b62-bfff-211cec5287e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-7c2389e5-5a60-436e-95f8-173c27c1bcd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-662d6d13-f610-4287-ae92-2a2ad43ca723,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-b52666bf-cd61-49d4-b3cc-df73fad4dda2,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-f5633d39-2336-4ad0-95b8-ac6603dae136,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-db5d5f5e-05d2-470b-8913-3c3b76d090e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425163785-172.17.0.12-1595849691811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37248,DS-5dfefbba-2719-4dd1-8dd3-8c4eb7e5fc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-109df6cf-8890-4564-819c-3658b6179daa,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-c7c5de39-9f15-45e9-a082-e6a000d38840,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-b2166f1b-ccc5-4b16-b644-8193bca56164,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-cc98e86c-83cd-464a-8bb5-d24d1031d19d,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-96e937dd-0d07-459e-bd6b-18b248006948,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-3f875c74-842c-4313-9921-2e001834a4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-70c7aee8-0058-4546-beb7-e493d68993a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425163785-172.17.0.12-1595849691811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37248,DS-5dfefbba-2719-4dd1-8dd3-8c4eb7e5fc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-109df6cf-8890-4564-819c-3658b6179daa,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-c7c5de39-9f15-45e9-a082-e6a000d38840,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-b2166f1b-ccc5-4b16-b644-8193bca56164,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-cc98e86c-83cd-464a-8bb5-d24d1031d19d,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-96e937dd-0d07-459e-bd6b-18b248006948,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-3f875c74-842c-4313-9921-2e001834a4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-70c7aee8-0058-4546-beb7-e493d68993a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148713641-172.17.0.12-1595850267619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41028,DS-1d80c227-ab86-4d87-af30-e6fbd061ee9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-3122be16-0c80-4b65-832d-ed5feae50ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-85b4b730-f995-4341-b850-e3a622a35504,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-259c7f6b-faf9-42c0-8025-75aacb0544b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-0ac1d651-6212-4c4c-a080-6048a9f5af17,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-580b0d8b-166b-4ac8-92a5-45e6c0747bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-df807b5a-36dd-4427-abf7-f2c89277bbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-e79830df-d43d-41fe-94e3-c993d83524a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148713641-172.17.0.12-1595850267619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41028,DS-1d80c227-ab86-4d87-af30-e6fbd061ee9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-3122be16-0c80-4b65-832d-ed5feae50ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-85b4b730-f995-4341-b850-e3a622a35504,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-259c7f6b-faf9-42c0-8025-75aacb0544b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-0ac1d651-6212-4c4c-a080-6048a9f5af17,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-580b0d8b-166b-4ac8-92a5-45e6c0747bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-df807b5a-36dd-4427-abf7-f2c89277bbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-e79830df-d43d-41fe-94e3-c993d83524a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965796823-172.17.0.12-1595850311411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45396,DS-43c4e48b-c75e-4c27-b852-1c75e2d08062,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-b08b6885-e04e-4a84-919b-ef7ba9ef9a37,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-cf657f31-9780-4cc3-9338-e90cbb3359f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-a5b4087b-a9be-48de-9da0-985660443f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-3daa5213-e6af-41ea-aeb8-c909b35d482b,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-af027007-abf1-46c3-8af2-24dd4ab329de,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-ba10c6f2-137d-4061-9cf7-46922efbb7db,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-04c21f6f-fe43-4f49-9953-2fc75f61ae8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965796823-172.17.0.12-1595850311411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45396,DS-43c4e48b-c75e-4c27-b852-1c75e2d08062,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-b08b6885-e04e-4a84-919b-ef7ba9ef9a37,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-cf657f31-9780-4cc3-9338-e90cbb3359f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-a5b4087b-a9be-48de-9da0-985660443f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-3daa5213-e6af-41ea-aeb8-c909b35d482b,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-af027007-abf1-46c3-8af2-24dd4ab329de,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-ba10c6f2-137d-4061-9cf7-46922efbb7db,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-04c21f6f-fe43-4f49-9953-2fc75f61ae8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996667978-172.17.0.12-1595850994813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-7c1e45c3-f018-4236-8387-25b92027cf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-7867a0cc-7665-4cd2-a43f-a33eb1cf74ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-5dd624cc-c10b-46eb-8041-e470458b4ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-e9730b72-6e6f-4985-8ec5-07022c5456cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-ab6d7655-ab7e-4807-a0d2-f647ec500d48,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-237187a3-8a10-4476-af90-04d07859616c,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-4a82c276-ee79-4620-9927-067829e265dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-5ee774a0-a634-4972-a30f-e9efc9eb036d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996667978-172.17.0.12-1595850994813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-7c1e45c3-f018-4236-8387-25b92027cf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-7867a0cc-7665-4cd2-a43f-a33eb1cf74ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-5dd624cc-c10b-46eb-8041-e470458b4ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-e9730b72-6e6f-4985-8ec5-07022c5456cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-ab6d7655-ab7e-4807-a0d2-f647ec500d48,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-237187a3-8a10-4476-af90-04d07859616c,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-4a82c276-ee79-4620-9927-067829e265dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-5ee774a0-a634-4972-a30f-e9efc9eb036d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971919350-172.17.0.12-1595851037442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46667,DS-1edc5496-8867-4af2-b444-51e280d9e3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-6b17c558-e110-4a22-b3e3-563b7575699e,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-2a79cf85-0b41-4f8c-81a6-9114ac0e3c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-ba36b623-034d-41db-a18c-1acef089314c,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-84d8bc6e-0c17-4b69-939d-1e187c955784,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-d51bf604-9991-4e88-902c-95bf02091ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-bf58329d-272e-4463-b7f9-6b3ec89026dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-811f02d0-7f03-4125-8614-6ffcb8f12a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971919350-172.17.0.12-1595851037442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46667,DS-1edc5496-8867-4af2-b444-51e280d9e3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-6b17c558-e110-4a22-b3e3-563b7575699e,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-2a79cf85-0b41-4f8c-81a6-9114ac0e3c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-ba36b623-034d-41db-a18c-1acef089314c,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-84d8bc6e-0c17-4b69-939d-1e187c955784,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-d51bf604-9991-4e88-902c-95bf02091ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-bf58329d-272e-4463-b7f9-6b3ec89026dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-811f02d0-7f03-4125-8614-6ffcb8f12a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159159343-172.17.0.12-1595851420658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33669,DS-1f7ff672-ec68-44cb-b516-02bdb872d741,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-ebba3b6a-0a16-4317-ae70-3cbcc01b6a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-2c22be15-75b7-479b-a8f9-0a018aa80eca,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-928548e8-57ba-4e6c-addd-8373bd2399e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-329fc303-1033-49bb-ad52-840f0be8f1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-11b87593-dbe1-4491-8ea9-f7e923ec5940,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-9faf901c-1e7b-4bab-af76-af3939add29e,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-5d556e97-ad5c-4364-b105-d900c7d3c4e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159159343-172.17.0.12-1595851420658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33669,DS-1f7ff672-ec68-44cb-b516-02bdb872d741,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-ebba3b6a-0a16-4317-ae70-3cbcc01b6a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-2c22be15-75b7-479b-a8f9-0a018aa80eca,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-928548e8-57ba-4e6c-addd-8373bd2399e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-329fc303-1033-49bb-ad52-840f0be8f1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-11b87593-dbe1-4491-8ea9-f7e923ec5940,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-9faf901c-1e7b-4bab-af76-af3939add29e,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-5d556e97-ad5c-4364-b105-d900c7d3c4e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111653117-172.17.0.12-1595851607258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40730,DS-759873e5-5c02-40b0-b88b-9cbe1281423d,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-6176c578-aaca-41eb-a0b9-da108dc20cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-97f65933-a85f-43e1-84df-09d771731130,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-8d33cded-9c38-4311-b7c9-96d82064abc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-a7fa3a59-9281-4295-9534-a81b4118b69f,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-e65d1e8a-3d1a-4b76-b8d8-ab39db216a69,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-31ef897d-7709-4b9f-bfbd-66046ef3aaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-a1fae870-16b9-4826-bc41-0b5bc0f1be0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111653117-172.17.0.12-1595851607258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40730,DS-759873e5-5c02-40b0-b88b-9cbe1281423d,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-6176c578-aaca-41eb-a0b9-da108dc20cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-97f65933-a85f-43e1-84df-09d771731130,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-8d33cded-9c38-4311-b7c9-96d82064abc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-a7fa3a59-9281-4295-9534-a81b4118b69f,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-e65d1e8a-3d1a-4b76-b8d8-ab39db216a69,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-31ef897d-7709-4b9f-bfbd-66046ef3aaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-a1fae870-16b9-4826-bc41-0b5bc0f1be0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486773559-172.17.0.12-1595851804372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36094,DS-641c249f-5766-41d1-94d4-610aa3ad9f89,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-1a439c32-49dd-47bd-b3ee-f02104058359,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-d8b719a4-7738-404b-83ad-65a5f9aeebd3,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-b77d142f-b163-4377-8965-aaa5128d5f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-609c12b6-2522-4e62-9357-cc48a054011f,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-9206fe60-b629-47d7-98ed-d519f5fcccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-f4c4ad21-823e-4b0a-b506-ddb5c8b06c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-9d46986d-5aaa-432a-8b2f-54991ab45158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486773559-172.17.0.12-1595851804372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36094,DS-641c249f-5766-41d1-94d4-610aa3ad9f89,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-1a439c32-49dd-47bd-b3ee-f02104058359,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-d8b719a4-7738-404b-83ad-65a5f9aeebd3,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-b77d142f-b163-4377-8965-aaa5128d5f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-609c12b6-2522-4e62-9357-cc48a054011f,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-9206fe60-b629-47d7-98ed-d519f5fcccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-f4c4ad21-823e-4b0a-b506-ddb5c8b06c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-9d46986d-5aaa-432a-8b2f-54991ab45158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761011437-172.17.0.12-1595852325201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42460,DS-8319f3fb-0b8f-461f-a69d-2f6311e0e63b,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-d4d42d04-74bd-4aad-b8ac-b7282648a6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-4c8036fa-2b99-48fe-a578-6f2d3ce08e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-4d3c0a36-c581-4485-b3ef-00de2e86937f,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-0fd05159-1530-41db-b252-044d8dddcd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-7645a889-9beb-473e-8342-6f1c0a113161,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-a35b4032-44ed-4cbb-91cd-54edc3f85a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-822cdd4c-7186-415a-88cb-8881bcf27d96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761011437-172.17.0.12-1595852325201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42460,DS-8319f3fb-0b8f-461f-a69d-2f6311e0e63b,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-d4d42d04-74bd-4aad-b8ac-b7282648a6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-4c8036fa-2b99-48fe-a578-6f2d3ce08e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-4d3c0a36-c581-4485-b3ef-00de2e86937f,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-0fd05159-1530-41db-b252-044d8dddcd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-7645a889-9beb-473e-8342-6f1c0a113161,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-a35b4032-44ed-4cbb-91cd-54edc3f85a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-822cdd4c-7186-415a-88cb-8881bcf27d96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066513095-172.17.0.12-1595852911804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41551,DS-d9d87ebb-41dd-43b8-965f-9d162436fb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-1869bd50-03b3-4fe5-8415-c3e2848989d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-264ea238-8162-4ed0-9211-ab98eb762710,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-d61c7a8e-bc7d-4e1f-a33a-75afbfcafd61,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-da1891ce-e269-426c-be5c-4863d3b9520d,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-ffd53327-3ae1-4692-95f2-a8b351d999dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-b2448e1a-1e7e-439a-b8fc-20ac8893ac67,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-42041099-d07c-4ac9-9ca7-fe1f1cd3edcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066513095-172.17.0.12-1595852911804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41551,DS-d9d87ebb-41dd-43b8-965f-9d162436fb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-1869bd50-03b3-4fe5-8415-c3e2848989d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-264ea238-8162-4ed0-9211-ab98eb762710,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-d61c7a8e-bc7d-4e1f-a33a-75afbfcafd61,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-da1891ce-e269-426c-be5c-4863d3b9520d,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-ffd53327-3ae1-4692-95f2-a8b351d999dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-b2448e1a-1e7e-439a-b8fc-20ac8893ac67,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-42041099-d07c-4ac9-9ca7-fe1f1cd3edcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174705531-172.17.0.12-1595853138309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39552,DS-52fb534d-b493-4bbe-8183-f6286a93cda6,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-a3a84cff-6906-4cbf-95db-ac6d1a6f6f49,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-f53b0a85-7c5c-4cb2-9cc1-98337af57abd,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-befd83e1-dff0-416c-8da7-12823c552b26,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-4b57ee3e-1b0c-4812-a985-78b1f58bb29d,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-f07500c2-b49a-4ab0-8c48-8a1a415abe01,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-e09ba782-49e3-499e-941e-8dbfa54031ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-a7189d4e-c996-42d9-8e95-e15e4661d74e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1174705531-172.17.0.12-1595853138309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39552,DS-52fb534d-b493-4bbe-8183-f6286a93cda6,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-a3a84cff-6906-4cbf-95db-ac6d1a6f6f49,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-f53b0a85-7c5c-4cb2-9cc1-98337af57abd,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-befd83e1-dff0-416c-8da7-12823c552b26,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-4b57ee3e-1b0c-4812-a985-78b1f58bb29d,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-f07500c2-b49a-4ab0-8c48-8a1a415abe01,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-e09ba782-49e3-499e-941e-8dbfa54031ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-a7189d4e-c996-42d9-8e95-e15e4661d74e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682194132-172.17.0.12-1595853178902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35095,DS-b52aa725-4930-404c-8a3e-80ae5b32e3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-196ad30c-a19c-4d73-8182-c165967b72f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-eec4d381-75ee-487e-b05b-e882c87b72e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-60b98952-8edb-4ad3-8d1a-bc8387fcbb47,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-d1feb543-f700-4603-ae6b-a8d54db304c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-a2fad1bb-2da0-4bb7-b5d8-f646e760bfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-3c9db220-c9f7-485a-986f-87ce9a5ec36a,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-aac05de1-3b93-4be7-a7a3-649b76d6dc11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682194132-172.17.0.12-1595853178902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35095,DS-b52aa725-4930-404c-8a3e-80ae5b32e3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-196ad30c-a19c-4d73-8182-c165967b72f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-eec4d381-75ee-487e-b05b-e882c87b72e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-60b98952-8edb-4ad3-8d1a-bc8387fcbb47,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-d1feb543-f700-4603-ae6b-a8d54db304c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-a2fad1bb-2da0-4bb7-b5d8-f646e760bfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-3c9db220-c9f7-485a-986f-87ce9a5ec36a,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-aac05de1-3b93-4be7-a7a3-649b76d6dc11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653354472-172.17.0.12-1595853347834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-4f59e001-82dc-4071-907e-5a69189cdaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-23aacc54-99ed-40e8-97f8-27633862615c,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-8e89825f-6310-4ecd-830e-7482dce889ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-f6482704-cd48-4448-9b2e-654983bf495a,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-71993d8b-e3f1-4e6f-8b60-ea8c265ac6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-cafeab0f-2ca1-476e-9bb7-0058744bb7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-621e4af8-ca67-488e-867b-dafe13ed915a,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-77b962ac-d04c-45b4-aad2-adebc62ed7a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653354472-172.17.0.12-1595853347834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-4f59e001-82dc-4071-907e-5a69189cdaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-23aacc54-99ed-40e8-97f8-27633862615c,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-8e89825f-6310-4ecd-830e-7482dce889ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-f6482704-cd48-4448-9b2e-654983bf495a,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-71993d8b-e3f1-4e6f-8b60-ea8c265ac6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-cafeab0f-2ca1-476e-9bb7-0058744bb7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-621e4af8-ca67-488e-867b-dafe13ed915a,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-77b962ac-d04c-45b4-aad2-adebc62ed7a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986663209-172.17.0.12-1595853808205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41315,DS-33d28e14-d1e9-43fd-99b4-ae4be01133c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-cce9abb4-297b-44c3-b126-6bc7bd99e5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-df846502-3c24-4a9d-9ab5-9c79f7f639f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-d272f0d9-bc0c-419d-b92e-6043e42bfee1,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-9b584aea-6e82-4287-a605-0914ba041557,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-10d9a0e1-aa0e-4ca2-b74a-c4998312284a,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-6f33e2d5-6b1d-41fc-8741-3458f94325f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-2153af94-e743-4a24-9ddb-f8bedef14321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-986663209-172.17.0.12-1595853808205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41315,DS-33d28e14-d1e9-43fd-99b4-ae4be01133c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-cce9abb4-297b-44c3-b126-6bc7bd99e5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-df846502-3c24-4a9d-9ab5-9c79f7f639f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-d272f0d9-bc0c-419d-b92e-6043e42bfee1,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-9b584aea-6e82-4287-a605-0914ba041557,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-10d9a0e1-aa0e-4ca2-b74a-c4998312284a,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-6f33e2d5-6b1d-41fc-8741-3458f94325f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-2153af94-e743-4a24-9ddb-f8bedef14321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788486098-172.17.0.12-1595853875339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36095,DS-0b636c2c-c56c-4c0f-87f5-f8c2fe91f831,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-04322e7a-ae7b-4ce3-99ea-91516831d800,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-2328a394-ad5e-4800-9aae-d2bab2bb2a67,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-b777ef1c-201c-4765-9d4e-fdf9bc4afaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-f08c8251-ce5f-40aa-97a6-e3f945eb6ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-3a084c85-488f-4d00-98b3-915122f52aad,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-6fdf7cae-968d-470f-bee2-cc1868963063,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-908c3b18-54e0-4dca-a7f5-46afb2306204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788486098-172.17.0.12-1595853875339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36095,DS-0b636c2c-c56c-4c0f-87f5-f8c2fe91f831,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-04322e7a-ae7b-4ce3-99ea-91516831d800,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-2328a394-ad5e-4800-9aae-d2bab2bb2a67,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-b777ef1c-201c-4765-9d4e-fdf9bc4afaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-f08c8251-ce5f-40aa-97a6-e3f945eb6ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-3a084c85-488f-4d00-98b3-915122f52aad,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-6fdf7cae-968d-470f-bee2-cc1868963063,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-908c3b18-54e0-4dca-a7f5-46afb2306204,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-922157730-172.17.0.12-1595854091092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40653,DS-88f6f31b-fa2a-4049-8509-fae1cc1e5d81,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-79645a61-15d3-43cc-bde7-a45cdd163021,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-ec765ccb-63af-4a55-aa3c-e9d0a4cdd065,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-363ee68f-9bb7-4275-9bd9-4e5d58533a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-76a595c2-92c7-429c-af25-835b72d214d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-32abda0d-c75a-452d-a637-af56f68f8f57,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-52ec8c1b-e304-45d0-9c9e-7085678753c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-74158fed-c0b5-437d-8c8c-baab00cd09fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-922157730-172.17.0.12-1595854091092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40653,DS-88f6f31b-fa2a-4049-8509-fae1cc1e5d81,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-79645a61-15d3-43cc-bde7-a45cdd163021,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-ec765ccb-63af-4a55-aa3c-e9d0a4cdd065,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-363ee68f-9bb7-4275-9bd9-4e5d58533a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-76a595c2-92c7-429c-af25-835b72d214d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-32abda0d-c75a-452d-a637-af56f68f8f57,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-52ec8c1b-e304-45d0-9c9e-7085678753c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-74158fed-c0b5-437d-8c8c-baab00cd09fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441868105-172.17.0.12-1595854513759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35511,DS-c5a3fc22-1c3d-4a46-b071-e8c46991f41b,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-ad5920d0-ef55-4012-ba0a-4f076e5a071e,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-5f30e7d3-58cf-4c37-9f33-ceadbe4a45e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-335b08d3-d1e2-4557-8a96-3105e5d00b90,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-6c91903e-f5d6-45c8-bd9a-ba85983e1027,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-c76276d4-c360-4506-a31f-07ec90f15b11,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-a4890ec4-3dbd-4a56-9056-ccbced90f344,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-95cd9e70-bb47-406f-aecc-8da42fd3483a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441868105-172.17.0.12-1595854513759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35511,DS-c5a3fc22-1c3d-4a46-b071-e8c46991f41b,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-ad5920d0-ef55-4012-ba0a-4f076e5a071e,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-5f30e7d3-58cf-4c37-9f33-ceadbe4a45e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-335b08d3-d1e2-4557-8a96-3105e5d00b90,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-6c91903e-f5d6-45c8-bd9a-ba85983e1027,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-c76276d4-c360-4506-a31f-07ec90f15b11,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-a4890ec4-3dbd-4a56-9056-ccbced90f344,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-95cd9e70-bb47-406f-aecc-8da42fd3483a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1591268368-172.17.0.12-1595854773666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45146,DS-fa319c1f-1007-4e9b-b681-6d9446502305,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-73ee4fa0-988a-4f68-9dcf-95698f7fdcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-b9a20f63-0430-4fd1-a25a-b0be139b6a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-b09bc973-c33b-4eb0-9dec-099a13cc49c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-4d87ab77-acd4-4822-bfd3-bc63445e9099,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-87390047-0429-42be-9d27-8244f0383b67,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-260f830f-29ba-41b9-89f6-3b58a131b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-696f696f-b926-479a-a9d5-002e884c5b98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1591268368-172.17.0.12-1595854773666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45146,DS-fa319c1f-1007-4e9b-b681-6d9446502305,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-73ee4fa0-988a-4f68-9dcf-95698f7fdcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-b9a20f63-0430-4fd1-a25a-b0be139b6a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-b09bc973-c33b-4eb0-9dec-099a13cc49c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-4d87ab77-acd4-4822-bfd3-bc63445e9099,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-87390047-0429-42be-9d27-8244f0383b67,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-260f830f-29ba-41b9-89f6-3b58a131b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-696f696f-b926-479a-a9d5-002e884c5b98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-149484004-172.17.0.12-1595855114171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40071,DS-62654ddb-615b-4284-bec6-ee6278c0bebb,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-0065cbda-2f23-4d5c-a907-820e6a63150c,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-126347ed-5100-419c-8a91-88a58683464e,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-bd32e551-a8f4-496a-98d0-4158008a2e17,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-07227fde-2356-4957-8b8a-2c22ce4f6c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-97b49511-a65e-4826-81b1-f8cf9016164e,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-df4ad67a-c89f-4aac-9774-e4c272c95a87,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-2d414c72-68c1-4bc4-b383-219957cce471,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-149484004-172.17.0.12-1595855114171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40071,DS-62654ddb-615b-4284-bec6-ee6278c0bebb,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-0065cbda-2f23-4d5c-a907-820e6a63150c,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-126347ed-5100-419c-8a91-88a58683464e,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-bd32e551-a8f4-496a-98d0-4158008a2e17,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-07227fde-2356-4957-8b8a-2c22ce4f6c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-97b49511-a65e-4826-81b1-f8cf9016164e,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-df4ad67a-c89f-4aac-9774-e4c272c95a87,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-2d414c72-68c1-4bc4-b383-219957cce471,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-822439005-172.17.0.12-1595855602161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39677,DS-b7e22dce-9c22-43c0-bb5c-6d05ce7aa71f,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-a1ccedf5-1168-4551-81da-39af1785e43b,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-08a816f1-7d79-4e4b-b318-b9334c433bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-025d3723-c4f7-4bc2-b138-593f29bb4723,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-c73b3d81-86ed-448f-971f-1ef8c09aabfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-8075d7e3-d009-4f20-bd05-bd8c4f4f875f,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-4dd77206-4f33-4549-b13b-c18a74a72d81,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-77ab4b5b-1b44-4df0-b024-d736abc669aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-822439005-172.17.0.12-1595855602161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39677,DS-b7e22dce-9c22-43c0-bb5c-6d05ce7aa71f,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-a1ccedf5-1168-4551-81da-39af1785e43b,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-08a816f1-7d79-4e4b-b318-b9334c433bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-025d3723-c4f7-4bc2-b138-593f29bb4723,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-c73b3d81-86ed-448f-971f-1ef8c09aabfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-8075d7e3-d009-4f20-bd05-bd8c4f4f875f,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-4dd77206-4f33-4549-b13b-c18a74a72d81,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-77ab4b5b-1b44-4df0-b024-d736abc669aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6835
