reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426540734-172.17.0.6-1595929380467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38486,DS-6ec37189-f896-4d2d-aba9-8a84a86705ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-65d9f50d-2bef-40e1-a70e-d7cdb34a5120,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-ff6c5f8f-f647-4d9c-869c-413c100f2ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-da590b41-b06a-48c1-94cb-c709ae4e24aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-79dbe164-900f-45e2-bfdb-74fc42e2119d,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-85563ce6-adb5-4a96-be7f-cb582612db17,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-ff240c07-ecfa-4b95-8618-cf26c2857daa,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-7e2569a9-a575-49a9-a99e-e0c637705506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426540734-172.17.0.6-1595929380467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38486,DS-6ec37189-f896-4d2d-aba9-8a84a86705ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40927,DS-65d9f50d-2bef-40e1-a70e-d7cdb34a5120,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-ff6c5f8f-f647-4d9c-869c-413c100f2ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-da590b41-b06a-48c1-94cb-c709ae4e24aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-79dbe164-900f-45e2-bfdb-74fc42e2119d,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-85563ce6-adb5-4a96-be7f-cb582612db17,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-ff240c07-ecfa-4b95-8618-cf26c2857daa,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-7e2569a9-a575-49a9-a99e-e0c637705506,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60737461-172.17.0.6-1595929743427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43277,DS-ee72f10c-649b-414b-a3c2-893153b1c1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-dc610ed5-c029-4367-9f95-39a7b65284a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-e9fcc7d4-7c39-42f9-b576-0a855c35a931,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-c2544ba0-f403-4c62-adae-e9058c2beb26,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-ea9bb1cc-f271-4c6a-bf32-e475b4e66cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-b60cb71d-1953-49fb-952c-c82b60bb9728,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-b1022d6c-6c12-4514-9e46-57a0c811215c,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-9018e051-ffb0-465b-a785-60b3181f2c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60737461-172.17.0.6-1595929743427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43277,DS-ee72f10c-649b-414b-a3c2-893153b1c1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-dc610ed5-c029-4367-9f95-39a7b65284a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-e9fcc7d4-7c39-42f9-b576-0a855c35a931,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-c2544ba0-f403-4c62-adae-e9058c2beb26,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-ea9bb1cc-f271-4c6a-bf32-e475b4e66cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-b60cb71d-1953-49fb-952c-c82b60bb9728,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-b1022d6c-6c12-4514-9e46-57a0c811215c,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-9018e051-ffb0-465b-a785-60b3181f2c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36182390-172.17.0.6-1595929779665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34578,DS-245917bb-9170-481a-b3f7-6d272c6f7a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-77bd7800-5e6d-422c-8771-daec958e253d,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-7ce660e9-3aa5-4fe3-b7b9-648d0cbf0f29,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-8237792d-6607-43dc-8baf-16753dda3fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-d63fbb67-6e21-4540-8370-afa29ae3253a,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-285a5dd1-578a-4dfe-938a-955ccff8c5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-9fc62a8a-8c47-4d1f-914c-c5294b6b7960,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-43be2d9a-022b-45d9-b9f0-3bb13336e0df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36182390-172.17.0.6-1595929779665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34578,DS-245917bb-9170-481a-b3f7-6d272c6f7a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-77bd7800-5e6d-422c-8771-daec958e253d,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-7ce660e9-3aa5-4fe3-b7b9-648d0cbf0f29,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-8237792d-6607-43dc-8baf-16753dda3fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-d63fbb67-6e21-4540-8370-afa29ae3253a,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-285a5dd1-578a-4dfe-938a-955ccff8c5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-9fc62a8a-8c47-4d1f-914c-c5294b6b7960,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-43be2d9a-022b-45d9-b9f0-3bb13336e0df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557601411-172.17.0.6-1595930303170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41702,DS-02c97651-08a2-4fe0-a31d-2a7f59df2e60,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-0726a3b3-d19b-4b8d-8b06-62fafe5beae4,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-47b425f7-df3c-4bda-ad78-3ce5f5531ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-2c0de9ab-53b9-4549-809a-c93145a0778c,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-ef59110f-d16f-4378-a2bc-cbf3700334c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-dc1bd2f6-682e-4afa-b6c3-433d4afee223,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-e6f48123-b994-44ff-8973-86e49913da4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-38845d6c-00a7-4783-9fc6-4161c0de02a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557601411-172.17.0.6-1595930303170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41702,DS-02c97651-08a2-4fe0-a31d-2a7f59df2e60,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-0726a3b3-d19b-4b8d-8b06-62fafe5beae4,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-47b425f7-df3c-4bda-ad78-3ce5f5531ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-2c0de9ab-53b9-4549-809a-c93145a0778c,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-ef59110f-d16f-4378-a2bc-cbf3700334c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-dc1bd2f6-682e-4afa-b6c3-433d4afee223,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-e6f48123-b994-44ff-8973-86e49913da4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-38845d6c-00a7-4783-9fc6-4161c0de02a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133076931-172.17.0.6-1595930385593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36541,DS-98b045cf-a7a3-4610-a1be-e8cff918ee08,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-88180667-b600-4574-ac9b-153186b6b0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-c4078af1-93c2-40e9-a2e1-6e019a3a2ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-dd60179e-8f87-4bc5-a5fd-ddc354626ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-c4dfd78d-31d6-41f2-a3a1-df7f73969ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-56fc51d4-debf-44c1-b9db-422072392931,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-9cf33ee4-82e5-4d05-9efa-65125f9006af,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-688a70c4-e71f-4a43-96c3-3c3c3dd44604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133076931-172.17.0.6-1595930385593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36541,DS-98b045cf-a7a3-4610-a1be-e8cff918ee08,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-88180667-b600-4574-ac9b-153186b6b0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-c4078af1-93c2-40e9-a2e1-6e019a3a2ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:46307,DS-dd60179e-8f87-4bc5-a5fd-ddc354626ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-c4dfd78d-31d6-41f2-a3a1-df7f73969ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-56fc51d4-debf-44c1-b9db-422072392931,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-9cf33ee4-82e5-4d05-9efa-65125f9006af,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-688a70c4-e71f-4a43-96c3-3c3c3dd44604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243745540-172.17.0.6-1595930592712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35155,DS-3a240387-985b-4cfc-b930-edce2c8d2f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-a45cfafe-84cf-4b4c-9622-06a06542ec77,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-45308677-ba30-4c9f-91a5-0bb8efec0667,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-c718fe07-6e34-4fa7-b481-e345e26600d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-1f86fc6c-9c83-4f2e-b05c-aeb41e781832,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-563833d8-c614-4da7-922b-623f613fa24d,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-38703909-e877-4169-83ed-2207d3ca92c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-2a53e5a1-8e73-4dc5-8280-86c7010c184f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1243745540-172.17.0.6-1595930592712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35155,DS-3a240387-985b-4cfc-b930-edce2c8d2f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-a45cfafe-84cf-4b4c-9622-06a06542ec77,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-45308677-ba30-4c9f-91a5-0bb8efec0667,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-c718fe07-6e34-4fa7-b481-e345e26600d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-1f86fc6c-9c83-4f2e-b05c-aeb41e781832,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-563833d8-c614-4da7-922b-623f613fa24d,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-38703909-e877-4169-83ed-2207d3ca92c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-2a53e5a1-8e73-4dc5-8280-86c7010c184f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442919145-172.17.0.6-1595930632357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42190,DS-836aff30-1831-45b3-9e5b-ba73a7e486a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-055cd50d-0af3-436f-a79a-39fe6dc7c999,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-d8a0f754-1fb6-48db-8057-83998c784470,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-0e97da68-876f-42df-b08c-f6d6868758c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-113b14b0-2424-472a-aa4a-f8d5e69d4e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-69ff3214-1632-400b-95cf-979595403184,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-ce42571f-80c7-42f5-af1b-f3f7ff533dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-cf64bf4f-a0c6-488b-91d1-d623f6609e4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442919145-172.17.0.6-1595930632357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42190,DS-836aff30-1831-45b3-9e5b-ba73a7e486a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-055cd50d-0af3-436f-a79a-39fe6dc7c999,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-d8a0f754-1fb6-48db-8057-83998c784470,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-0e97da68-876f-42df-b08c-f6d6868758c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-113b14b0-2424-472a-aa4a-f8d5e69d4e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-69ff3214-1632-400b-95cf-979595403184,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-ce42571f-80c7-42f5-af1b-f3f7ff533dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-cf64bf4f-a0c6-488b-91d1-d623f6609e4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485016494-172.17.0.6-1595930826384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39996,DS-4b8ac196-9f57-497b-a1f0-f709610bd336,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-e4f44b40-8b22-482c-b2f6-06fcab8543ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-25a746b2-3a3e-4458-93a8-e72ee5f0facb,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-d35afa64-1182-4b94-be9b-92f11cc1d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-c002d112-7580-4938-953b-6aa55d5ef99b,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-9cfd30af-6e1a-4ae1-ba31-ae165e65f4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-b68017fa-352a-41a0-a5eb-cbd0ef5e57a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-06e237c3-78e1-45e2-8ae6-b8b6306feec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485016494-172.17.0.6-1595930826384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39996,DS-4b8ac196-9f57-497b-a1f0-f709610bd336,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-e4f44b40-8b22-482c-b2f6-06fcab8543ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-25a746b2-3a3e-4458-93a8-e72ee5f0facb,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-d35afa64-1182-4b94-be9b-92f11cc1d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-c002d112-7580-4938-953b-6aa55d5ef99b,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-9cfd30af-6e1a-4ae1-ba31-ae165e65f4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-b68017fa-352a-41a0-a5eb-cbd0ef5e57a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-06e237c3-78e1-45e2-8ae6-b8b6306feec3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-201976863-172.17.0.6-1595931709065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39807,DS-685f3f01-5561-4488-99d4-e5f8662ca01d,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-5cc9ee90-9fd1-4cbe-a3fb-fbb913af4ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-bddb88a5-3d18-4cb5-b0c9-bb43ea61e78d,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-9626dfc6-18ae-4a6f-a1ee-85bb88b268b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-4f4771a3-de0c-460f-ac28-30aead85dde5,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-7eec9584-3732-451d-9563-862f861c3141,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-43edb4b8-219a-45a0-b15d-dbab95959ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-506e1f04-a6db-457f-a7a4-ceb50ec1fe6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-201976863-172.17.0.6-1595931709065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39807,DS-685f3f01-5561-4488-99d4-e5f8662ca01d,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-5cc9ee90-9fd1-4cbe-a3fb-fbb913af4ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-bddb88a5-3d18-4cb5-b0c9-bb43ea61e78d,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-9626dfc6-18ae-4a6f-a1ee-85bb88b268b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-4f4771a3-de0c-460f-ac28-30aead85dde5,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-7eec9584-3732-451d-9563-862f861c3141,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-43edb4b8-219a-45a0-b15d-dbab95959ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-506e1f04-a6db-457f-a7a4-ceb50ec1fe6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668043060-172.17.0.6-1595932578394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45596,DS-34296f05-bd84-467f-962a-b2c30f6f5f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-d17f410e-0c72-4fb6-b615-cf4e8bbc3456,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-6f31bdca-8a89-46ca-9820-e54ee1aa1e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-5a5b58c4-3890-4d29-9994-3f8150836066,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-758f8bad-4abc-4ad7-89cc-a3859a2594fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-d95256af-481e-471f-9056-d47c93c5c547,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-9de34ddb-19fd-4810-b7e3-365e39cdfe02,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-8d391fa0-62ea-42a7-8dc5-574d243fa6db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668043060-172.17.0.6-1595932578394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45596,DS-34296f05-bd84-467f-962a-b2c30f6f5f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-d17f410e-0c72-4fb6-b615-cf4e8bbc3456,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-6f31bdca-8a89-46ca-9820-e54ee1aa1e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-5a5b58c4-3890-4d29-9994-3f8150836066,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-758f8bad-4abc-4ad7-89cc-a3859a2594fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-d95256af-481e-471f-9056-d47c93c5c547,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-9de34ddb-19fd-4810-b7e3-365e39cdfe02,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-8d391fa0-62ea-42a7-8dc5-574d243fa6db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180295774-172.17.0.6-1595932657775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33280,DS-799410fd-2680-4a96-a328-a4eea8c6f230,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-8483a944-5cb0-4b94-8eeb-0c8769cb7781,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-c55ffd66-5d6c-40a3-a290-2b3cb53a844a,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-71adb45b-832e-42bd-af91-4184043660ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-60066010-a8c4-4044-819f-30de7acbe374,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-a71ec512-b131-4a88-b4d9-5f964f9bec5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-31acb027-ff73-4aff-a25c-e0ccf0b0cde1,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-90edbdfb-59c7-4a89-a5f3-846625b76eeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180295774-172.17.0.6-1595932657775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33280,DS-799410fd-2680-4a96-a328-a4eea8c6f230,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-8483a944-5cb0-4b94-8eeb-0c8769cb7781,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-c55ffd66-5d6c-40a3-a290-2b3cb53a844a,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-71adb45b-832e-42bd-af91-4184043660ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-60066010-a8c4-4044-819f-30de7acbe374,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-a71ec512-b131-4a88-b4d9-5f964f9bec5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-31acb027-ff73-4aff-a25c-e0ccf0b0cde1,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-90edbdfb-59c7-4a89-a5f3-846625b76eeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107132816-172.17.0.6-1595932698658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37896,DS-d229d94a-35c8-425b-98e0-3cd21902ad7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-927c923f-c812-427f-87f0-dc69c58661de,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-4f270dfd-d5fa-46d0-a5d3-ce40876e734e,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-46c7e4e2-e686-4802-a095-8cc50cfe683f,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-e3605308-2433-45d8-880b-ecc10c77f343,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-19fbfe04-8ecf-4898-876f-65949c0e80c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-bc1faeb6-9a68-4e37-989b-60669f0c2e02,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-42697c43-75e0-4dbb-8d79-21ba4a46621b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1107132816-172.17.0.6-1595932698658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37896,DS-d229d94a-35c8-425b-98e0-3cd21902ad7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-927c923f-c812-427f-87f0-dc69c58661de,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-4f270dfd-d5fa-46d0-a5d3-ce40876e734e,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-46c7e4e2-e686-4802-a095-8cc50cfe683f,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-e3605308-2433-45d8-880b-ecc10c77f343,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-19fbfe04-8ecf-4898-876f-65949c0e80c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-bc1faeb6-9a68-4e37-989b-60669f0c2e02,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-42697c43-75e0-4dbb-8d79-21ba4a46621b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225322412-172.17.0.6-1595933809702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46038,DS-dac46f25-032d-4005-90bc-ef6cb96b1d84,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-ce27cdbe-b74e-4a97-b053-f4ffccc87302,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-3a62e361-ba17-4dd7-8c17-07872ea6e407,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-ca77cc3e-d35b-4c83-b2f9-4128396f3efc,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-04ccdf22-8468-45c1-8a86-eea7a4c9454f,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-48b4e7d9-10a0-47bd-b41a-00bd3a80eccd,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-60cc7332-07b9-4043-9bf6-f89c5c391285,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-5d687635-ca52-4098-a6eb-49df1903d0e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225322412-172.17.0.6-1595933809702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46038,DS-dac46f25-032d-4005-90bc-ef6cb96b1d84,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-ce27cdbe-b74e-4a97-b053-f4ffccc87302,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-3a62e361-ba17-4dd7-8c17-07872ea6e407,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-ca77cc3e-d35b-4c83-b2f9-4128396f3efc,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-04ccdf22-8468-45c1-8a86-eea7a4c9454f,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-48b4e7d9-10a0-47bd-b41a-00bd3a80eccd,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-60cc7332-07b9-4043-9bf6-f89c5c391285,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-5d687635-ca52-4098-a6eb-49df1903d0e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5903
