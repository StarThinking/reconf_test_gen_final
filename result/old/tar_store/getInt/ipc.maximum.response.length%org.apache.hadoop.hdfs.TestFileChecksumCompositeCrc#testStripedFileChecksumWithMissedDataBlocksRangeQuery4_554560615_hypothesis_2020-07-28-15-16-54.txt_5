reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507872361-172.17.0.5-1595949504967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38213,DS-50f5f5fb-fd2e-4034-b3d0-c577b4d9cc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-ad9a7d11-22f2-418c-ab04-e542b1fc8ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-daae5fda-3b40-46e5-8486-70049a0857b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-f8ff5954-720b-41c3-ab1e-63fd5f9fb5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-5c6a3369-671b-486e-b151-530a56fa0871,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-9e32d95d-4158-4e86-8be0-9494fac95c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-69df92b5-4cc7-43cd-a533-761a1d235fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-dbaa1973-8a35-45fc-8062-a60330ec005a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507872361-172.17.0.5-1595949504967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38213,DS-50f5f5fb-fd2e-4034-b3d0-c577b4d9cc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-ad9a7d11-22f2-418c-ab04-e542b1fc8ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-daae5fda-3b40-46e5-8486-70049a0857b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-f8ff5954-720b-41c3-ab1e-63fd5f9fb5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-5c6a3369-671b-486e-b151-530a56fa0871,DISK], DatanodeInfoWithStorage[127.0.0.1:39632,DS-9e32d95d-4158-4e86-8be0-9494fac95c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-69df92b5-4cc7-43cd-a533-761a1d235fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-dbaa1973-8a35-45fc-8062-a60330ec005a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034036509-172.17.0.5-1595949680410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35172,DS-c69434a5-9cd7-4ad1-95ef-bde1fd7c312b,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-a8d6dc9b-9220-47c2-8ee8-47cfcd89ad48,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-2fddac7e-ba56-434d-87b3-0bc93cd00e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-9961a2c5-587f-4073-9d4a-6fc0a61f1f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-2de071fc-29bd-464a-b8bd-8302457825c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-0bf518e0-01ba-4a4d-b31e-8ad9cd3b94f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-13cc23fc-042d-4815-9e73-cb9acdf839b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-de790b38-831c-499a-ae3d-96111589ab58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034036509-172.17.0.5-1595949680410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35172,DS-c69434a5-9cd7-4ad1-95ef-bde1fd7c312b,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-a8d6dc9b-9220-47c2-8ee8-47cfcd89ad48,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-2fddac7e-ba56-434d-87b3-0bc93cd00e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-9961a2c5-587f-4073-9d4a-6fc0a61f1f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-2de071fc-29bd-464a-b8bd-8302457825c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-0bf518e0-01ba-4a4d-b31e-8ad9cd3b94f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-13cc23fc-042d-4815-9e73-cb9acdf839b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-de790b38-831c-499a-ae3d-96111589ab58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862208222-172.17.0.5-1595950029088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45723,DS-a1d6de9e-a957-40c0-a60f-2e32183f4368,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-4963fba1-62c7-4379-8b34-7510624c0947,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-d22cc075-2953-4855-87be-02664768190a,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-3660546f-95ed-493f-b949-8d446a91243d,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-428ca7f4-e106-4f69-9246-d1aeff779b73,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-7a56f46a-b708-4977-95a4-6f3789c22231,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-ae782748-4f3f-4b09-8c50-75dd5c11b221,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-d4ece8a0-11e0-43b1-8ff1-2245f51c5525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862208222-172.17.0.5-1595950029088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45723,DS-a1d6de9e-a957-40c0-a60f-2e32183f4368,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-4963fba1-62c7-4379-8b34-7510624c0947,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-d22cc075-2953-4855-87be-02664768190a,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-3660546f-95ed-493f-b949-8d446a91243d,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-428ca7f4-e106-4f69-9246-d1aeff779b73,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-7a56f46a-b708-4977-95a4-6f3789c22231,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-ae782748-4f3f-4b09-8c50-75dd5c11b221,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-d4ece8a0-11e0-43b1-8ff1-2245f51c5525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035581834-172.17.0.5-1595950312106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46074,DS-4ecdd948-a9a3-40ac-922b-d26445c5388f,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-b5fe950b-840c-4d2b-aeb9-0d1613bb8fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-ff2c5a64-644f-40e5-a445-2e62fdb64359,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-250c3a01-f539-4454-8f34-bc17f89051a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-feeca971-2980-41aa-9c2a-d2575a690313,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-93612f70-1549-4ff1-bc72-cbb3f5ab8c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-46ee0d5b-f44d-4f16-9231-e0f116648115,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-af7f2747-75ca-4c05-aaad-c62ac0ff331e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035581834-172.17.0.5-1595950312106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46074,DS-4ecdd948-a9a3-40ac-922b-d26445c5388f,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-b5fe950b-840c-4d2b-aeb9-0d1613bb8fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-ff2c5a64-644f-40e5-a445-2e62fdb64359,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-250c3a01-f539-4454-8f34-bc17f89051a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-feeca971-2980-41aa-9c2a-d2575a690313,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-93612f70-1549-4ff1-bc72-cbb3f5ab8c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-46ee0d5b-f44d-4f16-9231-e0f116648115,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-af7f2747-75ca-4c05-aaad-c62ac0ff331e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018486730-172.17.0.5-1595950348416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46577,DS-bf2d5329-f651-4db4-9fe8-c37b62db1b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-9ba4b956-1882-4301-9a96-a23e83805f84,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-f8bc83e0-24d7-480a-bfca-1b11119a58d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-23983dbf-7f08-40bd-ba2a-29f935718b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-f70076dc-8da3-492a-b51c-8fd86db58259,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-54a57318-a308-4935-b45d-28956c495b64,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-59553b4e-c2e6-41d5-a3b0-2bc5f099682b,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-bd7b4816-c5f1-4f49-b6fc-82169235a76e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018486730-172.17.0.5-1595950348416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46577,DS-bf2d5329-f651-4db4-9fe8-c37b62db1b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-9ba4b956-1882-4301-9a96-a23e83805f84,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-f8bc83e0-24d7-480a-bfca-1b11119a58d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-23983dbf-7f08-40bd-ba2a-29f935718b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-f70076dc-8da3-492a-b51c-8fd86db58259,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-54a57318-a308-4935-b45d-28956c495b64,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-59553b4e-c2e6-41d5-a3b0-2bc5f099682b,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-bd7b4816-c5f1-4f49-b6fc-82169235a76e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432888803-172.17.0.5-1595950382726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44976,DS-b264d36e-585b-421b-ab96-35e83715cb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-6d377e83-282e-497e-bf2d-cb2943525334,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-a0d2b74f-35ff-4d0f-8298-dbc9dacddbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-353851f8-aeda-473d-a88b-8b6e2df75ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-b68c8147-7858-402e-a33a-9b3fcebe54f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-eac4101e-4b34-446b-bc02-f088a61aa95f,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-39f9448e-f5e1-4f8a-9de6-3da5ec0a67f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-3251e21d-9324-4dab-869d-5062fce9d31d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432888803-172.17.0.5-1595950382726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44976,DS-b264d36e-585b-421b-ab96-35e83715cb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-6d377e83-282e-497e-bf2d-cb2943525334,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-a0d2b74f-35ff-4d0f-8298-dbc9dacddbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-353851f8-aeda-473d-a88b-8b6e2df75ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-b68c8147-7858-402e-a33a-9b3fcebe54f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-eac4101e-4b34-446b-bc02-f088a61aa95f,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-39f9448e-f5e1-4f8a-9de6-3da5ec0a67f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-3251e21d-9324-4dab-869d-5062fce9d31d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575993009-172.17.0.5-1595950808811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37908,DS-d6eb62bd-3ed0-4e86-ad27-5938739b0581,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-52ba4f21-396d-459c-8405-9d454a2b4519,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-2b73cb87-0aa9-423d-8872-26efa187aaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-149f2f19-2f22-409b-8ce5-6521844fd140,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-29d0bd1f-a84c-4664-ac0c-7d12da6fb70a,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-946e3b6a-5873-4417-9f25-7edc16026409,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-dc42357d-b447-448a-9ffb-f1ed1355668d,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-074e057a-49dd-4374-a7fa-725738dbcb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575993009-172.17.0.5-1595950808811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37908,DS-d6eb62bd-3ed0-4e86-ad27-5938739b0581,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-52ba4f21-396d-459c-8405-9d454a2b4519,DISK], DatanodeInfoWithStorage[127.0.0.1:34402,DS-2b73cb87-0aa9-423d-8872-26efa187aaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-149f2f19-2f22-409b-8ce5-6521844fd140,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-29d0bd1f-a84c-4664-ac0c-7d12da6fb70a,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-946e3b6a-5873-4417-9f25-7edc16026409,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-dc42357d-b447-448a-9ffb-f1ed1355668d,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-074e057a-49dd-4374-a7fa-725738dbcb44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15882032-172.17.0.5-1595951911125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-c749b015-4017-46dd-9a3f-950bb87af11d,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-cf36a7b7-0f15-485a-b0f8-2a59a271186c,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-7de80d44-0d4e-4726-bbb6-027135052958,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-2d26e6b3-5198-40d3-bd12-6ab05d654582,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-ff2d68d0-10d4-478f-9db7-fc87d2717bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-404e6841-c0cb-476d-92ec-8481b01e78ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-4f9ff972-25f3-4c03-9e0b-5f268b10bbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-8c3d48a1-df05-402c-aafe-cdb6ece65318,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15882032-172.17.0.5-1595951911125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-c749b015-4017-46dd-9a3f-950bb87af11d,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-cf36a7b7-0f15-485a-b0f8-2a59a271186c,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-7de80d44-0d4e-4726-bbb6-027135052958,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-2d26e6b3-5198-40d3-bd12-6ab05d654582,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-ff2d68d0-10d4-478f-9db7-fc87d2717bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-404e6841-c0cb-476d-92ec-8481b01e78ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-4f9ff972-25f3-4c03-9e0b-5f268b10bbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-8c3d48a1-df05-402c-aafe-cdb6ece65318,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27224455-172.17.0.5-1595953002959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45996,DS-386a71c7-0086-48d3-8338-eb7ea10cfff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-291df474-34d0-428c-afb0-5face17de3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-b5dc222d-4421-4fe9-ab23-04c0c11e3d09,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-91ba0059-134b-401f-99fe-3ebc55b6e2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-459074bb-7ace-4eb1-842a-522b3bf1308c,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-ba40abdd-bc7c-4894-8fcc-0747cf54b954,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-78ab6ead-0d2b-4cc2-bb5a-0a9f17ea9faf,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-75c0a5bc-f0de-4f03-ba39-ecc503642cf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27224455-172.17.0.5-1595953002959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45996,DS-386a71c7-0086-48d3-8338-eb7ea10cfff6,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-291df474-34d0-428c-afb0-5face17de3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-b5dc222d-4421-4fe9-ab23-04c0c11e3d09,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-91ba0059-134b-401f-99fe-3ebc55b6e2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-459074bb-7ace-4eb1-842a-522b3bf1308c,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-ba40abdd-bc7c-4894-8fcc-0747cf54b954,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-78ab6ead-0d2b-4cc2-bb5a-0a9f17ea9faf,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-75c0a5bc-f0de-4f03-ba39-ecc503642cf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380518201-172.17.0.5-1595953405643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44954,DS-147a9f40-5ef5-4728-a285-714f44a7e8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-220814c3-af07-4006-84f2-c7a8414cd54e,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-43a37886-4db1-4222-a5ba-6ef312050067,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-b44699c6-50d9-46ae-9640-1925c601d681,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-22905282-5bb3-4eca-979b-a9d84edd4424,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-c03cecb6-b0dc-4a63-9461-df6f94863e74,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-310bc87c-51af-48d3-bc9c-aeee6e65b214,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-eb916ad4-f9b2-429f-9b0a-a9fbe5588a21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380518201-172.17.0.5-1595953405643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44954,DS-147a9f40-5ef5-4728-a285-714f44a7e8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-220814c3-af07-4006-84f2-c7a8414cd54e,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-43a37886-4db1-4222-a5ba-6ef312050067,DISK], DatanodeInfoWithStorage[127.0.0.1:40442,DS-b44699c6-50d9-46ae-9640-1925c601d681,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-22905282-5bb3-4eca-979b-a9d84edd4424,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-c03cecb6-b0dc-4a63-9461-df6f94863e74,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-310bc87c-51af-48d3-bc9c-aeee6e65b214,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-eb916ad4-f9b2-429f-9b0a-a9fbe5588a21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180974477-172.17.0.5-1595953545423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-c459f8bf-d23c-436c-bad2-47f162879f90,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-7e8aa6d9-36e9-48ef-86c1-ccf779aa4e99,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-755ee6d1-45cb-4c42-8560-47eb0c9b5b76,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-b84d58e3-07a9-459f-b564-fde72a02df50,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-a623fdd8-f980-4d4d-8887-a7a3bfafe706,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-625a274c-3df8-4b7b-a802-ca948c21198e,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-2749fcd3-fe0e-4c64-8f0a-0f88fd16e663,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-65d56b95-f8fc-4bac-b784-dfbd721a2f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180974477-172.17.0.5-1595953545423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-c459f8bf-d23c-436c-bad2-47f162879f90,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-7e8aa6d9-36e9-48ef-86c1-ccf779aa4e99,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-755ee6d1-45cb-4c42-8560-47eb0c9b5b76,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-b84d58e3-07a9-459f-b564-fde72a02df50,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-a623fdd8-f980-4d4d-8887-a7a3bfafe706,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-625a274c-3df8-4b7b-a802-ca948c21198e,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-2749fcd3-fe0e-4c64-8f0a-0f88fd16e663,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-65d56b95-f8fc-4bac-b784-dfbd721a2f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130792279-172.17.0.5-1595953609733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45952,DS-684cb755-1888-4105-b904-ff3858d817d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-06da1f63-96d2-4809-9376-c7c03e7eb30c,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-bd6a1610-6c3e-491a-afd8-736f9660f6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-adba38d8-9244-44af-8dcb-425074425b22,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-823e80c2-54f4-4978-8409-dc4b63b07be1,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-af267267-2796-4033-b8a1-b6761e2168dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-35e86823-0724-49c2-af11-ef811726ca73,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-ac1bdfb8-eca2-47ba-baf0-2b8b31cf5878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130792279-172.17.0.5-1595953609733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45952,DS-684cb755-1888-4105-b904-ff3858d817d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-06da1f63-96d2-4809-9376-c7c03e7eb30c,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-bd6a1610-6c3e-491a-afd8-736f9660f6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-adba38d8-9244-44af-8dcb-425074425b22,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-823e80c2-54f4-4978-8409-dc4b63b07be1,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-af267267-2796-4033-b8a1-b6761e2168dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-35e86823-0724-49c2-af11-ef811726ca73,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-ac1bdfb8-eca2-47ba-baf0-2b8b31cf5878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554316795-172.17.0.5-1595953750599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41055,DS-713f344c-59b1-4420-8c7a-b9e673ca3354,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-a2547de4-d915-43c1-bcd6-72df06ea87c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-7b055f1f-65c3-4412-8ebf-16a3a1e34d81,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-e762cf08-2a8c-4338-9f68-77c5e71e18cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-68b3eae8-b26b-4afe-baa3-4efc0a1f7a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-d9270538-f43b-4bcd-a2bc-a56e57b0cfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-5cab7379-cfba-47e1-825a-f2d2ef473fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-47c90a94-89a4-4c4a-b164-20d2cd4c1684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-554316795-172.17.0.5-1595953750599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41055,DS-713f344c-59b1-4420-8c7a-b9e673ca3354,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-a2547de4-d915-43c1-bcd6-72df06ea87c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-7b055f1f-65c3-4412-8ebf-16a3a1e34d81,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-e762cf08-2a8c-4338-9f68-77c5e71e18cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-68b3eae8-b26b-4afe-baa3-4efc0a1f7a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-d9270538-f43b-4bcd-a2bc-a56e57b0cfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-5cab7379-cfba-47e1-825a-f2d2ef473fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-47c90a94-89a4-4c4a-b164-20d2cd4c1684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085366338-172.17.0.5-1595953921262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39475,DS-87088306-b287-4c64-8cd4-dd9c0f80cc18,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-d49de551-056e-4b2b-a42f-45a2b20608b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-1a8b0709-696a-4d5e-b256-37fa93cdf984,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-26cc85b9-625f-4e89-8d37-8ec0bb84ae7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-9732bd7d-7843-42ff-b0a1-31ac973d5e05,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-690760db-af64-41df-bb78-048e938b8a27,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-9949f7ab-78e7-43ef-b520-b0f08bdfce2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-023cc4ce-ec8d-452e-b531-f155a6e08610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085366338-172.17.0.5-1595953921262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39475,DS-87088306-b287-4c64-8cd4-dd9c0f80cc18,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-d49de551-056e-4b2b-a42f-45a2b20608b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-1a8b0709-696a-4d5e-b256-37fa93cdf984,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-26cc85b9-625f-4e89-8d37-8ec0bb84ae7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-9732bd7d-7843-42ff-b0a1-31ac973d5e05,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-690760db-af64-41df-bb78-048e938b8a27,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-9949f7ab-78e7-43ef-b520-b0f08bdfce2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-023cc4ce-ec8d-452e-b531-f155a6e08610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414516584-172.17.0.5-1595954019764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36713,DS-aecb3158-7b88-4df1-b661-99221f9127bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-5e005ff2-ce79-4da4-a19e-321c92971a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-1a817fab-cf5a-41dd-9a06-03d0c34346fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-b0137638-d82c-4af5-8fd6-e00eb78250c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-123f2ba9-4358-4af6-862e-6ae30ec4f9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-f3755db7-26b5-4840-a5c1-5c234e8884f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-23663203-ace3-4aaf-aa16-750daf78829f,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-04f261c2-0732-4ce7-b42f-b46e21e5b3f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414516584-172.17.0.5-1595954019764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36713,DS-aecb3158-7b88-4df1-b661-99221f9127bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-5e005ff2-ce79-4da4-a19e-321c92971a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-1a817fab-cf5a-41dd-9a06-03d0c34346fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-b0137638-d82c-4af5-8fd6-e00eb78250c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-123f2ba9-4358-4af6-862e-6ae30ec4f9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-f3755db7-26b5-4840-a5c1-5c234e8884f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-23663203-ace3-4aaf-aa16-750daf78829f,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-04f261c2-0732-4ce7-b42f-b46e21e5b3f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3326984-172.17.0.5-1595954092037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39501,DS-4d7eca82-49b1-4aac-a2a7-677ff283f77c,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-e53e8e43-537e-481a-ad2f-83db596d387a,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-70bdba53-98db-45cd-9fe0-65ff95b6ccab,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-f8066e9d-9b95-414f-82a7-24528c8114b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-563d9e36-4db0-44f7-989b-061591ba9e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-69473f80-e759-4085-af50-83a8bb7fa259,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-ec6e5bbf-1497-441c-b0d8-7cba3b23c021,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-5bcdb245-1e80-4e18-a091-746e4ac00e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3326984-172.17.0.5-1595954092037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39501,DS-4d7eca82-49b1-4aac-a2a7-677ff283f77c,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-e53e8e43-537e-481a-ad2f-83db596d387a,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-70bdba53-98db-45cd-9fe0-65ff95b6ccab,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-f8066e9d-9b95-414f-82a7-24528c8114b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-563d9e36-4db0-44f7-989b-061591ba9e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44397,DS-69473f80-e759-4085-af50-83a8bb7fa259,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-ec6e5bbf-1497-441c-b0d8-7cba3b23c021,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-5bcdb245-1e80-4e18-a091-746e4ac00e74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 16777216
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621591415-172.17.0.5-1595954299952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44148,DS-b358aac2-d770-4928-a2c1-e0ff4075cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-df3e9206-afa4-4d72-9769-9554d5250fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-0d349537-6f2d-417c-aacc-08714c2cbd20,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-4c2c1a09-fe2b-4c59-b6cf-40aad7bf6c63,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-fd6e896e-b4d1-4ecc-821e-34413f97d0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-b4666a05-7318-4c49-9c46-2c126e7cc915,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-37bb1ed3-3f78-458e-959c-cda4d7b6d2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-f4e0adbf-a25e-4318-af70-366eab7f0542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621591415-172.17.0.5-1595954299952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44148,DS-b358aac2-d770-4928-a2c1-e0ff4075cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-df3e9206-afa4-4d72-9769-9554d5250fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-0d349537-6f2d-417c-aacc-08714c2cbd20,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-4c2c1a09-fe2b-4c59-b6cf-40aad7bf6c63,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-fd6e896e-b4d1-4ecc-821e-34413f97d0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-b4666a05-7318-4c49-9c46-2c126e7cc915,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-37bb1ed3-3f78-458e-959c-cda4d7b6d2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-f4e0adbf-a25e-4318-af70-366eab7f0542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5138
