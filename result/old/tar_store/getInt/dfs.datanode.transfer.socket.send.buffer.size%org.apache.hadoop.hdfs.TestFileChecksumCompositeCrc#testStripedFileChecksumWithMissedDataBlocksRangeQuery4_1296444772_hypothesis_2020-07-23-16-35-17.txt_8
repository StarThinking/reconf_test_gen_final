reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208465270-172.17.0.18-1595522259039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37698,DS-eefdc10d-6ae0-4260-b463-a3a48edf3c21,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-d2ffbf59-452d-46b8-8908-be404ade54bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-4aa8a3fe-6350-4e36-9715-13d6db4b78f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-8416e667-af65-46f7-adef-55c75c11746b,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-e80fb774-35ff-4f4b-a5fc-71193eadf550,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-6edbfe90-5a66-49b8-94b4-e4a398c53748,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-1af94fa0-dab7-4ea6-a330-124c8ac413a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-d9ed9a70-c079-47d2-8426-1c01aa321738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208465270-172.17.0.18-1595522259039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37698,DS-eefdc10d-6ae0-4260-b463-a3a48edf3c21,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-d2ffbf59-452d-46b8-8908-be404ade54bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-4aa8a3fe-6350-4e36-9715-13d6db4b78f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-8416e667-af65-46f7-adef-55c75c11746b,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-e80fb774-35ff-4f4b-a5fc-71193eadf550,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-6edbfe90-5a66-49b8-94b4-e4a398c53748,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-1af94fa0-dab7-4ea6-a330-124c8ac413a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-d9ed9a70-c079-47d2-8426-1c01aa321738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836752578-172.17.0.18-1595522415395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46830,DS-6d2a518c-3007-4e0e-aa05-20e3ffb0fb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-24b956c5-5631-4abc-a7ec-7aedc19a9e76,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-07c36f2b-f6d9-4ea2-acd4-727d4c992d56,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-875bde2f-5ece-453b-9803-85787372b26e,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-6fecfd49-1b04-4c03-8fd4-a1fb19ef53e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-749b5936-a729-45c8-80ac-106c57577e62,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-859bedac-add4-41ae-8128-42d85e6491c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-36f6f3a0-9ac4-43fe-9473-6954efe96e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836752578-172.17.0.18-1595522415395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46830,DS-6d2a518c-3007-4e0e-aa05-20e3ffb0fb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-24b956c5-5631-4abc-a7ec-7aedc19a9e76,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-07c36f2b-f6d9-4ea2-acd4-727d4c992d56,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-875bde2f-5ece-453b-9803-85787372b26e,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-6fecfd49-1b04-4c03-8fd4-a1fb19ef53e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-749b5936-a729-45c8-80ac-106c57577e62,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-859bedac-add4-41ae-8128-42d85e6491c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-36f6f3a0-9ac4-43fe-9473-6954efe96e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379963120-172.17.0.18-1595522573209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41086,DS-13026a1b-bbc8-4f23-bc82-c4fe6ff10a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-18a45662-0d77-4f58-bbae-2807c6a7c842,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-afebf200-a43f-45c4-912a-bf32980db4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-196733de-97ac-4454-b27b-1da1ffa201aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-f129ced8-a44d-4876-8c03-7e0348982f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-9c41f7f4-7455-47b2-9dfc-a50d80a31c59,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-050cebe2-02d8-4e18-bf55-cc2468b23b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-68591b40-c026-4e9c-a18b-f05b682b49c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379963120-172.17.0.18-1595522573209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41086,DS-13026a1b-bbc8-4f23-bc82-c4fe6ff10a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-18a45662-0d77-4f58-bbae-2807c6a7c842,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-afebf200-a43f-45c4-912a-bf32980db4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-196733de-97ac-4454-b27b-1da1ffa201aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-f129ced8-a44d-4876-8c03-7e0348982f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-9c41f7f4-7455-47b2-9dfc-a50d80a31c59,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-050cebe2-02d8-4e18-bf55-cc2468b23b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-68591b40-c026-4e9c-a18b-f05b682b49c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70435533-172.17.0.18-1595522954076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39178,DS-e0023950-9572-46a4-902d-92f8af2a05e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-1dab1025-1db8-4634-8f28-08449eab8b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-e1f75395-e7df-490b-a93b-8ba3df3f12b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-7f8641d9-dffb-4107-9670-ce15c66e957f,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-9f70e2cf-f509-40cc-9435-1a1dfc86b718,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-b6e5edc3-eaaa-47ea-a682-ac1d673d319b,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-ca4bd061-995c-4c64-9e95-4cbda662029e,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-a1f358c2-9804-4e8f-a477-29b81d6f4a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70435533-172.17.0.18-1595522954076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39178,DS-e0023950-9572-46a4-902d-92f8af2a05e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-1dab1025-1db8-4634-8f28-08449eab8b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-e1f75395-e7df-490b-a93b-8ba3df3f12b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-7f8641d9-dffb-4107-9670-ce15c66e957f,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-9f70e2cf-f509-40cc-9435-1a1dfc86b718,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-b6e5edc3-eaaa-47ea-a682-ac1d673d319b,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-ca4bd061-995c-4c64-9e95-4cbda662029e,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-a1f358c2-9804-4e8f-a477-29b81d6f4a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652126119-172.17.0.18-1595523101766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41570,DS-e867a450-dee8-47e4-a43d-092663b0ad18,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-c66c42c9-66e2-45cd-9a12-de2cfd413f72,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-3841e1a4-e046-4959-ab09-8104df2c2dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-3ffd96c6-e6c6-4709-9a23-d8d66343dc54,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-39e9acc9-553f-42fd-83cb-a4e51ce92118,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-08babdce-785f-4c6f-a228-bfcfb099bfad,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-ece3c844-fdd7-46ff-ab81-2424c77af8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-4eb36bf4-582f-4afd-89dd-5abb651418a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652126119-172.17.0.18-1595523101766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41570,DS-e867a450-dee8-47e4-a43d-092663b0ad18,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-c66c42c9-66e2-45cd-9a12-de2cfd413f72,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-3841e1a4-e046-4959-ab09-8104df2c2dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-3ffd96c6-e6c6-4709-9a23-d8d66343dc54,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-39e9acc9-553f-42fd-83cb-a4e51ce92118,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-08babdce-785f-4c6f-a228-bfcfb099bfad,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-ece3c844-fdd7-46ff-ab81-2424c77af8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-4eb36bf4-582f-4afd-89dd-5abb651418a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067946467-172.17.0.18-1595523178121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37384,DS-00678b6b-58b2-461f-9ff0-40f590629067,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-e34980aa-179f-47da-924c-31396d806532,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-ca4aa9c3-1c79-43b2-8050-9e835943fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-1c431852-bf03-4ea0-b1ac-9f5d88496b05,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-c150adfd-f404-483e-a9d1-57e76d1d1e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-bc72cc5e-332f-43fa-9612-a4006bd2e1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-084a5239-c1a1-442d-8ffe-95ccc8c8dde5,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-6f066741-226f-4221-aada-a4bae7b7f312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067946467-172.17.0.18-1595523178121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37384,DS-00678b6b-58b2-461f-9ff0-40f590629067,DISK], DatanodeInfoWithStorage[127.0.0.1:38460,DS-e34980aa-179f-47da-924c-31396d806532,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-ca4aa9c3-1c79-43b2-8050-9e835943fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-1c431852-bf03-4ea0-b1ac-9f5d88496b05,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-c150adfd-f404-483e-a9d1-57e76d1d1e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-bc72cc5e-332f-43fa-9612-a4006bd2e1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-084a5239-c1a1-442d-8ffe-95ccc8c8dde5,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-6f066741-226f-4221-aada-a4bae7b7f312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432245217-172.17.0.18-1595523209621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40824,DS-c3aa9430-6076-48d7-9b76-e852c7f81d97,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-957c2e83-dbd8-4a5e-b1f6-4a1f077039a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-3b399c1c-1b36-42e0-8e77-8625f85f8de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-2187ef38-0b3a-4333-8cad-555a0c7e0f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-bef34102-fc68-4629-bd8c-669e7d88529b,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-2fed7838-f8d7-46e3-b9ba-85ced9004293,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-3cb773d6-5a25-4603-a400-96c63406ce2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-60d3e705-88f5-4d01-aa59-36f46ef6864e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432245217-172.17.0.18-1595523209621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40824,DS-c3aa9430-6076-48d7-9b76-e852c7f81d97,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-957c2e83-dbd8-4a5e-b1f6-4a1f077039a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-3b399c1c-1b36-42e0-8e77-8625f85f8de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-2187ef38-0b3a-4333-8cad-555a0c7e0f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-bef34102-fc68-4629-bd8c-669e7d88529b,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-2fed7838-f8d7-46e3-b9ba-85ced9004293,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-3cb773d6-5a25-4603-a400-96c63406ce2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-60d3e705-88f5-4d01-aa59-36f46ef6864e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364660202-172.17.0.18-1595523706101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42842,DS-39e71a31-30da-4129-ae0c-bae50a0381fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-02641e73-5559-4776-b73e-8e69aafb966e,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-8388a9b6-e8c7-4483-99ac-fc9581b2ac81,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-106dcd74-92b7-410c-8ae8-8d961ccc4180,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-39acaf93-87e1-4750-8439-eebdf65c051c,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-2cf71673-213f-4f1a-81b8-5c777d7f75f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-40a0988b-581d-4765-83f1-57132c23890d,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-636a2427-28c2-4fca-b012-e72fa89ec0ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364660202-172.17.0.18-1595523706101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42842,DS-39e71a31-30da-4129-ae0c-bae50a0381fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-02641e73-5559-4776-b73e-8e69aafb966e,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-8388a9b6-e8c7-4483-99ac-fc9581b2ac81,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-106dcd74-92b7-410c-8ae8-8d961ccc4180,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-39acaf93-87e1-4750-8439-eebdf65c051c,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-2cf71673-213f-4f1a-81b8-5c777d7f75f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-40a0988b-581d-4765-83f1-57132c23890d,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-636a2427-28c2-4fca-b012-e72fa89ec0ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741705802-172.17.0.18-1595525175489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37130,DS-235868bb-bb89-4b30-9886-b635e094a59f,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-a7ae0934-c133-4cb5-a52b-a2881605c339,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-43e0f4da-e07b-470c-854f-fb44407a0985,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-28e317d5-d136-4db4-af22-fc1ecb017a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-c0378f17-96f9-4a5b-9e7f-8ec245f54f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-686e5f88-0c23-40d8-afb8-7fc3acfc6379,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-8464f971-5fde-4057-8c8d-93940d8dd0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-ec610e1b-8251-49b5-8df6-945a358a64d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741705802-172.17.0.18-1595525175489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37130,DS-235868bb-bb89-4b30-9886-b635e094a59f,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-a7ae0934-c133-4cb5-a52b-a2881605c339,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-43e0f4da-e07b-470c-854f-fb44407a0985,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-28e317d5-d136-4db4-af22-fc1ecb017a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-c0378f17-96f9-4a5b-9e7f-8ec245f54f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-686e5f88-0c23-40d8-afb8-7fc3acfc6379,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-8464f971-5fde-4057-8c8d-93940d8dd0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-ec610e1b-8251-49b5-8df6-945a358a64d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656392767-172.17.0.18-1595525416390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40322,DS-334d9895-a724-4e4b-a449-07169a2ce738,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-9f17535b-1cc1-4501-a94a-740a830f6108,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-af58be02-076a-4f52-9a57-20f7c9f51bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-e214f784-63c6-48b3-b49f-b2479dcef240,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-cf429336-27c7-4794-a9e1-46566df1be14,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-1a4ebe1a-d9bd-449b-9e2c-c68c237bfac1,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-d7cd07ae-8421-4176-9a73-1abf97b611de,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-3826097f-bbf2-44e2-ae31-d49bb72b24e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656392767-172.17.0.18-1595525416390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40322,DS-334d9895-a724-4e4b-a449-07169a2ce738,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-9f17535b-1cc1-4501-a94a-740a830f6108,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-af58be02-076a-4f52-9a57-20f7c9f51bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-e214f784-63c6-48b3-b49f-b2479dcef240,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-cf429336-27c7-4794-a9e1-46566df1be14,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-1a4ebe1a-d9bd-449b-9e2c-c68c237bfac1,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-d7cd07ae-8421-4176-9a73-1abf97b611de,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-3826097f-bbf2-44e2-ae31-d49bb72b24e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742555327-172.17.0.18-1595525492629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45818,DS-cac41fd3-8d0e-4fe4-b963-5f8688838bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-4bb96509-2e8f-4ae1-9ed7-81229941eb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-e341a958-01fe-4b3d-8b49-1b73df6eb469,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-eed7475a-8cd3-4393-90f4-69a83af0470d,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-85e7ef73-3ecf-4053-b088-bccef8e09a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-9e111904-8c36-48a8-8791-e2faf6de77f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-d9b6b1a8-b1da-4926-8861-80c49f6490de,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-226573a7-a68f-47b7-b7dd-75e176c9860b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742555327-172.17.0.18-1595525492629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45818,DS-cac41fd3-8d0e-4fe4-b963-5f8688838bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-4bb96509-2e8f-4ae1-9ed7-81229941eb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-e341a958-01fe-4b3d-8b49-1b73df6eb469,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-eed7475a-8cd3-4393-90f4-69a83af0470d,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-85e7ef73-3ecf-4053-b088-bccef8e09a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-9e111904-8c36-48a8-8791-e2faf6de77f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44268,DS-d9b6b1a8-b1da-4926-8861-80c49f6490de,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-226573a7-a68f-47b7-b7dd-75e176c9860b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370405416-172.17.0.18-1595525956301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45560,DS-71480e13-8538-4177-8a5e-3588499d9278,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-0b168dcc-bc2f-4372-9b39-20d5add5b005,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-7f38277d-6bd3-4b72-9592-d5e562ea0236,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-5aef4c43-28c2-4ced-9c86-141137a1a427,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-7fee5817-6821-4cfe-9e25-9a4715e10415,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-f30eb6b6-75b0-42f7-b526-a4c572f92820,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-a9e71852-62a8-4cca-8200-f1919f1dcd83,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-0e7800dc-2bf5-4ed8-97d1-c02040c2f5d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370405416-172.17.0.18-1595525956301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45560,DS-71480e13-8538-4177-8a5e-3588499d9278,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-0b168dcc-bc2f-4372-9b39-20d5add5b005,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-7f38277d-6bd3-4b72-9592-d5e562ea0236,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-5aef4c43-28c2-4ced-9c86-141137a1a427,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-7fee5817-6821-4cfe-9e25-9a4715e10415,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-f30eb6b6-75b0-42f7-b526-a4c572f92820,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-a9e71852-62a8-4cca-8200-f1919f1dcd83,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-0e7800dc-2bf5-4ed8-97d1-c02040c2f5d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245305944-172.17.0.18-1595526122232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46103,DS-2aa58e27-e04e-4cd7-99b3-0f4b50814b59,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-2ebb8162-1c82-4cf1-94be-b6b575d6d6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-3cba48fd-a4c6-4f79-98d4-64792116c380,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-eaedd5cc-aada-4572-95f7-95e673a24585,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-41338a7e-d181-4f0b-96f6-f71954c9d372,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-dec25162-845b-4ad9-9fc1-f5d9b3520a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-03244100-79aa-44d6-bba4-dcd9a1cb3228,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-6b6b1488-ccc4-44b2-8140-ab593bc5c502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245305944-172.17.0.18-1595526122232:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46103,DS-2aa58e27-e04e-4cd7-99b3-0f4b50814b59,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-2ebb8162-1c82-4cf1-94be-b6b575d6d6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-3cba48fd-a4c6-4f79-98d4-64792116c380,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-eaedd5cc-aada-4572-95f7-95e673a24585,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-41338a7e-d181-4f0b-96f6-f71954c9d372,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-dec25162-845b-4ad9-9fc1-f5d9b3520a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-03244100-79aa-44d6-bba4-dcd9a1cb3228,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-6b6b1488-ccc4-44b2-8140-ab593bc5c502,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365648512-172.17.0.18-1595526394842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45520,DS-42f3dda9-eeed-4e87-8e25-b64e1606e052,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-0a74f6d9-d73c-4965-8ff4-9bc0b99c291b,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-a63d6882-2f7f-4a54-bbbe-502bcd08ee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-334e292c-057f-4edd-90d6-e7d5a55583fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-b2f0c514-f8bd-48ee-87eb-70b9614ff502,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-a7828845-1359-4792-800c-61761fcc2f14,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-53fba069-464d-49da-ae0d-79eb6dbe8ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-c4122b32-64b4-46fd-9aa5-597900ccb7bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365648512-172.17.0.18-1595526394842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45520,DS-42f3dda9-eeed-4e87-8e25-b64e1606e052,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-0a74f6d9-d73c-4965-8ff4-9bc0b99c291b,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-a63d6882-2f7f-4a54-bbbe-502bcd08ee3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-334e292c-057f-4edd-90d6-e7d5a55583fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-b2f0c514-f8bd-48ee-87eb-70b9614ff502,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-a7828845-1359-4792-800c-61761fcc2f14,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-53fba069-464d-49da-ae0d-79eb6dbe8ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-c4122b32-64b4-46fd-9aa5-597900ccb7bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702990749-172.17.0.18-1595526823146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37933,DS-03ed2496-c6d3-4bb8-bc40-f3d711494ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-e8bc6292-d2bf-43c4-a58f-e38869361c97,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-35d1b904-dbb5-44c0-92f3-c670ff9a116d,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-9839689f-99f2-4b06-a46a-ace3971ed9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-f0e9c5e0-5d5f-4bcc-ad78-6ac9aa5c22ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-9eaf640d-7c79-4d22-86e7-2c406bb549b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-8707c08c-e4c0-4e11-ae88-3e39732159b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-0ea42d2d-7851-4be1-a6e5-4ec9112bdbff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702990749-172.17.0.18-1595526823146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37933,DS-03ed2496-c6d3-4bb8-bc40-f3d711494ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-e8bc6292-d2bf-43c4-a58f-e38869361c97,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-35d1b904-dbb5-44c0-92f3-c670ff9a116d,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-9839689f-99f2-4b06-a46a-ace3971ed9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-f0e9c5e0-5d5f-4bcc-ad78-6ac9aa5c22ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-9eaf640d-7c79-4d22-86e7-2c406bb549b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-8707c08c-e4c0-4e11-ae88-3e39732159b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-0ea42d2d-7851-4be1-a6e5-4ec9112bdbff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745921589-172.17.0.18-1595527137783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38703,DS-b8ceced5-eb8e-4f78-8de4-0788691abf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-472d6475-6c72-43bc-930c-1b3a3633ab2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-0cd709a1-aad1-41d2-bbbe-499933cac34d,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-122df68e-6138-4228-918a-59a00f22d272,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-a294e0e1-c297-47e7-b4fb-b7335d8cdf15,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-84d22285-ac1b-4519-8030-6ad8e2ea4089,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-94f86bee-e1d2-4472-a632-a0c9e431fca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-74495e3d-6323-43ad-941c-5ed3ffd6e7c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745921589-172.17.0.18-1595527137783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38703,DS-b8ceced5-eb8e-4f78-8de4-0788691abf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-472d6475-6c72-43bc-930c-1b3a3633ab2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-0cd709a1-aad1-41d2-bbbe-499933cac34d,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-122df68e-6138-4228-918a-59a00f22d272,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-a294e0e1-c297-47e7-b4fb-b7335d8cdf15,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-84d22285-ac1b-4519-8030-6ad8e2ea4089,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-94f86bee-e1d2-4472-a632-a0c9e431fca7,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-74495e3d-6323-43ad-941c-5ed3ffd6e7c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196922748-172.17.0.18-1595527888071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43437,DS-2f67bf87-daa2-4d51-80a9-d9935448d862,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-18fab0eb-9880-4fa7-9c8e-806b75fad7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-c92c7ec7-19d2-49bc-aa46-bb6db018b15e,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-f787f703-ddb8-4bcd-bbd0-380f4dcaa09f,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-324fd18f-446b-4fb7-a7ca-6cb08119b723,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-f9af5cff-35c8-402c-ae35-89f3d57c6589,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-a6e415e6-e69c-45c5-a911-8aedcc2783c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-3ca38f20-75e7-47cf-af09-f765aceef792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196922748-172.17.0.18-1595527888071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43437,DS-2f67bf87-daa2-4d51-80a9-d9935448d862,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-18fab0eb-9880-4fa7-9c8e-806b75fad7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-c92c7ec7-19d2-49bc-aa46-bb6db018b15e,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-f787f703-ddb8-4bcd-bbd0-380f4dcaa09f,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-324fd18f-446b-4fb7-a7ca-6cb08119b723,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-f9af5cff-35c8-402c-ae35-89f3d57c6589,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-a6e415e6-e69c-45c5-a911-8aedcc2783c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-3ca38f20-75e7-47cf-af09-f765aceef792,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5873
