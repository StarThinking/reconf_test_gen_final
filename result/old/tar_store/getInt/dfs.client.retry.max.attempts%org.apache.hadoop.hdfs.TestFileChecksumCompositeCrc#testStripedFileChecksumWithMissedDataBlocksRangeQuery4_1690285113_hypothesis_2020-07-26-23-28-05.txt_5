reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708913217-172.17.0.8-1595806391881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37431,DS-0d479fb1-6c35-47fa-b8a3-67b306eab180,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-629510d4-d5b8-4ab6-8023-b1def21e6579,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-0ebf71c3-d24a-4394-90c7-d6837d701fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-a751cf86-709a-4945-91ff-09c99b5e7449,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-6aa19ba7-1560-46db-87d4-0d7ed8bed1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-bd95581b-cfd2-4344-9e42-9bc26fb856b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-23809de6-9e6a-4aff-84a0-2d9472b3e904,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-d2c92e7b-ddc5-4a19-9bc9-e9c640a58f03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708913217-172.17.0.8-1595806391881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37431,DS-0d479fb1-6c35-47fa-b8a3-67b306eab180,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-629510d4-d5b8-4ab6-8023-b1def21e6579,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-0ebf71c3-d24a-4394-90c7-d6837d701fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-a751cf86-709a-4945-91ff-09c99b5e7449,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-6aa19ba7-1560-46db-87d4-0d7ed8bed1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-bd95581b-cfd2-4344-9e42-9bc26fb856b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-23809de6-9e6a-4aff-84a0-2d9472b3e904,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-d2c92e7b-ddc5-4a19-9bc9-e9c640a58f03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388683213-172.17.0.8-1595806564891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32896,DS-94a0d757-9c64-47e1-a538-008c4246decd,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-c374aa63-2a49-4466-8fe7-ae95c2778c26,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-7ef4ce5c-4eb9-4dba-9fa1-d7db7c4d2ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-fa502228-f78e-4f66-894f-4ff54049ecdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-a008fb4b-034e-4736-a682-cf7b77ee5d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-f5daab4b-b3df-4602-8e4c-061eef89ac99,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-c18c515b-7abf-4a40-8a1c-5a6f3de297ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-80504bb2-2d7e-4f9f-8455-5e854d0b2437,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388683213-172.17.0.8-1595806564891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32896,DS-94a0d757-9c64-47e1-a538-008c4246decd,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-c374aa63-2a49-4466-8fe7-ae95c2778c26,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-7ef4ce5c-4eb9-4dba-9fa1-d7db7c4d2ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-fa502228-f78e-4f66-894f-4ff54049ecdf,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-a008fb4b-034e-4736-a682-cf7b77ee5d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-f5daab4b-b3df-4602-8e4c-061eef89ac99,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-c18c515b-7abf-4a40-8a1c-5a6f3de297ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-80504bb2-2d7e-4f9f-8455-5e854d0b2437,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86669268-172.17.0.8-1595806638042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37399,DS-a40bdaa8-f8ea-4632-9614-8dd5fde2f0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-5f233c59-4b64-4024-8636-3b7d2953e68c,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-5a1c6375-a1d3-419e-bfd8-456f44299e49,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-ab5b3082-aa60-4f0a-9a9a-e51c07aecf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-b75e7bcd-5aa1-49ec-9053-4b175a519f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-41ea0a8e-096c-430f-9a76-22ca48d7377f,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-5b0280dd-a981-4a73-a226-bc86636f4399,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-b3c9fbf5-6c0f-422a-b654-886882f5ae9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86669268-172.17.0.8-1595806638042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37399,DS-a40bdaa8-f8ea-4632-9614-8dd5fde2f0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-5f233c59-4b64-4024-8636-3b7d2953e68c,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-5a1c6375-a1d3-419e-bfd8-456f44299e49,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-ab5b3082-aa60-4f0a-9a9a-e51c07aecf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-b75e7bcd-5aa1-49ec-9053-4b175a519f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-41ea0a8e-096c-430f-9a76-22ca48d7377f,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-5b0280dd-a981-4a73-a226-bc86636f4399,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-b3c9fbf5-6c0f-422a-b654-886882f5ae9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060718977-172.17.0.8-1595807248718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36729,DS-173b1f87-28ba-43a6-b90b-21e58be2adc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-507c5f54-0198-4ef6-b7db-3aaccad67fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-21300ce3-c6b2-44c9-abe8-dac57280fde3,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-be541322-56ea-47d4-856e-b582c516ca20,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-82092e8f-8e7f-4332-baeb-e080426ce26b,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-65d69827-52ab-40a1-8267-15a5cea5000b,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-29a1f332-dc9f-4b12-b461-37ae489add43,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-823474e3-4f0a-4a10-920d-3f2b85283897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060718977-172.17.0.8-1595807248718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36729,DS-173b1f87-28ba-43a6-b90b-21e58be2adc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-507c5f54-0198-4ef6-b7db-3aaccad67fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-21300ce3-c6b2-44c9-abe8-dac57280fde3,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-be541322-56ea-47d4-856e-b582c516ca20,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-82092e8f-8e7f-4332-baeb-e080426ce26b,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-65d69827-52ab-40a1-8267-15a5cea5000b,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-29a1f332-dc9f-4b12-b461-37ae489add43,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-823474e3-4f0a-4a10-920d-3f2b85283897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442170648-172.17.0.8-1595807507722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45213,DS-2be16105-873b-4781-af36-e84d57f58d96,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-cbcdfbd6-7eb3-4d30-be81-b5e0de79d025,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-eb9922ac-645f-44c0-9aa4-4987061005c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-d2d4a70c-2824-4fd4-b603-8a3c5be4e415,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-06847e95-49b1-483a-a7d0-48f704227be2,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-4ab5e35b-0fbe-486b-80a4-f124baf7239f,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-55be24f8-8031-4e2a-8347-3bba86d5321f,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-5e24605e-16fb-496a-b9d6-4293e5902ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442170648-172.17.0.8-1595807507722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45213,DS-2be16105-873b-4781-af36-e84d57f58d96,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-cbcdfbd6-7eb3-4d30-be81-b5e0de79d025,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-eb9922ac-645f-44c0-9aa4-4987061005c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-d2d4a70c-2824-4fd4-b603-8a3c5be4e415,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-06847e95-49b1-483a-a7d0-48f704227be2,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-4ab5e35b-0fbe-486b-80a4-f124baf7239f,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-55be24f8-8031-4e2a-8347-3bba86d5321f,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-5e24605e-16fb-496a-b9d6-4293e5902ad5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724750788-172.17.0.8-1595807882945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40251,DS-cffc121a-f5b5-4cc1-95dc-3c795f45d41a,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-24b3d5c8-5a51-40c8-ba8d-0cd0741cf023,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-6a414078-8432-4559-a74a-201cc72c3a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-00e5cc11-00b0-4436-bd03-a0f806a9c736,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-fcb60d39-9b22-439f-b684-90248051d90c,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-510841d1-d921-4a36-a709-7d05c952a489,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-eb468e5a-a238-4a7e-b4d6-e0e3787bf171,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-5ba3ad28-c89d-4269-8d42-f159ba777595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724750788-172.17.0.8-1595807882945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40251,DS-cffc121a-f5b5-4cc1-95dc-3c795f45d41a,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-24b3d5c8-5a51-40c8-ba8d-0cd0741cf023,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-6a414078-8432-4559-a74a-201cc72c3a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-00e5cc11-00b0-4436-bd03-a0f806a9c736,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-fcb60d39-9b22-439f-b684-90248051d90c,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-510841d1-d921-4a36-a709-7d05c952a489,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-eb468e5a-a238-4a7e-b4d6-e0e3787bf171,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-5ba3ad28-c89d-4269-8d42-f159ba777595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390556861-172.17.0.8-1595808198339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40505,DS-3f3b23df-d3f8-487c-b168-5b9e7453d396,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-c8743732-9139-4611-9c5f-c4b02bafb10a,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-ff30d729-6e82-4189-8a8c-3dc618e30d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-2e4e6a03-1bee-444b-955e-8f8775e54f36,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-9577b257-a57c-4584-9f58-a8adfe02d494,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-9a2b016d-5374-4cfb-8421-af0aab214407,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-03999057-86a7-4dc2-8f03-c5a1d7449236,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-cddf4db4-251c-4985-baf6-b2608fdfcef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390556861-172.17.0.8-1595808198339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40505,DS-3f3b23df-d3f8-487c-b168-5b9e7453d396,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-c8743732-9139-4611-9c5f-c4b02bafb10a,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-ff30d729-6e82-4189-8a8c-3dc618e30d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-2e4e6a03-1bee-444b-955e-8f8775e54f36,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-9577b257-a57c-4584-9f58-a8adfe02d494,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-9a2b016d-5374-4cfb-8421-af0aab214407,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-03999057-86a7-4dc2-8f03-c5a1d7449236,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-cddf4db4-251c-4985-baf6-b2608fdfcef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571053539-172.17.0.8-1595808918165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36731,DS-f8d11484-8bb8-4240-8018-87318b2a16b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-7b90ed0b-ccaa-4fb3-a0f3-5c18fb52343c,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-a3d0d705-905b-4955-8eb7-3a223bd1f7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-6b3f41da-cd05-41f6-88b4-af4f1df3a81b,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-74ef1e3d-d117-432b-a014-3e495c194fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-5a0bfd89-d7f0-4edf-b779-8c666fc70dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-1ef7ae06-24ac-4cc5-991a-6b887d4645ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-d8bb49a7-051c-4fda-af53-e140df544b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571053539-172.17.0.8-1595808918165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36731,DS-f8d11484-8bb8-4240-8018-87318b2a16b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-7b90ed0b-ccaa-4fb3-a0f3-5c18fb52343c,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-a3d0d705-905b-4955-8eb7-3a223bd1f7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-6b3f41da-cd05-41f6-88b4-af4f1df3a81b,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-74ef1e3d-d117-432b-a014-3e495c194fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-5a0bfd89-d7f0-4edf-b779-8c666fc70dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-1ef7ae06-24ac-4cc5-991a-6b887d4645ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-d8bb49a7-051c-4fda-af53-e140df544b1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249661951-172.17.0.8-1595808984412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38949,DS-323c5c51-62c9-4770-ad2e-de26f8757dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-cf9da097-408f-4c39-813e-9d2c2ea722a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-756305c1-059d-4ffb-be43-1fae2d6ecc69,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-49703848-00e1-497e-8c04-7fec15e0d673,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-6372d6c6-a0f2-4e1d-b59d-9867d4bd52b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-6d9a65d8-5471-4ddd-bd51-20af86d819ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-1185c165-ae04-4ac2-961f-cb2449211b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-83d6645b-8bd6-4280-a100-f1bd09baf257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249661951-172.17.0.8-1595808984412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38949,DS-323c5c51-62c9-4770-ad2e-de26f8757dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-cf9da097-408f-4c39-813e-9d2c2ea722a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-756305c1-059d-4ffb-be43-1fae2d6ecc69,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-49703848-00e1-497e-8c04-7fec15e0d673,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-6372d6c6-a0f2-4e1d-b59d-9867d4bd52b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-6d9a65d8-5471-4ddd-bd51-20af86d819ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-1185c165-ae04-4ac2-961f-cb2449211b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-83d6645b-8bd6-4280-a100-f1bd09baf257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300073996-172.17.0.8-1595809435038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32898,DS-e501e3a2-bd9c-4b74-af3a-3c6a93da2960,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-8ce58c5d-4398-4783-9148-92a8daebb1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-892690e4-e23e-4580-b834-290845ddb430,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-b916c725-2551-4a8d-98ef-a0ac9150741d,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-68756735-4d3e-4c87-ac25-01d66d3f6e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-3c7610f4-59a3-4192-866a-1594f826b7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-b0758231-0229-4ca9-98a9-a69f31379092,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-1e6a4792-0ff9-457b-9950-dc817483b241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300073996-172.17.0.8-1595809435038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32898,DS-e501e3a2-bd9c-4b74-af3a-3c6a93da2960,DISK], DatanodeInfoWithStorage[127.0.0.1:43093,DS-8ce58c5d-4398-4783-9148-92a8daebb1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-892690e4-e23e-4580-b834-290845ddb430,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-b916c725-2551-4a8d-98ef-a0ac9150741d,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-68756735-4d3e-4c87-ac25-01d66d3f6e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-3c7610f4-59a3-4192-866a-1594f826b7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-b0758231-0229-4ca9-98a9-a69f31379092,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-1e6a4792-0ff9-457b-9950-dc817483b241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460643271-172.17.0.8-1595810116948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36075,DS-852dac1e-446a-4a63-9e6d-5e67cd8a488b,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-5032599c-fb00-4667-9b62-f913c0be0381,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-8c6c20dd-9cc1-4420-b907-f0b62b309a70,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-9738bf24-2381-468f-835a-e696a8833e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-897d4cc7-ca2d-402f-8886-c394abee1950,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-fc7a06e1-f735-4f8a-9c70-a17b0a8f2310,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-58502bc0-a9bf-4bbd-9efb-1da99bee3e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-7467248a-e3b0-4686-be47-9461c3aed872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1460643271-172.17.0.8-1595810116948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36075,DS-852dac1e-446a-4a63-9e6d-5e67cd8a488b,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-5032599c-fb00-4667-9b62-f913c0be0381,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-8c6c20dd-9cc1-4420-b907-f0b62b309a70,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-9738bf24-2381-468f-835a-e696a8833e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-897d4cc7-ca2d-402f-8886-c394abee1950,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-fc7a06e1-f735-4f8a-9c70-a17b0a8f2310,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-58502bc0-a9bf-4bbd-9efb-1da99bee3e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-7467248a-e3b0-4686-be47-9461c3aed872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136013500-172.17.0.8-1595810216342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-a3263767-e542-4f3b-b5aa-396b80825e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-084c01c5-75d2-49b4-a2b9-af090e80dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-dd718cbf-a888-46a6-ab16-b937b5d0bded,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-5a983f96-5304-46ce-bad1-71cfbc9fac94,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-11020874-18bc-44fa-8ea8-ed9761110ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-4b869e93-d55e-4b32-a008-6ed86c34ad73,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-b24e032d-b7fd-4edf-8874-31b293a33262,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-e4a077dc-9bfe-4202-a46b-6060224c3461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136013500-172.17.0.8-1595810216342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-a3263767-e542-4f3b-b5aa-396b80825e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-084c01c5-75d2-49b4-a2b9-af090e80dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-dd718cbf-a888-46a6-ab16-b937b5d0bded,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-5a983f96-5304-46ce-bad1-71cfbc9fac94,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-11020874-18bc-44fa-8ea8-ed9761110ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-4b869e93-d55e-4b32-a008-6ed86c34ad73,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-b24e032d-b7fd-4edf-8874-31b293a33262,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-e4a077dc-9bfe-4202-a46b-6060224c3461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200685667-172.17.0.8-1595810486095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34207,DS-0541afc7-b69f-459c-817e-967f6365dbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-9506842e-d740-49b9-8d03-86fa7611143f,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-43f16c8e-01c6-46d8-be47-5b94326a0dae,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-f98adbcf-f515-44f9-992e-835e092e0562,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-c58d3f9f-ae2c-4740-b448-91c99a7fc48e,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-f266d836-a75e-4988-9d93-7750deadd937,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-e2f88323-38a8-4a77-a1dd-d211228dbfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-91fc0016-d544-441f-85a3-64e4366f033a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200685667-172.17.0.8-1595810486095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34207,DS-0541afc7-b69f-459c-817e-967f6365dbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-9506842e-d740-49b9-8d03-86fa7611143f,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-43f16c8e-01c6-46d8-be47-5b94326a0dae,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-f98adbcf-f515-44f9-992e-835e092e0562,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-c58d3f9f-ae2c-4740-b448-91c99a7fc48e,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-f266d836-a75e-4988-9d93-7750deadd937,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-e2f88323-38a8-4a77-a1dd-d211228dbfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-91fc0016-d544-441f-85a3-64e4366f033a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57763786-172.17.0.8-1595811139186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-065358b3-dbee-4ab4-a02e-dcb111bbd972,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-10d44dbb-21cc-4e99-8ccf-04e87e602762,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-55be389d-578c-434b-abcd-e4f662bb5fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-4a14b2cc-2390-488a-b637-e23b8645c1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-8d9b8ba4-ca72-4f3e-a5dd-60b2f6d76496,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-36deab8d-9bc9-40c3-803f-ac3ec1a34a46,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-f37f2761-6ee3-47e8-9ab8-3f9383240814,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-ac5e93d6-52ab-4195-afe6-5b39671e4d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57763786-172.17.0.8-1595811139186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33478,DS-065358b3-dbee-4ab4-a02e-dcb111bbd972,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-10d44dbb-21cc-4e99-8ccf-04e87e602762,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-55be389d-578c-434b-abcd-e4f662bb5fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-4a14b2cc-2390-488a-b637-e23b8645c1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-8d9b8ba4-ca72-4f3e-a5dd-60b2f6d76496,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-36deab8d-9bc9-40c3-803f-ac3ec1a34a46,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-f37f2761-6ee3-47e8-9ab8-3f9383240814,DISK], DatanodeInfoWithStorage[127.0.0.1:44709,DS-ac5e93d6-52ab-4195-afe6-5b39671e4d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5306
