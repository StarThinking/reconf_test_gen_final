reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219737592-172.17.0.21-1595964387694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43418,DS-6009cc5d-8269-436f-9126-df3fe4856770,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-422a6792-b992-490e-a84b-d5d8d65d46e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-f8f789ea-5c7d-491c-81e0-5ea9468e1d87,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-d5229fea-08ae-4881-9160-ee3434da089d,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-cb2442f3-4e15-4875-be2a-baf7c872533f,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-0f1107ea-5a4d-4501-9d66-f2f24ffb53a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-de4505c6-e780-4051-8e89-199f0fa01921,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-f4f741d1-3eea-4afe-8579-422d48614884,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219737592-172.17.0.21-1595964387694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43418,DS-6009cc5d-8269-436f-9126-df3fe4856770,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-422a6792-b992-490e-a84b-d5d8d65d46e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-f8f789ea-5c7d-491c-81e0-5ea9468e1d87,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-d5229fea-08ae-4881-9160-ee3434da089d,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-cb2442f3-4e15-4875-be2a-baf7c872533f,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-0f1107ea-5a4d-4501-9d66-f2f24ffb53a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-de4505c6-e780-4051-8e89-199f0fa01921,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-f4f741d1-3eea-4afe-8579-422d48614884,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583296198-172.17.0.21-1595964424664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46526,DS-076fa596-631c-43a2-aac3-bcf1d69a652b,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-a75cb238-c774-4164-8dff-014de501cacd,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-1ef8e02b-a277-4b21-a584-20060cb856b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-eef23cd3-36a2-4efa-b14b-3b5f6cbe7d29,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-a051ad3b-7717-4aa9-bdb4-345f061c7856,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-ef55920b-8291-4bcb-9aab-7c370151187c,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-51f0ccee-1b18-4a2b-8292-8332c8206078,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-251d2cc3-2d5a-42c2-9d83-378e7185b061,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-583296198-172.17.0.21-1595964424664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46526,DS-076fa596-631c-43a2-aac3-bcf1d69a652b,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-a75cb238-c774-4164-8dff-014de501cacd,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-1ef8e02b-a277-4b21-a584-20060cb856b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-eef23cd3-36a2-4efa-b14b-3b5f6cbe7d29,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-a051ad3b-7717-4aa9-bdb4-345f061c7856,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-ef55920b-8291-4bcb-9aab-7c370151187c,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-51f0ccee-1b18-4a2b-8292-8332c8206078,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-251d2cc3-2d5a-42c2-9d83-378e7185b061,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581908815-172.17.0.21-1595964578630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37779,DS-ecbb5a59-fb69-44da-af65-b971ecdba64f,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-dd3760ed-322e-43ab-b5d8-6a6208b0f926,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-84759488-35d1-45e7-819b-699224818e66,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-bc8a00a7-9851-41f0-b4c0-1901b6057953,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-2c3c163e-1ba3-4982-8dc3-7b605469fb73,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-995b5add-1da3-4b0e-8871-83751822f054,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-cf7b0807-90f3-44a7-8399-9abbd6b1ebbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-59da3b50-04ce-4c42-9501-b5f4feef66eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581908815-172.17.0.21-1595964578630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37779,DS-ecbb5a59-fb69-44da-af65-b971ecdba64f,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-dd3760ed-322e-43ab-b5d8-6a6208b0f926,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-84759488-35d1-45e7-819b-699224818e66,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-bc8a00a7-9851-41f0-b4c0-1901b6057953,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-2c3c163e-1ba3-4982-8dc3-7b605469fb73,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-995b5add-1da3-4b0e-8871-83751822f054,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-cf7b0807-90f3-44a7-8399-9abbd6b1ebbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-59da3b50-04ce-4c42-9501-b5f4feef66eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191048358-172.17.0.21-1595964772158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35660,DS-5095db1e-61bf-4848-8b4a-cac645e6b9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-534d6c0b-9ce9-4942-ae8a-291304a771b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-3c062be0-e59b-4333-9d2c-b9ddb43d4b64,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-6df8d242-9d67-4134-b430-cfe9e78871f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-46bfb68e-e2de-49e7-ab32-e3b015f9aff0,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-c976de98-4d7b-42f2-a399-5e78c98b4b02,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-cb0584bb-85dd-4230-b7d5-300470027930,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-e7cf8b40-2959-43e9-b597-2124e16890c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-191048358-172.17.0.21-1595964772158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35660,DS-5095db1e-61bf-4848-8b4a-cac645e6b9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-534d6c0b-9ce9-4942-ae8a-291304a771b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-3c062be0-e59b-4333-9d2c-b9ddb43d4b64,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-6df8d242-9d67-4134-b430-cfe9e78871f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34692,DS-46bfb68e-e2de-49e7-ab32-e3b015f9aff0,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-c976de98-4d7b-42f2-a399-5e78c98b4b02,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-cb0584bb-85dd-4230-b7d5-300470027930,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-e7cf8b40-2959-43e9-b597-2124e16890c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917646601-172.17.0.21-1595964872822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42797,DS-d65cae53-372a-42a4-90c3-246b64dc6828,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-8a0f4e1f-4df7-42af-88c1-a0b9d7da7ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-9e00ac10-aa53-4b89-a875-8a6b6a99365c,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-e873a256-cd74-41cf-b3d1-8fe6cdf00e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-89ef4c02-3f80-47a8-a272-aa1bac64e828,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-685fafac-bef9-4538-bb58-d7fcbe41937d,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-8e189705-a56b-4ddb-b017-bf42bcf735f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-5cca6ab0-3e9a-4947-a3a5-3e8e8a8caa8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917646601-172.17.0.21-1595964872822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42797,DS-d65cae53-372a-42a4-90c3-246b64dc6828,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-8a0f4e1f-4df7-42af-88c1-a0b9d7da7ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-9e00ac10-aa53-4b89-a875-8a6b6a99365c,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-e873a256-cd74-41cf-b3d1-8fe6cdf00e4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-89ef4c02-3f80-47a8-a272-aa1bac64e828,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-685fafac-bef9-4538-bb58-d7fcbe41937d,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-8e189705-a56b-4ddb-b017-bf42bcf735f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-5cca6ab0-3e9a-4947-a3a5-3e8e8a8caa8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320456291-172.17.0.21-1595965170715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33977,DS-fbdcac42-d810-44e6-a648-0e137e933478,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-28088141-635a-4504-879e-7fa8ca878f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-82d80c8b-38af-48e5-9bcb-46237c905013,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-2c4482c3-28c2-4b07-9f17-dad7ec589332,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-8db3e219-6e80-4b35-b33f-2b53ec1e0acb,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-7bba146d-c46f-49da-9ebc-fef884c1aa18,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-01190f01-547f-440b-9cbe-338c77fc03b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-394573d9-2f83-4b21-bf7d-51a101561572,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320456291-172.17.0.21-1595965170715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33977,DS-fbdcac42-d810-44e6-a648-0e137e933478,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-28088141-635a-4504-879e-7fa8ca878f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-82d80c8b-38af-48e5-9bcb-46237c905013,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-2c4482c3-28c2-4b07-9f17-dad7ec589332,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-8db3e219-6e80-4b35-b33f-2b53ec1e0acb,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-7bba146d-c46f-49da-9ebc-fef884c1aa18,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-01190f01-547f-440b-9cbe-338c77fc03b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-394573d9-2f83-4b21-bf7d-51a101561572,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1075628303-172.17.0.21-1595965446952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41072,DS-a8b433f7-5b82-42d5-ae92-f42cc311dd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-ada080e7-4034-46e3-9b6c-749a8a981ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-9e2fe755-1cd9-498c-bad6-b6530109cb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-f7d2ea95-74ca-4d2d-8b3f-d0772a4f6028,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-bc3a4e7c-cbb0-4744-b225-83cec6150ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-b7ddbfc9-5d8e-48ef-a32e-bd36e069f537,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-35ad77dc-a756-4be6-a48e-9b0e72bb1430,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-b19e55bd-70bb-497d-8270-13542b7c4c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1075628303-172.17.0.21-1595965446952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41072,DS-a8b433f7-5b82-42d5-ae92-f42cc311dd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-ada080e7-4034-46e3-9b6c-749a8a981ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-9e2fe755-1cd9-498c-bad6-b6530109cb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-f7d2ea95-74ca-4d2d-8b3f-d0772a4f6028,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-bc3a4e7c-cbb0-4744-b225-83cec6150ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-b7ddbfc9-5d8e-48ef-a32e-bd36e069f537,DISK], DatanodeInfoWithStorage[127.0.0.1:35848,DS-35ad77dc-a756-4be6-a48e-9b0e72bb1430,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-b19e55bd-70bb-497d-8270-13542b7c4c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577398400-172.17.0.21-1595965481135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36563,DS-1ab80995-3af3-468d-a26d-35f0420d9fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-24fddb85-1cf7-4ba3-9186-82cce4eb8f85,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-cab7aec9-0fcb-49f5-9c83-8ccf0acda2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-650fa0e4-33ad-4c73-a314-79cfa48e9d48,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-db989fb3-c132-4718-9aae-21a4c91340a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-a5f76b18-78e7-4873-b1c5-a43eb04c7de0,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-d64fdd82-58f6-4913-b15c-8a9f11632642,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-af2423a4-4a7f-4de8-abc8-160cc78b44ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577398400-172.17.0.21-1595965481135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36563,DS-1ab80995-3af3-468d-a26d-35f0420d9fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-24fddb85-1cf7-4ba3-9186-82cce4eb8f85,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-cab7aec9-0fcb-49f5-9c83-8ccf0acda2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-650fa0e4-33ad-4c73-a314-79cfa48e9d48,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-db989fb3-c132-4718-9aae-21a4c91340a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-a5f76b18-78e7-4873-b1c5-a43eb04c7de0,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-d64fdd82-58f6-4913-b15c-8a9f11632642,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-af2423a4-4a7f-4de8-abc8-160cc78b44ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182812685-172.17.0.21-1595965755562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42568,DS-68cba66f-5959-4c57-9de0-01f59b31c0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-52f7e121-f9bd-40c8-bb72-f5537fa04d11,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-a3678ccd-777d-4b26-a30b-a0ea56f0a308,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-ed50cb54-f7e5-40cb-a260-bde3d9a1d875,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-2b06bd8e-499d-440c-82e4-9f73d4d160d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-a5fe46f3-3724-4171-85df-0b70a0131274,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-8cd941bc-8aea-4f90-9f98-6a44db972cde,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-e40a6667-5bb1-4b00-8be2-c38f19e6cb63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182812685-172.17.0.21-1595965755562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42568,DS-68cba66f-5959-4c57-9de0-01f59b31c0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-52f7e121-f9bd-40c8-bb72-f5537fa04d11,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-a3678ccd-777d-4b26-a30b-a0ea56f0a308,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-ed50cb54-f7e5-40cb-a260-bde3d9a1d875,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-2b06bd8e-499d-440c-82e4-9f73d4d160d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-a5fe46f3-3724-4171-85df-0b70a0131274,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-8cd941bc-8aea-4f90-9f98-6a44db972cde,DISK], DatanodeInfoWithStorage[127.0.0.1:40387,DS-e40a6667-5bb1-4b00-8be2-c38f19e6cb63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1854645782-172.17.0.21-1595965935569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42990,DS-ac8f5ef1-59e7-4066-ac16-4d615da6fc32,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-2eb888f3-8c4c-4740-b936-bf81982d8c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-ed1368eb-a553-4d64-9ce4-ad531f0b3a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-8eb078b7-0a81-47f6-83bd-03ea82d264c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-3bbf70de-6d6c-408f-91e2-6a31fbdd448e,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-b8486f13-8a1b-4013-8c67-4393dcf42a01,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-d3f08b69-433a-47b9-bd1b-4e7225a1d66f,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-5e3ac863-b21d-4114-afc6-68469e3c1b8f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1854645782-172.17.0.21-1595965935569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42990,DS-ac8f5ef1-59e7-4066-ac16-4d615da6fc32,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-2eb888f3-8c4c-4740-b936-bf81982d8c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-ed1368eb-a553-4d64-9ce4-ad531f0b3a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-8eb078b7-0a81-47f6-83bd-03ea82d264c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-3bbf70de-6d6c-408f-91e2-6a31fbdd448e,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-b8486f13-8a1b-4013-8c67-4393dcf42a01,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-d3f08b69-433a-47b9-bd1b-4e7225a1d66f,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-5e3ac863-b21d-4114-afc6-68469e3c1b8f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124174651-172.17.0.21-1595966535182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34602,DS-50d45d96-dc0f-4ae7-8d52-a616cd60be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-1f8b51d1-ae3f-4daa-baa6-8a436724de0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-b3171e10-b149-45d1-8262-7cbffa3567d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-4fb7ecc3-f7f5-4a43-bf07-d7b012e5a8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-dd504ce0-f39f-453b-b569-34ead5fa187e,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-8d74540e-5db6-435f-b780-b2499051f3de,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-f498a4b4-6341-4a5a-9060-e7f6a3db4171,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-fff3aef3-e323-4bb2-ae4c-b96966a2f0e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124174651-172.17.0.21-1595966535182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34602,DS-50d45d96-dc0f-4ae7-8d52-a616cd60be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-1f8b51d1-ae3f-4daa-baa6-8a436724de0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-b3171e10-b149-45d1-8262-7cbffa3567d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-4fb7ecc3-f7f5-4a43-bf07-d7b012e5a8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-dd504ce0-f39f-453b-b569-34ead5fa187e,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-8d74540e-5db6-435f-b780-b2499051f3de,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-f498a4b4-6341-4a5a-9060-e7f6a3db4171,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-fff3aef3-e323-4bb2-ae4c-b96966a2f0e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152680541-172.17.0.21-1595966607788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37838,DS-767ef9b8-651f-417f-bc87-5d3549a63a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-9daf8fa1-b5bf-4082-aba6-1071343d255f,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-8444de11-f20a-4b22-a794-6a97325cd223,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-6bd5f2d9-13a9-4dca-b97e-ac20166c037c,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-85cf4e06-80b0-4614-b0a0-80dc10e4e8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-bf681092-df6a-4404-ae15-16319d122b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-756cb2e1-8188-45e0-839c-e2e999292037,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-30218e0c-faa2-41e7-be31-28ec274cfd93,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152680541-172.17.0.21-1595966607788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37838,DS-767ef9b8-651f-417f-bc87-5d3549a63a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-9daf8fa1-b5bf-4082-aba6-1071343d255f,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-8444de11-f20a-4b22-a794-6a97325cd223,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-6bd5f2d9-13a9-4dca-b97e-ac20166c037c,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-85cf4e06-80b0-4614-b0a0-80dc10e4e8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-bf681092-df6a-4404-ae15-16319d122b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-756cb2e1-8188-45e0-839c-e2e999292037,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-30218e0c-faa2-41e7-be31-28ec274cfd93,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509141900-172.17.0.21-1595966912673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38733,DS-9ac47d90-1edb-4aab-88c1-30b2db61a986,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-18eba07d-80df-4a77-ba70-cd1c0098430a,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-e5d44a54-3bee-458b-9e2b-78e2ab94e0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-6598f694-69e6-482a-ad7b-bc753642953a,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-9c18c728-d59c-4fbe-8eb3-d05e68e76462,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-ef007c39-4854-48fe-83c4-1faa653b8ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-39a08f0d-ef99-4207-81a3-69c85050180d,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-a10980e6-1899-4672-aba0-4fc4b7e38ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509141900-172.17.0.21-1595966912673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38733,DS-9ac47d90-1edb-4aab-88c1-30b2db61a986,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-18eba07d-80df-4a77-ba70-cd1c0098430a,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-e5d44a54-3bee-458b-9e2b-78e2ab94e0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-6598f694-69e6-482a-ad7b-bc753642953a,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-9c18c728-d59c-4fbe-8eb3-d05e68e76462,DISK], DatanodeInfoWithStorage[127.0.0.1:37423,DS-ef007c39-4854-48fe-83c4-1faa653b8ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-39a08f0d-ef99-4207-81a3-69c85050180d,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-a10980e6-1899-4672-aba0-4fc4b7e38ede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963822729-172.17.0.21-1595966950099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36355,DS-6a5aa31d-5915-48de-ac45-8128433de878,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-a83f9039-f3fd-4b3a-a362-0a9fb1e514ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-a5af6215-bf34-4599-a254-659f7dd36b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-5428f923-2ed1-452b-a0f8-85666eb61de4,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-4bb5c734-1151-4d92-8a63-6260501ad94f,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-40cea2ee-d561-400b-b88f-9e62673e0164,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-1ec748da-065e-48a3-bb48-a1e02bb52983,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-8df556ff-071b-45c3-8114-7cd67b1741f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963822729-172.17.0.21-1595966950099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36355,DS-6a5aa31d-5915-48de-ac45-8128433de878,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-a83f9039-f3fd-4b3a-a362-0a9fb1e514ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-a5af6215-bf34-4599-a254-659f7dd36b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-5428f923-2ed1-452b-a0f8-85666eb61de4,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-4bb5c734-1151-4d92-8a63-6260501ad94f,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-40cea2ee-d561-400b-b88f-9e62673e0164,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-1ec748da-065e-48a3-bb48-a1e02bb52983,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-8df556ff-071b-45c3-8114-7cd67b1741f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090642526-172.17.0.21-1595967152180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39321,DS-8e9fe43e-0037-4a78-b9dd-0477c4124ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-8625a723-ad1c-4a03-a726-8156ee693d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-22712d21-060a-4226-98a3-34517fad6e07,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-924b56a7-d874-4bea-91ad-5f7ea4ee86f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-9d8fec59-97f4-4d74-9232-158a1fd164ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-b5d1dfdd-7934-4960-acb5-260a58e1ccaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-b9bd340b-9f36-401d-9338-dec8edc2bffd,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-1dc6c077-d71e-413a-b7e3-a090717bfc91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090642526-172.17.0.21-1595967152180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39321,DS-8e9fe43e-0037-4a78-b9dd-0477c4124ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-8625a723-ad1c-4a03-a726-8156ee693d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-22712d21-060a-4226-98a3-34517fad6e07,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-924b56a7-d874-4bea-91ad-5f7ea4ee86f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42574,DS-9d8fec59-97f4-4d74-9232-158a1fd164ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-b5d1dfdd-7934-4960-acb5-260a58e1ccaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-b9bd340b-9f36-401d-9338-dec8edc2bffd,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-1dc6c077-d71e-413a-b7e3-a090717bfc91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404995814-172.17.0.21-1595967261094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-28491b10-611f-476f-b479-f8bb7f2e633b,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-dbc38319-7cd8-40d9-8c22-3c43278005b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-a2a25e9f-18de-4c15-b21e-5e16b1dc7dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-6068b1ee-8da4-425c-aa43-a08251db6c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-af48213e-3d33-4ac3-a163-73b7dc693e01,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-999d097c-c07c-46d1-a2a4-5939e29c077c,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-75149955-3bdf-4a6c-9b68-c06534a5529e,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-3af5c6bf-7c10-421c-8c88-33d60bb3613d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404995814-172.17.0.21-1595967261094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-28491b10-611f-476f-b479-f8bb7f2e633b,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-dbc38319-7cd8-40d9-8c22-3c43278005b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-a2a25e9f-18de-4c15-b21e-5e16b1dc7dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-6068b1ee-8da4-425c-aa43-a08251db6c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-af48213e-3d33-4ac3-a163-73b7dc693e01,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-999d097c-c07c-46d1-a2a4-5939e29c077c,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-75149955-3bdf-4a6c-9b68-c06534a5529e,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-3af5c6bf-7c10-421c-8c88-33d60bb3613d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243716597-172.17.0.21-1595967439371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35271,DS-71cd9cf1-411f-4e01-a632-5edb89b46d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-69946b74-feb8-427f-9ed2-59883c09ca6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-2e7d2984-7f76-4a3d-af2a-5da94b0fc3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-0a443a7d-c425-4203-a550-53fe91560737,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-72366ba4-09df-42cc-9128-87250aee6ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-a814991d-211a-4469-ae1d-bb0c201aee6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-3791aea6-4fd0-4c9a-ab1f-fe08b007054d,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-9465e8ae-c64e-4ef3-9d4d-86ee211f3bb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243716597-172.17.0.21-1595967439371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35271,DS-71cd9cf1-411f-4e01-a632-5edb89b46d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-69946b74-feb8-427f-9ed2-59883c09ca6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-2e7d2984-7f76-4a3d-af2a-5da94b0fc3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-0a443a7d-c425-4203-a550-53fe91560737,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-72366ba4-09df-42cc-9128-87250aee6ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-a814991d-211a-4469-ae1d-bb0c201aee6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-3791aea6-4fd0-4c9a-ab1f-fe08b007054d,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-9465e8ae-c64e-4ef3-9d4d-86ee211f3bb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108484138-172.17.0.21-1595968090841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46410,DS-f1d1efa5-10e5-475e-a68a-0746ca4b44c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-f084fdc2-9652-40b1-8848-28b53373ae48,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-ebd47f1d-8a10-4e9b-92f1-f377a0b556fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-f2d602b4-a9cd-490d-bad4-fad0d56deba9,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-a3732da4-24b9-46b0-ba72-cc37a894048b,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-5ae104d4-fb73-4234-841e-f83e36cb60ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-1f8511e8-1def-43cc-b04d-5004094f9428,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-c1ea83d4-039f-44e4-8fc3-8d19e7456da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108484138-172.17.0.21-1595968090841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46410,DS-f1d1efa5-10e5-475e-a68a-0746ca4b44c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-f084fdc2-9652-40b1-8848-28b53373ae48,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-ebd47f1d-8a10-4e9b-92f1-f377a0b556fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-f2d602b4-a9cd-490d-bad4-fad0d56deba9,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-a3732da4-24b9-46b0-ba72-cc37a894048b,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-5ae104d4-fb73-4234-841e-f83e36cb60ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-1f8511e8-1def-43cc-b04d-5004094f9428,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-c1ea83d4-039f-44e4-8fc3-8d19e7456da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980086765-172.17.0.21-1595968123788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34494,DS-68928b8b-c024-4cfb-bd80-1b4bf6bd7ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-5493fc61-00a3-40c0-b99b-9406263f4695,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-bc6a5574-3153-4612-a090-d58a012df2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-d8e9c032-8cf6-4b82-8d76-dfd8f00df82b,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-eace09da-2f40-4a78-8ba6-3b9d6b5544c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-475bc3e5-1a50-4b1c-8b81-1b3afd4646a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-8c223ceb-c015-47b4-84b4-89073fc9fca4,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-8a0a0655-3b3a-4a67-888a-3fdf8967342f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980086765-172.17.0.21-1595968123788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34494,DS-68928b8b-c024-4cfb-bd80-1b4bf6bd7ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-5493fc61-00a3-40c0-b99b-9406263f4695,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-bc6a5574-3153-4612-a090-d58a012df2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-d8e9c032-8cf6-4b82-8d76-dfd8f00df82b,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-eace09da-2f40-4a78-8ba6-3b9d6b5544c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34780,DS-475bc3e5-1a50-4b1c-8b81-1b3afd4646a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-8c223ceb-c015-47b4-84b4-89073fc9fca4,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-8a0a0655-3b3a-4a67-888a-3fdf8967342f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116122601-172.17.0.21-1595968486952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42262,DS-dccdb6d8-5bb2-46ed-8e74-1fb63294d321,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-2db3e8fc-9e63-4f5a-a417-cd50333c2eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-b5c2f766-4713-404b-895e-6ec39cb88c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-a5a39c57-40af-4f75-ac12-a4c4c698213e,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-d4533963-fa85-4e20-a59a-cb3413bc07ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-6c7f2324-e8c2-40af-b753-ef638e0cfd69,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-6c077910-3e42-434c-a2d4-3ef90e266c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-35b38606-eed9-44f1-936b-a7a76147e390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116122601-172.17.0.21-1595968486952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42262,DS-dccdb6d8-5bb2-46ed-8e74-1fb63294d321,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-2db3e8fc-9e63-4f5a-a417-cd50333c2eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-b5c2f766-4713-404b-895e-6ec39cb88c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-a5a39c57-40af-4f75-ac12-a4c4c698213e,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-d4533963-fa85-4e20-a59a-cb3413bc07ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-6c7f2324-e8c2-40af-b753-ef638e0cfd69,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-6c077910-3e42-434c-a2d4-3ef90e266c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-35b38606-eed9-44f1-936b-a7a76147e390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775246413-172.17.0.21-1595968850342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41011,DS-ad1fe2fc-c792-47af-a649-99f93cff7ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-e9d8271c-25db-4a50-894c-ae4c144e5eab,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-fb2ba261-5631-4d76-b37d-d998a6067ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-cbcb9ffb-1f67-4650-8e5a-01cd5a2ac8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-2777e993-6839-4890-8139-97d6afbf4af6,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-5dbf9a6f-4dd4-4cac-9ddd-eb994ba61c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-178f2819-bd8d-42c0-97b7-faa8b9d5dca1,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-e0fc7b81-4a31-4727-8e27-af93d735a030,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775246413-172.17.0.21-1595968850342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41011,DS-ad1fe2fc-c792-47af-a649-99f93cff7ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-e9d8271c-25db-4a50-894c-ae4c144e5eab,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-fb2ba261-5631-4d76-b37d-d998a6067ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-cbcb9ffb-1f67-4650-8e5a-01cd5a2ac8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-2777e993-6839-4890-8139-97d6afbf4af6,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-5dbf9a6f-4dd4-4cac-9ddd-eb994ba61c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-178f2819-bd8d-42c0-97b7-faa8b9d5dca1,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-e0fc7b81-4a31-4727-8e27-af93d735a030,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489918503-172.17.0.21-1595968881494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39307,DS-4040356c-7ce7-4a71-b401-53b5df60f645,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-7515ed09-074d-4031-ba97-c56124793dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-2834bc78-f27d-4a84-ba42-79fcd478ce7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-0365e338-973c-4997-892a-2c5365a21f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-fabb71bf-9c3d-49d3-adcf-3837264cd1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-0d174dea-9ef9-4135-8883-ed96f9b7f315,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-3dd3ec4d-84d0-4a7b-828d-ee253c4c7113,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-26d58d7b-2500-4814-b1bb-f3982fb47560,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489918503-172.17.0.21-1595968881494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39307,DS-4040356c-7ce7-4a71-b401-53b5df60f645,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-7515ed09-074d-4031-ba97-c56124793dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-2834bc78-f27d-4a84-ba42-79fcd478ce7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-0365e338-973c-4997-892a-2c5365a21f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-fabb71bf-9c3d-49d3-adcf-3837264cd1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-0d174dea-9ef9-4135-8883-ed96f9b7f315,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-3dd3ec4d-84d0-4a7b-828d-ee253c4c7113,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-26d58d7b-2500-4814-b1bb-f3982fb47560,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436679255-172.17.0.21-1595969173151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41926,DS-09a06f41-5fd4-4759-9888-ce17fd9b40c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-3c9a3fa3-64f0-46e3-ab6f-71ac392a6a00,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-da7bbb73-2f20-4faf-8146-e9af23f6586d,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-05cc54e5-cbe3-4a6e-b1cf-5b1bd555974a,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-d83ee809-4fcf-44d6-a16d-1dea911f4447,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-7bf4cb4e-9a78-400a-9a2e-b9f764e22f35,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-1653de37-562d-4eba-94e4-d81b9c0549ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-abb7f849-fb93-4f6c-93dd-4e80b4e0086f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436679255-172.17.0.21-1595969173151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41926,DS-09a06f41-5fd4-4759-9888-ce17fd9b40c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-3c9a3fa3-64f0-46e3-ab6f-71ac392a6a00,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-da7bbb73-2f20-4faf-8146-e9af23f6586d,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-05cc54e5-cbe3-4a6e-b1cf-5b1bd555974a,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-d83ee809-4fcf-44d6-a16d-1dea911f4447,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-7bf4cb4e-9a78-400a-9a2e-b9f764e22f35,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-1653de37-562d-4eba-94e4-d81b9c0549ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-abb7f849-fb93-4f6c-93dd-4e80b4e0086f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 6000000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574740356-172.17.0.21-1595969283810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32936,DS-24bd52f5-163d-4437-a1d6-61f3386cacdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-f25230f0-0081-48f1-aef7-2346d29148ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-62b2d334-4c9c-4677-a370-1e0303854d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-2255124a-794e-441a-a0fb-0cb4109073df,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-46e173b3-7dc0-485e-a454-a92cb4b89c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-6c04aaca-17c5-4bde-a6e8-2f88ab853dae,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-d0e2c40c-2881-43ab-a8c2-716c4b9ffa6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-6ba73c30-7207-4f22-8566-e4b980b65827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574740356-172.17.0.21-1595969283810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32936,DS-24bd52f5-163d-4437-a1d6-61f3386cacdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-f25230f0-0081-48f1-aef7-2346d29148ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-62b2d334-4c9c-4677-a370-1e0303854d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-2255124a-794e-441a-a0fb-0cb4109073df,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-46e173b3-7dc0-485e-a454-a92cb4b89c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-6c04aaca-17c5-4bde-a6e8-2f88ab853dae,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-d0e2c40c-2881-43ab-a8c2-716c4b9ffa6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-6ba73c30-7207-4f22-8566-e4b980b65827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: might be true error
Total execution time in seconds : 5277
