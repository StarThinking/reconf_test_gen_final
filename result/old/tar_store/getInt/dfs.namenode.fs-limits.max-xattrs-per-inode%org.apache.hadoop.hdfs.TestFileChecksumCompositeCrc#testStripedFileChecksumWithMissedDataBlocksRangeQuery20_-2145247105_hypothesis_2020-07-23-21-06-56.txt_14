reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517570184-172.17.0.17-1595539066835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-b5efd05f-f9c4-418c-987d-3d99bd0d6e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-1805ffea-3c96-4249-87de-257b01219f66,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-d4aaf87b-b9cf-4d7f-8db9-fe203ea8685c,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-7b422807-97bc-4eb5-aa8f-e0cc551b5848,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-15e303b4-d1c0-4b83-a21f-6c5877f7d48a,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-18d3354f-27e5-40f2-94be-2b1e8bb227f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-336222a8-4f14-4947-8556-e1907a6d6577,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-19fced41-2b1a-4c03-a5c7-4f66ac0369ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517570184-172.17.0.17-1595539066835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-b5efd05f-f9c4-418c-987d-3d99bd0d6e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-1805ffea-3c96-4249-87de-257b01219f66,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-d4aaf87b-b9cf-4d7f-8db9-fe203ea8685c,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-7b422807-97bc-4eb5-aa8f-e0cc551b5848,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-15e303b4-d1c0-4b83-a21f-6c5877f7d48a,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-18d3354f-27e5-40f2-94be-2b1e8bb227f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-336222a8-4f14-4947-8556-e1907a6d6577,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-19fced41-2b1a-4c03-a5c7-4f66ac0369ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854999122-172.17.0.17-1595539284547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40647,DS-c21db6a6-f195-48bb-9bcb-2d1e9f7e95bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-030fed63-027b-4f16-8726-9889f89b1eea,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-ce766034-ee7f-4049-b2e4-e12b3d53b9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-52573bc9-e729-435b-b02f-1f4a81d4c009,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-005a9aac-4145-464d-84a8-78da015d0db4,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-4458115c-0c6d-4049-980b-4fe2ca512378,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-ccbded66-c3fa-411e-ba2a-aa39e8c34625,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-ce1c2ccc-d076-4d40-9584-5bcf6ab47b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-854999122-172.17.0.17-1595539284547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40647,DS-c21db6a6-f195-48bb-9bcb-2d1e9f7e95bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-030fed63-027b-4f16-8726-9889f89b1eea,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-ce766034-ee7f-4049-b2e4-e12b3d53b9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-52573bc9-e729-435b-b02f-1f4a81d4c009,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-005a9aac-4145-464d-84a8-78da015d0db4,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-4458115c-0c6d-4049-980b-4fe2ca512378,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-ccbded66-c3fa-411e-ba2a-aa39e8c34625,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-ce1c2ccc-d076-4d40-9584-5bcf6ab47b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953688821-172.17.0.17-1595539737505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44563,DS-e2ee8ea1-0022-4312-93c7-71ce34628a20,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-2e400703-a5f6-42c2-b234-061e1a835691,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-384f600f-8f71-400e-a73b-c8e823c537ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-f2753583-4d0a-4d59-8cee-f86f1f9a2ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-ee43894a-772a-44b8-9352-4d48a6706e92,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-f69c88c8-562a-4121-b9f5-c9288aee9aea,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-9a62f059-b74d-48e5-b44a-2363434acae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-ed0d8c55-d707-4c65-b130-930703e2fbab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953688821-172.17.0.17-1595539737505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44563,DS-e2ee8ea1-0022-4312-93c7-71ce34628a20,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-2e400703-a5f6-42c2-b234-061e1a835691,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-384f600f-8f71-400e-a73b-c8e823c537ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-f2753583-4d0a-4d59-8cee-f86f1f9a2ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-ee43894a-772a-44b8-9352-4d48a6706e92,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-f69c88c8-562a-4121-b9f5-c9288aee9aea,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-9a62f059-b74d-48e5-b44a-2363434acae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-ed0d8c55-d707-4c65-b130-930703e2fbab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919542671-172.17.0.17-1595540347983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43861,DS-bbc8a040-4d3e-4988-bc1b-d89008d1736e,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-780092d6-d80c-4a66-9a62-9174951dad09,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-e2cf28f0-0eb3-4e9d-9fd6-251ef8b53a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-4c8c80ad-42eb-40e8-9fe4-0bd6da591425,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-8d7218bc-74dc-4f03-9965-e6073d026f61,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-15650139-a003-4c0c-bcb0-0a16a3dbbc23,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-c593cac5-962a-49a4-86cb-eee9715fe711,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-f58258ec-011f-44da-bf60-d6a2e445b608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919542671-172.17.0.17-1595540347983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43861,DS-bbc8a040-4d3e-4988-bc1b-d89008d1736e,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-780092d6-d80c-4a66-9a62-9174951dad09,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-e2cf28f0-0eb3-4e9d-9fd6-251ef8b53a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-4c8c80ad-42eb-40e8-9fe4-0bd6da591425,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-8d7218bc-74dc-4f03-9965-e6073d026f61,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-15650139-a003-4c0c-bcb0-0a16a3dbbc23,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-c593cac5-962a-49a4-86cb-eee9715fe711,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-f58258ec-011f-44da-bf60-d6a2e445b608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082141839-172.17.0.17-1595540593498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39402,DS-cca7564e-d03e-4f33-89be-4eb58afa9b67,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-7d100de9-ab66-4db7-9e3a-02e60a415973,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-5b88aef2-7a80-46c1-adf4-eaf74d6ab2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-0cd742b3-cab9-43bd-8796-1f3c9bdb7d15,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-61eabdb8-44d1-4b69-9b92-29bc44b6d271,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-4742c03c-99d4-4b8f-819f-87c0b8545a00,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-b1c0d882-ae0b-4d34-bc93-ffbb29f052b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-105d614b-6cd2-48ff-9112-cf192021833c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082141839-172.17.0.17-1595540593498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39402,DS-cca7564e-d03e-4f33-89be-4eb58afa9b67,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-7d100de9-ab66-4db7-9e3a-02e60a415973,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-5b88aef2-7a80-46c1-adf4-eaf74d6ab2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-0cd742b3-cab9-43bd-8796-1f3c9bdb7d15,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-61eabdb8-44d1-4b69-9b92-29bc44b6d271,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-4742c03c-99d4-4b8f-819f-87c0b8545a00,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-b1c0d882-ae0b-4d34-bc93-ffbb29f052b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-105d614b-6cd2-48ff-9112-cf192021833c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374505703-172.17.0.17-1595541831224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39625,DS-78346570-5512-4c23-8852-927a03988441,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-2d1357ad-2dd0-4963-bb00-548af64e6279,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-7ce9807e-8a5c-4ead-997d-6215601de55d,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-f8eab90b-acae-451d-babf-d8ae03fc0a97,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-fbfc4e51-7950-43ba-8e22-48363ade7608,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-cc46bbe4-0ac0-4072-8e2e-c6ec804ef58a,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-3b209b60-7c97-4bb9-9aa2-6f22456c31bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-c18b1fa5-e169-4c39-acdd-4750ff7dd9df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374505703-172.17.0.17-1595541831224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39625,DS-78346570-5512-4c23-8852-927a03988441,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-2d1357ad-2dd0-4963-bb00-548af64e6279,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-7ce9807e-8a5c-4ead-997d-6215601de55d,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-f8eab90b-acae-451d-babf-d8ae03fc0a97,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-fbfc4e51-7950-43ba-8e22-48363ade7608,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-cc46bbe4-0ac0-4072-8e2e-c6ec804ef58a,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-3b209b60-7c97-4bb9-9aa2-6f22456c31bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-c18b1fa5-e169-4c39-acdd-4750ff7dd9df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353592462-172.17.0.17-1595542100968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35096,DS-906adc8e-0f35-4ab1-b952-b627a51f3aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-459a155e-ee92-44cf-ba18-1b5a46ef5d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-3687d9e0-18b5-472a-ab42-900a1e3d9b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-f3e0da9a-2888-4e21-a7b7-e004da152282,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-3bec811c-cc79-48a8-9a42-018c40aeeae5,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-e2c28db9-b5d7-47a1-95b6-930fa03fd802,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-1194773c-5c6b-4ee4-a976-e630a264bf20,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-2888b4f7-7a22-4dd0-b64f-5f42cf2465aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1353592462-172.17.0.17-1595542100968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35096,DS-906adc8e-0f35-4ab1-b952-b627a51f3aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-459a155e-ee92-44cf-ba18-1b5a46ef5d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-3687d9e0-18b5-472a-ab42-900a1e3d9b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-f3e0da9a-2888-4e21-a7b7-e004da152282,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-3bec811c-cc79-48a8-9a42-018c40aeeae5,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-e2c28db9-b5d7-47a1-95b6-930fa03fd802,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-1194773c-5c6b-4ee4-a976-e630a264bf20,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-2888b4f7-7a22-4dd0-b64f-5f42cf2465aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428944206-172.17.0.17-1595542366575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36256,DS-35757ac1-ce75-4fd7-be25-91e72d4e1ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-fdf95f48-1a06-4d93-a74f-1b4cd72766e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-4900ba7e-27e3-40af-be64-af217a71524b,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-487748b8-69b4-41cf-b8cd-7c8d39d3c4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-74e84814-b81f-4e21-a73e-1553f742f84b,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-cd0501b2-e708-4d4e-afcb-b54f0bfe4299,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-db630fda-8c92-41dd-817a-e76555afe6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-6959e5e5-cafd-47bc-bc64-9912c13e0f0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428944206-172.17.0.17-1595542366575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36256,DS-35757ac1-ce75-4fd7-be25-91e72d4e1ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-fdf95f48-1a06-4d93-a74f-1b4cd72766e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34149,DS-4900ba7e-27e3-40af-be64-af217a71524b,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-487748b8-69b4-41cf-b8cd-7c8d39d3c4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-74e84814-b81f-4e21-a73e-1553f742f84b,DISK], DatanodeInfoWithStorage[127.0.0.1:43303,DS-cd0501b2-e708-4d4e-afcb-b54f0bfe4299,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-db630fda-8c92-41dd-817a-e76555afe6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-6959e5e5-cafd-47bc-bc64-9912c13e0f0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943301868-172.17.0.17-1595542891235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44340,DS-5e7093ba-a1e1-4c59-b65b-173608531761,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-6c887b03-0c1e-4ed4-8f0f-f42fc123042e,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-de58adb9-33e1-437a-a65d-7b47c5beb900,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-72be81e0-6845-49bc-a507-031a96a7bdef,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-73ccf864-a8e0-4e75-8e52-41ef60dd31c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-48b0eb9c-9d80-4f35-9612-ca29bbfeca99,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-40921cbc-b6d6-4d1f-a85e-1d0325ba33fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-87ee1691-0b4a-420c-81e8-27f81608cbac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943301868-172.17.0.17-1595542891235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44340,DS-5e7093ba-a1e1-4c59-b65b-173608531761,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-6c887b03-0c1e-4ed4-8f0f-f42fc123042e,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-de58adb9-33e1-437a-a65d-7b47c5beb900,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-72be81e0-6845-49bc-a507-031a96a7bdef,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-73ccf864-a8e0-4e75-8e52-41ef60dd31c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-48b0eb9c-9d80-4f35-9612-ca29bbfeca99,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-40921cbc-b6d6-4d1f-a85e-1d0325ba33fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-87ee1691-0b4a-420c-81e8-27f81608cbac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402461270-172.17.0.17-1595542962787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46861,DS-ced53c02-7400-43e1-bf67-1dc17d96e165,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-237b1342-6992-401a-a804-d207333e357c,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-63ac4c4e-dd9c-43b4-b38a-e950fa5caa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-ee17f87b-e12c-4366-ab13-08d9f89e96e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-58d75718-130c-4ac1-a14d-2dcded9fd71c,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-15c55c07-392e-4e58-a6f7-cdeb9dfaf363,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-21747b60-5413-44e7-aab6-49dffbf9c15f,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-5e915d1e-32fe-4c58-ada0-8eade92863a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402461270-172.17.0.17-1595542962787:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46861,DS-ced53c02-7400-43e1-bf67-1dc17d96e165,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-237b1342-6992-401a-a804-d207333e357c,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-63ac4c4e-dd9c-43b4-b38a-e950fa5caa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-ee17f87b-e12c-4366-ab13-08d9f89e96e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-58d75718-130c-4ac1-a14d-2dcded9fd71c,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-15c55c07-392e-4e58-a6f7-cdeb9dfaf363,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-21747b60-5413-44e7-aab6-49dffbf9c15f,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-5e915d1e-32fe-4c58-ada0-8eade92863a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811301976-172.17.0.17-1595543158070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33615,DS-84c850c0-ea2a-4159-9050-88a673d12133,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-7e37d334-9fd6-449c-8d19-1f8253263352,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-bd8c9340-af59-40ae-ab0d-601fe826de55,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-ca73b376-ae5c-43f3-b1d2-1951497bd60f,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-bb1fb57b-16f1-4e46-9b51-978b35d2260e,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-2c1f6732-3578-4c68-af4a-fce2a9479bea,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-f881ab4c-0c9b-4d07-a195-c6ac9121e9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-dc91b7ed-7b71-4d26-8a77-30353623f895,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811301976-172.17.0.17-1595543158070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33615,DS-84c850c0-ea2a-4159-9050-88a673d12133,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-7e37d334-9fd6-449c-8d19-1f8253263352,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-bd8c9340-af59-40ae-ab0d-601fe826de55,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-ca73b376-ae5c-43f3-b1d2-1951497bd60f,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-bb1fb57b-16f1-4e46-9b51-978b35d2260e,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-2c1f6732-3578-4c68-af4a-fce2a9479bea,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-f881ab4c-0c9b-4d07-a195-c6ac9121e9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-dc91b7ed-7b71-4d26-8a77-30353623f895,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1897390591-172.17.0.17-1595543303522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38717,DS-8ddbb728-6407-4ad6-83e1-8d375743d745,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-ba279cab-dc20-48ea-a72d-c56644c6eac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-9931af0b-4df2-41b7-bb15-870b89851fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-5bddb691-8cc5-459c-878a-88a9ff01df8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-cb531d5e-3373-4684-b8b1-533fc216cff9,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-63e459ec-a7e4-4ce1-8d92-65a679a5aae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-820d2dc5-b960-4575-8c95-de12b771ff9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-60899c99-5aa3-4889-814e-2b3251b5d9a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1897390591-172.17.0.17-1595543303522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38717,DS-8ddbb728-6407-4ad6-83e1-8d375743d745,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-ba279cab-dc20-48ea-a72d-c56644c6eac4,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-9931af0b-4df2-41b7-bb15-870b89851fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-5bddb691-8cc5-459c-878a-88a9ff01df8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-cb531d5e-3373-4684-b8b1-533fc216cff9,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-63e459ec-a7e4-4ce1-8d92-65a679a5aae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-820d2dc5-b960-4575-8c95-de12b771ff9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-60899c99-5aa3-4889-814e-2b3251b5d9a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1729184914-172.17.0.17-1595543590311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35787,DS-0730ee87-efc3-4143-b56c-0300299e7762,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-d9811634-23ba-4da4-981a-c0195a51f24c,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-45418217-1b20-4c20-90e1-9ca66fffba08,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-7aff520d-998e-4260-a9f9-af51d5d904a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-1b4f3f8f-8bf8-49b9-9213-6bdbf1f95e45,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-65bd6afd-d5ed-4581-9ae3-232e07bf1a91,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-1ba16ce0-f259-485b-9fa6-8e40ffc8364d,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-9478526d-4840-492b-8ebb-116b4cf33130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1729184914-172.17.0.17-1595543590311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35787,DS-0730ee87-efc3-4143-b56c-0300299e7762,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-d9811634-23ba-4da4-981a-c0195a51f24c,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-45418217-1b20-4c20-90e1-9ca66fffba08,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-7aff520d-998e-4260-a9f9-af51d5d904a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-1b4f3f8f-8bf8-49b9-9213-6bdbf1f95e45,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-65bd6afd-d5ed-4581-9ae3-232e07bf1a91,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-1ba16ce0-f259-485b-9fa6-8e40ffc8364d,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-9478526d-4840-492b-8ebb-116b4cf33130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 64
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-131472369-172.17.0.17-1595543701073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35827,DS-30f0bfb8-a4d1-44b0-ab73-ef4f11598e44,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-db634732-277c-447d-ad3e-0ca246543225,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-4db4f4dc-51ca-403b-882c-c5f8c967fab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-8d997a65-48dd-478e-960d-5e2d0e98f6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-1be052c7-2c18-4edf-8646-af8c91a8e6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-2cad7a0d-15aa-45ae-a5b1-e0836657de12,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-75ba2c9f-b4e4-4557-bea9-ef9d70488bae,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-67c14857-4548-4150-99d6-c31466bea9b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-131472369-172.17.0.17-1595543701073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35827,DS-30f0bfb8-a4d1-44b0-ab73-ef4f11598e44,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-db634732-277c-447d-ad3e-0ca246543225,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-4db4f4dc-51ca-403b-882c-c5f8c967fab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-8d997a65-48dd-478e-960d-5e2d0e98f6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-1be052c7-2c18-4edf-8646-af8c91a8e6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-2cad7a0d-15aa-45ae-a5b1-e0836657de12,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-75ba2c9f-b4e4-4557-bea9-ef9d70488bae,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-67c14857-4548-4150-99d6-c31466bea9b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5442
