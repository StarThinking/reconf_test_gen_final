reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194566475-172.17.0.20-1595592053358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46201,DS-07c6f719-00f7-4277-832e-e74c70fceeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-c7bc017d-75c5-4730-87b6-b0938cee6004,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-ec7ca068-bdc2-4feb-8f9e-b94585170547,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-77f84384-7989-4568-b3fa-38d04837b935,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-95135d81-0fd9-4efb-8a67-f55b73dd7e78,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-e9ef070b-34a7-46f5-aac7-77e329d1ca0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-31e9c0d4-d179-4608-b467-8bcb07a805a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-b3a7669f-7de9-4042-87c3-9f018c0e9b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194566475-172.17.0.20-1595592053358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46201,DS-07c6f719-00f7-4277-832e-e74c70fceeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-c7bc017d-75c5-4730-87b6-b0938cee6004,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-ec7ca068-bdc2-4feb-8f9e-b94585170547,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-77f84384-7989-4568-b3fa-38d04837b935,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-95135d81-0fd9-4efb-8a67-f55b73dd7e78,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-e9ef070b-34a7-46f5-aac7-77e329d1ca0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-31e9c0d4-d179-4608-b467-8bcb07a805a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-b3a7669f-7de9-4042-87c3-9f018c0e9b26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671374295-172.17.0.20-1595592423674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42352,DS-f080ca2d-9961-460c-b6e4-b5b8666ff3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-d5330d61-8100-4af5-9ea8-5fe3ca28ad6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-8e5f0009-04cd-40fa-9930-55b42ea12a75,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-7aed0729-935f-4a53-80ad-22ced64c7093,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-5ef3709f-a7b1-4f78-8aea-a8dffdba113e,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-c83c7303-ee65-4bb1-8526-37c679a490d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-c93ea6e4-5663-4621-8a38-febdf064826e,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-6691efae-f35b-4c42-8ee1-4df86a7a0e27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-671374295-172.17.0.20-1595592423674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42352,DS-f080ca2d-9961-460c-b6e4-b5b8666ff3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-d5330d61-8100-4af5-9ea8-5fe3ca28ad6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-8e5f0009-04cd-40fa-9930-55b42ea12a75,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-7aed0729-935f-4a53-80ad-22ced64c7093,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-5ef3709f-a7b1-4f78-8aea-a8dffdba113e,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-c83c7303-ee65-4bb1-8526-37c679a490d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-c93ea6e4-5663-4621-8a38-febdf064826e,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-6691efae-f35b-4c42-8ee1-4df86a7a0e27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163622349-172.17.0.20-1595592573658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36516,DS-a9efa8fb-fff1-49f9-b3c8-5e307b555c19,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-fd2ebade-2b8e-47a8-8fe7-4f027ab09cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-04fad7d7-74e0-4604-93e4-bc68affcd0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-a299b715-8e3e-4388-ab40-bd743fd69151,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-8a02a217-7598-4dd7-a99c-114da3f66a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-a9d9df39-0f66-40cc-904c-a792568bae0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-8d792ce7-8423-45e6-8983-47465c7d7c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-1e9e2504-0eba-41cd-919f-cc376f942005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163622349-172.17.0.20-1595592573658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36516,DS-a9efa8fb-fff1-49f9-b3c8-5e307b555c19,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-fd2ebade-2b8e-47a8-8fe7-4f027ab09cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-04fad7d7-74e0-4604-93e4-bc68affcd0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-a299b715-8e3e-4388-ab40-bd743fd69151,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-8a02a217-7598-4dd7-a99c-114da3f66a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-a9d9df39-0f66-40cc-904c-a792568bae0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-8d792ce7-8423-45e6-8983-47465c7d7c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-1e9e2504-0eba-41cd-919f-cc376f942005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646131368-172.17.0.20-1595592863935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38924,DS-351b5604-0aaa-4d0c-8fd1-d58e82a00577,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-e1907ae2-5bc8-4fa5-bc81-7c191bb8d7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-d14b3c6a-99ab-49c3-8328-050bae3d0dba,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-4e41549e-0d9f-4021-8b33-963a2bfb485b,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-6997e1e7-86d9-40d0-b6d2-8fcc3fe75804,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-ec0e3a35-a7d1-477b-960a-b4b01b66311e,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-21ab0910-b6de-4753-8dbc-b1557a016085,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-387b12a1-eb32-4d5d-8696-040e755c2c7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646131368-172.17.0.20-1595592863935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38924,DS-351b5604-0aaa-4d0c-8fd1-d58e82a00577,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-e1907ae2-5bc8-4fa5-bc81-7c191bb8d7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-d14b3c6a-99ab-49c3-8328-050bae3d0dba,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-4e41549e-0d9f-4021-8b33-963a2bfb485b,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-6997e1e7-86d9-40d0-b6d2-8fcc3fe75804,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-ec0e3a35-a7d1-477b-960a-b4b01b66311e,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-21ab0910-b6de-4753-8dbc-b1557a016085,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-387b12a1-eb32-4d5d-8696-040e755c2c7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81595303-172.17.0.20-1595592953704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38762,DS-f827563b-f721-4b93-aeed-7ef8ce96c9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-b9a5f6dc-ae8d-4846-b4c6-39b7bac330bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-7d36b132-65f1-4149-83f8-d7231f83ca8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-5a339c19-37c4-40ae-b426-cbacd484b9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-84b2a94b-7156-436e-8c91-497e719d24c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-30c56e49-ace8-4586-b984-1724c33ba40a,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-2a9f371a-5c42-421b-8b9b-860568af0b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-3fbf651e-6273-4ec5-a3be-59db8054b536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-81595303-172.17.0.20-1595592953704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38762,DS-f827563b-f721-4b93-aeed-7ef8ce96c9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-b9a5f6dc-ae8d-4846-b4c6-39b7bac330bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-7d36b132-65f1-4149-83f8-d7231f83ca8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-5a339c19-37c4-40ae-b426-cbacd484b9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-84b2a94b-7156-436e-8c91-497e719d24c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-30c56e49-ace8-4586-b984-1724c33ba40a,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-2a9f371a-5c42-421b-8b9b-860568af0b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-3fbf651e-6273-4ec5-a3be-59db8054b536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232883692-172.17.0.20-1595593394808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38250,DS-8c12e643-3dbd-4d2b-bc90-c2d0d66c3cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-c7c1f86f-5480-47bb-9490-79b17303e29d,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-40323485-6aa8-4967-97fa-cc5a002d0421,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-7b8460af-907a-4c80-92fa-53f5c4ddb7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-214a920e-4ccd-4cf2-8319-c6cd24936894,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-9d7b3fea-6d6a-4a04-bb1e-e43acb2d4117,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-42fd1a95-31ab-4c56-a34b-8c690be7b0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-b9e2cd2c-a5c4-45f7-a0e5-e459e8395db8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1232883692-172.17.0.20-1595593394808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38250,DS-8c12e643-3dbd-4d2b-bc90-c2d0d66c3cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-c7c1f86f-5480-47bb-9490-79b17303e29d,DISK], DatanodeInfoWithStorage[127.0.0.1:42987,DS-40323485-6aa8-4967-97fa-cc5a002d0421,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-7b8460af-907a-4c80-92fa-53f5c4ddb7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-214a920e-4ccd-4cf2-8319-c6cd24936894,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-9d7b3fea-6d6a-4a04-bb1e-e43acb2d4117,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-42fd1a95-31ab-4c56-a34b-8c690be7b0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-b9e2cd2c-a5c4-45f7-a0e5-e459e8395db8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1089528447-172.17.0.20-1595593898738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37033,DS-7adebf18-2f55-48d3-b8b9-ca30ba1dceb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-24f30a54-1fdc-4aab-8da8-2bcd6b785470,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-58aeda5f-496f-4bcc-b05a-9d96d50eb833,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-ca3a90fb-0a22-4f2b-92fa-c93f8e236276,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-547755ae-5df9-4cb7-8033-961515b9a850,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-55e5215e-6d0f-47f5-b1bf-02f4a223830c,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-780957b7-31fc-4c85-9012-4d67cdb6076d,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-cc06c1f9-4358-4553-ba9f-852c9fa344ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1089528447-172.17.0.20-1595593898738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37033,DS-7adebf18-2f55-48d3-b8b9-ca30ba1dceb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-24f30a54-1fdc-4aab-8da8-2bcd6b785470,DISK], DatanodeInfoWithStorage[127.0.0.1:41326,DS-58aeda5f-496f-4bcc-b05a-9d96d50eb833,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-ca3a90fb-0a22-4f2b-92fa-c93f8e236276,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-547755ae-5df9-4cb7-8033-961515b9a850,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-55e5215e-6d0f-47f5-b1bf-02f4a223830c,DISK], DatanodeInfoWithStorage[127.0.0.1:46334,DS-780957b7-31fc-4c85-9012-4d67cdb6076d,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-cc06c1f9-4358-4553-ba9f-852c9fa344ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200479022-172.17.0.20-1595594120727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43096,DS-94ccdba9-0ee7-47a8-ac21-e3f31e95e3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-e8b0e0ca-6aea-427b-ba5b-cea7a646d716,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-95da85f6-87e3-45bd-aa7f-c9723f60df5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-aa96bd82-cb17-464a-946f-0c2b96736eae,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-9907e79a-2bcf-49f3-bfc5-c3c9c32abcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-2989ab4a-8abb-492e-89f0-da8eb56c0bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-ed9f496e-141d-4dfa-a0fe-6ecad527a922,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-4253bf59-defb-4203-a9a4-c3d99c66541b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-200479022-172.17.0.20-1595594120727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43096,DS-94ccdba9-0ee7-47a8-ac21-e3f31e95e3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-e8b0e0ca-6aea-427b-ba5b-cea7a646d716,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-95da85f6-87e3-45bd-aa7f-c9723f60df5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-aa96bd82-cb17-464a-946f-0c2b96736eae,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-9907e79a-2bcf-49f3-bfc5-c3c9c32abcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-2989ab4a-8abb-492e-89f0-da8eb56c0bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-ed9f496e-141d-4dfa-a0fe-6ecad527a922,DISK], DatanodeInfoWithStorage[127.0.0.1:40966,DS-4253bf59-defb-4203-a9a4-c3d99c66541b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1816859126-172.17.0.20-1595594216970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39923,DS-9af58c27-8429-4d57-8c87-9fc2f0493df8,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-7aa570bc-d8d6-4d3e-99b3-182e9f156f41,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-e4325e52-4ce2-4180-813b-5de7d5c47f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-441d3a68-6fdd-4d81-8708-b103710bff8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-191091b5-5691-4166-9aa5-1013d7553c29,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-31fd6de4-fee6-4a1c-9499-3103108d9406,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-c9cb7574-a593-4c38-b396-08041f44626f,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-99558cca-ceea-4239-9357-e0049c6e7bc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1816859126-172.17.0.20-1595594216970:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39923,DS-9af58c27-8429-4d57-8c87-9fc2f0493df8,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-7aa570bc-d8d6-4d3e-99b3-182e9f156f41,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-e4325e52-4ce2-4180-813b-5de7d5c47f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-441d3a68-6fdd-4d81-8708-b103710bff8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-191091b5-5691-4166-9aa5-1013d7553c29,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-31fd6de4-fee6-4a1c-9499-3103108d9406,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-c9cb7574-a593-4c38-b396-08041f44626f,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-99558cca-ceea-4239-9357-e0049c6e7bc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159580761-172.17.0.20-1595595084530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36411,DS-ecb46e48-51f8-4378-9583-2a76559884dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-114d811d-dce3-4878-8965-e8dd964f7b68,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-a425c194-9c3a-4ec0-89a8-dfa1f06941b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-8f04cd5c-3ed5-4ab3-b844-6aa9e7ddb47b,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-4b6d4b8c-f5ef-4cda-9b87-48ab621295c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-0e4975dd-fb9b-4e4c-ae0f-6b2417eeabfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-2de74ada-dd59-47fe-90c1-13681f9b8e64,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-fe6a59f4-6e5f-4b68-b320-dd3cd348ffa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159580761-172.17.0.20-1595595084530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36411,DS-ecb46e48-51f8-4378-9583-2a76559884dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-114d811d-dce3-4878-8965-e8dd964f7b68,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-a425c194-9c3a-4ec0-89a8-dfa1f06941b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-8f04cd5c-3ed5-4ab3-b844-6aa9e7ddb47b,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-4b6d4b8c-f5ef-4cda-9b87-48ab621295c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-0e4975dd-fb9b-4e4c-ae0f-6b2417eeabfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-2de74ada-dd59-47fe-90c1-13681f9b8e64,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-fe6a59f4-6e5f-4b68-b320-dd3cd348ffa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115301689-172.17.0.20-1595595360462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-576be60f-e4ad-4521-9d11-17fccc32fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-f83cfaf4-7d19-489a-8081-07bfc98fd1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-b25bca40-4359-42e2-aa0d-de032ae3578a,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-415c56bf-a9d2-46a1-a651-4866c9c9a9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-3ba94d3f-fa10-4e29-877b-d9e4b89ec1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-ae695154-d7ed-45c3-955a-256ddecce2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-3fd29863-1e22-41a4-9487-fb11e1bf3a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-34265a23-6eb4-4ca6-90ac-e92145313161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115301689-172.17.0.20-1595595360462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-576be60f-e4ad-4521-9d11-17fccc32fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-f83cfaf4-7d19-489a-8081-07bfc98fd1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-b25bca40-4359-42e2-aa0d-de032ae3578a,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-415c56bf-a9d2-46a1-a651-4866c9c9a9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-3ba94d3f-fa10-4e29-877b-d9e4b89ec1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-ae695154-d7ed-45c3-955a-256ddecce2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-3fd29863-1e22-41a4-9487-fb11e1bf3a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-34265a23-6eb4-4ca6-90ac-e92145313161,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1256663979-172.17.0.20-1595595486202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35612,DS-5000dafc-963d-4d78-b46a-bffb4c1fda6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-74262d90-7f1a-4b44-ad76-df09a5d12bde,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-205f9b02-7b89-4a5c-9601-45d4e042b49e,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-708a87e4-a1e2-4615-af4f-e26fdce968a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-15227718-7407-440d-9a49-575125a5da78,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-a9e63394-5eb7-4884-bc57-af635664349a,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-f062b348-4d00-463a-afb0-7aed186e33e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-bba091e4-ff14-4dbb-8465-4dd80a212091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1256663979-172.17.0.20-1595595486202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35612,DS-5000dafc-963d-4d78-b46a-bffb4c1fda6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-74262d90-7f1a-4b44-ad76-df09a5d12bde,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-205f9b02-7b89-4a5c-9601-45d4e042b49e,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-708a87e4-a1e2-4615-af4f-e26fdce968a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-15227718-7407-440d-9a49-575125a5da78,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-a9e63394-5eb7-4884-bc57-af635664349a,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-f062b348-4d00-463a-afb0-7aed186e33e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-bba091e4-ff14-4dbb-8465-4dd80a212091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386740457-172.17.0.20-1595596263395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35198,DS-e04d5e9f-2349-470f-82a4-55b9c1d5ecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-1ed8750c-afc1-4d37-bad8-e4fa479a5e57,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-a0c07c6e-4367-4f1b-b813-347b88f39e62,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-602c0a39-9cba-4a81-9323-00562653cf84,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-51326378-2304-47e1-ba8b-c6e213db689d,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-89653b02-8877-4629-a56b-a819f07b75d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-e0b778af-8ea5-421f-a8ea-55c82c4fd720,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-2d582528-72d0-468e-a1f8-3ecf8a916640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386740457-172.17.0.20-1595596263395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35198,DS-e04d5e9f-2349-470f-82a4-55b9c1d5ecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-1ed8750c-afc1-4d37-bad8-e4fa479a5e57,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-a0c07c6e-4367-4f1b-b813-347b88f39e62,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-602c0a39-9cba-4a81-9323-00562653cf84,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-51326378-2304-47e1-ba8b-c6e213db689d,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-89653b02-8877-4629-a56b-a819f07b75d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-e0b778af-8ea5-421f-a8ea-55c82c4fd720,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-2d582528-72d0-468e-a1f8-3ecf8a916640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1683577739-172.17.0.20-1595596785284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41035,DS-78703b7b-f5a0-4f41-8f77-db0a383c41d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-90c468d8-b7ed-4828-9e6b-9955777e2ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-3561b8bb-28b2-4730-a05c-fc3435f3ad80,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-1dd1738b-8a50-41ee-ac0b-987b206939c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-d062d4dd-8eb1-45bd-9845-8ad99a25bcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-faac5648-f3ca-4fad-bc6d-83da0daabc49,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-839210e2-2279-4bde-bb3f-15a7d0f42946,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-838b998e-4f17-4577-aaf1-38527805a2af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1683577739-172.17.0.20-1595596785284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41035,DS-78703b7b-f5a0-4f41-8f77-db0a383c41d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-90c468d8-b7ed-4828-9e6b-9955777e2ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-3561b8bb-28b2-4730-a05c-fc3435f3ad80,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-1dd1738b-8a50-41ee-ac0b-987b206939c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-d062d4dd-8eb1-45bd-9845-8ad99a25bcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-faac5648-f3ca-4fad-bc6d-83da0daabc49,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-839210e2-2279-4bde-bb3f-15a7d0f42946,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-838b998e-4f17-4577-aaf1-38527805a2af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937959089-172.17.0.20-1595597017306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43556,DS-45d09abf-de36-4e73-aaff-dce766be1077,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-dfd28481-da23-47e1-b167-0bc158e444bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-ea07fb16-a512-4cf7-8ffe-5057b829f4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-1b80eac0-3d08-42eb-a2ce-df40ccb849e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-7d5eb96f-9df8-4c2a-8acb-15401991db06,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-443e3ddf-a1f9-434c-b629-f975b7678315,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-22529499-39ef-4989-8546-124bd4491156,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-e1677f6d-e0e0-43e5-b079-d8fd4d600180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937959089-172.17.0.20-1595597017306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43556,DS-45d09abf-de36-4e73-aaff-dce766be1077,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-dfd28481-da23-47e1-b167-0bc158e444bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-ea07fb16-a512-4cf7-8ffe-5057b829f4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-1b80eac0-3d08-42eb-a2ce-df40ccb849e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-7d5eb96f-9df8-4c2a-8acb-15401991db06,DISK], DatanodeInfoWithStorage[127.0.0.1:34884,DS-443e3ddf-a1f9-434c-b629-f975b7678315,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-22529499-39ef-4989-8546-124bd4491156,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-e1677f6d-e0e0-43e5-b079-d8fd4d600180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838516322-172.17.0.20-1595597120444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44658,DS-730abcf6-4ee6-4646-a348-df685c11e018,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-667e0485-d725-4517-bd17-d9af34bc4d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-14cf7758-c795-42ea-aa75-e206f55c90d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-97ee87ad-ee12-4f31-b8ae-b396dfa8622f,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-bed97514-fb55-44c4-affb-1e26a4f96f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-204fdb06-7b4e-4b0c-addb-c7d45f5baabd,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-a80fa9d0-904f-48e0-994d-61c6a488a895,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-8f6bb339-478f-411a-9ef8-c631d8a02034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1838516322-172.17.0.20-1595597120444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44658,DS-730abcf6-4ee6-4646-a348-df685c11e018,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-667e0485-d725-4517-bd17-d9af34bc4d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-14cf7758-c795-42ea-aa75-e206f55c90d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-97ee87ad-ee12-4f31-b8ae-b396dfa8622f,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-bed97514-fb55-44c4-affb-1e26a4f96f40,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-204fdb06-7b4e-4b0c-addb-c7d45f5baabd,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-a80fa9d0-904f-48e0-994d-61c6a488a895,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-8f6bb339-478f-411a-9ef8-c631d8a02034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369859506-172.17.0.20-1595597805694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37093,DS-e34e92ca-0cd0-463b-9b52-5cdfb35752fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-bedb4af3-a934-46f9-9c2c-5900ac4463a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-16b13b3f-8d82-4b86-8c66-a9a1c9bbacd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-f0fb4e0d-f982-42f9-a5ca-6d8b4ecc96c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-df39988d-ea15-4701-8aff-18a85b55720c,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-5d6bdb55-0dda-452a-bc28-f0033fa2a533,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-da3eede1-7edc-41cf-8707-d3b0d44aca49,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-2daa663b-64ea-45f2-88e3-8c8bdb7e9959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1369859506-172.17.0.20-1595597805694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37093,DS-e34e92ca-0cd0-463b-9b52-5cdfb35752fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-bedb4af3-a934-46f9-9c2c-5900ac4463a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-16b13b3f-8d82-4b86-8c66-a9a1c9bbacd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-f0fb4e0d-f982-42f9-a5ca-6d8b4ecc96c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-df39988d-ea15-4701-8aff-18a85b55720c,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-5d6bdb55-0dda-452a-bc28-f0033fa2a533,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-da3eede1-7edc-41cf-8707-d3b0d44aca49,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-2daa663b-64ea-45f2-88e3-8c8bdb7e9959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519923681-172.17.0.20-1595598305880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46313,DS-c7b78f15-75f8-4854-a96f-d5e7ec4b45c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-b5a70bfd-17ef-4e94-bb48-1ec148696eea,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-390b68f6-57e3-45c5-ad07-956fb70b5f07,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-87f2386b-1bdc-40c6-bf9b-d8137bf77de0,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-97ee74ea-b232-4f19-8606-b4c58dd4556f,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-3abd40a9-b9e0-4a38-934b-6b3ed7fedd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-d0c2bb0c-4e16-4332-b94b-6a57cb07fb08,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-166fd0d7-7e3d-4ec5-959e-6ba4036435e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519923681-172.17.0.20-1595598305880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46313,DS-c7b78f15-75f8-4854-a96f-d5e7ec4b45c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-b5a70bfd-17ef-4e94-bb48-1ec148696eea,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-390b68f6-57e3-45c5-ad07-956fb70b5f07,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-87f2386b-1bdc-40c6-bf9b-d8137bf77de0,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-97ee74ea-b232-4f19-8606-b4c58dd4556f,DISK], DatanodeInfoWithStorage[127.0.0.1:38163,DS-3abd40a9-b9e0-4a38-934b-6b3ed7fedd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-d0c2bb0c-4e16-4332-b94b-6a57cb07fb08,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-166fd0d7-7e3d-4ec5-959e-6ba4036435e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058710169-172.17.0.20-1595598352371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34032,DS-a38379e5-b5eb-4115-80f0-2eae1d2d0b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-a069d256-8644-4695-8efd-b327df37ad45,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-708ea470-ca2f-4b39-b55d-65116072e988,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-33d7d275-5a53-48b7-921d-0215d264cfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-a3b9ff16-15a8-4341-b425-6a0840bf5558,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-e84bb04a-8354-490c-b5f2-6b37e8e1edca,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-0112cff9-8200-4f54-8729-144de2e1de2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-a4d453a4-f515-4578-9f0a-cb77ed16ac91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2058710169-172.17.0.20-1595598352371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34032,DS-a38379e5-b5eb-4115-80f0-2eae1d2d0b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-a069d256-8644-4695-8efd-b327df37ad45,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-708ea470-ca2f-4b39-b55d-65116072e988,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-33d7d275-5a53-48b7-921d-0215d264cfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-a3b9ff16-15a8-4341-b425-6a0840bf5558,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-e84bb04a-8354-490c-b5f2-6b37e8e1edca,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-0112cff9-8200-4f54-8729-144de2e1de2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-a4d453a4-f515-4578-9f0a-cb77ed16ac91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-54478367-172.17.0.20-1595598549875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33914,DS-be3f4223-7349-4422-bb7a-14f8a82232d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-50afe808-c933-435f-b8c7-1605c8d4d1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-ca77bd58-08db-46a5-a009-cfea726c2fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-643dea23-cacc-4716-9d67-a0da2d91b9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-59513f8f-12b7-4d00-995c-d3d11c7f8bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-9c5d16b7-3cf0-4130-bd21-b0927123ab79,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-58efb276-4fcb-4f97-8781-5c0f90225693,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-02032ace-8e2f-4838-ab98-b6811a815f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-54478367-172.17.0.20-1595598549875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33914,DS-be3f4223-7349-4422-bb7a-14f8a82232d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-50afe808-c933-435f-b8c7-1605c8d4d1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-ca77bd58-08db-46a5-a009-cfea726c2fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-643dea23-cacc-4716-9d67-a0da2d91b9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-59513f8f-12b7-4d00-995c-d3d11c7f8bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-9c5d16b7-3cf0-4130-bd21-b0927123ab79,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-58efb276-4fcb-4f97-8781-5c0f90225693,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-02032ace-8e2f-4838-ab98-b6811a815f97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.invalidate.limit
component: hdfs:NameNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330088018-172.17.0.20-1595598636299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43757,DS-a1c1b06b-2994-4197-a439-b24c049d0c00,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-9df2a298-0011-493e-b6cc-cd65b7d091f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-11d03804-b2db-41e8-ba02-e02bd44b6ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-e5d795ee-0d44-4f4e-ac39-d3bebec6fdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-52449810-a75e-4904-9d0f-eeb8a7b205ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-44f3bcd5-e591-4905-a4ae-423a96109a29,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-6fb9e419-277b-4c1b-a6e0-8dca4f337856,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-f4387493-b331-446d-b53f-a75f42e90704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330088018-172.17.0.20-1595598636299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43757,DS-a1c1b06b-2994-4197-a439-b24c049d0c00,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-9df2a298-0011-493e-b6cc-cd65b7d091f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-11d03804-b2db-41e8-ba02-e02bd44b6ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-e5d795ee-0d44-4f4e-ac39-d3bebec6fdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-52449810-a75e-4904-9d0f-eeb8a7b205ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-44f3bcd5-e591-4905-a4ae-423a96109a29,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-6fb9e419-277b-4c1b-a6e0-8dca4f337856,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-f4387493-b331-446d-b53f-a75f42e90704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6758
