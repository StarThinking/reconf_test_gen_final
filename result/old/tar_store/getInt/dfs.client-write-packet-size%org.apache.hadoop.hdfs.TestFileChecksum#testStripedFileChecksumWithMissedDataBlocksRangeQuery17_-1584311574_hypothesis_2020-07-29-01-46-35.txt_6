reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-390080777-172.17.0.12-1595988457721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45237,DS-4b2ac970-582a-4269-a1b6-d566d729d3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-a5f391be-0290-4ca7-9d2f-d2abdb48e584,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-9859e089-4dd0-4554-9658-faf207e14b79,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-88a1b4cb-76d0-41f6-a705-728cc16f9f88,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-61af14c3-0cc1-4c90-93fb-428e6f871310,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-cd9f3267-4f41-4ba0-8242-5f3d72b2152f,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-f7f042ef-4547-4d9b-87b7-a04c208ef735,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-f570d26c-a097-42a9-9e3d-f88c8825e1da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-390080777-172.17.0.12-1595988457721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45237,DS-4b2ac970-582a-4269-a1b6-d566d729d3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-a5f391be-0290-4ca7-9d2f-d2abdb48e584,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-9859e089-4dd0-4554-9658-faf207e14b79,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-88a1b4cb-76d0-41f6-a705-728cc16f9f88,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-61af14c3-0cc1-4c90-93fb-428e6f871310,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-cd9f3267-4f41-4ba0-8242-5f3d72b2152f,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-f7f042ef-4547-4d9b-87b7-a04c208ef735,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-f570d26c-a097-42a9-9e3d-f88c8825e1da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205862934-172.17.0.12-1595988541473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44082,DS-5f191dd7-f04e-4fc3-be1b-494972f70916,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-4d62abac-08df-4703-957e-760c69b96861,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-64d3dec2-b078-45dc-a857-cc3e5b12a5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-a2007fb6-2d6e-4d7b-a340-85b810fbd034,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-4e04f0c4-cc70-4fe0-8729-0b0a83f1c875,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-8fa79727-8c8e-485e-aa30-0f68935d630b,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-3a040524-9f2e-44e7-afd4-7140f862abd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-0daf31f0-e069-446e-b180-7f3419ba686c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205862934-172.17.0.12-1595988541473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44082,DS-5f191dd7-f04e-4fc3-be1b-494972f70916,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-4d62abac-08df-4703-957e-760c69b96861,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-64d3dec2-b078-45dc-a857-cc3e5b12a5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-a2007fb6-2d6e-4d7b-a340-85b810fbd034,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-4e04f0c4-cc70-4fe0-8729-0b0a83f1c875,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-8fa79727-8c8e-485e-aa30-0f68935d630b,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-3a040524-9f2e-44e7-afd4-7140f862abd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-0daf31f0-e069-446e-b180-7f3419ba686c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761173653-172.17.0.12-1595988862032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39931,DS-24d77bb9-c850-461a-8d7a-8df28532807c,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-527e580a-4064-4d8c-a808-79539b7a4ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-9c39aa6f-ba8a-410b-8607-c5003d5342c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-3f4a55ff-9767-4ad4-9b66-c4e3049a89fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-a9cda9e1-2d96-4a52-801f-ee7790d601e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-9d285ffb-db92-44c3-a747-2af173051236,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-e50824c1-665f-4888-a85f-a81a1c5de8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-4b13ac2e-2e40-4ab2-9fe0-702aa7c9baef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761173653-172.17.0.12-1595988862032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39931,DS-24d77bb9-c850-461a-8d7a-8df28532807c,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-527e580a-4064-4d8c-a808-79539b7a4ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-9c39aa6f-ba8a-410b-8607-c5003d5342c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-3f4a55ff-9767-4ad4-9b66-c4e3049a89fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-a9cda9e1-2d96-4a52-801f-ee7790d601e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-9d285ffb-db92-44c3-a747-2af173051236,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-e50824c1-665f-4888-a85f-a81a1c5de8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-4b13ac2e-2e40-4ab2-9fe0-702aa7c9baef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577041167-172.17.0.12-1595989292636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36283,DS-ccc74ccd-510e-4379-9b31-3fa479f2bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-a54b9ad5-f05b-41c9-b95a-1f62e64435af,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-46adc5c6-7b93-4779-a9d4-89203778afa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-c33a31a2-5272-47a6-9f97-6cbf5ddb9479,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-f48e312e-c8d8-4a85-82ee-ffdae2c429d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-f2bbf020-00f9-4a01-9ed3-22861db03cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-8b950e0e-0aaa-48c3-8cf0-5b7b754e62a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-ae56ef9f-7209-40d0-969d-4e78682a0bf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577041167-172.17.0.12-1595989292636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36283,DS-ccc74ccd-510e-4379-9b31-3fa479f2bde2,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-a54b9ad5-f05b-41c9-b95a-1f62e64435af,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-46adc5c6-7b93-4779-a9d4-89203778afa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-c33a31a2-5272-47a6-9f97-6cbf5ddb9479,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-f48e312e-c8d8-4a85-82ee-ffdae2c429d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-f2bbf020-00f9-4a01-9ed3-22861db03cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-8b950e0e-0aaa-48c3-8cf0-5b7b754e62a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-ae56ef9f-7209-40d0-969d-4e78682a0bf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893595458-172.17.0.12-1595989727806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34558,DS-04a396a3-0f1d-42b2-8c5c-e39efe58f30a,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-6b83d1bb-8539-41d5-a8bf-ca279bc52e80,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-0efbe749-4d2b-4fbb-957f-ab4e0b614d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-0ab295cd-ff7a-4be2-97a9-01a1161f6ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-9e9285b7-17ae-4949-80b6-df9346897d18,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-858be59a-feb6-4ab5-827f-6a15ffde37b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-72dd9431-cd17-427c-8347-490c05f4c2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-889860dd-60ae-4bbf-9d70-46e02d04f0b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893595458-172.17.0.12-1595989727806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34558,DS-04a396a3-0f1d-42b2-8c5c-e39efe58f30a,DISK], DatanodeInfoWithStorage[127.0.0.1:34138,DS-6b83d1bb-8539-41d5-a8bf-ca279bc52e80,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-0efbe749-4d2b-4fbb-957f-ab4e0b614d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-0ab295cd-ff7a-4be2-97a9-01a1161f6ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:43925,DS-9e9285b7-17ae-4949-80b6-df9346897d18,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-858be59a-feb6-4ab5-827f-6a15ffde37b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-72dd9431-cd17-427c-8347-490c05f4c2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-889860dd-60ae-4bbf-9d70-46e02d04f0b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1090536827-172.17.0.12-1595991149964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-bff0c803-b31b-4ebe-88cc-fe06c6c35249,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-196a45d1-62ed-4e59-99c5-8e95d3034db8,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-48619d15-a322-4c59-907e-5e07cede16ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-cdb23df8-88da-4fe1-8906-4c797e56cebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-bf3bdcd1-fa0d-45d1-8749-40e314635330,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-07342a30-29ae-46db-a43d-70b78c337e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-b9640f12-91e8-4dce-8348-ddba0152f4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-3bb1bf0d-fbce-418d-b85d-3de6214b7640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1090536827-172.17.0.12-1595991149964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-bff0c803-b31b-4ebe-88cc-fe06c6c35249,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-196a45d1-62ed-4e59-99c5-8e95d3034db8,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-48619d15-a322-4c59-907e-5e07cede16ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-cdb23df8-88da-4fe1-8906-4c797e56cebe,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-bf3bdcd1-fa0d-45d1-8749-40e314635330,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-07342a30-29ae-46db-a43d-70b78c337e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-b9640f12-91e8-4dce-8348-ddba0152f4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-3bb1bf0d-fbce-418d-b85d-3de6214b7640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358215459-172.17.0.12-1595991752963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43071,DS-11e857ff-7703-4584-9e81-e45a8b3fb601,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-6e86fec1-9e62-4756-9bc3-b5a027707dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-50b36ccd-dc9a-43d4-9d99-4d96e35ee41f,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-e9a51b42-6838-4aad-8caf-c2940a8c8b16,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-69578030-1aa8-4d64-aa1d-5cbf6fab1af7,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-d9bf02d4-2ebc-44d0-8385-c2243942752a,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-9edc0611-c9b1-4184-9db3-fb84dbfcdb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-d049242a-ef6c-48c4-95e3-7c7e3fe1ed3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358215459-172.17.0.12-1595991752963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43071,DS-11e857ff-7703-4584-9e81-e45a8b3fb601,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-6e86fec1-9e62-4756-9bc3-b5a027707dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-50b36ccd-dc9a-43d4-9d99-4d96e35ee41f,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-e9a51b42-6838-4aad-8caf-c2940a8c8b16,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-69578030-1aa8-4d64-aa1d-5cbf6fab1af7,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-d9bf02d4-2ebc-44d0-8385-c2243942752a,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-9edc0611-c9b1-4184-9db3-fb84dbfcdb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-d049242a-ef6c-48c4-95e3-7c7e3fe1ed3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1950324136-172.17.0.12-1595992899038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41973,DS-15b6e02b-ea2b-4b51-b794-de38a368d1af,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-d773c47b-b027-4bdb-867b-e404f1413a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-00a2ec83-8659-4cef-a555-c1d2429cfbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-32832a4c-2e17-486b-8213-f9887c13711a,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-a8a85a5b-ebdc-49fb-b363-2cffcf2c66d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-2669f08b-7f6b-4c16-9e25-c0d75db05c18,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-f97c5226-1fa4-42f3-9a3e-74274c0748ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-501e921e-a328-4711-bca9-0cbd9adcfd8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1950324136-172.17.0.12-1595992899038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41973,DS-15b6e02b-ea2b-4b51-b794-de38a368d1af,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-d773c47b-b027-4bdb-867b-e404f1413a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-00a2ec83-8659-4cef-a555-c1d2429cfbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-32832a4c-2e17-486b-8213-f9887c13711a,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-a8a85a5b-ebdc-49fb-b363-2cffcf2c66d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-2669f08b-7f6b-4c16-9e25-c0d75db05c18,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-f97c5226-1fa4-42f3-9a3e-74274c0748ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-501e921e-a328-4711-bca9-0cbd9adcfd8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client-write-packet-size
component: hdfs:NameNode
v1: 8192
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969896229-172.17.0.12-1595992998516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40733,DS-2fbd9ed5-05e9-49ef-a471-b6625e07b0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-ab87796c-cb19-4140-879b-f8477cfdfce3,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-7c8f6ac6-cb0d-4f15-a997-abaaf2872628,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-bf1bf808-e2c2-483b-ad6c-e197794bebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-38bbff29-162e-4206-abed-161c23ec187d,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-db104628-d986-4a32-b568-4530333be955,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-b862a636-3766-43f0-90da-06618809b588,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-e049108d-ee74-448b-b0e3-b2fea696428c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969896229-172.17.0.12-1595992998516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40733,DS-2fbd9ed5-05e9-49ef-a471-b6625e07b0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-ab87796c-cb19-4140-879b-f8477cfdfce3,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-7c8f6ac6-cb0d-4f15-a997-abaaf2872628,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-bf1bf808-e2c2-483b-ad6c-e197794bebfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-38bbff29-162e-4206-abed-161c23ec187d,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-db104628-d986-4a32-b568-4530333be955,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-b862a636-3766-43f0-90da-06618809b588,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-e049108d-ee74-448b-b0e3-b2fea696428c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 6848
