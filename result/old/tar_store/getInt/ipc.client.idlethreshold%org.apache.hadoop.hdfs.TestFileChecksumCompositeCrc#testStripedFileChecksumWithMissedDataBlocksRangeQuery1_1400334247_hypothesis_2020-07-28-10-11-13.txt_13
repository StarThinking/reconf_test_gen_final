reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62316090-172.17.0.14-1595931091053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40975,DS-c17740eb-5b51-4d3e-bd90-266801d187b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-4eb6762e-aae4-4649-a96d-09534111a715,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-b03d380d-7612-4545-b3bf-6f131e148ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-300ac975-9dde-47c6-b3e7-06570a997e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-494e3005-4335-458a-bed9-3b0735f242e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-ba877a9d-550f-48a9-b4cc-1ab5c21b6804,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-74cf17dd-52c0-4432-bcfa-c0929a01d8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-a04b4f3d-7ee3-46ce-9faf-10313e33173e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-62316090-172.17.0.14-1595931091053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40975,DS-c17740eb-5b51-4d3e-bd90-266801d187b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-4eb6762e-aae4-4649-a96d-09534111a715,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-b03d380d-7612-4545-b3bf-6f131e148ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-300ac975-9dde-47c6-b3e7-06570a997e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-494e3005-4335-458a-bed9-3b0735f242e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-ba877a9d-550f-48a9-b4cc-1ab5c21b6804,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-74cf17dd-52c0-4432-bcfa-c0929a01d8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-a04b4f3d-7ee3-46ce-9faf-10313e33173e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060753406-172.17.0.14-1595932132995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46164,DS-50fdad5c-bace-40d3-8cc4-30fac3d67d00,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-48f2e8bd-e74c-4a0d-822f-01ad7271000b,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-4a8973ad-1cd6-4f8a-bfa6-be134ed85cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-a30b1292-9dd6-47c7-af25-3af114a2446c,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-a18c6800-dde5-426e-9f8f-727dcb352511,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-29ccbf47-c639-4313-a037-f942158bf53a,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-cf08487c-c166-4da7-9e17-ff736e15fbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-13826846-7424-433d-bc44-7206478fa8ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060753406-172.17.0.14-1595932132995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46164,DS-50fdad5c-bace-40d3-8cc4-30fac3d67d00,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-48f2e8bd-e74c-4a0d-822f-01ad7271000b,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-4a8973ad-1cd6-4f8a-bfa6-be134ed85cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-a30b1292-9dd6-47c7-af25-3af114a2446c,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-a18c6800-dde5-426e-9f8f-727dcb352511,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-29ccbf47-c639-4313-a037-f942158bf53a,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-cf08487c-c166-4da7-9e17-ff736e15fbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-13826846-7424-433d-bc44-7206478fa8ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528821602-172.17.0.14-1595932243135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41849,DS-ce033c7e-15c3-4f4f-ac1f-cd930d17b9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-128b85d6-385a-413b-8c9b-813ff1ae5599,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-c75918ba-d44f-43bf-b640-dbda32fa3408,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-1c4213b0-3625-45b4-ba69-6ab9fc1002aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-65e611ad-68c8-49b7-be2c-6b0b96154c61,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-f0745042-11d4-45b6-86b1-6a2e9da83b49,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-035240f0-1dbe-4f36-a68f-98cf20a63fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-025b51f1-e6e9-4158-8df0-680c3d392c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528821602-172.17.0.14-1595932243135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41849,DS-ce033c7e-15c3-4f4f-ac1f-cd930d17b9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-128b85d6-385a-413b-8c9b-813ff1ae5599,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-c75918ba-d44f-43bf-b640-dbda32fa3408,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-1c4213b0-3625-45b4-ba69-6ab9fc1002aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-65e611ad-68c8-49b7-be2c-6b0b96154c61,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-f0745042-11d4-45b6-86b1-6a2e9da83b49,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-035240f0-1dbe-4f36-a68f-98cf20a63fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-025b51f1-e6e9-4158-8df0-680c3d392c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418366562-172.17.0.14-1595932722854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39973,DS-98a6a337-979c-46d5-a8e3-60ac2abfd9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-6fb81deb-dd6a-42f8-a01c-5aa19ff015ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-fce7ed57-cb8f-45e9-94bc-bd8723ab67fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-b2a1be8e-22ef-458a-bd4b-6fd447acdd00,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-950ef202-7642-4ca8-b7a4-2f333578c780,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-dfcb1f2c-6ace-4ee1-a4cd-332d9b0f3590,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-27e8ef39-30a3-4928-804a-d11c59ffb12c,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-d4c7b902-2045-43b1-9526-d9a82e9a908b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418366562-172.17.0.14-1595932722854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39973,DS-98a6a337-979c-46d5-a8e3-60ac2abfd9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-6fb81deb-dd6a-42f8-a01c-5aa19ff015ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-fce7ed57-cb8f-45e9-94bc-bd8723ab67fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-b2a1be8e-22ef-458a-bd4b-6fd447acdd00,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-950ef202-7642-4ca8-b7a4-2f333578c780,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-dfcb1f2c-6ace-4ee1-a4cd-332d9b0f3590,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-27e8ef39-30a3-4928-804a-d11c59ffb12c,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-d4c7b902-2045-43b1-9526-d9a82e9a908b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238195937-172.17.0.14-1595932901523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-2bb62df4-4c21-4a17-b95a-e72b5319f349,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-1f030505-9581-4c38-b1e1-eb4e88eeda91,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-48d17a7d-d2b7-4a92-8fd5-2737cf8f36b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-c7c620c2-1f4b-4569-af8c-a7d5015c3ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-1b3a810e-e2c7-46ee-950b-b7cfe09fa650,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-6cf1cd0e-7b5e-4011-be12-c3babe8c9164,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-35f88174-e17f-410e-9aa5-7b01dd85eeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-5ea892da-203d-47e8-8eb6-15982f319b8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238195937-172.17.0.14-1595932901523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-2bb62df4-4c21-4a17-b95a-e72b5319f349,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-1f030505-9581-4c38-b1e1-eb4e88eeda91,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-48d17a7d-d2b7-4a92-8fd5-2737cf8f36b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-c7c620c2-1f4b-4569-af8c-a7d5015c3ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-1b3a810e-e2c7-46ee-950b-b7cfe09fa650,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-6cf1cd0e-7b5e-4011-be12-c3babe8c9164,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-35f88174-e17f-410e-9aa5-7b01dd85eeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-5ea892da-203d-47e8-8eb6-15982f319b8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943902923-172.17.0.14-1595933063851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46846,DS-6e6e5e20-365f-4051-9875-fb5ea262d518,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-44fab1ef-1adf-438b-888e-723236aabf49,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-3a6597f4-3373-4111-9f8b-a184561d5df2,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-b2685180-1315-4fab-8188-07f9b20b884d,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-4b2b21e6-833a-4771-9842-9482655e7f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-f02d2bba-d55a-42cf-a092-9aa7791090ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-569c2a56-8b6b-4f4b-a8f3-4f19a1c8f007,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-8a3f048a-211e-4b80-83db-87ef4abe0007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943902923-172.17.0.14-1595933063851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46846,DS-6e6e5e20-365f-4051-9875-fb5ea262d518,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-44fab1ef-1adf-438b-888e-723236aabf49,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-3a6597f4-3373-4111-9f8b-a184561d5df2,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-b2685180-1315-4fab-8188-07f9b20b884d,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-4b2b21e6-833a-4771-9842-9482655e7f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-f02d2bba-d55a-42cf-a092-9aa7791090ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-569c2a56-8b6b-4f4b-a8f3-4f19a1c8f007,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-8a3f048a-211e-4b80-83db-87ef4abe0007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520969073-172.17.0.14-1595933316226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43833,DS-e3ef53d8-7f09-4931-9479-d11997eca101,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-05a0ffea-75cd-44c8-b0b3-4dd24dad6c98,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-421f6e22-2617-412a-9242-4ed3540ffe7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-5e49d0c4-96df-4828-9885-e750174a150d,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-7b259364-52aa-4e1e-9543-179dfa41d5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-7a46b0f0-aaf6-466a-b34e-1a1dfb0bcb37,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-e289d0d0-36f7-47bc-961b-274c7754a825,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-de33abc3-3539-493d-b950-1baa4d0714b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520969073-172.17.0.14-1595933316226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43833,DS-e3ef53d8-7f09-4931-9479-d11997eca101,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-05a0ffea-75cd-44c8-b0b3-4dd24dad6c98,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-421f6e22-2617-412a-9242-4ed3540ffe7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-5e49d0c4-96df-4828-9885-e750174a150d,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-7b259364-52aa-4e1e-9543-179dfa41d5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-7a46b0f0-aaf6-466a-b34e-1a1dfb0bcb37,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-e289d0d0-36f7-47bc-961b-274c7754a825,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-de33abc3-3539-493d-b950-1baa4d0714b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050146932-172.17.0.14-1595934809063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36491,DS-04378714-520e-4153-81a7-4c15e419b079,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-509e4cdd-f606-44c5-9dfd-56037f01547b,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-19e3bb32-e521-4dcd-b70f-a9cdaa15c469,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-ba0b4862-821f-4d83-9453-f6200f1438ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-4c2a2ae4-4c59-44e2-bb9b-f87fa9907e16,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-bfe8902b-ec60-4d22-ac45-d20658cbc347,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-2c945b43-6b6f-405d-84da-4fbcf67570e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-50ff5292-9d07-4172-9f06-dc82321810b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050146932-172.17.0.14-1595934809063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36491,DS-04378714-520e-4153-81a7-4c15e419b079,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-509e4cdd-f606-44c5-9dfd-56037f01547b,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-19e3bb32-e521-4dcd-b70f-a9cdaa15c469,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-ba0b4862-821f-4d83-9453-f6200f1438ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-4c2a2ae4-4c59-44e2-bb9b-f87fa9907e16,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-bfe8902b-ec60-4d22-ac45-d20658cbc347,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-2c945b43-6b6f-405d-84da-4fbcf67570e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-50ff5292-9d07-4172-9f06-dc82321810b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548136299-172.17.0.14-1595935037911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44581,DS-07ff45b4-e8a4-451b-890e-d3bf6a803793,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-0709ca8e-b5a9-4aa4-8c9a-7de5c51ad1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-01e250c9-972b-448d-8698-14a597acf91a,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-d2c13c5e-e288-45c6-a627-3f1f513767a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-62914f64-087d-4cd2-be4c-371342208fec,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-e84840f7-740a-4ee1-b884-d393fd47c80a,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-498e38ae-f196-43b7-a0d5-eec887a46491,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-7003d313-5810-4b96-bb6f-585955b4b108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548136299-172.17.0.14-1595935037911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44581,DS-07ff45b4-e8a4-451b-890e-d3bf6a803793,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-0709ca8e-b5a9-4aa4-8c9a-7de5c51ad1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-01e250c9-972b-448d-8698-14a597acf91a,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-d2c13c5e-e288-45c6-a627-3f1f513767a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-62914f64-087d-4cd2-be4c-371342208fec,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-e84840f7-740a-4ee1-b884-d393fd47c80a,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-498e38ae-f196-43b7-a0d5-eec887a46491,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-7003d313-5810-4b96-bb6f-585955b4b108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134268883-172.17.0.14-1595935727603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45897,DS-8845a00b-2a41-4d94-b932-0fed9f4a5e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-c211dccc-a56a-4916-a0ee-6ff86557715c,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-458cb5f1-ee52-4c24-b0c2-1158b0f3b348,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-a5bc7024-f559-4621-8510-8fce3ba86e52,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-9def08d0-afe9-456a-8c98-ab242bdcbe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-b6c08616-4478-426c-9d48-9fd116c7917c,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-ad4beee4-613a-4b27-8ccd-b1f9b0525367,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-0b0f45c3-3462-4ff3-ba3d-cc994445c0b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134268883-172.17.0.14-1595935727603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45897,DS-8845a00b-2a41-4d94-b932-0fed9f4a5e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-c211dccc-a56a-4916-a0ee-6ff86557715c,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-458cb5f1-ee52-4c24-b0c2-1158b0f3b348,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-a5bc7024-f559-4621-8510-8fce3ba86e52,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-9def08d0-afe9-456a-8c98-ab242bdcbe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-b6c08616-4478-426c-9d48-9fd116c7917c,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-ad4beee4-613a-4b27-8ccd-b1f9b0525367,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-0b0f45c3-3462-4ff3-ba3d-cc994445c0b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855716684-172.17.0.14-1595935801933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39713,DS-eeb575f1-17de-4982-8e6d-d4035a4f9993,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-eba1d67b-b557-4273-a720-6b52d2879de8,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-594d1532-22a7-4745-b969-5f4d1b77d478,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-c99d511b-768b-4cc3-a481-72b3df337ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-d99e8d2e-c9fe-41c6-8d89-2472431b9fed,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-a4d2b5a0-44d4-4a98-bf6d-ea03b86980e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-b17a5981-15a1-4372-bc18-6cf841aa47c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-a4cd5a87-2107-4f43-ad5f-70193f96bbfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855716684-172.17.0.14-1595935801933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39713,DS-eeb575f1-17de-4982-8e6d-d4035a4f9993,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-eba1d67b-b557-4273-a720-6b52d2879de8,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-594d1532-22a7-4745-b969-5f4d1b77d478,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-c99d511b-768b-4cc3-a481-72b3df337ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-d99e8d2e-c9fe-41c6-8d89-2472431b9fed,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-a4d2b5a0-44d4-4a98-bf6d-ea03b86980e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-b17a5981-15a1-4372-bc18-6cf841aa47c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-a4cd5a87-2107-4f43-ad5f-70193f96bbfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500555098-172.17.0.14-1595935983598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-c5a83273-c234-4b2f-9634-ba5afd344721,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-fdc8ed2d-3e16-475a-9c1d-1bcc13b03f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-f44e93b9-993b-4390-9f25-4491980ca635,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-878233b9-6942-4085-b37d-e7994c8be1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-5b72e746-827a-4697-bae5-7e1d3be19ece,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-5624d6f0-4623-458b-9c5a-96ade8bfe48e,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-e9064e94-253a-4d35-8a97-92dd5cb68034,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-e8cde66e-d1c2-41bf-a80e-3285e62b7fab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500555098-172.17.0.14-1595935983598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-c5a83273-c234-4b2f-9634-ba5afd344721,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-fdc8ed2d-3e16-475a-9c1d-1bcc13b03f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-f44e93b9-993b-4390-9f25-4491980ca635,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-878233b9-6942-4085-b37d-e7994c8be1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-5b72e746-827a-4697-bae5-7e1d3be19ece,DISK], DatanodeInfoWithStorage[127.0.0.1:44852,DS-5624d6f0-4623-458b-9c5a-96ade8bfe48e,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-e9064e94-253a-4d35-8a97-92dd5cb68034,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-e8cde66e-d1c2-41bf-a80e-3285e62b7fab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045792101-172.17.0.14-1595936310668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46299,DS-2ebfecdc-2cdc-413e-b8ca-02f62248042f,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-fe99637b-a2d9-4e69-ad2b-f61f63409789,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-8b15f69c-5b0e-4340-a90b-5ceb6e3a7a21,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-1e1d6623-17e7-4b99-9061-7176ccd15dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-c5f94cde-958a-4fc1-ade0-d4bbf6592c38,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-6696b23e-cc21-45e9-98d5-4caf292a0cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-dd3ba657-fde2-43cb-8161-a248e0c8a0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-0b506881-4fe3-4213-9fa9-a29aa0275104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045792101-172.17.0.14-1595936310668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46299,DS-2ebfecdc-2cdc-413e-b8ca-02f62248042f,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-fe99637b-a2d9-4e69-ad2b-f61f63409789,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-8b15f69c-5b0e-4340-a90b-5ceb6e3a7a21,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-1e1d6623-17e7-4b99-9061-7176ccd15dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-c5f94cde-958a-4fc1-ade0-d4bbf6592c38,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-6696b23e-cc21-45e9-98d5-4caf292a0cff,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-dd3ba657-fde2-43cb-8161-a248e0c8a0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-0b506881-4fe3-4213-9fa9-a29aa0275104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752572498-172.17.0.14-1595936526793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44417,DS-405344d5-86be-4134-9f68-a1f417d55410,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-bab5c14c-01b3-484f-ad0c-d6361addd0be,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-0cdeb2a3-2951-4a84-a7a7-8c94348ed3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-5563baf8-73c2-4fe5-bf73-07ef357d3f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-0ba09829-3ad6-42c4-ab38-d47a651ef2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-4605034e-a5b3-4a94-aded-7c7929ced0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-e8c431f8-cc0c-40c6-9206-f8a9ac34dcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-f4324a08-0939-4587-8303-8d7c1871ef6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752572498-172.17.0.14-1595936526793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44417,DS-405344d5-86be-4134-9f68-a1f417d55410,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-bab5c14c-01b3-484f-ad0c-d6361addd0be,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-0cdeb2a3-2951-4a84-a7a7-8c94348ed3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-5563baf8-73c2-4fe5-bf73-07ef357d3f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-0ba09829-3ad6-42c4-ab38-d47a651ef2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-4605034e-a5b3-4a94-aded-7c7929ced0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-e8c431f8-cc0c-40c6-9206-f8a9ac34dcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-f4324a08-0939-4587-8303-8d7c1871ef6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995023949-172.17.0.14-1595936562007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39904,DS-6268555f-914a-4916-a53c-623bea2af4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-49911cae-c2a4-460f-ad9f-79ab115e13c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-4676c547-f37f-4147-90f0-7a040a43a34a,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-199ad476-64eb-4209-9e9c-e6ffffefcbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-0cbdec17-5658-4bcb-99cf-fd47ba8bd2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-88c25bcf-fc4e-4f79-adcd-10a60d0f9bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-bf8f8a96-19b8-4aa6-84b2-8820e10c6484,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-4c83e4e9-1734-44bf-959b-7e55f06059e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995023949-172.17.0.14-1595936562007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39904,DS-6268555f-914a-4916-a53c-623bea2af4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-49911cae-c2a4-460f-ad9f-79ab115e13c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-4676c547-f37f-4147-90f0-7a040a43a34a,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-199ad476-64eb-4209-9e9c-e6ffffefcbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34113,DS-0cbdec17-5658-4bcb-99cf-fd47ba8bd2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-88c25bcf-fc4e-4f79-adcd-10a60d0f9bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-bf8f8a96-19b8-4aa6-84b2-8820e10c6484,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-4c83e4e9-1734-44bf-959b-7e55f06059e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5502
