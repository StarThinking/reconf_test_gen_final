reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169837692-172.17.0.13-1595552202850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44033,DS-ec74b57c-59fa-4c6b-931b-de28538f3e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-4b00a7d7-5045-4ae1-83c2-174da740f3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-ca8fc46e-2e98-4533-bfae-4e43b3877312,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-9c78fe90-ef4c-4aa1-91a2-7d938a194e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-70af8322-e4c1-473a-b308-e8213d36ef46,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-6fff3a66-7e40-45e7-bcac-c70a60696cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-06016a42-fb1c-4ffc-a0b9-4472efe68c63,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-4807fd6c-b6b2-48d7-acd2-9beb298bca5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169837692-172.17.0.13-1595552202850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44033,DS-ec74b57c-59fa-4c6b-931b-de28538f3e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-4b00a7d7-5045-4ae1-83c2-174da740f3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-ca8fc46e-2e98-4533-bfae-4e43b3877312,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-9c78fe90-ef4c-4aa1-91a2-7d938a194e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-70af8322-e4c1-473a-b308-e8213d36ef46,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-6fff3a66-7e40-45e7-bcac-c70a60696cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-06016a42-fb1c-4ffc-a0b9-4472efe68c63,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-4807fd6c-b6b2-48d7-acd2-9beb298bca5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727869132-172.17.0.13-1595552443399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45362,DS-9fcbc404-bc11-4264-87a4-1c79cc01d181,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-1c61e4a1-e362-43a0-9357-9fe4a0d47ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-4fec1187-97c7-41f5-ad01-d84204daeac8,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-41b0a4f2-5ff8-4354-a908-0cd89799c208,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-da36d836-31bd-466a-9b0f-78cdaeb8282d,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-312011b4-e6e2-49bd-a6ce-b308902ab2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-1e90d6c5-7e16-470d-8d08-a4704e267433,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-a1a46711-30f6-4ca8-b2c5-b22967634c04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727869132-172.17.0.13-1595552443399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45362,DS-9fcbc404-bc11-4264-87a4-1c79cc01d181,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-1c61e4a1-e362-43a0-9357-9fe4a0d47ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-4fec1187-97c7-41f5-ad01-d84204daeac8,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-41b0a4f2-5ff8-4354-a908-0cd89799c208,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-da36d836-31bd-466a-9b0f-78cdaeb8282d,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-312011b4-e6e2-49bd-a6ce-b308902ab2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-1e90d6c5-7e16-470d-8d08-a4704e267433,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-a1a46711-30f6-4ca8-b2c5-b22967634c04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489841240-172.17.0.13-1595552909856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34330,DS-39a8fdcf-76d3-4620-b223-51b31a5fbd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-4ac791fa-7e6f-4c47-abd8-891369ef8d05,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-0a260173-4175-401e-a485-95b692f86ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-7de9e3f6-4c79-4012-bc94-cf9caacd5f49,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-566ab405-2a0f-4fe7-8aa6-32a6d5a98c46,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-538ddce8-e488-4a13-bcc0-87631941203e,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-ba04faa5-cdd5-49a0-a9dc-2a30da7ef886,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-3bb3d692-5734-4390-ad4a-1391553f49cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489841240-172.17.0.13-1595552909856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34330,DS-39a8fdcf-76d3-4620-b223-51b31a5fbd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-4ac791fa-7e6f-4c47-abd8-891369ef8d05,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-0a260173-4175-401e-a485-95b692f86ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-7de9e3f6-4c79-4012-bc94-cf9caacd5f49,DISK], DatanodeInfoWithStorage[127.0.0.1:41282,DS-566ab405-2a0f-4fe7-8aa6-32a6d5a98c46,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-538ddce8-e488-4a13-bcc0-87631941203e,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-ba04faa5-cdd5-49a0-a9dc-2a30da7ef886,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-3bb3d692-5734-4390-ad4a-1391553f49cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558263537-172.17.0.13-1595552941219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40645,DS-854f1acd-ec08-4e3f-ac1d-994af3db9870,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-3889f27c-8002-4c24-9e31-51fa1c54487a,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-04a1dd9f-5715-422b-bdd7-3bfc581ce9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-8e56fbc0-931e-404e-abe4-5ad455027f35,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-761731f6-7336-456f-8bb9-d0738878a00f,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-cfb3e54d-144a-4877-94af-a1b3551bcb78,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-eeecd091-9d95-4ec6-a654-3391c37ddbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-717ee663-a229-4efd-bb13-3b9bf76eaba7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558263537-172.17.0.13-1595552941219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40645,DS-854f1acd-ec08-4e3f-ac1d-994af3db9870,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-3889f27c-8002-4c24-9e31-51fa1c54487a,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-04a1dd9f-5715-422b-bdd7-3bfc581ce9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-8e56fbc0-931e-404e-abe4-5ad455027f35,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-761731f6-7336-456f-8bb9-d0738878a00f,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-cfb3e54d-144a-4877-94af-a1b3551bcb78,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-eeecd091-9d95-4ec6-a654-3391c37ddbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-717ee663-a229-4efd-bb13-3b9bf76eaba7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853258620-172.17.0.13-1595553016990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41562,DS-f5253853-28ff-4e2b-80e0-341739918fab,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-3bbf8009-6629-47ff-a14e-5699119bb668,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-ca647141-7aad-4634-9372-f01b807e92f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-e7d5a877-1a4f-465b-9447-1498d6200833,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-b8033d59-83aa-4083-a6c6-969dac0d1e65,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-2ef783e6-3a70-4101-8b56-e438943ada38,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-e4ea41eb-4c71-470f-83c2-dad5a7a99df7,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-977afed4-6b8f-4f54-994c-43a2ef847f95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1853258620-172.17.0.13-1595553016990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41562,DS-f5253853-28ff-4e2b-80e0-341739918fab,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-3bbf8009-6629-47ff-a14e-5699119bb668,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-ca647141-7aad-4634-9372-f01b807e92f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-e7d5a877-1a4f-465b-9447-1498d6200833,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-b8033d59-83aa-4083-a6c6-969dac0d1e65,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-2ef783e6-3a70-4101-8b56-e438943ada38,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-e4ea41eb-4c71-470f-83c2-dad5a7a99df7,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-977afed4-6b8f-4f54-994c-43a2ef847f95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967196134-172.17.0.13-1595553369417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44038,DS-e63dae66-3d59-4c4c-96d1-ebdeda3f8d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-fafa48fb-49b8-4a57-86bc-9dbc55377820,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-854a548c-b4c1-4aef-b71a-94ca1f045150,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-719e8edd-2feb-4ca5-b8ec-d3ea302a263a,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-1736905b-7ef7-4354-8b53-854db812e624,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-f43695ea-8b66-48a7-85cf-5ce4498fbdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-ea2344bd-12e4-401a-936a-98da9feecaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-e2def46c-b41b-4bbc-9e8f-18bcf1d6f580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967196134-172.17.0.13-1595553369417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44038,DS-e63dae66-3d59-4c4c-96d1-ebdeda3f8d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-fafa48fb-49b8-4a57-86bc-9dbc55377820,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-854a548c-b4c1-4aef-b71a-94ca1f045150,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-719e8edd-2feb-4ca5-b8ec-d3ea302a263a,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-1736905b-7ef7-4354-8b53-854db812e624,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-f43695ea-8b66-48a7-85cf-5ce4498fbdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-ea2344bd-12e4-401a-936a-98da9feecaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-e2def46c-b41b-4bbc-9e8f-18bcf1d6f580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789204752-172.17.0.13-1595553797539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43416,DS-6b32b6f3-ac5f-46f4-9c75-74e2e8a7d876,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-000ccf8c-e634-4ae9-9ba1-5eea2a8cb2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-af29b5be-34af-4ffd-8052-2b1b49b7181e,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-ca20b2a6-2bf3-4b24-9417-a13e0bacee05,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-07bfa54c-8439-4341-8d13-e598aa9a6f64,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-1f6ca72c-acdf-49ca-8c09-83d2781c2c96,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-fb2f713d-9010-4960-98cb-71f8bae618e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-84241547-b68f-45bc-b63e-c769016c3530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789204752-172.17.0.13-1595553797539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43416,DS-6b32b6f3-ac5f-46f4-9c75-74e2e8a7d876,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-000ccf8c-e634-4ae9-9ba1-5eea2a8cb2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-af29b5be-34af-4ffd-8052-2b1b49b7181e,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-ca20b2a6-2bf3-4b24-9417-a13e0bacee05,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-07bfa54c-8439-4341-8d13-e598aa9a6f64,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-1f6ca72c-acdf-49ca-8c09-83d2781c2c96,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-fb2f713d-9010-4960-98cb-71f8bae618e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-84241547-b68f-45bc-b63e-c769016c3530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327375649-172.17.0.13-1595554388083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41486,DS-2c1caaa9-f840-4dcc-ba82-b02c2c14ba72,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-1059d4f0-2a7b-4b50-93b9-dfcc416ba7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-787ff6cd-97b0-4821-a8ae-d61130189e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-414722dc-5b47-4cc5-b925-3fd0e20d982a,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-6e5ab955-ceab-4413-9942-fb04045c11f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-73682f0e-75d6-4661-b504-04cf8de25dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-8f30c6d8-4a54-48e3-9e6a-73f25c88ef45,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-5ff45fb0-deb9-43ec-8798-6c7c2a23bd4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327375649-172.17.0.13-1595554388083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41486,DS-2c1caaa9-f840-4dcc-ba82-b02c2c14ba72,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-1059d4f0-2a7b-4b50-93b9-dfcc416ba7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-787ff6cd-97b0-4821-a8ae-d61130189e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-414722dc-5b47-4cc5-b925-3fd0e20d982a,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-6e5ab955-ceab-4413-9942-fb04045c11f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-73682f0e-75d6-4661-b504-04cf8de25dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-8f30c6d8-4a54-48e3-9e6a-73f25c88ef45,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-5ff45fb0-deb9-43ec-8798-6c7c2a23bd4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803083539-172.17.0.13-1595554717623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43671,DS-bf468c65-2617-4fbc-9c27-c5333520871b,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-c806501f-cfec-4714-be09-ff1e50af5b83,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-9bba42b6-c5d9-473d-9240-746d0783d0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-93d74bf8-6d71-40ba-b4bf-462d0480b845,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-6a1176bc-8572-4e07-83f7-1e29ece112be,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-c7639fcc-d37c-4de5-b4cb-a9f893532d48,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-90e7471e-cfef-4bf1-9360-03acf5a75741,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-01bb1fb8-a095-4931-ba95-feb29d6d6e34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803083539-172.17.0.13-1595554717623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43671,DS-bf468c65-2617-4fbc-9c27-c5333520871b,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-c806501f-cfec-4714-be09-ff1e50af5b83,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-9bba42b6-c5d9-473d-9240-746d0783d0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-93d74bf8-6d71-40ba-b4bf-462d0480b845,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-6a1176bc-8572-4e07-83f7-1e29ece112be,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-c7639fcc-d37c-4de5-b4cb-a9f893532d48,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-90e7471e-cfef-4bf1-9360-03acf5a75741,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-01bb1fb8-a095-4931-ba95-feb29d6d6e34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-164400722-172.17.0.13-1595554877308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33150,DS-f29b5eca-8d61-4140-b24c-ee6bab101cad,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-de4d72ed-8530-4e6c-9987-a74de18943f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-5bea8f90-3467-46c1-95dd-1b212ee67126,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-5d52cd39-4dab-4bbc-a9da-460dad251672,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-ef739519-d8cf-423c-9a97-2abf350406dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-abeea24f-6549-4ffe-ac86-d6f6ca65ef31,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-158b995c-6026-439f-ab4c-8582898c29c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-fbd21ee6-eee6-4b7b-9454-0b87c9405f7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-164400722-172.17.0.13-1595554877308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33150,DS-f29b5eca-8d61-4140-b24c-ee6bab101cad,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-de4d72ed-8530-4e6c-9987-a74de18943f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-5bea8f90-3467-46c1-95dd-1b212ee67126,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-5d52cd39-4dab-4bbc-a9da-460dad251672,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-ef739519-d8cf-423c-9a97-2abf350406dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-abeea24f-6549-4ffe-ac86-d6f6ca65ef31,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-158b995c-6026-439f-ab4c-8582898c29c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-fbd21ee6-eee6-4b7b-9454-0b87c9405f7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416530681-172.17.0.13-1595554950542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43658,DS-949bdabb-0f7a-446a-b0dc-d00713a24434,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-fef34656-9868-451f-aa07-5c0039d6030f,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-e1221547-265d-481b-89b3-35daab910256,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-10d42350-5242-445b-950e-74779212b48a,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-9ac2207a-143d-4158-8bd8-76c256df52ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-9ec842f5-faa6-47cd-bee5-64b2fe01a135,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-caa06b3b-ab56-4f18-9806-47597aaa138e,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-20eb3c47-8427-4c29-aceb-db9952f041d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416530681-172.17.0.13-1595554950542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43658,DS-949bdabb-0f7a-446a-b0dc-d00713a24434,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-fef34656-9868-451f-aa07-5c0039d6030f,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-e1221547-265d-481b-89b3-35daab910256,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-10d42350-5242-445b-950e-74779212b48a,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-9ac2207a-143d-4158-8bd8-76c256df52ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-9ec842f5-faa6-47cd-bee5-64b2fe01a135,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-caa06b3b-ab56-4f18-9806-47597aaa138e,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-20eb3c47-8427-4c29-aceb-db9952f041d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251067145-172.17.0.13-1595555346699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39271,DS-6c2e3b99-18f8-4e2b-8372-280f3d54bda9,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-6e2152c6-44eb-4be9-be1e-8791326d64b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-7e2384b3-6d8d-4b0b-9363-ffd6b78a8ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-ad5a39ae-b048-497b-801a-d6f742b0b891,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-e0cdb2d0-c110-4ec9-8b53-5d6ecf3fd0df,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-dc0f65bc-22f4-4d07-b14a-d9d983920ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-2276c7a4-45f6-4881-b741-7977fc421122,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-41f3ce0e-dc63-4c09-9d8e-6fd426a12865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251067145-172.17.0.13-1595555346699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39271,DS-6c2e3b99-18f8-4e2b-8372-280f3d54bda9,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-6e2152c6-44eb-4be9-be1e-8791326d64b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-7e2384b3-6d8d-4b0b-9363-ffd6b78a8ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-ad5a39ae-b048-497b-801a-d6f742b0b891,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-e0cdb2d0-c110-4ec9-8b53-5d6ecf3fd0df,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-dc0f65bc-22f4-4d07-b14a-d9d983920ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-2276c7a4-45f6-4881-b741-7977fc421122,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-41f3ce0e-dc63-4c09-9d8e-6fd426a12865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662838436-172.17.0.13-1595555432073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37812,DS-2a7a148f-27a0-4abf-88ad-dd8d111661f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-bef64e39-95ab-4fc8-8fb6-161d0874f8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-794c8093-797d-47b6-9627-bf48cc2fefcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-6082dbb6-250d-4780-a805-ce6f423f2ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-7c9676d4-cc25-45df-8288-668a4081102f,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-7b429824-335b-4946-9b64-a95f8c23fb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-879775f0-ab55-4ed5-a83d-42b91b3d3807,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-ed933be8-9526-408f-b51f-99723f8c27cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662838436-172.17.0.13-1595555432073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37812,DS-2a7a148f-27a0-4abf-88ad-dd8d111661f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-bef64e39-95ab-4fc8-8fb6-161d0874f8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-794c8093-797d-47b6-9627-bf48cc2fefcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-6082dbb6-250d-4780-a805-ce6f423f2ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-7c9676d4-cc25-45df-8288-668a4081102f,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-7b429824-335b-4946-9b64-a95f8c23fb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-879775f0-ab55-4ed5-a83d-42b91b3d3807,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-ed933be8-9526-408f-b51f-99723f8c27cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486064967-172.17.0.13-1595555506808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41546,DS-8f529a39-8d5d-47e0-868c-d42f27af12b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-66237d90-a7f3-4da5-a009-4ae1b6b18b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-83bf5acd-ba2e-45d5-9cf5-26c446533d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-eafaa859-0e82-4be4-8fac-4227d81749b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-07383e6b-3e37-49e5-b7aa-d59865eaee6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-5a4d3aac-22fb-417d-b8d6-00eedb980331,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-573652c6-73fe-4a94-8572-3c7463f50dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-8106c4de-747f-4c38-af3c-1f3aa8654c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486064967-172.17.0.13-1595555506808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41546,DS-8f529a39-8d5d-47e0-868c-d42f27af12b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-66237d90-a7f3-4da5-a009-4ae1b6b18b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-83bf5acd-ba2e-45d5-9cf5-26c446533d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-eafaa859-0e82-4be4-8fac-4227d81749b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-07383e6b-3e37-49e5-b7aa-d59865eaee6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-5a4d3aac-22fb-417d-b8d6-00eedb980331,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-573652c6-73fe-4a94-8572-3c7463f50dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-8106c4de-747f-4c38-af3c-1f3aa8654c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7297207-172.17.0.13-1595556120319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38451,DS-59f82c6c-8275-4b89-af8e-707aa2a8308b,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-6fa9e297-7021-4044-aae5-ba1db117c8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-f0c86e66-2930-4b1e-a738-aae9df6a4118,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-8634274b-a646-4820-9613-c0c155bc4419,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-347f3678-2f75-4ed3-b4d2-524d73f2a4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-59dd1667-baaa-4352-aa9f-35565ab12d16,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-a04ee2f8-5ba1-4d7f-933f-39164c855dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-e6e94c72-9cc0-4d09-acf6-31592bcbfd30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7297207-172.17.0.13-1595556120319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38451,DS-59f82c6c-8275-4b89-af8e-707aa2a8308b,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-6fa9e297-7021-4044-aae5-ba1db117c8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-f0c86e66-2930-4b1e-a738-aae9df6a4118,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-8634274b-a646-4820-9613-c0c155bc4419,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-347f3678-2f75-4ed3-b4d2-524d73f2a4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-59dd1667-baaa-4352-aa9f-35565ab12d16,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-a04ee2f8-5ba1-4d7f-933f-39164c855dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-e6e94c72-9cc0-4d09-acf6-31592bcbfd30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040477654-172.17.0.13-1595556556225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41670,DS-8379182c-6724-4350-aae2-eb3a36942104,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-e9c4f3d7-9427-40f4-bb51-8ee4719af505,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-eefa4197-2d8e-4f79-baef-0f4e8895feab,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-6e883b2e-7bd8-45c9-bca7-497c38ba68a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-2f69e9d3-1684-4b77-b9b5-ec5661494e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-e1388cc5-a061-4cd4-bb51-740b680b8624,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-3040aacd-16ef-4da9-a2d2-32726525633a,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-8107ccb8-57b2-4f93-a0e6-7a13b1e19145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040477654-172.17.0.13-1595556556225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41670,DS-8379182c-6724-4350-aae2-eb3a36942104,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-e9c4f3d7-9427-40f4-bb51-8ee4719af505,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-eefa4197-2d8e-4f79-baef-0f4e8895feab,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-6e883b2e-7bd8-45c9-bca7-497c38ba68a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-2f69e9d3-1684-4b77-b9b5-ec5661494e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-e1388cc5-a061-4cd4-bb51-740b680b8624,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-3040aacd-16ef-4da9-a2d2-32726525633a,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-8107ccb8-57b2-4f93-a0e6-7a13b1e19145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448108479-172.17.0.13-1595556689979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-81ff01cd-b179-4614-82ba-4b59c6daf92f,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-94ea5b89-eac6-4a3d-8f71-7264c75f2e89,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-8ea5c6e9-1eb5-437f-b47c-9b4711502905,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-7e445a13-1c66-4222-9b3e-93eea8fc7189,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-fd3d2d1c-68ca-4ab6-a1e1-48f850f4f1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-01e1b7cc-95cf-4031-8b4b-4cbdf7a0824e,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-0eb187c5-a97e-4f6a-accb-b7ed731a8e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-8cbdf774-65b1-4c1c-87b7-dd17633d9cb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448108479-172.17.0.13-1595556689979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-81ff01cd-b179-4614-82ba-4b59c6daf92f,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-94ea5b89-eac6-4a3d-8f71-7264c75f2e89,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-8ea5c6e9-1eb5-437f-b47c-9b4711502905,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-7e445a13-1c66-4222-9b3e-93eea8fc7189,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-fd3d2d1c-68ca-4ab6-a1e1-48f850f4f1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-01e1b7cc-95cf-4031-8b4b-4cbdf7a0824e,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-0eb187c5-a97e-4f6a-accb-b7ed731a8e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-8cbdf774-65b1-4c1c-87b7-dd17633d9cb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-11466169-172.17.0.13-1595557070466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36003,DS-3271f99b-dd6a-41dd-937f-bf0cd66abf04,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-3c2b6ce0-786f-4c09-8cc1-cb8b159dd86a,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-42d555e2-0e38-4eb0-b6dc-f0a08a785c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-5f817989-2519-490b-80e4-0aa52f7d3146,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-b2d25535-54ab-4687-9d59-10e0e9a17d63,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-79f76018-dbd4-49e7-b22e-72f545b861fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-f03717cc-85e8-4006-9692-a4efdbc3f871,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-5849ee8a-0174-461e-8555-915a0c4244c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-11466169-172.17.0.13-1595557070466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36003,DS-3271f99b-dd6a-41dd-937f-bf0cd66abf04,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-3c2b6ce0-786f-4c09-8cc1-cb8b159dd86a,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-42d555e2-0e38-4eb0-b6dc-f0a08a785c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-5f817989-2519-490b-80e4-0aa52f7d3146,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-b2d25535-54ab-4687-9d59-10e0e9a17d63,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-79f76018-dbd4-49e7-b22e-72f545b861fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-f03717cc-85e8-4006-9692-a4efdbc3f871,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-5849ee8a-0174-461e-8555-915a0c4244c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852774096-172.17.0.13-1595557108651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45776,DS-f01ec83d-faf1-4a88-8f73-22888f22e811,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-6fa94f89-a752-4c11-9b89-83bf97ee7410,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-eca3e417-44a7-4411-af39-38bfd8056e24,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-b472641d-d329-4340-9a4f-ec15e165208b,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-e296bd4c-bfd5-46a5-8ef4-9294e5ccf10d,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-17328036-f6dd-443b-b7af-8f02de807f66,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-1c7f76a3-5d86-484f-afa8-1fae596d9a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-667944b5-6ca5-4998-aa48-fac32db0377c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852774096-172.17.0.13-1595557108651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45776,DS-f01ec83d-faf1-4a88-8f73-22888f22e811,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-6fa94f89-a752-4c11-9b89-83bf97ee7410,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-eca3e417-44a7-4411-af39-38bfd8056e24,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-b472641d-d329-4340-9a4f-ec15e165208b,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-e296bd4c-bfd5-46a5-8ef4-9294e5ccf10d,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-17328036-f6dd-443b-b7af-8f02de807f66,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-1c7f76a3-5d86-484f-afa8-1fae596d9a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-667944b5-6ca5-4998-aa48-fac32db0377c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995298806-172.17.0.13-1595557180633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34557,DS-af896233-1124-4a7c-b391-51fe23bbb9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-1259d48e-ba82-4aab-af54-090bb46ddb77,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-60b36e8b-2fc7-4fbd-b70b-ca0b963c9fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-9ab56e9e-9f55-4c31-aba6-33555107d3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-da4daae4-60b3-4372-9a06-0e77b6bb5a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-2980f6d6-0db7-4a5d-8f74-86181a1eb5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-3ade8b42-07d7-4f14-a7eb-c745fd47d1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-a078011a-aaaa-4658-8fbb-f691e75d9803,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995298806-172.17.0.13-1595557180633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34557,DS-af896233-1124-4a7c-b391-51fe23bbb9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-1259d48e-ba82-4aab-af54-090bb46ddb77,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-60b36e8b-2fc7-4fbd-b70b-ca0b963c9fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-9ab56e9e-9f55-4c31-aba6-33555107d3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-da4daae4-60b3-4372-9a06-0e77b6bb5a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-2980f6d6-0db7-4a5d-8f74-86181a1eb5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-3ade8b42-07d7-4f14-a7eb-c745fd47d1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-a078011a-aaaa-4658-8fbb-f691e75d9803,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102377804-172.17.0.13-1595557219420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39975,DS-9d63a6c0-c6c4-47c4-9ef4-8380f11f50b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-bbd5e43c-40b4-4e6d-8b6a-9fe6f9732f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-5f33f384-c2f2-4f1a-b10c-24fcfe8eae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-cf3a2bf9-356a-41a9-b1db-adb1c9bcfd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-0af3f4dd-ccc4-4689-bd44-3c5b96fee1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-1eda71d7-8889-4e22-b706-02c2bb907610,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-46ae58b7-9067-4290-84af-e6c7006abc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-703ed978-0fc8-4065-ac7e-9c5747c7fc4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102377804-172.17.0.13-1595557219420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39975,DS-9d63a6c0-c6c4-47c4-9ef4-8380f11f50b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-bbd5e43c-40b4-4e6d-8b6a-9fe6f9732f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-5f33f384-c2f2-4f1a-b10c-24fcfe8eae2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-cf3a2bf9-356a-41a9-b1db-adb1c9bcfd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-0af3f4dd-ccc4-4689-bd44-3c5b96fee1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-1eda71d7-8889-4e22-b706-02c2bb907610,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-46ae58b7-9067-4290-84af-e6c7006abc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-703ed978-0fc8-4065-ac7e-9c5747c7fc4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.max.attempts
component: hdfs:NameNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065018900-172.17.0.13-1595557557161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44947,DS-585380c2-c490-4394-8a2f-72a8eae0b9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-e618d3fb-ca76-4009-9b4f-29925e57739a,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-f1511b4b-0eb2-4a48-bf8f-2c6add303977,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-7a468d7c-3596-454e-ac55-31ebc3e47a49,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-54a8f214-2b43-40df-b4e9-4684990e64ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-2d80e0e5-460d-4c83-b51d-fa06811f5c94,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-7c1de09d-bdf0-428e-8d63-4276378230ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-07eaaa8b-c29d-46de-aaad-16c5f503e913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065018900-172.17.0.13-1595557557161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44947,DS-585380c2-c490-4394-8a2f-72a8eae0b9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-e618d3fb-ca76-4009-9b4f-29925e57739a,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-f1511b4b-0eb2-4a48-bf8f-2c6add303977,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-7a468d7c-3596-454e-ac55-31ebc3e47a49,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-54a8f214-2b43-40df-b4e9-4684990e64ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-2d80e0e5-460d-4c83-b51d-fa06811f5c94,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-7c1de09d-bdf0-428e-8d63-4276378230ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-07eaaa8b-c29d-46de-aaad-16c5f503e913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5645
