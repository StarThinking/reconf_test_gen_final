reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130111804-172.17.0.11-1595850990185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38596,DS-661480a3-2ff3-4092-9a30-c10ea909a86b,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-f47916cb-d3e1-47bc-a62c-1c183924b5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-5ad84b3e-f650-4961-be82-77cd3ecebc72,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-09562a88-f43e-46d0-b772-09d06a45f9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-1f2cb940-b7db-4564-b40b-6f7a7e652e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-54873b92-40de-48b0-8806-a317da998c32,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-a79e98c4-f133-4ba0-a98f-1b91c872a0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-a2017890-9e1e-4ce1-9cef-6c8a8c0ec79c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130111804-172.17.0.11-1595850990185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38596,DS-661480a3-2ff3-4092-9a30-c10ea909a86b,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-f47916cb-d3e1-47bc-a62c-1c183924b5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-5ad84b3e-f650-4961-be82-77cd3ecebc72,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-09562a88-f43e-46d0-b772-09d06a45f9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-1f2cb940-b7db-4564-b40b-6f7a7e652e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-54873b92-40de-48b0-8806-a317da998c32,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-a79e98c4-f133-4ba0-a98f-1b91c872a0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-a2017890-9e1e-4ce1-9cef-6c8a8c0ec79c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362187849-172.17.0.11-1595851099314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-ea8e8117-77bd-490a-bc92-4c1d1a3091ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-53a5e3df-7e00-444c-ba0e-61b7b15436ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-6868fd74-7761-4637-b9a6-d9c8a787af18,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-c7862522-3def-434f-947d-94b295df15d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-3b1e2c9a-79a8-46a9-b04a-eadb2da7c5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-cb320d96-fedb-480b-9b9e-d4555310e2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-3f34eed8-936e-44da-9fd2-26c6cc459ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-664d8d1a-95d6-44e0-83e7-464868200425,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362187849-172.17.0.11-1595851099314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42454,DS-ea8e8117-77bd-490a-bc92-4c1d1a3091ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-53a5e3df-7e00-444c-ba0e-61b7b15436ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-6868fd74-7761-4637-b9a6-d9c8a787af18,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-c7862522-3def-434f-947d-94b295df15d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-3b1e2c9a-79a8-46a9-b04a-eadb2da7c5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-cb320d96-fedb-480b-9b9e-d4555310e2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-3f34eed8-936e-44da-9fd2-26c6cc459ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-664d8d1a-95d6-44e0-83e7-464868200425,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183240550-172.17.0.11-1595851184312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37679,DS-0a10cf8c-f1f6-4bb9-b21c-f26324ee7b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-d2b55ff0-afc3-46f1-b3c1-8d4ecd8facf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-a09bdee7-9e81-4cbd-b557-5158e424f8be,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-d6010171-3ed8-43d2-b4db-25739590722b,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-17f84492-5d70-4482-9630-17489be91af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-ef5ac849-d2b0-4947-a8c5-f12660af0b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-b4fec96f-a390-4955-9039-b3b6daaa2820,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-5e56898d-ae29-47b8-8e5f-767e5f4ff9d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183240550-172.17.0.11-1595851184312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37679,DS-0a10cf8c-f1f6-4bb9-b21c-f26324ee7b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-d2b55ff0-afc3-46f1-b3c1-8d4ecd8facf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-a09bdee7-9e81-4cbd-b557-5158e424f8be,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-d6010171-3ed8-43d2-b4db-25739590722b,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-17f84492-5d70-4482-9630-17489be91af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-ef5ac849-d2b0-4947-a8c5-f12660af0b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-b4fec96f-a390-4955-9039-b3b6daaa2820,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-5e56898d-ae29-47b8-8e5f-767e5f4ff9d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749784220-172.17.0.11-1595851295422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34232,DS-002c3fcf-25dd-46d3-87d7-94c2128423aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-eee370a4-f3e5-4f49-808c-926f2d7a1a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-a02a17e5-2b56-4d0e-b5aa-90a4e5f2b2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-d81a0139-e048-43aa-91c4-e102ec537a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-41348c24-57ed-456c-82f7-acebc95c0247,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-7b8dc4d0-fa60-4f85-bda4-dfb2ca8a93c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-5ca960c5-b255-43c2-92e6-9be989098e78,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-bf433c51-08eb-4ac1-9111-eee9b1a6cf87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749784220-172.17.0.11-1595851295422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34232,DS-002c3fcf-25dd-46d3-87d7-94c2128423aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-eee370a4-f3e5-4f49-808c-926f2d7a1a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-a02a17e5-2b56-4d0e-b5aa-90a4e5f2b2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-d81a0139-e048-43aa-91c4-e102ec537a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-41348c24-57ed-456c-82f7-acebc95c0247,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-7b8dc4d0-fa60-4f85-bda4-dfb2ca8a93c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-5ca960c5-b255-43c2-92e6-9be989098e78,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-bf433c51-08eb-4ac1-9111-eee9b1a6cf87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748261668-172.17.0.11-1595851441166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44537,DS-f64b9002-7d1d-45d5-99b8-a8153cbf0aad,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-dbc524a4-df8c-45e5-9ef5-9eefd4c19056,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-e7466b43-d22d-4f14-b503-083371d722e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-7db6769a-8e26-405d-b746-66839656b8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-eba1f28d-0ab9-49ba-9820-127cb7a10974,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-6a3656b7-e4e6-4742-bd81-da8c2e2a5ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-2b26d77c-f187-48a9-af17-8f9249eba423,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-2fa44bb4-a73f-432d-b54a-a16aa635fd0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748261668-172.17.0.11-1595851441166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44537,DS-f64b9002-7d1d-45d5-99b8-a8153cbf0aad,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-dbc524a4-df8c-45e5-9ef5-9eefd4c19056,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-e7466b43-d22d-4f14-b503-083371d722e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-7db6769a-8e26-405d-b746-66839656b8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-eba1f28d-0ab9-49ba-9820-127cb7a10974,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-6a3656b7-e4e6-4742-bd81-da8c2e2a5ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-2b26d77c-f187-48a9-af17-8f9249eba423,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-2fa44bb4-a73f-432d-b54a-a16aa635fd0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121612989-172.17.0.11-1595851521533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43616,DS-20da7b06-358e-44bc-8b26-03426bdfe91b,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-877e5160-c055-4064-a9f9-520abc429b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-da1b8d0f-0a79-41fc-be37-cff0de3c60ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-855078ab-bb5a-4eb7-a6cf-3ade10f76c58,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-1281462d-500a-477c-b103-c9c4a7e5fef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-c923626b-4194-4144-9344-f00d2b60c260,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-086e1904-1434-4a94-b299-bb8f70a7cc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-28464fd4-9d32-4ead-b9da-7d332273e504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121612989-172.17.0.11-1595851521533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43616,DS-20da7b06-358e-44bc-8b26-03426bdfe91b,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-877e5160-c055-4064-a9f9-520abc429b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-da1b8d0f-0a79-41fc-be37-cff0de3c60ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-855078ab-bb5a-4eb7-a6cf-3ade10f76c58,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-1281462d-500a-477c-b103-c9c4a7e5fef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-c923626b-4194-4144-9344-f00d2b60c260,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-086e1904-1434-4a94-b299-bb8f70a7cc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-28464fd4-9d32-4ead-b9da-7d332273e504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818511655-172.17.0.11-1595851702659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-18ed2014-e043-4b7e-a101-a5bb15dbd489,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-8b19fef7-72b2-4b25-a967-f38d216b5a89,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-4e584354-865f-4b47-b121-91ec564bf382,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-2b600efc-414d-41df-840b-b8806329ad39,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-5d8f3930-0fae-437c-b4b0-e0c155318921,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-ff42ab49-15c7-457c-be23-88684bc0ed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-8a312760-692a-401d-9ebd-71cca0547b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-03c5aeb3-f23a-45bb-9f01-5fc6464951ae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818511655-172.17.0.11-1595851702659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38154,DS-18ed2014-e043-4b7e-a101-a5bb15dbd489,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-8b19fef7-72b2-4b25-a967-f38d216b5a89,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-4e584354-865f-4b47-b121-91ec564bf382,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-2b600efc-414d-41df-840b-b8806329ad39,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-5d8f3930-0fae-437c-b4b0-e0c155318921,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-ff42ab49-15c7-457c-be23-88684bc0ed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-8a312760-692a-401d-9ebd-71cca0547b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-03c5aeb3-f23a-45bb-9f01-5fc6464951ae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479932356-172.17.0.11-1595851741256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-a1914093-b4c8-4d4e-b989-f7b173c88efd,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-1b843d08-d520-40d0-b14f-1ec6acbd53f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-bde5ed1a-371c-4fb0-8a54-8e1bb5541171,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-c6125d5c-af12-4ead-83ed-99093fda7888,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-856a76b0-1a94-4b3f-b34c-aeb2e9763cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-d87244dc-ed0e-49ee-801b-7bf23c6bf940,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-551e3f6a-d3d8-4dcc-aa71-1db102590a27,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-2fd44c99-8c94-4680-ad1f-2d9b6846ca09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-479932356-172.17.0.11-1595851741256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33463,DS-a1914093-b4c8-4d4e-b989-f7b173c88efd,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-1b843d08-d520-40d0-b14f-1ec6acbd53f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-bde5ed1a-371c-4fb0-8a54-8e1bb5541171,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-c6125d5c-af12-4ead-83ed-99093fda7888,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-856a76b0-1a94-4b3f-b34c-aeb2e9763cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-d87244dc-ed0e-49ee-801b-7bf23c6bf940,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-551e3f6a-d3d8-4dcc-aa71-1db102590a27,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-2fd44c99-8c94-4680-ad1f-2d9b6846ca09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141517254-172.17.0.11-1595851897102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34670,DS-2d43c27a-685f-4b07-b7bd-5d00b7ef6065,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-4f577309-9629-4ecb-a5bd-04aff3f8635e,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-b7893940-1074-4e56-80f7-f199262442db,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-3290ce51-c7ef-4290-9985-2ab079fa7774,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-6fc04fa3-40a5-411c-88e9-461803edfa07,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-6ca4cb16-ab1a-47b8-8ccc-7eecc7f7a815,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-d0d2ea70-a421-4c2b-a187-b154fd26fc59,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-9b1a669e-8384-4dd5-b2fe-3fbb675a50fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141517254-172.17.0.11-1595851897102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34670,DS-2d43c27a-685f-4b07-b7bd-5d00b7ef6065,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-4f577309-9629-4ecb-a5bd-04aff3f8635e,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-b7893940-1074-4e56-80f7-f199262442db,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-3290ce51-c7ef-4290-9985-2ab079fa7774,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-6fc04fa3-40a5-411c-88e9-461803edfa07,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-6ca4cb16-ab1a-47b8-8ccc-7eecc7f7a815,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-d0d2ea70-a421-4c2b-a187-b154fd26fc59,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-9b1a669e-8384-4dd5-b2fe-3fbb675a50fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56262213-172.17.0.11-1595852117009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46613,DS-a1df2d8c-80e9-403a-b33d-467580bde047,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-c6c2034e-2d71-4522-8597-ad47382d68dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-04582c8b-e221-48e2-99e9-707fe7c9a5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-adbec704-2688-49ef-8258-0adbec78cb24,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-f4202e55-8664-439d-bfd9-cbcf64397733,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-028818d3-526a-4b0c-91f8-2994df2be72b,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-d12d0898-243f-41e3-b4e6-2f9e6d89812a,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-f9a58574-30ae-4551-8474-657022056a18,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56262213-172.17.0.11-1595852117009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46613,DS-a1df2d8c-80e9-403a-b33d-467580bde047,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-c6c2034e-2d71-4522-8597-ad47382d68dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-04582c8b-e221-48e2-99e9-707fe7c9a5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-adbec704-2688-49ef-8258-0adbec78cb24,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-f4202e55-8664-439d-bfd9-cbcf64397733,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-028818d3-526a-4b0c-91f8-2994df2be72b,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-d12d0898-243f-41e3-b4e6-2f9e6d89812a,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-f9a58574-30ae-4551-8474-657022056a18,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13593307-172.17.0.11-1595852228525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40605,DS-25918444-7cf2-458f-bc2e-0107ea34238a,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-a88dfd41-fbcd-430d-b9d5-7f0cbbad790f,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-52a6927e-6481-40ad-acc5-19d4ed818d14,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-aae889b5-6493-4ed1-938f-d64bdc0a4421,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-01deafbc-5148-4336-b606-2c7ba25c90f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-34cfc834-aa26-4ca9-b579-3a7816617469,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-6a3e5113-3440-4729-b12d-dbf614f0f9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-f882d6e8-8471-41e4-a7bd-373e4be703cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13593307-172.17.0.11-1595852228525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40605,DS-25918444-7cf2-458f-bc2e-0107ea34238a,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-a88dfd41-fbcd-430d-b9d5-7f0cbbad790f,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-52a6927e-6481-40ad-acc5-19d4ed818d14,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-aae889b5-6493-4ed1-938f-d64bdc0a4421,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-01deafbc-5148-4336-b606-2c7ba25c90f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-34cfc834-aa26-4ca9-b579-3a7816617469,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-6a3e5113-3440-4729-b12d-dbf614f0f9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-f882d6e8-8471-41e4-a7bd-373e4be703cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301713019-172.17.0.11-1595852456137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42515,DS-3b66693c-7706-4da1-8980-83d65a5f7afa,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-134ff0ce-f885-4fad-9086-b40426289565,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-fb3cfb13-46e9-4668-83ec-fab912cc402a,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-9cee0e39-847b-47be-a21e-25ce1a2032b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-a4729826-7e66-46e2-aa59-df7e06271ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-8e4fb667-c32c-4657-a488-7ca581768545,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-c9d45193-a55e-4a6e-9363-ea08711050a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-e6d48891-f2bd-455d-a34e-76d71d603f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301713019-172.17.0.11-1595852456137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42515,DS-3b66693c-7706-4da1-8980-83d65a5f7afa,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-134ff0ce-f885-4fad-9086-b40426289565,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-fb3cfb13-46e9-4668-83ec-fab912cc402a,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-9cee0e39-847b-47be-a21e-25ce1a2032b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-a4729826-7e66-46e2-aa59-df7e06271ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-8e4fb667-c32c-4657-a488-7ca581768545,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-c9d45193-a55e-4a6e-9363-ea08711050a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-e6d48891-f2bd-455d-a34e-76d71d603f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133004089-172.17.0.11-1595852723180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44738,DS-6276b946-ce83-4d81-8aa1-653e2ee24fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-239d748d-889b-433d-b612-96551cc52d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-c9c0c853-9da0-40e4-9e6e-7c1d35462ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-d8c37341-ff8e-4cec-a02e-6d4da247532c,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-6b53d545-b83d-4fd1-bc76-7a1396e9f1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-cb7442d5-a87d-49a4-9058-f45b31dc82d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-a39ce632-dae3-4beb-84a7-d891b409a094,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-de7693d6-f4fe-470d-ae43-3888dce0ba2d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133004089-172.17.0.11-1595852723180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44738,DS-6276b946-ce83-4d81-8aa1-653e2ee24fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-239d748d-889b-433d-b612-96551cc52d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-c9c0c853-9da0-40e4-9e6e-7c1d35462ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-d8c37341-ff8e-4cec-a02e-6d4da247532c,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-6b53d545-b83d-4fd1-bc76-7a1396e9f1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-cb7442d5-a87d-49a4-9058-f45b31dc82d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-a39ce632-dae3-4beb-84a7-d891b409a094,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-de7693d6-f4fe-470d-ae43-3888dce0ba2d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328553400-172.17.0.11-1595852757902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39206,DS-b7669100-74c6-401b-bd49-a6652c267f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-263eceab-624a-43be-b844-964216c1d24a,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-6abe4d18-77eb-4a96-b882-319107cac467,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-5a350684-542e-4372-8dc6-35ec286476c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-b646174b-0cea-49d0-a521-b1d051c3cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-89d5d5b9-499e-403d-b8cf-6d5acb53e309,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-5b6bb372-4ef6-4947-ae5e-49c62fa727f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-35f32bfb-1185-4ddb-848c-ae4ff50f41b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328553400-172.17.0.11-1595852757902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39206,DS-b7669100-74c6-401b-bd49-a6652c267f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-263eceab-624a-43be-b844-964216c1d24a,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-6abe4d18-77eb-4a96-b882-319107cac467,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-5a350684-542e-4372-8dc6-35ec286476c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-b646174b-0cea-49d0-a521-b1d051c3cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-89d5d5b9-499e-403d-b8cf-6d5acb53e309,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-5b6bb372-4ef6-4947-ae5e-49c62fa727f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36552,DS-35f32bfb-1185-4ddb-848c-ae4ff50f41b2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141181904-172.17.0.11-1595853216573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-29986b4f-de1e-407e-a159-38573bd32434,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-eafb1bc6-2cfb-4452-b82c-5a5ed7c19ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-dd95662d-1538-4802-ab63-7a440c9014ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-3f7e9d88-71db-46f3-bb0a-33e82bf8639e,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-3d2e9268-4e45-41ef-b785-3fb9afb2e3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-f4b91014-9506-4cf3-b97c-c5f1e23e354f,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-6417031e-49eb-4692-a8e9-0b32f0be6a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-43d651d4-1b76-4857-93d0-d76ace56693c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141181904-172.17.0.11-1595853216573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-29986b4f-de1e-407e-a159-38573bd32434,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-eafb1bc6-2cfb-4452-b82c-5a5ed7c19ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-dd95662d-1538-4802-ab63-7a440c9014ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-3f7e9d88-71db-46f3-bb0a-33e82bf8639e,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-3d2e9268-4e45-41ef-b785-3fb9afb2e3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-f4b91014-9506-4cf3-b97c-c5f1e23e354f,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-6417031e-49eb-4692-a8e9-0b32f0be6a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-43d651d4-1b76-4857-93d0-d76ace56693c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398626737-172.17.0.11-1595853265658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33094,DS-d52669e2-9d12-4fd7-ace0-a813b6712b64,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-b4b5f90e-fe60-4538-ad9d-597405d69f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-99fc5548-6d54-493e-8b33-1a655a67d5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-9d2bfaa6-b0cc-4352-ac3b-c771e0965818,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-41940f27-5c0b-40f2-8473-8dadb8d7e084,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-fee43104-4b33-4af6-be48-5f5b9c010089,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-94b5c77d-951a-48e8-a1df-d77ce22f7ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-44a362d1-ebf9-4f33-bb2b-e47f45a8d00d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398626737-172.17.0.11-1595853265658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33094,DS-d52669e2-9d12-4fd7-ace0-a813b6712b64,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-b4b5f90e-fe60-4538-ad9d-597405d69f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-99fc5548-6d54-493e-8b33-1a655a67d5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-9d2bfaa6-b0cc-4352-ac3b-c771e0965818,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-41940f27-5c0b-40f2-8473-8dadb8d7e084,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-fee43104-4b33-4af6-be48-5f5b9c010089,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-94b5c77d-951a-48e8-a1df-d77ce22f7ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-44a362d1-ebf9-4f33-bb2b-e47f45a8d00d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752925123-172.17.0.11-1595853499576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35614,DS-963ff176-9cee-4e92-8fd0-7d2d67c813a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-502732d3-d20c-41cc-9508-cb3fd30a948e,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-e69dbc0f-1e4c-40b6-af56-c3cd4a8bfe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-6f8f48dd-c729-487f-9c68-5312434b3a72,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-a3258e51-e7ef-4698-ba71-f25ac95a1758,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-502d01cf-22ec-4a8e-a109-6d8f56a34d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-83faabfa-e27c-4d8f-acf5-83c2ed0139b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-059df253-0372-4b46-bb57-e23bedfb4059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-752925123-172.17.0.11-1595853499576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35614,DS-963ff176-9cee-4e92-8fd0-7d2d67c813a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-502732d3-d20c-41cc-9508-cb3fd30a948e,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-e69dbc0f-1e4c-40b6-af56-c3cd4a8bfe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-6f8f48dd-c729-487f-9c68-5312434b3a72,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-a3258e51-e7ef-4698-ba71-f25ac95a1758,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-502d01cf-22ec-4a8e-a109-6d8f56a34d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-83faabfa-e27c-4d8f-acf5-83c2ed0139b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-059df253-0372-4b46-bb57-e23bedfb4059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810632410-172.17.0.11-1595853921917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46825,DS-508e072a-f3b8-4522-9718-088e6d33ecc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-187f1cfe-c010-4af6-84b1-67626f3724cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-e89d3186-ee33-4468-9324-6f9d5a3f40f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-dd4fdfc2-5047-4a7d-892c-3ed2d7ecbe75,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-d0f3d465-7017-4fe9-91da-8f0a68604fac,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-1dd1451b-8f66-484d-8144-260ad562817a,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-80c0a706-43ae-4ff8-81d6-dd8dc7d80d48,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-1cf1845b-e228-48a3-92b3-d18139b6b09d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810632410-172.17.0.11-1595853921917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46825,DS-508e072a-f3b8-4522-9718-088e6d33ecc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-187f1cfe-c010-4af6-84b1-67626f3724cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-e89d3186-ee33-4468-9324-6f9d5a3f40f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38240,DS-dd4fdfc2-5047-4a7d-892c-3ed2d7ecbe75,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-d0f3d465-7017-4fe9-91da-8f0a68604fac,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-1dd1451b-8f66-484d-8144-260ad562817a,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-80c0a706-43ae-4ff8-81d6-dd8dc7d80d48,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-1cf1845b-e228-48a3-92b3-d18139b6b09d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773699615-172.17.0.11-1595854305640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39483,DS-6a21cde8-5666-4266-9903-452e2bba6712,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-52e1907a-8c95-444f-8a4e-4ca9048f7348,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-cc36f33d-ed6d-4c77-8679-418e4c058285,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-b37dba03-31e7-45d9-94e5-b354cbc47694,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-5e13a13d-335b-4a08-9d5f-6898c84798d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-54c576f3-dcb7-4397-90f8-8c280fd1ebf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-a8b95711-b6ec-43b5-8811-fbb93eb01990,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-3476f763-ea85-4a12-bdc0-faad2aed2c88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-773699615-172.17.0.11-1595854305640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39483,DS-6a21cde8-5666-4266-9903-452e2bba6712,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-52e1907a-8c95-444f-8a4e-4ca9048f7348,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-cc36f33d-ed6d-4c77-8679-418e4c058285,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-b37dba03-31e7-45d9-94e5-b354cbc47694,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-5e13a13d-335b-4a08-9d5f-6898c84798d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-54c576f3-dcb7-4397-90f8-8c280fd1ebf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-a8b95711-b6ec-43b5-8811-fbb93eb01990,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-3476f763-ea85-4a12-bdc0-faad2aed2c88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115765496-172.17.0.11-1595854463094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40706,DS-5c4405af-3780-49a7-a77a-564ec0c03633,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-cd64a939-11ca-4512-8f4f-ad68619840e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-8ab53460-9258-4745-8c17-bdb3bc68ff5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-0a2dc71e-9eec-4218-8f66-3f3e6ac58a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-4f5d122f-cc6b-4d09-a464-1043426a2a59,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-ab44e3de-e011-4ae3-9a4b-325afa85b4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-e78a0ff6-c61e-45f4-be6b-209f3239bbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-4c5fc82f-ee4c-4f2e-9f8c-16e068590075,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115765496-172.17.0.11-1595854463094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40706,DS-5c4405af-3780-49a7-a77a-564ec0c03633,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-cd64a939-11ca-4512-8f4f-ad68619840e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-8ab53460-9258-4745-8c17-bdb3bc68ff5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-0a2dc71e-9eec-4218-8f66-3f3e6ac58a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-4f5d122f-cc6b-4d09-a464-1043426a2a59,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-ab44e3de-e011-4ae3-9a4b-325afa85b4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34683,DS-e78a0ff6-c61e-45f4-be6b-209f3239bbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-4c5fc82f-ee4c-4f2e-9f8c-16e068590075,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215773319-172.17.0.11-1595854502024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45757,DS-45917714-9ea6-4247-93d0-ea4a068ac7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-e5f53319-1cda-47c0-8c0c-0341ed62511b,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-b8594b90-fca4-46c4-84bc-e65f77e1d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-aae04b2e-0f4a-4d46-a9d1-57ef3f0552ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-69d43b51-4c8c-421d-a6bd-8fb4e91d6467,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-377d4875-ac3a-47c5-8e6a-0fe22af91752,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-c9144af9-20ea-43dc-b166-58032b9fcf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-d853bad4-1c89-4ab6-857f-8851c179d395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215773319-172.17.0.11-1595854502024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45757,DS-45917714-9ea6-4247-93d0-ea4a068ac7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-e5f53319-1cda-47c0-8c0c-0341ed62511b,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-b8594b90-fca4-46c4-84bc-e65f77e1d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-aae04b2e-0f4a-4d46-a9d1-57ef3f0552ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-69d43b51-4c8c-421d-a6bd-8fb4e91d6467,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-377d4875-ac3a-47c5-8e6a-0fe22af91752,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-c9144af9-20ea-43dc-b166-58032b9fcf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-d853bad4-1c89-4ab6-857f-8851c179d395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981300951-172.17.0.11-1595854618630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40764,DS-c678ff51-e3b7-4844-b537-6b53f4f791b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-09c2238b-3a3c-47e9-92bb-90ea97624b51,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-407379d6-19c1-4aec-b747-9a99ac6173e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-88959b64-6c49-448b-880d-9abee9dcfdda,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-11a95b7d-b6ad-42b7-8b7e-eec53945b4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-0e2fe0a5-5c26-4484-ab79-bd62b54a4b40,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-4b37d037-37e7-46cc-8c0f-226313ffa7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-a027f4b0-473f-4ed0-8fc8-a20d4fc41e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1981300951-172.17.0.11-1595854618630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40764,DS-c678ff51-e3b7-4844-b537-6b53f4f791b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-09c2238b-3a3c-47e9-92bb-90ea97624b51,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-407379d6-19c1-4aec-b747-9a99ac6173e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-88959b64-6c49-448b-880d-9abee9dcfdda,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-11a95b7d-b6ad-42b7-8b7e-eec53945b4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-0e2fe0a5-5c26-4484-ab79-bd62b54a4b40,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-4b37d037-37e7-46cc-8c0f-226313ffa7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-a027f4b0-473f-4ed0-8fc8-a20d4fc41e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076676397-172.17.0.11-1595854862772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43586,DS-319ab20f-d76f-4906-ade0-24f80b8d4430,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-ce4e1505-b553-4214-b281-f785f81409e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-7a68fb88-2708-4038-af75-f96b42379c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-2b47ffdd-5443-4b80-913f-e469062999c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-1d9db036-18ee-4fec-a85e-0c1769f59ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-8bc6043c-b51c-4d9d-aa69-2b27b8ba5b91,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-20276c8e-fce6-42ae-9971-ff28f84198e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-1bde46ba-10ef-4705-9f4e-dc8bc0ca528c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076676397-172.17.0.11-1595854862772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43586,DS-319ab20f-d76f-4906-ade0-24f80b8d4430,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-ce4e1505-b553-4214-b281-f785f81409e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-7a68fb88-2708-4038-af75-f96b42379c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-2b47ffdd-5443-4b80-913f-e469062999c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-1d9db036-18ee-4fec-a85e-0c1769f59ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-8bc6043c-b51c-4d9d-aa69-2b27b8ba5b91,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-20276c8e-fce6-42ae-9971-ff28f84198e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-1bde46ba-10ef-4705-9f4e-dc8bc0ca528c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999304294-172.17.0.11-1595854902144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46145,DS-e2571575-929d-4f02-ac7c-6a271e524785,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-80b32f45-8cf2-4d61-9b3b-5901bb7db2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-40a09172-8365-4b32-b95f-3e9c72eda245,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-49f000f7-1c25-450b-87b4-a62a9b7116c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-35ef6901-f2b5-4e8b-bd69-ea6384689da4,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-4d14cceb-3777-4dff-8427-1abd8b20b69c,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-ac98fda1-c6cb-4dfe-9645-4778db6dde9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-c1977ab2-f00d-44f6-b07a-37bf88ea0cf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999304294-172.17.0.11-1595854902144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46145,DS-e2571575-929d-4f02-ac7c-6a271e524785,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-80b32f45-8cf2-4d61-9b3b-5901bb7db2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-40a09172-8365-4b32-b95f-3e9c72eda245,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-49f000f7-1c25-450b-87b4-a62a9b7116c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-35ef6901-f2b5-4e8b-bd69-ea6384689da4,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-4d14cceb-3777-4dff-8427-1abd8b20b69c,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-ac98fda1-c6cb-4dfe-9645-4778db6dde9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-c1977ab2-f00d-44f6-b07a-37bf88ea0cf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974184243-172.17.0.11-1595855124551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33260,DS-78ee8702-2ecf-4f4a-8fa9-af7951791191,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-f54a733a-60fa-45b0-bb0b-ee1a6b4f23a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-24fa6249-5326-4763-a8fe-c34771fcb6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-6dd9a135-e27e-4347-be4d-1229d477504e,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-502cb09d-580f-4ce9-bf28-6bf891116d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-79840629-5901-455c-8b56-7a0d449ab362,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-02d4f568-8cc4-4efb-ae92-0c9eea274703,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-818b281e-7cd7-4ef9-9cb8-558149265528,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974184243-172.17.0.11-1595855124551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33260,DS-78ee8702-2ecf-4f4a-8fa9-af7951791191,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-f54a733a-60fa-45b0-bb0b-ee1a6b4f23a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-24fa6249-5326-4763-a8fe-c34771fcb6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-6dd9a135-e27e-4347-be4d-1229d477504e,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-502cb09d-580f-4ce9-bf28-6bf891116d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-79840629-5901-455c-8b56-7a0d449ab362,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-02d4f568-8cc4-4efb-ae92-0c9eea274703,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-818b281e-7cd7-4ef9-9cb8-558149265528,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915878268-172.17.0.11-1595855162534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35959,DS-f159c445-fcf9-498e-8d09-0dd931096d48,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-abcebede-1d25-4181-bfb3-bd3f66a22744,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-afef7a78-0b4a-435f-b2e5-8c53307ef05b,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-b00a09cb-0260-41d2-b4e6-aa78098a3b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-67ad4e31-82fb-4daa-bcb3-c0e9f7023d42,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-2a44b28d-c3ce-4c48-ac72-271b2ef1e6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-edc2d21b-dfd8-447f-8bdc-d332430d2d22,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-f48438b1-4843-46ad-9c02-28b8ada646e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915878268-172.17.0.11-1595855162534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35959,DS-f159c445-fcf9-498e-8d09-0dd931096d48,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-abcebede-1d25-4181-bfb3-bd3f66a22744,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-afef7a78-0b4a-435f-b2e5-8c53307ef05b,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-b00a09cb-0260-41d2-b4e6-aa78098a3b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-67ad4e31-82fb-4daa-bcb3-c0e9f7023d42,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-2a44b28d-c3ce-4c48-ac72-271b2ef1e6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-edc2d21b-dfd8-447f-8bdc-d332430d2d22,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-f48438b1-4843-46ad-9c02-28b8ada646e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963393578-172.17.0.11-1595855393418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46281,DS-85eb3db8-bb25-42cc-907d-f1e69d53b9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-bde9711c-9f7d-4239-a77b-43e5a726eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-e96342df-cbb0-4638-b032-65d9c4050dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-3519e7d1-d306-4822-8460-a2e07c4b47df,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-9da9e80e-9efa-4967-9374-1828536c98f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-c2bb76be-aec4-4e26-8b36-cd051c06c8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-e4060dd0-576b-491a-b9a8-7f726da2369a,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-02e39af9-9035-4cbf-9848-4fee72e62078,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963393578-172.17.0.11-1595855393418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46281,DS-85eb3db8-bb25-42cc-907d-f1e69d53b9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-bde9711c-9f7d-4239-a77b-43e5a726eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-e96342df-cbb0-4638-b032-65d9c4050dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-3519e7d1-d306-4822-8460-a2e07c4b47df,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-9da9e80e-9efa-4967-9374-1828536c98f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-c2bb76be-aec4-4e26-8b36-cd051c06c8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-e4060dd0-576b-491a-b9a8-7f726da2369a,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-02e39af9-9035-4cbf-9848-4fee72e62078,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379916997-172.17.0.11-1595855433892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42453,DS-992cc597-316d-4697-ab42-5240c469efa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-cbb311b5-f0af-4ea9-a192-0a38280a2492,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-ac083464-819e-47ab-be13-4748f12651b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-0e9038cb-f3c8-422b-960f-57467e5bac89,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-d1651045-55e2-47ef-afbe-d13008ea7ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-3028b84d-8846-4c36-a3cc-3bf2c357b2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-106700b4-d189-4f9c-9750-362f5acd23b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-b3024b4b-c70d-4cff-86ce-e16fc334f096,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379916997-172.17.0.11-1595855433892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42453,DS-992cc597-316d-4697-ab42-5240c469efa2,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-cbb311b5-f0af-4ea9-a192-0a38280a2492,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-ac083464-819e-47ab-be13-4748f12651b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-0e9038cb-f3c8-422b-960f-57467e5bac89,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-d1651045-55e2-47ef-afbe-d13008ea7ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-3028b84d-8846-4c36-a3cc-3bf2c357b2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-106700b4-d189-4f9c-9750-362f5acd23b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-b3024b4b-c70d-4cff-86ce-e16fc334f096,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58230898-172.17.0.11-1595855927575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44933,DS-5688bfbb-93ed-4d2c-b7be-7e0d5074520a,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-38b747d7-168d-4662-97b0-9ee98fe34688,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-74213e31-2e71-4fb4-9b8d-3e3ae5abb87b,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-46db0121-310e-4e78-a489-8d018017a9be,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-63e14573-e23b-41e1-bcb4-c1fda29a5112,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-42d87dda-7fc4-46c7-8153-a0f532537bac,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-93a129cf-f5e6-4471-afbc-017228e64e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-878cb82a-057d-495b-8171-2590cbdfde31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58230898-172.17.0.11-1595855927575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44933,DS-5688bfbb-93ed-4d2c-b7be-7e0d5074520a,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-38b747d7-168d-4662-97b0-9ee98fe34688,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-74213e31-2e71-4fb4-9b8d-3e3ae5abb87b,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-46db0121-310e-4e78-a489-8d018017a9be,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-63e14573-e23b-41e1-bcb4-c1fda29a5112,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-42d87dda-7fc4-46c7-8153-a0f532537bac,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-93a129cf-f5e6-4471-afbc-017228e64e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-878cb82a-057d-495b-8171-2590cbdfde31,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121262312-172.17.0.11-1595856081548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35493,DS-57a01be9-79e5-4dba-9401-20899497cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-4b8466ed-66b0-43c7-922f-e7e748396935,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-0632be27-aa34-40ce-a02a-62b9ea15b085,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-102f14eb-d62a-4717-9283-562b36482f97,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-1eb6f291-404e-4a9d-8614-9655b19b8db5,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-d6ab1fa6-3c6b-483c-a3e6-c2fdafb7184c,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-17f19f9b-0411-49d0-bc7e-ac5f44164fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-b255e188-5e37-407e-958c-52bcf0f21756,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121262312-172.17.0.11-1595856081548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35493,DS-57a01be9-79e5-4dba-9401-20899497cfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-4b8466ed-66b0-43c7-922f-e7e748396935,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-0632be27-aa34-40ce-a02a-62b9ea15b085,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-102f14eb-d62a-4717-9283-562b36482f97,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-1eb6f291-404e-4a9d-8614-9655b19b8db5,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-d6ab1fa6-3c6b-483c-a3e6-c2fdafb7184c,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-17f19f9b-0411-49d0-bc7e-ac5f44164fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-b255e188-5e37-407e-958c-52bcf0f21756,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259165206-172.17.0.11-1595856377966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42266,DS-1c71550e-2882-4401-b42e-3bd88365af75,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-bda7a3b0-a7d0-4913-a874-4f7a76962f48,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-d2eaac7e-1983-4e3f-aa21-555d6ac1b927,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-f2c08228-d5a2-40a0-b7d5-7a05238b0064,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-6b47f5b0-b7e7-477e-957f-52459070974d,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-0a92a5af-459e-4f70-b711-a38808abf699,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-4f510d41-1dc2-4028-95a9-d34b8b82db8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-4cfea906-0958-4e12-bdaa-8951c7ecc6b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259165206-172.17.0.11-1595856377966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42266,DS-1c71550e-2882-4401-b42e-3bd88365af75,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-bda7a3b0-a7d0-4913-a874-4f7a76962f48,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-d2eaac7e-1983-4e3f-aa21-555d6ac1b927,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-f2c08228-d5a2-40a0-b7d5-7a05238b0064,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-6b47f5b0-b7e7-477e-957f-52459070974d,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-0a92a5af-459e-4f70-b711-a38808abf699,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-4f510d41-1dc2-4028-95a9-d34b8b82db8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-4cfea906-0958-4e12-bdaa-8951c7ecc6b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507493508-172.17.0.11-1595856418780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45615,DS-eda83445-a3c4-42ec-b74f-b7d9603acda2,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-7d1dd749-02e0-4407-994a-cb86a545d6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-1d7a049b-6bcc-4402-9234-4c6ae088101c,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-df9fac2e-f27f-4f07-b829-3cd254979346,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-19f99cbc-4826-4a05-8850-1a4547e54d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-66c3ada5-c126-4e1e-be40-192bfdfdd371,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-f162802d-b37f-45b3-a37a-3a417306fb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-9f2c0aa9-d5df-43b6-b9b5-d33ce0bc8800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507493508-172.17.0.11-1595856418780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45615,DS-eda83445-a3c4-42ec-b74f-b7d9603acda2,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-7d1dd749-02e0-4407-994a-cb86a545d6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-1d7a049b-6bcc-4402-9234-4c6ae088101c,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-df9fac2e-f27f-4f07-b829-3cd254979346,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-19f99cbc-4826-4a05-8850-1a4547e54d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-66c3ada5-c126-4e1e-be40-192bfdfdd371,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-f162802d-b37f-45b3-a37a-3a417306fb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-9f2c0aa9-d5df-43b6-b9b5-d33ce0bc8800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530629148-172.17.0.11-1595856525752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43071,DS-ac90ccaf-607e-4f38-a45b-cb3c2b87984e,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-a191b504-b5c4-4434-89cd-618ce987b201,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-f2bbc5f7-dcdd-40c9-b9cc-20206855d6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-cad8398c-4e11-40b7-99e5-dce38d2729b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-cc9fac43-e068-4689-884a-08acb854f530,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-de9b939a-cfaa-4a5f-83ac-ff0788bf642e,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-fde657b3-4a34-4d76-843b-197fdfac5ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-1cd6e657-df77-4c33-8523-f4d7adbd3714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530629148-172.17.0.11-1595856525752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43071,DS-ac90ccaf-607e-4f38-a45b-cb3c2b87984e,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-a191b504-b5c4-4434-89cd-618ce987b201,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-f2bbc5f7-dcdd-40c9-b9cc-20206855d6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-cad8398c-4e11-40b7-99e5-dce38d2729b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-cc9fac43-e068-4689-884a-08acb854f530,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-de9b939a-cfaa-4a5f-83ac-ff0788bf642e,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-fde657b3-4a34-4d76-843b-197fdfac5ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-1cd6e657-df77-4c33-8523-f4d7adbd3714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79174586-172.17.0.11-1595856625974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44918,DS-33a04825-4bc0-4e70-aeab-0505fd35bd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-d7b0ebae-4742-48f0-86f5-854684fa012f,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-af31fe72-9a5c-4390-90c8-8d144435aa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-7677b2d4-7063-4525-b997-7e521988f93d,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-e27f6d5d-aecb-4208-b3bb-9481914810b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-24b43cb4-77e3-4e44-be49-50c218905c22,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-59e7f0dd-8156-4651-924e-218e7f441695,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-d9188490-4010-47fd-9d5e-5f88f05dd8af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79174586-172.17.0.11-1595856625974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44918,DS-33a04825-4bc0-4e70-aeab-0505fd35bd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-d7b0ebae-4742-48f0-86f5-854684fa012f,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-af31fe72-9a5c-4390-90c8-8d144435aa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-7677b2d4-7063-4525-b997-7e521988f93d,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-e27f6d5d-aecb-4208-b3bb-9481914810b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-24b43cb4-77e3-4e44-be49-50c218905c22,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-59e7f0dd-8156-4651-924e-218e7f441695,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-d9188490-4010-47fd-9d5e-5f88f05dd8af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5703
