reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097930648-172.17.0.7-1595992175334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44664,DS-84513f6d-baf3-4004-9f41-9ee240616bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-ef60a6d0-1d29-4260-a742-2f8930e379a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-10d4a0d5-23fe-458b-99f2-82362f5a45f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-476520c7-aa41-4743-9e90-8a37c1edcdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-95e1fc0f-b5f8-4abf-8507-5b5964adb088,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-3fbe2bf7-98cf-4712-8ead-9298e9201e89,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-033a7d96-ad62-4f6e-b303-531bf2cb796c,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-bb47cb9c-287f-43d3-8784-f4c8cf41ce7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097930648-172.17.0.7-1595992175334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44664,DS-84513f6d-baf3-4004-9f41-9ee240616bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-ef60a6d0-1d29-4260-a742-2f8930e379a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-10d4a0d5-23fe-458b-99f2-82362f5a45f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-476520c7-aa41-4743-9e90-8a37c1edcdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-95e1fc0f-b5f8-4abf-8507-5b5964adb088,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-3fbe2bf7-98cf-4712-8ead-9298e9201e89,DISK], DatanodeInfoWithStorage[127.0.0.1:35068,DS-033a7d96-ad62-4f6e-b303-531bf2cb796c,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-bb47cb9c-287f-43d3-8784-f4c8cf41ce7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536127668-172.17.0.7-1595992350136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43387,DS-46b633d5-e85a-47a6-9413-4d7eb6dd4596,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-21196fb3-37cc-4164-a8ff-eef7f04ccf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-0b1a122e-a525-4211-8818-2981e9acb300,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-0300a981-f5b4-4f9a-88ec-c61d1decf08e,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-2ca14f0e-b784-40cd-821a-441f65448eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-8e528cb6-e6db-45bf-be1b-356d483a1e91,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-02a47706-e7d2-4955-99f0-64120c201e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-88315802-9c89-4d9d-9eb9-6623c3375f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536127668-172.17.0.7-1595992350136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43387,DS-46b633d5-e85a-47a6-9413-4d7eb6dd4596,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-21196fb3-37cc-4164-a8ff-eef7f04ccf0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-0b1a122e-a525-4211-8818-2981e9acb300,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-0300a981-f5b4-4f9a-88ec-c61d1decf08e,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-2ca14f0e-b784-40cd-821a-441f65448eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-8e528cb6-e6db-45bf-be1b-356d483a1e91,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-02a47706-e7d2-4955-99f0-64120c201e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-88315802-9c89-4d9d-9eb9-6623c3375f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620913187-172.17.0.7-1595992385913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39285,DS-5e94c18e-5711-4ff4-923e-689906e1af5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-59e05482-b73e-4598-8eb5-d9ace452c489,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-325f7200-dc06-4024-b21a-9e7fecab4472,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-717ba5ed-8781-4430-8137-d1e2a0e9adeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-32d7755e-a5e7-44fd-921e-578e3a9a5204,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-569b6f98-57ce-48d3-9a5c-5e1badf66675,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-b494ecef-5474-4548-93c0-e93bbfba0025,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-42cbab48-cc0d-43a3-b9a3-654fb3de4f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620913187-172.17.0.7-1595992385913:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39285,DS-5e94c18e-5711-4ff4-923e-689906e1af5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-59e05482-b73e-4598-8eb5-d9ace452c489,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-325f7200-dc06-4024-b21a-9e7fecab4472,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-717ba5ed-8781-4430-8137-d1e2a0e9adeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-32d7755e-a5e7-44fd-921e-578e3a9a5204,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-569b6f98-57ce-48d3-9a5c-5e1badf66675,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-b494ecef-5474-4548-93c0-e93bbfba0025,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-42cbab48-cc0d-43a3-b9a3-654fb3de4f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552374826-172.17.0.7-1595992587455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36184,DS-cbe3f192-4651-4143-8c34-5e7be3ed5583,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-f86f216d-2e86-48b7-88c2-4c6d4fa511d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-2b8c45ff-d5ae-41e5-b1f5-836926ff373f,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-9af273dd-254f-4a70-9fa1-7c0c8ce0cd64,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-e3e439fc-c5d2-4023-af3c-4053a03c922d,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-1dea06cb-8095-49a0-a9aa-f984bdfedf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-da7c13cf-12c6-45b2-847d-af0f549e7402,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-8f9a9a2a-e23e-41fd-95a4-75ff60726a97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552374826-172.17.0.7-1595992587455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36184,DS-cbe3f192-4651-4143-8c34-5e7be3ed5583,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-f86f216d-2e86-48b7-88c2-4c6d4fa511d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-2b8c45ff-d5ae-41e5-b1f5-836926ff373f,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-9af273dd-254f-4a70-9fa1-7c0c8ce0cd64,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-e3e439fc-c5d2-4023-af3c-4053a03c922d,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-1dea06cb-8095-49a0-a9aa-f984bdfedf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-da7c13cf-12c6-45b2-847d-af0f549e7402,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-8f9a9a2a-e23e-41fd-95a4-75ff60726a97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259875075-172.17.0.7-1595992699750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44284,DS-f1a47515-5819-46f1-9384-af754bc5e0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-4d4e35ac-d10a-461f-b8a1-79de96a15902,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-c2c0f2cc-a342-4c27-bb85-59d6f5882484,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-8a5210fb-b010-4c5a-9660-186d824ba8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-2943403a-6425-4fa5-9236-0c2dcbe8fe23,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-7d8123df-67e4-478f-ab72-1af994e189d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-63b242e3-31a3-48f5-aea3-cd8a24ee25ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-4c88255d-9f5d-4ecd-b8f3-cd6517cbff86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259875075-172.17.0.7-1595992699750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44284,DS-f1a47515-5819-46f1-9384-af754bc5e0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-4d4e35ac-d10a-461f-b8a1-79de96a15902,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-c2c0f2cc-a342-4c27-bb85-59d6f5882484,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-8a5210fb-b010-4c5a-9660-186d824ba8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-2943403a-6425-4fa5-9236-0c2dcbe8fe23,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-7d8123df-67e4-478f-ab72-1af994e189d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-63b242e3-31a3-48f5-aea3-cd8a24ee25ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-4c88255d-9f5d-4ecd-b8f3-cd6517cbff86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090470188-172.17.0.7-1595993167252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41165,DS-134b50c3-9892-4b1d-83d9-957d2334699b,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-7d0d5dea-de44-4f10-b16e-e8a1e8667238,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-16b04d91-e6be-4016-8c1d-e7714535bb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-acd77aea-d2f0-497d-9a70-430ae40672e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-0e16ab2d-46bb-4c63-8516-771ec341bdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-a90f8495-a25d-4645-8bae-59491a3babd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-31c4946b-4d7f-4b65-8caa-87921b32bded,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-3e526a49-b92f-4fa5-9cfe-19dc07321984,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2090470188-172.17.0.7-1595993167252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41165,DS-134b50c3-9892-4b1d-83d9-957d2334699b,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-7d0d5dea-de44-4f10-b16e-e8a1e8667238,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-16b04d91-e6be-4016-8c1d-e7714535bb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-acd77aea-d2f0-497d-9a70-430ae40672e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-0e16ab2d-46bb-4c63-8516-771ec341bdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-a90f8495-a25d-4645-8bae-59491a3babd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-31c4946b-4d7f-4b65-8caa-87921b32bded,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-3e526a49-b92f-4fa5-9cfe-19dc07321984,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575682421-172.17.0.7-1595993307950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40665,DS-2489c4d1-0ef3-4378-8a5c-e84da92b48e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-1b369beb-7960-46c5-8129-4406af686e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-da7e93c5-7207-4595-b845-5c1f794f5955,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-29ddb6a9-1475-4694-8b49-3b35c27a04cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-1f06547c-1d9e-4c9b-970d-ce018e297c18,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-d3fd75c6-5b51-47e6-acd1-fedbc9b5ced5,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-aa049164-fab8-4cdf-9843-cd82cee5fab4,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-2bc7b660-a080-4fe0-9793-ec134c980024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575682421-172.17.0.7-1595993307950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40665,DS-2489c4d1-0ef3-4378-8a5c-e84da92b48e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-1b369beb-7960-46c5-8129-4406af686e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-da7e93c5-7207-4595-b845-5c1f794f5955,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-29ddb6a9-1475-4694-8b49-3b35c27a04cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-1f06547c-1d9e-4c9b-970d-ce018e297c18,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-d3fd75c6-5b51-47e6-acd1-fedbc9b5ced5,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-aa049164-fab8-4cdf-9843-cd82cee5fab4,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-2bc7b660-a080-4fe0-9793-ec134c980024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394855599-172.17.0.7-1595994098898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34693,DS-0503691f-a126-4cd1-9d7b-5d86306affc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-45d60343-2b8b-4fa8-aa3b-638f80fc50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-a76c2849-d15d-452e-bfce-7a6827912eed,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-183769dc-9dbf-45a6-81f4-3891005e8640,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-da083364-148f-4df5-96f0-e1d1ddf871b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-560bdf17-d808-43ef-a691-acbb13a3910c,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-bfec9d89-25e7-4ab7-b5a6-dcf398cb3a21,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-1ac65485-5c8b-4057-aef5-ef0d430e451b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394855599-172.17.0.7-1595994098898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34693,DS-0503691f-a126-4cd1-9d7b-5d86306affc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-45d60343-2b8b-4fa8-aa3b-638f80fc50bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-a76c2849-d15d-452e-bfce-7a6827912eed,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-183769dc-9dbf-45a6-81f4-3891005e8640,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-da083364-148f-4df5-96f0-e1d1ddf871b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-560bdf17-d808-43ef-a691-acbb13a3910c,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-bfec9d89-25e7-4ab7-b5a6-dcf398cb3a21,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-1ac65485-5c8b-4057-aef5-ef0d430e451b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905394435-172.17.0.7-1595994553749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34785,DS-c2c1bad5-f562-454d-9544-ebe5cc11ff1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-cbb4d33e-a98d-47c0-b40e-fb74cfbc2153,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-16bd4380-8472-4659-8486-852e5dc9c111,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-69c05d68-2f34-47d3-8e10-8b8d856d0183,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-ee65257f-64b4-4dcc-8038-d3086b384da0,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-f079051d-d88a-468c-b219-ac599063b5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-d4a61aca-01d5-499a-bf52-402f8e33cc58,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-7d4a82b4-157d-4734-b05d-ae89ba8827ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905394435-172.17.0.7-1595994553749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34785,DS-c2c1bad5-f562-454d-9544-ebe5cc11ff1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-cbb4d33e-a98d-47c0-b40e-fb74cfbc2153,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-16bd4380-8472-4659-8486-852e5dc9c111,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-69c05d68-2f34-47d3-8e10-8b8d856d0183,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-ee65257f-64b4-4dcc-8038-d3086b384da0,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-f079051d-d88a-468c-b219-ac599063b5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-d4a61aca-01d5-499a-bf52-402f8e33cc58,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-7d4a82b4-157d-4734-b05d-ae89ba8827ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39346396-172.17.0.7-1595994891542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40474,DS-16c9e3a7-b0c5-4965-8d21-383edbaa2601,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-7d2045be-57b9-40a7-a1fd-8cac0d41d01d,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-ce604df5-28b1-457f-96fd-29eb164dcfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-e0f65c62-b496-43fe-80e1-efa18d2877c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-ae8b68f5-4647-4221-baa0-e78aed9f818c,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-f2df7ee0-7a9c-4a0a-8d27-bdf6d14bc448,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-a29bd36d-df34-425e-bb68-d1dd8056f8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-d61092d5-062c-4988-bd47-b696d2730365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39346396-172.17.0.7-1595994891542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40474,DS-16c9e3a7-b0c5-4965-8d21-383edbaa2601,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-7d2045be-57b9-40a7-a1fd-8cac0d41d01d,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-ce604df5-28b1-457f-96fd-29eb164dcfd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-e0f65c62-b496-43fe-80e1-efa18d2877c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-ae8b68f5-4647-4221-baa0-e78aed9f818c,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-f2df7ee0-7a9c-4a0a-8d27-bdf6d14bc448,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-a29bd36d-df34-425e-bb68-d1dd8056f8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-d61092d5-062c-4988-bd47-b696d2730365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740244224-172.17.0.7-1595995010318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35238,DS-ecf0cb71-2c9e-4462-896f-2d79b95d5145,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-893907e1-5557-46ee-b71e-88f17e45b510,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-9a44c5c1-3665-4248-b42e-2ff2d520dbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-e8795529-3d18-4150-adcb-24b4bf5697bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-4107cfed-018e-4cae-b0d7-546829fd7f52,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-da942214-9ed5-48e8-99da-7239907c4fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-4109cce3-7b0c-4835-a541-a82076877973,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-77a81891-cea4-4ae3-95ea-82e146af944a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740244224-172.17.0.7-1595995010318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35238,DS-ecf0cb71-2c9e-4462-896f-2d79b95d5145,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-893907e1-5557-46ee-b71e-88f17e45b510,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-9a44c5c1-3665-4248-b42e-2ff2d520dbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-e8795529-3d18-4150-adcb-24b4bf5697bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-4107cfed-018e-4cae-b0d7-546829fd7f52,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-da942214-9ed5-48e8-99da-7239907c4fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-4109cce3-7b0c-4835-a541-a82076877973,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-77a81891-cea4-4ae3-95ea-82e146af944a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043892389-172.17.0.7-1595995282643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46491,DS-3b7d5bd6-7b76-413e-84bc-c4ae5d639b83,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-d58cfeb5-0802-4198-b1df-fdb8e6ac89a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-43e643ee-b15e-40ed-856b-8c27c06a8b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-831eeb22-74e1-4882-8b10-2954093db1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-76bd6077-d215-4261-9327-a2fbb1731b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-417b6831-83bb-405a-9479-754b182b5001,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-a6d2707f-15b8-468d-9d97-32e664f740ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-22bf60e0-47fb-4d7b-9ba5-b3e80cb89b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2043892389-172.17.0.7-1595995282643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46491,DS-3b7d5bd6-7b76-413e-84bc-c4ae5d639b83,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-d58cfeb5-0802-4198-b1df-fdb8e6ac89a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-43e643ee-b15e-40ed-856b-8c27c06a8b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-831eeb22-74e1-4882-8b10-2954093db1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43996,DS-76bd6077-d215-4261-9327-a2fbb1731b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-417b6831-83bb-405a-9479-754b182b5001,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-a6d2707f-15b8-468d-9d97-32e664f740ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-22bf60e0-47fb-4d7b-9ba5-b3e80cb89b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323164265-172.17.0.7-1595995390420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45713,DS-429d1403-fb67-489a-8772-59f36e396425,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-cce326e9-3421-465d-a5d1-e59c55317375,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-c42bcc9c-52dd-4841-9dd0-03752020e6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-df285425-a2c2-494e-aeb5-df7a83ca92cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-5e2cf4c2-4758-4e1e-b322-8d26a6be585b,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-d81cffcf-a87a-4a7b-9e60-75292b8b1a24,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-d3638c2b-4f84-425c-a945-97a1a18d6d32,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-e4c1d459-acbe-4135-95e9-9969c0255258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323164265-172.17.0.7-1595995390420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45713,DS-429d1403-fb67-489a-8772-59f36e396425,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-cce326e9-3421-465d-a5d1-e59c55317375,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-c42bcc9c-52dd-4841-9dd0-03752020e6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-df285425-a2c2-494e-aeb5-df7a83ca92cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-5e2cf4c2-4758-4e1e-b322-8d26a6be585b,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-d81cffcf-a87a-4a7b-9e60-75292b8b1a24,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-d3638c2b-4f84-425c-a945-97a1a18d6d32,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-e4c1d459-acbe-4135-95e9-9969c0255258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158288758-172.17.0.7-1595995561463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38650,DS-ecea7c41-be09-4ad5-9097-de445ac5ae31,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-853ee4d3-2f24-4697-ae35-bf422dfb8636,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-3fb15666-71d4-493c-a5f7-dfa45cf141d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-f57e2bbc-c8f2-4581-8faa-7888b28aaedf,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-9c0a3c7d-46d3-4209-a103-b3a250ffe0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-faebefcb-273e-4026-8eef-79d26d49211d,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-012d9c2f-9153-45df-8712-6aabcceb1cca,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-d06c4e01-4d6b-4f0a-980d-1c86036abd98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158288758-172.17.0.7-1595995561463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38650,DS-ecea7c41-be09-4ad5-9097-de445ac5ae31,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-853ee4d3-2f24-4697-ae35-bf422dfb8636,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-3fb15666-71d4-493c-a5f7-dfa45cf141d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-f57e2bbc-c8f2-4581-8faa-7888b28aaedf,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-9c0a3c7d-46d3-4209-a103-b3a250ffe0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-faebefcb-273e-4026-8eef-79d26d49211d,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-012d9c2f-9153-45df-8712-6aabcceb1cca,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-d06c4e01-4d6b-4f0a-980d-1c86036abd98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513433169-172.17.0.7-1595995799748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44878,DS-0c34d628-0acf-4fc5-9aad-09a3b9e88a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-b5b6ff7a-9204-4bb5-aad5-b565616b6acf,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-de4cdebe-410e-462c-95bb-2d73ed67df59,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-c81a5b69-84eb-4366-a65a-3fec2a67b6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-de4909e1-3689-4992-9555-ae5e1633bb02,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-5254d8ed-2b4b-4b11-870d-99f3103daf73,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-d50b57f4-0ffa-4d74-9afb-5a9bc6678921,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-50e8b53a-0ed4-482d-8fc5-9e4bb6cd1a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513433169-172.17.0.7-1595995799748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44878,DS-0c34d628-0acf-4fc5-9aad-09a3b9e88a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-b5b6ff7a-9204-4bb5-aad5-b565616b6acf,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-de4cdebe-410e-462c-95bb-2d73ed67df59,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-c81a5b69-84eb-4366-a65a-3fec2a67b6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-de4909e1-3689-4992-9555-ae5e1633bb02,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-5254d8ed-2b4b-4b11-870d-99f3103daf73,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-d50b57f4-0ffa-4d74-9afb-5a9bc6678921,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-50e8b53a-0ed4-482d-8fc5-9e4bb6cd1a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897655910-172.17.0.7-1595996121230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33698,DS-378f5e71-67c3-435d-8793-49cf5b144633,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-fbb3a528-7f4a-4a22-b3a4-99163af23a50,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-01fac798-df1f-4d34-88cc-373f32780f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-8f7eac03-f15d-4193-a387-bd24ef4e2f42,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-155bc3d6-0772-42ca-83de-448a4a0de555,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-507bbf20-5b0e-40b8-938b-af1c35ea7191,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-06adfd3f-b80f-4c94-b38b-826c94763428,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-92f9124e-2777-472e-aff4-ccaf367dd5f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897655910-172.17.0.7-1595996121230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33698,DS-378f5e71-67c3-435d-8793-49cf5b144633,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-fbb3a528-7f4a-4a22-b3a4-99163af23a50,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-01fac798-df1f-4d34-88cc-373f32780f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-8f7eac03-f15d-4193-a387-bd24ef4e2f42,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-155bc3d6-0772-42ca-83de-448a4a0de555,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-507bbf20-5b0e-40b8-938b-af1c35ea7191,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-06adfd3f-b80f-4c94-b38b-826c94763428,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-92f9124e-2777-472e-aff4-ccaf367dd5f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123209056-172.17.0.7-1595996259387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45181,DS-755113d2-016d-4af3-b8f5-14445afbc45e,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-c12cc1e5-b17c-4fb5-b8ba-ada2863a2f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-29b23a95-8940-4314-a590-76adb690f27f,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-d7805cc0-bc7a-48dc-b377-fbe7927f9d27,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-868c8f55-0b75-477e-be4f-33f3c4e827c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-5f341a56-9fe3-4aa7-b011-144f1ffc060f,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-a4806422-0711-40d3-a6dc-156418958fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-0c8f866e-5c5f-4114-9a39-dfd101d46344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123209056-172.17.0.7-1595996259387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45181,DS-755113d2-016d-4af3-b8f5-14445afbc45e,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-c12cc1e5-b17c-4fb5-b8ba-ada2863a2f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-29b23a95-8940-4314-a590-76adb690f27f,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-d7805cc0-bc7a-48dc-b377-fbe7927f9d27,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-868c8f55-0b75-477e-be4f-33f3c4e827c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-5f341a56-9fe3-4aa7-b011-144f1ffc060f,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-a4806422-0711-40d3-a6dc-156418958fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-0c8f866e-5c5f-4114-9a39-dfd101d46344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990044310-172.17.0.7-1595996318219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35408,DS-079328d7-f1d2-4e7f-8ab6-92a7244689c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-fb8ec3f3-4d9e-4be1-bd14-426268c66ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-6a76ce7b-4517-48bd-b994-fd5b59879ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-41c97fbc-649e-4139-8d78-b49e057ecd30,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-22e6b2b5-f24a-434b-8571-cd497dcbedf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-fd40f5a3-9f5f-49f3-b120-2b6a65c4f333,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-32f477e5-2ef1-497a-87ad-758e1713c3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-a74b1df8-79cd-4bad-a498-ec63b5ff5eae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990044310-172.17.0.7-1595996318219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35408,DS-079328d7-f1d2-4e7f-8ab6-92a7244689c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-fb8ec3f3-4d9e-4be1-bd14-426268c66ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-6a76ce7b-4517-48bd-b994-fd5b59879ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-41c97fbc-649e-4139-8d78-b49e057ecd30,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-22e6b2b5-f24a-434b-8571-cd497dcbedf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-fd40f5a3-9f5f-49f3-b120-2b6a65c4f333,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-32f477e5-2ef1-497a-87ad-758e1713c3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-a74b1df8-79cd-4bad-a498-ec63b5ff5eae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255395016-172.17.0.7-1595996386203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45986,DS-a374afb4-3388-4d54-823f-e233f223c176,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-d89210ec-4b07-488c-a2d5-88af799fbd37,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-d3b62d46-9993-4f52-9165-47407119bc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-f96499c3-4af4-4cd8-81ff-70ce52c9b505,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-171ebf6e-680c-4f58-b9d6-cf52826c4fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-1f12dbd0-692a-47ad-9a98-c1ab8af61382,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-8ca3d9fe-1212-4b36-b566-63c35b4895de,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-2e486d4d-3aac-48c7-a916-baa71c0afe81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255395016-172.17.0.7-1595996386203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45986,DS-a374afb4-3388-4d54-823f-e233f223c176,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-d89210ec-4b07-488c-a2d5-88af799fbd37,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-d3b62d46-9993-4f52-9165-47407119bc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-f96499c3-4af4-4cd8-81ff-70ce52c9b505,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-171ebf6e-680c-4f58-b9d6-cf52826c4fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-1f12dbd0-692a-47ad-9a98-c1ab8af61382,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-8ca3d9fe-1212-4b36-b566-63c35b4895de,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-2e486d4d-3aac-48c7-a916-baa71c0afe81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422752870-172.17.0.7-1595996494701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43513,DS-fe56a3f4-7097-4953-8948-a0d2d20939e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-93ba9bfc-fb58-441c-8c36-2381d4908f73,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-930964cb-5032-49d5-a795-32007472421d,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-54c4ec21-4505-472b-b75a-f97454addcae,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-64229619-40f8-4f0b-90c7-a40b29581e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-e5ebfb35-41b1-4cc4-8a99-6a578b039b78,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-8c8f51cd-6e2c-4218-811b-997654327b96,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-7e17f46b-e176-42d7-a550-5113cd1597d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422752870-172.17.0.7-1595996494701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43513,DS-fe56a3f4-7097-4953-8948-a0d2d20939e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-93ba9bfc-fb58-441c-8c36-2381d4908f73,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-930964cb-5032-49d5-a795-32007472421d,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-54c4ec21-4505-472b-b75a-f97454addcae,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-64229619-40f8-4f0b-90c7-a40b29581e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-e5ebfb35-41b1-4cc4-8a99-6a578b039b78,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-8c8f51cd-6e2c-4218-811b-997654327b96,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-7e17f46b-e176-42d7-a550-5113cd1597d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892135337-172.17.0.7-1595996934901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-0d115876-1b22-4e4b-9fc1-02d40c89adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-c598d1f5-01c3-41ef-bf73-e4b7a88075cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-5a54ac3e-baa5-41ac-8624-13d44c7c861a,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-55284046-236d-42ba-98e0-82c36936bc15,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-a7423f26-c409-4763-a66a-001c25060bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-6952f01e-da23-4291-a120-9512a80b37a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-26371416-6fc5-4c96-ba38-2477e807d1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-008ab537-c6d9-4dae-8169-832f57b01349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892135337-172.17.0.7-1595996934901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-0d115876-1b22-4e4b-9fc1-02d40c89adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-c598d1f5-01c3-41ef-bf73-e4b7a88075cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-5a54ac3e-baa5-41ac-8624-13d44c7c861a,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-55284046-236d-42ba-98e0-82c36936bc15,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-a7423f26-c409-4763-a66a-001c25060bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-6952f01e-da23-4291-a120-9512a80b37a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-26371416-6fc5-4c96-ba38-2477e807d1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-008ab537-c6d9-4dae-8169-832f57b01349,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891194212-172.17.0.7-1595997000017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45708,DS-98dc4beb-28e5-4b96-8ed1-1db9f80294ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-56a8e68e-ea47-4619-9858-e320a45ff52f,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-2eb4f0fe-afbc-4d43-90a3-87c1c8d12f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-23556212-e0fd-42a0-b776-1ab9438cf9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-35c62c45-46fe-4871-9b6a-91f5eda6461c,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-7d61ac12-4113-4d99-8aa9-cf746e4079a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-de1e1dce-2166-4f01-a82f-75a5528baecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-60fce7c6-c2f2-420d-9f25-d3dabd2f08d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891194212-172.17.0.7-1595997000017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45708,DS-98dc4beb-28e5-4b96-8ed1-1db9f80294ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-56a8e68e-ea47-4619-9858-e320a45ff52f,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-2eb4f0fe-afbc-4d43-90a3-87c1c8d12f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-23556212-e0fd-42a0-b776-1ab9438cf9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-35c62c45-46fe-4871-9b6a-91f5eda6461c,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-7d61ac12-4113-4d99-8aa9-cf746e4079a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-de1e1dce-2166-4f01-a82f-75a5528baecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-60fce7c6-c2f2-420d-9f25-d3dabd2f08d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376437850-172.17.0.7-1595997175222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42200,DS-2e7e63b2-7b1e-4d66-a9a1-616e64c177ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-a4de077c-a9d4-4d8d-9df9-d765433cf6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-272ddea3-5aaf-447d-beec-74713fc3c046,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-e5120984-fe9e-497a-81cc-1b64238f3b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-9e38a5ee-dd21-4107-8c7f-cae211d2931d,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-f40671b9-8e6f-4a09-8962-3300b1182292,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-03ad6e48-ee05-4b2d-91f5-305cb40c2e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-58b762fa-8aef-45e9-bb32-d818ac799368,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376437850-172.17.0.7-1595997175222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42200,DS-2e7e63b2-7b1e-4d66-a9a1-616e64c177ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-a4de077c-a9d4-4d8d-9df9-d765433cf6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-272ddea3-5aaf-447d-beec-74713fc3c046,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-e5120984-fe9e-497a-81cc-1b64238f3b18,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-9e38a5ee-dd21-4107-8c7f-cae211d2931d,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-f40671b9-8e6f-4a09-8962-3300b1182292,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-03ad6e48-ee05-4b2d-91f5-305cb40c2e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-58b762fa-8aef-45e9-bb32-d818ac799368,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 1000
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271469070-172.17.0.7-1595997365085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45168,DS-09d4ab3e-e055-4c3a-9084-cde921239dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-47f2661a-76cd-44a4-9998-52d8eb96587e,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-6bb67e03-fe30-4f5d-9349-cd9872cdf5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-c78f787f-b446-480b-8939-be45f512ab7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-5bea10ec-4ebc-456d-adfc-a4881e8ab4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-042be5e5-f78b-40d5-ad60-c2deffd4cef1,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-1a7420c7-aad0-4c33-b38f-1ef5fc241c58,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-435676d4-88f2-46ce-8587-b7dd9fa182c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271469070-172.17.0.7-1595997365085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45168,DS-09d4ab3e-e055-4c3a-9084-cde921239dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-47f2661a-76cd-44a4-9998-52d8eb96587e,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-6bb67e03-fe30-4f5d-9349-cd9872cdf5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-c78f787f-b446-480b-8939-be45f512ab7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-5bea10ec-4ebc-456d-adfc-a4881e8ab4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-042be5e5-f78b-40d5-ad60-c2deffd4cef1,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-1a7420c7-aad0-4c33-b38f-1ef5fc241c58,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-435676d4-88f2-46ce-8587-b7dd9fa182c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5375
