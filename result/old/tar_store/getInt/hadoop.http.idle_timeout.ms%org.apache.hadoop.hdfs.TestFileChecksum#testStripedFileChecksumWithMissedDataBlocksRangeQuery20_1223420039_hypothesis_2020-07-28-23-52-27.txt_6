reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954574740-172.17.0.8-1595980426206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36218,DS-8154b921-9a4f-4699-a799-001333001abe,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-3da4994f-0aac-44e6-8afa-a2bfb1fd7bae,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-5315b99a-af79-4398-beb6-7a6d47eb279a,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-520ffcda-b80c-4c03-8cc3-c2aef4397065,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-ea73aa06-2fd4-4acd-8164-698f2d9c5c00,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-582ca123-4754-4e5b-b468-1dc8ad4b9187,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-105468fe-7089-4d6b-b193-d70e25a4f122,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-7ee6bf81-7d53-4ebb-8922-152b41a91b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954574740-172.17.0.8-1595980426206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36218,DS-8154b921-9a4f-4699-a799-001333001abe,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-3da4994f-0aac-44e6-8afa-a2bfb1fd7bae,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-5315b99a-af79-4398-beb6-7a6d47eb279a,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-520ffcda-b80c-4c03-8cc3-c2aef4397065,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-ea73aa06-2fd4-4acd-8164-698f2d9c5c00,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-582ca123-4754-4e5b-b468-1dc8ad4b9187,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-105468fe-7089-4d6b-b193-d70e25a4f122,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-7ee6bf81-7d53-4ebb-8922-152b41a91b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960666111-172.17.0.8-1595980889771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43884,DS-dfef2758-b758-41dd-aff8-739a0f8137a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-e3eb1227-fdc1-45c9-b4ab-cc331e5c0db8,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-b6eef34f-e493-41c9-8c0f-e00e1ea95bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-12649da1-7c58-421a-ba96-42ce44c3b815,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-428b0d9c-5595-4fed-abb4-c8f39316e68b,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-236e7e8c-4c61-4ff8-8434-b6115fc13e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-b814f61b-3c0d-42e2-b57d-b760ff99f944,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-f0d0880b-02e5-495d-9f27-017ccaf52efd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960666111-172.17.0.8-1595980889771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43884,DS-dfef2758-b758-41dd-aff8-739a0f8137a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-e3eb1227-fdc1-45c9-b4ab-cc331e5c0db8,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-b6eef34f-e493-41c9-8c0f-e00e1ea95bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-12649da1-7c58-421a-ba96-42ce44c3b815,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-428b0d9c-5595-4fed-abb4-c8f39316e68b,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-236e7e8c-4c61-4ff8-8434-b6115fc13e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-b814f61b-3c0d-42e2-b57d-b760ff99f944,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-f0d0880b-02e5-495d-9f27-017ccaf52efd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313146643-172.17.0.8-1595981003072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-47cc20e8-1436-4e37-bbdd-d29b3cc0b3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-c16b4572-469e-41d3-b86b-31d74f256b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-da45ce17-fbac-4826-bdb8-01287912bf97,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-36cb0501-0c53-4ecf-8d3b-173ee4a6267f,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-ec247a40-2e68-422e-a222-7572becc750f,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-46ea5821-a555-4ef1-bf5c-fe06b436f140,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-ea9e218e-3d04-4f2c-a93d-b6f59fc4230d,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-a3727db2-7fd3-45c0-8028-8ca4aa2ea588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313146643-172.17.0.8-1595981003072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39168,DS-47cc20e8-1436-4e37-bbdd-d29b3cc0b3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-c16b4572-469e-41d3-b86b-31d74f256b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-da45ce17-fbac-4826-bdb8-01287912bf97,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-36cb0501-0c53-4ecf-8d3b-173ee4a6267f,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-ec247a40-2e68-422e-a222-7572becc750f,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-46ea5821-a555-4ef1-bf5c-fe06b436f140,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-ea9e218e-3d04-4f2c-a93d-b6f59fc4230d,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-a3727db2-7fd3-45c0-8028-8ca4aa2ea588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-445406290-172.17.0.8-1595981247342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39094,DS-d5d7e704-50a0-4605-8cde-a52d47dd4653,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-822f256d-17b7-4d0a-a01c-563ed4a8c011,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-f5b3de8f-b37d-4ce9-8879-1429db4eabf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-1ccfe762-72ca-4040-9790-69ff48d8622f,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-a9f77bc9-1446-4911-9f32-9fbfdef71423,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-4cc88c41-8190-4596-b8fb-5e27eadad6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-e95cafa9-fdbb-4da5-8b99-c698dc27f9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-35f6932c-aa8b-4673-aeec-74b8c7fccbe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-445406290-172.17.0.8-1595981247342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39094,DS-d5d7e704-50a0-4605-8cde-a52d47dd4653,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-822f256d-17b7-4d0a-a01c-563ed4a8c011,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-f5b3de8f-b37d-4ce9-8879-1429db4eabf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-1ccfe762-72ca-4040-9790-69ff48d8622f,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-a9f77bc9-1446-4911-9f32-9fbfdef71423,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-4cc88c41-8190-4596-b8fb-5e27eadad6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-e95cafa9-fdbb-4da5-8b99-c698dc27f9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-35f6932c-aa8b-4673-aeec-74b8c7fccbe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038300737-172.17.0.8-1595982175803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35564,DS-4ad506da-f111-4037-8201-67cfa2392d33,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-1cf3e635-997c-4be8-9751-e611e61c18cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-d0564c1f-d2f7-4f92-af63-75d759967ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-45783b3b-538e-4ba9-b238-7bffd6dea00c,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-e847fc41-9421-4c82-9f9b-640f2948db94,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-c097e013-ad01-4114-9152-3ce99dd62693,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-dcb4186b-9d4c-45ab-bb9d-da0bf4bee586,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-3d8dcc38-fffe-412b-814d-45666115063e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038300737-172.17.0.8-1595982175803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35564,DS-4ad506da-f111-4037-8201-67cfa2392d33,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-1cf3e635-997c-4be8-9751-e611e61c18cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34758,DS-d0564c1f-d2f7-4f92-af63-75d759967ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-45783b3b-538e-4ba9-b238-7bffd6dea00c,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-e847fc41-9421-4c82-9f9b-640f2948db94,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-c097e013-ad01-4114-9152-3ce99dd62693,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-dcb4186b-9d4c-45ab-bb9d-da0bf4bee586,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-3d8dcc38-fffe-412b-814d-45666115063e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592594322-172.17.0.8-1595982569200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33532,DS-cddd7377-9ee7-443d-a03f-43393a27332d,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-65f2d5b5-e00e-4805-82a5-74aca90e035b,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-de67ae20-ef18-4241-827c-ce670013688b,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-c6eabe41-89b9-47ee-a0cf-4d141a1a227d,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-a2d0033a-9560-4711-a7b8-7dffeb31ddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-5302afc5-8b6d-422c-b97b-7c81a7e0f440,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-648ec98d-fbdc-4a07-bfca-cd739d1cabe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-4bf3e3c7-30c7-40b8-a2c0-374c2a76e0a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592594322-172.17.0.8-1595982569200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33532,DS-cddd7377-9ee7-443d-a03f-43393a27332d,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-65f2d5b5-e00e-4805-82a5-74aca90e035b,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-de67ae20-ef18-4241-827c-ce670013688b,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-c6eabe41-89b9-47ee-a0cf-4d141a1a227d,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-a2d0033a-9560-4711-a7b8-7dffeb31ddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-5302afc5-8b6d-422c-b97b-7c81a7e0f440,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-648ec98d-fbdc-4a07-bfca-cd739d1cabe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-4bf3e3c7-30c7-40b8-a2c0-374c2a76e0a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325583238-172.17.0.8-1595982880508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40627,DS-839e33a1-d369-45b7-80ae-7e6ba20d1d57,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-d486ed78-c0be-450b-b04c-184623dfe62c,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-ca394d9c-0756-4104-8163-cfecd7622b91,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-eae8c040-303a-43c9-b952-d9a4b55a737b,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-02bb5b54-a26a-4333-89e9-3d92f157953d,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-0968a031-4bde-489c-8e7e-e77c186d7525,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-43eb98ab-2a90-4ac5-9bcd-93a95742898d,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-a3a0b000-2570-4880-a27d-6a1ad17b1c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325583238-172.17.0.8-1595982880508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40627,DS-839e33a1-d369-45b7-80ae-7e6ba20d1d57,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-d486ed78-c0be-450b-b04c-184623dfe62c,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-ca394d9c-0756-4104-8163-cfecd7622b91,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-eae8c040-303a-43c9-b952-d9a4b55a737b,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-02bb5b54-a26a-4333-89e9-3d92f157953d,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-0968a031-4bde-489c-8e7e-e77c186d7525,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-43eb98ab-2a90-4ac5-9bcd-93a95742898d,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-a3a0b000-2570-4880-a27d-6a1ad17b1c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252020768-172.17.0.8-1595982914576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46246,DS-4c1ad519-2f8a-4552-8391-20e8f267cd09,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-97c213be-3b45-43a0-855d-b5c7433d725a,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-7808b4e0-9cd0-41a3-8856-aa7f3b647268,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-b5f062b1-ae59-404a-afa6-0f31bb04dc84,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-1ca410a2-ea87-4601-8720-c0fac94f2b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-b984e1fc-0f7d-43ab-b7df-e9d6709d07d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-679c7598-8a3d-4398-b980-bff61c903c39,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-1f1ab65c-d784-4104-a4e0-4453fdc482d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252020768-172.17.0.8-1595982914576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46246,DS-4c1ad519-2f8a-4552-8391-20e8f267cd09,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-97c213be-3b45-43a0-855d-b5c7433d725a,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-7808b4e0-9cd0-41a3-8856-aa7f3b647268,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-b5f062b1-ae59-404a-afa6-0f31bb04dc84,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-1ca410a2-ea87-4601-8720-c0fac94f2b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-b984e1fc-0f7d-43ab-b7df-e9d6709d07d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-679c7598-8a3d-4398-b980-bff61c903c39,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-1f1ab65c-d784-4104-a4e0-4453fdc482d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050988834-172.17.0.8-1595983486180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-12827bc2-57b2-4568-b8b0-50372805945f,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-3f3c96b2-9aa6-4400-81cd-49e285be7591,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-0770e4c0-407e-4546-8823-03fd816a1360,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-7d245237-694a-4dfb-b8d3-52c06fd7c4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-78f90719-45a1-462b-9766-624ea33dadc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-5a794c23-a954-4a63-8dfb-50bebee9fa61,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-eea4f3c4-cf65-4b45-bfa4-10301d617cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-6fe9e7ae-ac24-48d1-bbba-cef3f173425c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050988834-172.17.0.8-1595983486180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-12827bc2-57b2-4568-b8b0-50372805945f,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-3f3c96b2-9aa6-4400-81cd-49e285be7591,DISK], DatanodeInfoWithStorage[127.0.0.1:39901,DS-0770e4c0-407e-4546-8823-03fd816a1360,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-7d245237-694a-4dfb-b8d3-52c06fd7c4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-78f90719-45a1-462b-9766-624ea33dadc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-5a794c23-a954-4a63-8dfb-50bebee9fa61,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-eea4f3c4-cf65-4b45-bfa4-10301d617cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-6fe9e7ae-ac24-48d1-bbba-cef3f173425c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382515336-172.17.0.8-1595983673191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43591,DS-d3a1fdea-97a3-4c03-b2cd-dc8855ed1b10,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-8051d043-e87c-4dd6-819c-75fb8659e917,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-eff3dbe2-df95-4ac9-aeae-d71b51520c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-612770ab-6812-4497-be37-6f719e9d873b,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-d9b53bd4-91a2-436b-afcf-9e5ae056036e,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-a8308525-d12d-4e0a-89c1-1a76a46e5e98,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-b4f91e18-dc19-4535-8424-07dfaa473dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-3bb8352d-ed7d-416a-a5a6-e1a119be917a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382515336-172.17.0.8-1595983673191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43591,DS-d3a1fdea-97a3-4c03-b2cd-dc8855ed1b10,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-8051d043-e87c-4dd6-819c-75fb8659e917,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-eff3dbe2-df95-4ac9-aeae-d71b51520c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-612770ab-6812-4497-be37-6f719e9d873b,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-d9b53bd4-91a2-436b-afcf-9e5ae056036e,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-a8308525-d12d-4e0a-89c1-1a76a46e5e98,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-b4f91e18-dc19-4535-8424-07dfaa473dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-3bb8352d-ed7d-416a-a5a6-e1a119be917a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1759912557-172.17.0.8-1595984823767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40906,DS-10b87724-741a-478a-a324-73f7337d01f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-8894cd1b-acdf-40f5-8db8-24d4198193d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-b1683dc0-cbc2-4c6e-9b92-6ff9be9b9139,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-dcf6656b-b64b-4114-9e45-31892fd92c11,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-77992a3f-5a90-42e1-a3b3-ed9ba98fadb8,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-f810de6a-6124-4b80-9f1a-530ef60bdff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-9814f0cd-5e12-4aa3-b5fb-b4bc28afd1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-b29cf383-e18b-43eb-a483-8c291e96a1cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1759912557-172.17.0.8-1595984823767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40906,DS-10b87724-741a-478a-a324-73f7337d01f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-8894cd1b-acdf-40f5-8db8-24d4198193d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-b1683dc0-cbc2-4c6e-9b92-6ff9be9b9139,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-dcf6656b-b64b-4114-9e45-31892fd92c11,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-77992a3f-5a90-42e1-a3b3-ed9ba98fadb8,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-f810de6a-6124-4b80-9f1a-530ef60bdff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-9814f0cd-5e12-4aa3-b5fb-b4bc28afd1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-b29cf383-e18b-43eb-a483-8c291e96a1cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5231
