reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225782897-172.17.0.10-1596004811625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41379,DS-a838188c-e54c-4aa2-9a9c-78803e82ae5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-dfa66ea4-fc6a-4266-ae65-3b6f948147c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-1f1c9e31-48be-421b-a4f4-10cb643347cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-5fea4979-295d-4bad-a3ff-aa2f6d8e0f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-89b346cb-b0c0-437c-a547-d87bfe13854b,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-14642012-d7a1-48f4-933c-4e68440d5145,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-874afd24-d991-4e08-b453-92dcebaa1d69,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-1fb6e0ba-0a66-406e-ab0f-c8288084dac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225782897-172.17.0.10-1596004811625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41379,DS-a838188c-e54c-4aa2-9a9c-78803e82ae5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-dfa66ea4-fc6a-4266-ae65-3b6f948147c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-1f1c9e31-48be-421b-a4f4-10cb643347cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-5fea4979-295d-4bad-a3ff-aa2f6d8e0f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-89b346cb-b0c0-437c-a547-d87bfe13854b,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-14642012-d7a1-48f4-933c-4e68440d5145,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-874afd24-d991-4e08-b453-92dcebaa1d69,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-1fb6e0ba-0a66-406e-ab0f-c8288084dac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816531618-172.17.0.10-1596004884676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44888,DS-7996d1e2-8021-41be-9f4e-fe1379af2195,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-d356d4a6-9297-4bb4-83a9-78fb3462cc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-0321f069-6188-4158-b943-5d0973f8ded4,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-f8026fbf-669c-429a-b501-2a09f273d1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-aa225149-00f3-4f0d-b800-fdbae367ee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-e60a9911-1da7-4bf4-b04f-b2f2047a1f41,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-690c4887-1dce-42e0-b33a-47221908baba,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-b79d522b-0561-41aa-8da3-f32c36315a9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816531618-172.17.0.10-1596004884676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44888,DS-7996d1e2-8021-41be-9f4e-fe1379af2195,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-d356d4a6-9297-4bb4-83a9-78fb3462cc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-0321f069-6188-4158-b943-5d0973f8ded4,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-f8026fbf-669c-429a-b501-2a09f273d1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-aa225149-00f3-4f0d-b800-fdbae367ee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-e60a9911-1da7-4bf4-b04f-b2f2047a1f41,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-690c4887-1dce-42e0-b33a-47221908baba,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-b79d522b-0561-41aa-8da3-f32c36315a9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189053852-172.17.0.10-1596005005774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34317,DS-6d12196a-3226-41b1-b0f5-222a144300a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-b59d0b6c-1912-4c08-ad38-71ede9df1515,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-e4a3a0c4-8e7d-458d-8dc0-87281266b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-9f41d16e-9807-42aa-92bd-5bbd232bd0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-12e6d38b-d917-4429-a097-e46c9f8269bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-33dc52d5-2808-46f2-a044-a60956527f31,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-f3aa42dd-4036-498b-8eba-391ae23c94aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-c224f7a8-e3eb-49c2-8f4e-7df1b9d9969f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-189053852-172.17.0.10-1596005005774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34317,DS-6d12196a-3226-41b1-b0f5-222a144300a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-b59d0b6c-1912-4c08-ad38-71ede9df1515,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-e4a3a0c4-8e7d-458d-8dc0-87281266b6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-9f41d16e-9807-42aa-92bd-5bbd232bd0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-12e6d38b-d917-4429-a097-e46c9f8269bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45837,DS-33dc52d5-2808-46f2-a044-a60956527f31,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-f3aa42dd-4036-498b-8eba-391ae23c94aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-c224f7a8-e3eb-49c2-8f4e-7df1b9d9969f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497677286-172.17.0.10-1596006179250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35416,DS-dc5540d7-108a-4f81-a19f-3bbb492accdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-dbfb04ea-18c6-4d7f-84f8-361b0148776f,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-7152ce8e-be4a-496d-9bfe-1dffe205cfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-997dd35c-4290-4916-a295-48669ee20b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-4da44a57-4011-40ba-8e04-86e496094962,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-246071ab-6e9b-482b-bcfd-22384c4da0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-3d08eaf5-2083-4f56-9559-50db8ac34fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-41df8783-5d68-4944-93ce-a4bb1c3bc525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-497677286-172.17.0.10-1596006179250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35416,DS-dc5540d7-108a-4f81-a19f-3bbb492accdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-dbfb04ea-18c6-4d7f-84f8-361b0148776f,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-7152ce8e-be4a-496d-9bfe-1dffe205cfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-997dd35c-4290-4916-a295-48669ee20b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-4da44a57-4011-40ba-8e04-86e496094962,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-246071ab-6e9b-482b-bcfd-22384c4da0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-3d08eaf5-2083-4f56-9559-50db8ac34fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-41df8783-5d68-4944-93ce-a4bb1c3bc525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286088378-172.17.0.10-1596006347747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36975,DS-dd16799e-cd9b-4fb0-adeb-2ade74252e85,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-401c60b4-dc7a-411e-8f55-f2e2b811112b,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-3e04ba56-457c-4e38-b924-8c77ce686f40,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-d833553d-14b5-4add-b3f3-ffdf1fec0178,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-efc68c7c-70b7-4274-aa2e-8f49fc53d560,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-01c28424-835f-433a-ad1d-b224cc96a4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-ba6f76e5-2cb8-411d-af24-171014274489,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-82db32aa-b6e4-4a6f-bc02-0f18cf9eca24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286088378-172.17.0.10-1596006347747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36975,DS-dd16799e-cd9b-4fb0-adeb-2ade74252e85,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-401c60b4-dc7a-411e-8f55-f2e2b811112b,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-3e04ba56-457c-4e38-b924-8c77ce686f40,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-d833553d-14b5-4add-b3f3-ffdf1fec0178,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-efc68c7c-70b7-4274-aa2e-8f49fc53d560,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-01c28424-835f-433a-ad1d-b224cc96a4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-ba6f76e5-2cb8-411d-af24-171014274489,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-82db32aa-b6e4-4a6f-bc02-0f18cf9eca24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820306157-172.17.0.10-1596006761250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33285,DS-8d608900-6caa-4884-bb31-a51c7546fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-f19955fc-b51d-47ed-991a-75a77b285cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-ddf12816-b8d7-4fc7-b5f4-daa7303ccc99,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-32f8c87c-c32f-43ef-b38b-14e69a1a224a,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-c54cc2b9-7562-4b4e-aa09-886200902335,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-fe14b9b4-4ed0-4deb-a684-bfcd621e6323,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-8e1cd15a-6f39-4bf2-a4f4-7c0aac8883f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-ec48d716-4340-4dce-93ac-8321824b589f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-820306157-172.17.0.10-1596006761250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33285,DS-8d608900-6caa-4884-bb31-a51c7546fd65,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-f19955fc-b51d-47ed-991a-75a77b285cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-ddf12816-b8d7-4fc7-b5f4-daa7303ccc99,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-32f8c87c-c32f-43ef-b38b-14e69a1a224a,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-c54cc2b9-7562-4b4e-aa09-886200902335,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-fe14b9b4-4ed0-4deb-a684-bfcd621e6323,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-8e1cd15a-6f39-4bf2-a4f4-7c0aac8883f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-ec48d716-4340-4dce-93ac-8321824b589f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627512331-172.17.0.10-1596006800788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36524,DS-7bcf3caa-2ab6-4c7e-b33c-ae97b2a0e171,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-19f18497-4368-42db-af8c-fb60ff6115f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-f18904e9-c577-49df-a0e7-e6580f57e0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-3df8b346-75e3-43fb-b265-81768da7fba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-fcfd1d25-29cd-4049-a0a0-71019880c4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-0efbcdbd-33d8-49a9-9a98-62a09b01d136,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-231e581f-df05-4303-9a0c-f80309856e98,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-270d919d-8d7e-487a-a99d-4b3b4d379415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1627512331-172.17.0.10-1596006800788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36524,DS-7bcf3caa-2ab6-4c7e-b33c-ae97b2a0e171,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-19f18497-4368-42db-af8c-fb60ff6115f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-f18904e9-c577-49df-a0e7-e6580f57e0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-3df8b346-75e3-43fb-b265-81768da7fba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-fcfd1d25-29cd-4049-a0a0-71019880c4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-0efbcdbd-33d8-49a9-9a98-62a09b01d136,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-231e581f-df05-4303-9a0c-f80309856e98,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-270d919d-8d7e-487a-a99d-4b3b4d379415,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393602739-172.17.0.10-1596007558532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34199,DS-5856f623-17b6-4e8d-9599-03a392eca5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-e7bfa950-a3bb-43cc-b568-51140fc2d1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-38dbfc8d-fbbc-4b42-a656-f937b690e093,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-0cbdf7b4-144a-499c-a578-8b4bbba826a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-b7173eaf-6a71-4a44-a711-b4a5d382d9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-a4fad3eb-14ae-43a8-a3df-75446a36f8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-412b61f9-9f58-47bd-8571-47fb313ac861,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-5a636e60-5fde-4e8d-b881-5c3e12d02de4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393602739-172.17.0.10-1596007558532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34199,DS-5856f623-17b6-4e8d-9599-03a392eca5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-e7bfa950-a3bb-43cc-b568-51140fc2d1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-38dbfc8d-fbbc-4b42-a656-f937b690e093,DISK], DatanodeInfoWithStorage[127.0.0.1:39540,DS-0cbdf7b4-144a-499c-a578-8b4bbba826a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-b7173eaf-6a71-4a44-a711-b4a5d382d9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-a4fad3eb-14ae-43a8-a3df-75446a36f8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-412b61f9-9f58-47bd-8571-47fb313ac861,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-5a636e60-5fde-4e8d-b881-5c3e12d02de4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769683019-172.17.0.10-1596008075420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46229,DS-32172322-4d4f-4c51-a812-6d943f7af177,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-4704fb39-30f0-4e2d-a164-77d3383477f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-2e6f1da0-2a82-40f4-8948-065513b6504e,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-cce9e95f-556d-4939-b949-96c15469bb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-6b991f30-718f-4ad2-a891-f1f4c71189bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-f9773af9-bb3b-4e3b-8587-f65b52095877,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-7f6cbd0f-d89f-4237-91c9-aa85230839e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-89c47f81-8080-4169-99ec-5bc9436cfc09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769683019-172.17.0.10-1596008075420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46229,DS-32172322-4d4f-4c51-a812-6d943f7af177,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-4704fb39-30f0-4e2d-a164-77d3383477f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-2e6f1da0-2a82-40f4-8948-065513b6504e,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-cce9e95f-556d-4939-b949-96c15469bb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-6b991f30-718f-4ad2-a891-f1f4c71189bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-f9773af9-bb3b-4e3b-8587-f65b52095877,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-7f6cbd0f-d89f-4237-91c9-aa85230839e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-89c47f81-8080-4169-99ec-5bc9436cfc09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436787446-172.17.0.10-1596008349291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35244,DS-5e14936d-e2da-4d79-9771-81255cbebf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-29ce2210-304c-42fd-85e4-db9be0267cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-95836911-de8c-4189-b11f-55dc30581993,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-05fef1eb-642a-4930-a999-649622dd5ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-f701c32f-690d-4905-ab96-af1e6c711496,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-3ce1001f-dbba-4ce5-9572-cc6d41caa7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-5cadafc3-b4e0-48cd-904c-9aa464b51547,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-bbd8a524-a328-4bc7-8545-bb58b7518941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436787446-172.17.0.10-1596008349291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35244,DS-5e14936d-e2da-4d79-9771-81255cbebf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-29ce2210-304c-42fd-85e4-db9be0267cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-95836911-de8c-4189-b11f-55dc30581993,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-05fef1eb-642a-4930-a999-649622dd5ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-f701c32f-690d-4905-ab96-af1e6c711496,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-3ce1001f-dbba-4ce5-9572-cc6d41caa7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-5cadafc3-b4e0-48cd-904c-9aa464b51547,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-bbd8a524-a328-4bc7-8545-bb58b7518941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228220322-172.17.0.10-1596008392116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34061,DS-d534baf3-d467-44a2-8b71-d308c41f0ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-a837dd17-e7e6-43b0-a4ac-13fc72eb9c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-b3be0b02-7d83-41b9-a42e-a53c4f17505d,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-ca142d48-8758-4216-9002-5f9751c93ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-52e14c32-1c7c-4976-ad67-dbdc71cbc1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-456db87a-bdbb-4217-aff2-b06c6bf85f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-39ee5e29-9b05-46be-88dc-6c254a5108d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-c9b7e66c-4b79-49e9-8443-7e49f26b36f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228220322-172.17.0.10-1596008392116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34061,DS-d534baf3-d467-44a2-8b71-d308c41f0ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-a837dd17-e7e6-43b0-a4ac-13fc72eb9c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-b3be0b02-7d83-41b9-a42e-a53c4f17505d,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-ca142d48-8758-4216-9002-5f9751c93ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-52e14c32-1c7c-4976-ad67-dbdc71cbc1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-456db87a-bdbb-4217-aff2-b06c6bf85f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45450,DS-39ee5e29-9b05-46be-88dc-6c254a5108d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-c9b7e66c-4b79-49e9-8443-7e49f26b36f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796591578-172.17.0.10-1596008430919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37826,DS-865953af-6735-4823-a63c-9845750c3891,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-3c2319b0-db4d-49e2-b576-7ed8edfb589e,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-ab7e6804-7d1d-48d2-b477-62e403108ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-66fba03c-5b14-4186-bfe3-48e49bf575eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-9d27cc08-75ae-4b3d-a251-2ad050a2264b,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-a10394d2-dfbf-40a1-a709-7de2e676e42a,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-82161b01-4485-435c-9636-dd43eaf42a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-d0f60e29-a573-44b3-9dd8-f60db566979f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796591578-172.17.0.10-1596008430919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37826,DS-865953af-6735-4823-a63c-9845750c3891,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-3c2319b0-db4d-49e2-b576-7ed8edfb589e,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-ab7e6804-7d1d-48d2-b477-62e403108ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-66fba03c-5b14-4186-bfe3-48e49bf575eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-9d27cc08-75ae-4b3d-a251-2ad050a2264b,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-a10394d2-dfbf-40a1-a709-7de2e676e42a,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-82161b01-4485-435c-9636-dd43eaf42a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-d0f60e29-a573-44b3-9dd8-f60db566979f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708273424-172.17.0.10-1596008466784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37780,DS-543618b2-b651-48e2-be96-e1e68571225c,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-94fab0e6-55c4-45e3-992c-998c5ce61b48,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-f709e692-d548-4d81-ae99-8acde7531792,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-29e46580-c7c9-4071-b0dd-d826dcfee89e,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-10c29b46-cb65-40ca-b829-2023fdb84cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-df514e8e-eb28-4a7d-8ad5-0dae69532b82,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-5f6b85a6-ecf6-481b-a48a-f94fa12d9a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-8c673eb8-53a7-46b9-97d6-a39c86c6bd67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708273424-172.17.0.10-1596008466784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37780,DS-543618b2-b651-48e2-be96-e1e68571225c,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-94fab0e6-55c4-45e3-992c-998c5ce61b48,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-f709e692-d548-4d81-ae99-8acde7531792,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-29e46580-c7c9-4071-b0dd-d826dcfee89e,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-10c29b46-cb65-40ca-b829-2023fdb84cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-df514e8e-eb28-4a7d-8ad5-0dae69532b82,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-5f6b85a6-ecf6-481b-a48a-f94fa12d9a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-8c673eb8-53a7-46b9-97d6-a39c86c6bd67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766738148-172.17.0.10-1596008607907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38822,DS-a1f71ba5-0a6f-4fd1-8d1f-0ccca9319367,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-29b97694-3685-41f4-a8fd-c63c5cbb1e97,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-9696dac1-cc05-4868-907b-8fbed3fc6573,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-35061f32-9e0c-41f4-be53-1a9c31fb47e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-e6e0324e-3606-46a7-94c4-3af5fce1fcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-a19b3bc4-b15e-490d-a6f3-7325d38e3d77,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-c83190a7-2a05-4afe-80d2-48fcac679806,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-925ca70f-953e-44ec-a2d5-99c5ed1be7c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766738148-172.17.0.10-1596008607907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38822,DS-a1f71ba5-0a6f-4fd1-8d1f-0ccca9319367,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-29b97694-3685-41f4-a8fd-c63c5cbb1e97,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-9696dac1-cc05-4868-907b-8fbed3fc6573,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-35061f32-9e0c-41f4-be53-1a9c31fb47e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-e6e0324e-3606-46a7-94c4-3af5fce1fcd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-a19b3bc4-b15e-490d-a6f3-7325d38e3d77,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-c83190a7-2a05-4afe-80d2-48fcac679806,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-925ca70f-953e-44ec-a2d5-99c5ed1be7c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670116352-172.17.0.10-1596009064728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44078,DS-2e5c157f-60f1-4e4f-af45-00feacef364d,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-47e58b7d-713d-4c68-baaf-f5b5f35c8c46,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-8af98529-7daf-4550-b15e-5fec2d7d25b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-d58ffa8f-3a32-4881-b2d2-53f2bd82ee45,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-c49fb5a5-c335-4a9e-bd36-5a806582c5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-7889565c-a15c-414e-a8f3-c667d172dbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-e1a7e290-ac94-4a3d-9de5-24d4ec968a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-a1870528-1611-48dc-b564-03790d9dcb9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670116352-172.17.0.10-1596009064728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44078,DS-2e5c157f-60f1-4e4f-af45-00feacef364d,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-47e58b7d-713d-4c68-baaf-f5b5f35c8c46,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-8af98529-7daf-4550-b15e-5fec2d7d25b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-d58ffa8f-3a32-4881-b2d2-53f2bd82ee45,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-c49fb5a5-c335-4a9e-bd36-5a806582c5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-7889565c-a15c-414e-a8f3-c667d172dbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-e1a7e290-ac94-4a3d-9de5-24d4ec968a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-a1870528-1611-48dc-b564-03790d9dcb9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565812444-172.17.0.10-1596009179097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44300,DS-17e4021e-e3a0-4934-bd6c-84ff5c704351,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-b9d7c03f-f7d6-41b3-a01c-3b821aa68680,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-d9528dd8-632a-475f-a6fe-1028d0e40876,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-3c703f91-5708-4367-bd95-d788b6de04a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-30db15ee-318d-44ea-b819-b31ff8a0fc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-14eb6ea9-5300-4555-b31b-6684319903b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-85b5b76e-f766-4b47-954b-5433a83a78ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-2d0f59f4-950f-4a7c-bc74-6da93124f42a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565812444-172.17.0.10-1596009179097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44300,DS-17e4021e-e3a0-4934-bd6c-84ff5c704351,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-b9d7c03f-f7d6-41b3-a01c-3b821aa68680,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-d9528dd8-632a-475f-a6fe-1028d0e40876,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-3c703f91-5708-4367-bd95-d788b6de04a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-30db15ee-318d-44ea-b819-b31ff8a0fc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-14eb6ea9-5300-4555-b31b-6684319903b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-85b5b76e-f766-4b47-954b-5433a83a78ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-2d0f59f4-950f-4a7c-bc74-6da93124f42a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472629955-172.17.0.10-1596009267711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36392,DS-689e6325-054e-48b1-9665-d0472c3b072f,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-7e081d27-f637-4639-8da2-8c6202625738,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-89156ba8-1f8d-4969-9edd-f1a1877ec038,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-61ee706a-9423-46b6-908b-2676d32ec697,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-f71f72db-0fa4-4a10-9fa8-9db2d4fe1302,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-04ba24ed-cae9-47bb-a190-b955778ecf46,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-05d12591-18a8-479d-9561-ddffe79ea31c,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-cfe48d79-5700-437e-9bd1-a300058a8bd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472629955-172.17.0.10-1596009267711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36392,DS-689e6325-054e-48b1-9665-d0472c3b072f,DISK], DatanodeInfoWithStorage[127.0.0.1:44518,DS-7e081d27-f637-4639-8da2-8c6202625738,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-89156ba8-1f8d-4969-9edd-f1a1877ec038,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-61ee706a-9423-46b6-908b-2676d32ec697,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-f71f72db-0fa4-4a10-9fa8-9db2d4fe1302,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-04ba24ed-cae9-47bb-a190-b955778ecf46,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-05d12591-18a8-479d-9561-ddffe79ea31c,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-cfe48d79-5700-437e-9bd1-a300058a8bd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108666227-172.17.0.10-1596009482897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42159,DS-0d989a5a-5f88-456d-b151-9e40346071c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-efbb632d-a116-404c-beeb-282cf819c040,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-fd534c56-ee83-4acf-bf76-76b6ead930ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-d4b428b8-2d02-4d68-80f5-7896e57c4ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-acdbea4a-e4dd-432e-982e-81e90335f991,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-750445c5-25f6-4e25-8657-4b02cf881440,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-eef76730-1a2d-45c0-9ee7-058637d39714,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-240ef5cf-c4b4-4537-b2ca-992e74c5f155,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108666227-172.17.0.10-1596009482897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42159,DS-0d989a5a-5f88-456d-b151-9e40346071c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-efbb632d-a116-404c-beeb-282cf819c040,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-fd534c56-ee83-4acf-bf76-76b6ead930ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-d4b428b8-2d02-4d68-80f5-7896e57c4ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-acdbea4a-e4dd-432e-982e-81e90335f991,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-750445c5-25f6-4e25-8657-4b02cf881440,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-eef76730-1a2d-45c0-9ee7-058637d39714,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-240ef5cf-c4b4-4537-b2ca-992e74c5f155,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969026383-172.17.0.10-1596010038496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40967,DS-e51ecbe3-2f48-43f9-8a17-e3170ed89725,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-9a7bdc93-2efd-478b-b88a-07cf912507bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-42ff46b8-2e4a-4815-9be7-ef5ec3c928fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-fa9f2cd7-c8d9-4e82-8f90-8400eed39e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-b77ed5f3-2e52-4fcb-a04c-ef322debc620,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-772a5a4a-6663-48e1-a757-ae0c1a71324d,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-c003f879-a9d1-4279-9583-736a3175c385,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-2bd43a7c-8546-4495-99a7-3f2cfc99a037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969026383-172.17.0.10-1596010038496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40967,DS-e51ecbe3-2f48-43f9-8a17-e3170ed89725,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-9a7bdc93-2efd-478b-b88a-07cf912507bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-42ff46b8-2e4a-4815-9be7-ef5ec3c928fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-fa9f2cd7-c8d9-4e82-8f90-8400eed39e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-b77ed5f3-2e52-4fcb-a04c-ef322debc620,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-772a5a4a-6663-48e1-a757-ae0c1a71324d,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-c003f879-a9d1-4279-9583-736a3175c385,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-2bd43a7c-8546-4495-99a7-3f2cfc99a037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938225401-172.17.0.10-1596010245375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38022,DS-9c8f41d2-8caa-48a1-b55d-5450a3950c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-4fe096dd-3e04-4f17-bfeb-48ceee55e19d,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-020abaf0-5090-4395-85c0-a14722aa0f97,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-8d6163a4-d9d4-4404-8775-223306fbc41f,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-019e8250-4d2f-43be-8f0b-db4021343822,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-0efbea93-3414-405b-b390-1bb6f6583253,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-9653522b-e5cf-4d04-900b-a0af6fc16e35,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-fc0d4cdf-df8c-47eb-a936-18ad66d9ac17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938225401-172.17.0.10-1596010245375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38022,DS-9c8f41d2-8caa-48a1-b55d-5450a3950c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-4fe096dd-3e04-4f17-bfeb-48ceee55e19d,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-020abaf0-5090-4395-85c0-a14722aa0f97,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-8d6163a4-d9d4-4404-8775-223306fbc41f,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-019e8250-4d2f-43be-8f0b-db4021343822,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-0efbea93-3414-405b-b390-1bb6f6583253,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-9653522b-e5cf-4d04-900b-a0af6fc16e35,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-fc0d4cdf-df8c-47eb-a936-18ad66d9ac17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 50
v2: 80
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287942846-172.17.0.10-1596010719755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40857,DS-cea196a8-14ae-4fef-bc0b-d5a1b952e12f,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-52447fcb-8ae8-47ff-9b66-0bf9514615c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-d5f6b799-bb86-4acd-b375-9ea7e3f17988,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-bbf0a02a-0daf-400e-97f0-a9ff1bc90772,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-aa67d29b-5f12-47d5-bf73-c85599ca6dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-c82fba3c-6a8b-408c-8e4b-1a3546f1edcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-7e85376a-d224-4196-aaf4-9186384a332e,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-9bfe7dc0-fb09-44b0-b9a8-995d7d2b260b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1287942846-172.17.0.10-1596010719755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40857,DS-cea196a8-14ae-4fef-bc0b-d5a1b952e12f,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-52447fcb-8ae8-47ff-9b66-0bf9514615c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-d5f6b799-bb86-4acd-b375-9ea7e3f17988,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-bbf0a02a-0daf-400e-97f0-a9ff1bc90772,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-aa67d29b-5f12-47d5-bf73-c85599ca6dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-c82fba3c-6a8b-408c-8e4b-1a3546f1edcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-7e85376a-d224-4196-aaf4-9186384a332e,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-9bfe7dc0-fb09-44b0-b9a8-995d7d2b260b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6485
