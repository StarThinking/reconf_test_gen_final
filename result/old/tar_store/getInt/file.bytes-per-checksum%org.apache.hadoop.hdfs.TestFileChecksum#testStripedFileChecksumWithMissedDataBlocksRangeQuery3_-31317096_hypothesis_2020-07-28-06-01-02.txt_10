reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-296755256-172.17.0.9-1595916231062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46640,DS-85035e8d-98ca-495f-8ce6-f50f15dde67c,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-08a04085-01e3-4bde-9f77-96c133b64ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-b0c444fe-aad0-44fa-9803-dc06c3f38416,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-ec969a50-44a7-48b2-a8ad-e8215899c406,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-924f3f2c-7eae-42d5-bc8e-134668ce51ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-b5327d8c-6985-4f14-be14-8bca7b906201,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-9c4f2780-6b60-49af-bcbf-4c1680a1c759,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-9f5adc04-23df-45be-863f-4ee76462696b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-296755256-172.17.0.9-1595916231062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46640,DS-85035e8d-98ca-495f-8ce6-f50f15dde67c,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-08a04085-01e3-4bde-9f77-96c133b64ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-b0c444fe-aad0-44fa-9803-dc06c3f38416,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-ec969a50-44a7-48b2-a8ad-e8215899c406,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-924f3f2c-7eae-42d5-bc8e-134668ce51ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-b5327d8c-6985-4f14-be14-8bca7b906201,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-9c4f2780-6b60-49af-bcbf-4c1680a1c759,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-9f5adc04-23df-45be-863f-4ee76462696b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436155505-172.17.0.9-1595916313863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35286,DS-866dffcd-9c41-42e4-8651-0fddfcf2dc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-c7ac789a-072f-40b5-9687-57c6bf676ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-10b4c5ce-abbe-41b6-b79b-d51988e4768b,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-3a73e35e-12d0-4abe-a831-24c2170363c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-d3f8959f-7935-4d32-b921-880602e19366,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-e000e70c-e8ab-4abd-9664-827674eb405b,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-2e60b6a3-b30a-4d7f-b490-3fb8e4a5365b,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-bea85042-6617-4a23-b1ce-e9212247fd1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436155505-172.17.0.9-1595916313863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35286,DS-866dffcd-9c41-42e4-8651-0fddfcf2dc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33248,DS-c7ac789a-072f-40b5-9687-57c6bf676ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-10b4c5ce-abbe-41b6-b79b-d51988e4768b,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-3a73e35e-12d0-4abe-a831-24c2170363c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-d3f8959f-7935-4d32-b921-880602e19366,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-e000e70c-e8ab-4abd-9664-827674eb405b,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-2e60b6a3-b30a-4d7f-b490-3fb8e4a5365b,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-bea85042-6617-4a23-b1ce-e9212247fd1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408298463-172.17.0.9-1595916403720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38868,DS-91f85da9-863e-4bad-9c56-1135d85fed30,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-d53761d6-19e0-49bd-9edb-a84d0b86a755,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-c198e13c-b717-474c-9974-112a70b9cb24,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-80108c16-672c-4151-9f66-8c10c7ed5efc,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-ff2182e5-8137-46fb-90b5-72ec79331449,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-5b77a088-199d-49ce-b7d7-1a65b8b1753a,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-62f406f6-e240-4da0-993c-9903ad9181a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-a6b94565-cd67-4d4a-825d-56445f9b5f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1408298463-172.17.0.9-1595916403720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38868,DS-91f85da9-863e-4bad-9c56-1135d85fed30,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-d53761d6-19e0-49bd-9edb-a84d0b86a755,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-c198e13c-b717-474c-9974-112a70b9cb24,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-80108c16-672c-4151-9f66-8c10c7ed5efc,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-ff2182e5-8137-46fb-90b5-72ec79331449,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-5b77a088-199d-49ce-b7d7-1a65b8b1753a,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-62f406f6-e240-4da0-993c-9903ad9181a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-a6b94565-cd67-4d4a-825d-56445f9b5f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427609232-172.17.0.9-1595916767148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37465,DS-b79e35e9-9ab5-48dd-8a1f-a0ece2fad789,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-11dbbf2d-7ee5-49a4-8264-50b4e135fe90,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-4d275879-f7c3-4d66-9787-509f337676ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-38bb6a5d-1f6d-4172-bf4c-f2c8eb2aa310,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-52b45ae8-dd2b-4bd6-91ec-094900e1066c,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-c425300e-10c0-48c9-b864-7a4138e5b068,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-0525b82b-63c3-4885-a9d6-79fbb956701b,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-1d7cf302-e2e1-42d6-80c9-328bb2af287b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427609232-172.17.0.9-1595916767148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37465,DS-b79e35e9-9ab5-48dd-8a1f-a0ece2fad789,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-11dbbf2d-7ee5-49a4-8264-50b4e135fe90,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-4d275879-f7c3-4d66-9787-509f337676ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-38bb6a5d-1f6d-4172-bf4c-f2c8eb2aa310,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-52b45ae8-dd2b-4bd6-91ec-094900e1066c,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-c425300e-10c0-48c9-b864-7a4138e5b068,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-0525b82b-63c3-4885-a9d6-79fbb956701b,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-1d7cf302-e2e1-42d6-80c9-328bb2af287b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036343781-172.17.0.9-1595917250324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34389,DS-a70a3bff-e0c3-4683-b251-6c43f4918d69,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-f2574604-14b5-44fa-bbfe-55b7b1791ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-7c5cbb3a-a070-400b-ba5c-da746df5e456,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-bf15a52d-a7aa-4716-926e-511d6177a487,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-cbf3fe05-6faa-4d6c-a917-f4f1d5e1f444,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-792d32da-729a-4836-ac14-2c43df474123,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-2e0cd868-3692-4326-ba6b-73f55eca9b97,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-6bd4dff6-377c-4b64-9879-82393adb3bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036343781-172.17.0.9-1595917250324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34389,DS-a70a3bff-e0c3-4683-b251-6c43f4918d69,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-f2574604-14b5-44fa-bbfe-55b7b1791ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-7c5cbb3a-a070-400b-ba5c-da746df5e456,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-bf15a52d-a7aa-4716-926e-511d6177a487,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-cbf3fe05-6faa-4d6c-a917-f4f1d5e1f444,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-792d32da-729a-4836-ac14-2c43df474123,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-2e0cd868-3692-4326-ba6b-73f55eca9b97,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-6bd4dff6-377c-4b64-9879-82393adb3bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480480825-172.17.0.9-1595918380292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42958,DS-ccb71850-6a49-4b6e-a6fb-77b570bbf0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-4fb72b94-f7c7-4e3d-9ef1-f1ae075e78a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-944d9cac-7247-49a6-9546-ebf99c5fee58,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-e7dcf286-c52c-46f7-99b6-445c594253dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-5768fbd1-6940-4a87-b100-88c7c8d3975a,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-a9d4b05a-c0e1-4ac6-ab23-e750354b0004,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-7c1fa87a-a3ff-4e7c-84a4-1b639d7b2efc,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-fbc966fd-59ce-41b0-be21-35f53030cae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480480825-172.17.0.9-1595918380292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42958,DS-ccb71850-6a49-4b6e-a6fb-77b570bbf0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-4fb72b94-f7c7-4e3d-9ef1-f1ae075e78a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-944d9cac-7247-49a6-9546-ebf99c5fee58,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-e7dcf286-c52c-46f7-99b6-445c594253dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-5768fbd1-6940-4a87-b100-88c7c8d3975a,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-a9d4b05a-c0e1-4ac6-ab23-e750354b0004,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-7c1fa87a-a3ff-4e7c-84a4-1b639d7b2efc,DISK], DatanodeInfoWithStorage[127.0.0.1:41199,DS-fbc966fd-59ce-41b0-be21-35f53030cae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386455301-172.17.0.9-1595918992987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32863,DS-6db558f7-209f-48b5-82b9-06bfa702f9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-a09503a3-b443-475d-b9c3-5e50e0777332,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-ce5d38a9-d767-4557-a327-33e9cadd19bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-7647618b-7143-4c54-bb4d-460b8dd24407,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-30a5cb80-c35c-4598-9f05-bb51617c336c,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-61024cc1-704d-4907-ac39-43967dd35ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-6c8ca4d5-ccc5-4e40-8698-4356af60a397,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-95817ca1-6cf7-4de3-ac02-3ad537658a2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386455301-172.17.0.9-1595918992987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32863,DS-6db558f7-209f-48b5-82b9-06bfa702f9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-a09503a3-b443-475d-b9c3-5e50e0777332,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-ce5d38a9-d767-4557-a327-33e9cadd19bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-7647618b-7143-4c54-bb4d-460b8dd24407,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-30a5cb80-c35c-4598-9f05-bb51617c336c,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-61024cc1-704d-4907-ac39-43967dd35ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-6c8ca4d5-ccc5-4e40-8698-4356af60a397,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-95817ca1-6cf7-4de3-ac02-3ad537658a2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4366959-172.17.0.9-1595919801615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35549,DS-c1c1eff9-9da4-4096-9334-5ec732b3f3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-d84dd99e-a03e-4467-b464-07c437ec8fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-563b6110-91a7-4a90-9462-50db2702797f,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-299329df-d3a9-410f-a7a3-9b3601e10033,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-5b4cd2d1-b6d9-425e-8632-d4234090f0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-6c5235d7-57b7-4b13-a801-661e9a2e3c43,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-0d76dd4e-8a63-42a2-979e-49cd782db95a,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-5edb8cfe-d289-4337-bb30-488615b9308c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4366959-172.17.0.9-1595919801615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35549,DS-c1c1eff9-9da4-4096-9334-5ec732b3f3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-d84dd99e-a03e-4467-b464-07c437ec8fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-563b6110-91a7-4a90-9462-50db2702797f,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-299329df-d3a9-410f-a7a3-9b3601e10033,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-5b4cd2d1-b6d9-425e-8632-d4234090f0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-6c5235d7-57b7-4b13-a801-661e9a2e3c43,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-0d76dd4e-8a63-42a2-979e-49cd782db95a,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-5edb8cfe-d289-4337-bb30-488615b9308c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400591012-172.17.0.9-1595921036340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37207,DS-909d0c7f-801f-4607-856c-b3b47581b9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-83c5178e-251b-4524-be86-31099636f701,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-d9a91322-ff50-4b07-9c03-e95b8af526e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-1312a5be-4e27-416d-9937-b1ddd31a196a,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-4157f3e4-a0cb-4d7d-bdbb-f89cb49c74cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-e46ad944-30d9-478c-b076-90ecd54c4df9,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-dc0d8c00-3490-4f98-b845-ace142ea0278,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-7cadadd7-626b-426c-ab5e-5382bdcb83a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400591012-172.17.0.9-1595921036340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37207,DS-909d0c7f-801f-4607-856c-b3b47581b9cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-83c5178e-251b-4524-be86-31099636f701,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-d9a91322-ff50-4b07-9c03-e95b8af526e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-1312a5be-4e27-416d-9937-b1ddd31a196a,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-4157f3e4-a0cb-4d7d-bdbb-f89cb49c74cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-e46ad944-30d9-478c-b076-90ecd54c4df9,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-dc0d8c00-3490-4f98-b845-ace142ea0278,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-7cadadd7-626b-426c-ab5e-5382bdcb83a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914680973-172.17.0.9-1595921205100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32994,DS-40a29249-fc34-4a12-836c-e8a0f79e0e08,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-9885d5c6-912c-4550-b839-a50d0fb6bd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-13842ca7-15a9-4637-a38a-1c43a80638b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-88b08934-1853-4290-b3c9-c00a037d2df9,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-e07b4999-7d06-4195-ae99-5e8baf7483f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-2f9c5543-5682-4615-a650-8366039ae09b,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-7699aeab-5058-4429-b6a8-1e13e9183f29,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-b16515bb-35b5-4e8d-8ab6-8602cf8ffcb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914680973-172.17.0.9-1595921205100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32994,DS-40a29249-fc34-4a12-836c-e8a0f79e0e08,DISK], DatanodeInfoWithStorage[127.0.0.1:41984,DS-9885d5c6-912c-4550-b839-a50d0fb6bd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-13842ca7-15a9-4637-a38a-1c43a80638b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-88b08934-1853-4290-b3c9-c00a037d2df9,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-e07b4999-7d06-4195-ae99-5e8baf7483f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-2f9c5543-5682-4615-a650-8366039ae09b,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-7699aeab-5058-4429-b6a8-1e13e9183f29,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-b16515bb-35b5-4e8d-8ab6-8602cf8ffcb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629979078-172.17.0.9-1595922179898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35448,DS-a258f151-4c53-4693-b516-79ea397219c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-5b9cbab6-94d7-4026-a419-80c33272597d,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-fdd08857-ea95-49a7-aebc-297eaff292c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-7366f7f8-d0da-4a25-96f4-abef7773917a,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-4d86cdd5-7777-4e43-83d2-dd55e67d7b62,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-521b7bcd-e740-493a-b399-c3525b0a16f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-07305762-82c7-4232-bd3c-c4f6795d2075,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-830860b4-a3df-4b1b-a017-14422120cec2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629979078-172.17.0.9-1595922179898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35448,DS-a258f151-4c53-4693-b516-79ea397219c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-5b9cbab6-94d7-4026-a419-80c33272597d,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-fdd08857-ea95-49a7-aebc-297eaff292c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-7366f7f8-d0da-4a25-96f4-abef7773917a,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-4d86cdd5-7777-4e43-83d2-dd55e67d7b62,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-521b7bcd-e740-493a-b399-c3525b0a16f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-07305762-82c7-4232-bd3c-c4f6795d2075,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-830860b4-a3df-4b1b-a017-14422120cec2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455274067-172.17.0.9-1595922514204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33805,DS-21dda204-401e-4fce-8186-e60147e75bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-984fa372-39f8-40a5-9abd-f2f9b6756592,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-20228b7e-d9fa-45c0-9159-f55102212d79,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-770eb4eb-2daa-44bc-be52-7de972c41b26,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-3aedbd3e-d9a4-4c2c-8dc8-c46948f60516,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-359728f0-3abf-4084-9ad3-2a40a62870c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-ae9739a6-3220-48a9-ad85-dbdc9573e712,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-9938c2d9-d417-45c3-8e42-20f798cc14ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1455274067-172.17.0.9-1595922514204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33805,DS-21dda204-401e-4fce-8186-e60147e75bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-984fa372-39f8-40a5-9abd-f2f9b6756592,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-20228b7e-d9fa-45c0-9159-f55102212d79,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-770eb4eb-2daa-44bc-be52-7de972c41b26,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-3aedbd3e-d9a4-4c2c-8dc8-c46948f60516,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-359728f0-3abf-4084-9ad3-2a40a62870c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39993,DS-ae9739a6-3220-48a9-ad85-dbdc9573e712,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-9938c2d9-d417-45c3-8e42-20f798cc14ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: file.bytes-per-checksum
component: hdfs:DataNode
v1: 512
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550466950-172.17.0.9-1595922639793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36198,DS-ec9818d3-f2f7-4742-ac1b-c3b0b0770792,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-3622c97e-0b9e-4ca6-9ca7-3334e4eb8fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-9df158b6-ade9-43de-b0dd-1d82b4db8188,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-94ff9815-0f3f-4ccb-b8cc-71cd9ddb5689,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-4822178a-2d40-4e34-87a2-9ee243dd2797,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-efb00a42-890b-4b57-acbb-101c8cd17388,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-1b82c0e3-6fa6-4ce1-8909-cea88e5b5549,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-bd33f1d4-156b-403b-afdd-886d30d6c849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550466950-172.17.0.9-1595922639793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36198,DS-ec9818d3-f2f7-4742-ac1b-c3b0b0770792,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-3622c97e-0b9e-4ca6-9ca7-3334e4eb8fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-9df158b6-ade9-43de-b0dd-1d82b4db8188,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-94ff9815-0f3f-4ccb-b8cc-71cd9ddb5689,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-4822178a-2d40-4e34-87a2-9ee243dd2797,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-efb00a42-890b-4b57-acbb-101c8cd17388,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-1b82c0e3-6fa6-4ce1-8909-cea88e5b5549,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-bd33f1d4-156b-403b-afdd-886d30d6c849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6739
