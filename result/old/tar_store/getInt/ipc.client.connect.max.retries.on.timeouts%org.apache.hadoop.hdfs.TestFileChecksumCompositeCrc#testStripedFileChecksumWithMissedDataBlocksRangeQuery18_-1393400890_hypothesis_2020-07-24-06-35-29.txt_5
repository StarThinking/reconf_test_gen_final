reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151044196-172.17.0.12-1595572908871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42090,DS-600d813d-939e-4c5c-be53-acb22e3fbea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-7652709a-d6bd-489c-ad66-5dede08dfd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-16d6237b-9004-4bd5-9ddb-72932b7c3918,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-b3528b50-e2f7-4f7c-be47-764e39cec804,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-7387def2-bd0e-492a-b7a8-28fd51f5dfee,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-409f92fd-db52-4c5b-8235-df43a94feb73,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-4364ddbd-9a5d-45c0-a124-e18189c010c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-34eda640-2071-4964-9fae-92405e744d1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151044196-172.17.0.12-1595572908871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42090,DS-600d813d-939e-4c5c-be53-acb22e3fbea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-7652709a-d6bd-489c-ad66-5dede08dfd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-16d6237b-9004-4bd5-9ddb-72932b7c3918,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-b3528b50-e2f7-4f7c-be47-764e39cec804,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-7387def2-bd0e-492a-b7a8-28fd51f5dfee,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-409f92fd-db52-4c5b-8235-df43a94feb73,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-4364ddbd-9a5d-45c0-a124-e18189c010c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-34eda640-2071-4964-9fae-92405e744d1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315412223-172.17.0.12-1595573019831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39575,DS-26977ee0-cc49-4494-bdc1-8aeae41dfaae,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-918812ba-956a-4986-a003-4600784cdc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-3deadce9-6935-49d2-94eb-f30c9fe7f0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-3610c607-5a9f-45b4-b92d-fcfbdd157ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-b12b183c-a569-4932-bf2c-2c0cf6684977,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-8b96bdd3-daf0-4881-ac80-c6c8d065ae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-1a6f4201-25ea-4aa4-97f5-24f4689a4b17,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-4f9ba1bb-f535-4328-913a-6995d6eb4dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315412223-172.17.0.12-1595573019831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39575,DS-26977ee0-cc49-4494-bdc1-8aeae41dfaae,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-918812ba-956a-4986-a003-4600784cdc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-3deadce9-6935-49d2-94eb-f30c9fe7f0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-3610c607-5a9f-45b4-b92d-fcfbdd157ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-b12b183c-a569-4932-bf2c-2c0cf6684977,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-8b96bdd3-daf0-4881-ac80-c6c8d065ae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-1a6f4201-25ea-4aa4-97f5-24f4689a4b17,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-4f9ba1bb-f535-4328-913a-6995d6eb4dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1898522936-172.17.0.12-1595573349552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35421,DS-a88fc788-d2e7-437c-8365-265d42dc95a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-7c1ea34f-a126-4d3c-8f5e-15f2226bc30b,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-2e52f124-779e-4d45-a010-f05aea83b1df,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-3cbf42ba-9193-45f2-839b-1a02fb29ff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-54b387c0-a340-464a-bcf8-70d74f4853dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-3d72ad52-d1c1-4e55-a7bc-29947a9379b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-2bee3ac7-4740-4a66-bf1f-08fac47d3323,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-8e71bf02-1e09-4800-bb79-e1abd016be8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1898522936-172.17.0.12-1595573349552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35421,DS-a88fc788-d2e7-437c-8365-265d42dc95a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-7c1ea34f-a126-4d3c-8f5e-15f2226bc30b,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-2e52f124-779e-4d45-a010-f05aea83b1df,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-3cbf42ba-9193-45f2-839b-1a02fb29ff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-54b387c0-a340-464a-bcf8-70d74f4853dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-3d72ad52-d1c1-4e55-a7bc-29947a9379b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-2bee3ac7-4740-4a66-bf1f-08fac47d3323,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-8e71bf02-1e09-4800-bb79-e1abd016be8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254323940-172.17.0.12-1595573619231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44701,DS-6bd334de-5c23-4293-ad73-a003786782ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-4c87506c-199b-4d3c-a66c-acbcc142e440,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-9893c249-5543-4142-9d10-a129d04673d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-be3a7c1f-ce61-430e-9ceb-d16400dc95cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-36b05d20-b3b8-4249-bb89-2684f6b3a15b,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-69e36b51-55e2-4d17-a5ab-dfb7c617d31b,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-27f5d738-875c-4928-9205-31c6279108f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-d10c655e-13b8-481c-8a73-9d2554da10ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254323940-172.17.0.12-1595573619231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44701,DS-6bd334de-5c23-4293-ad73-a003786782ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-4c87506c-199b-4d3c-a66c-acbcc142e440,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-9893c249-5543-4142-9d10-a129d04673d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-be3a7c1f-ce61-430e-9ceb-d16400dc95cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-36b05d20-b3b8-4249-bb89-2684f6b3a15b,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-69e36b51-55e2-4d17-a5ab-dfb7c617d31b,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-27f5d738-875c-4928-9205-31c6279108f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-d10c655e-13b8-481c-8a73-9d2554da10ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738547936-172.17.0.12-1595574540655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42353,DS-d1f6680e-0a4f-4ae2-b14f-2c1848e65dab,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-61a6deb9-0201-41ee-b424-09d48cebe919,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-e600a76e-67c0-4eb5-91bd-f4e2382ddcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-5c524037-58f5-43b3-9422-714516117dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-c715567c-8601-4781-9fe5-d6a119634d43,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-585cd703-a36e-4484-a80c-a906fecb1812,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-aad93d7d-8264-4700-8c75-63b55ed05d46,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-82628445-8052-4a38-82d0-c8879cdee4e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738547936-172.17.0.12-1595574540655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42353,DS-d1f6680e-0a4f-4ae2-b14f-2c1848e65dab,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-61a6deb9-0201-41ee-b424-09d48cebe919,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-e600a76e-67c0-4eb5-91bd-f4e2382ddcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-5c524037-58f5-43b3-9422-714516117dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-c715567c-8601-4781-9fe5-d6a119634d43,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-585cd703-a36e-4484-a80c-a906fecb1812,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-aad93d7d-8264-4700-8c75-63b55ed05d46,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-82628445-8052-4a38-82d0-c8879cdee4e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202769602-172.17.0.12-1595574766070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46814,DS-0d636ebc-c24f-433d-ac40-cb147bc1b64c,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-f22e5d93-caaf-4729-a94d-977e48d34b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-e5be361a-894c-41cf-8148-840579d07268,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-07116ee3-bf1f-4591-8a0e-1c9cddcf082c,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-eef024f7-512d-4599-8975-80f2addc80ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-0e9b34b6-b9d8-4d92-9fd1-7964ab058600,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-76a8b947-6559-4576-8c2e-705eee6895f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-d3f7b228-36a7-4a7f-b42d-0faa9a5a61e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202769602-172.17.0.12-1595574766070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46814,DS-0d636ebc-c24f-433d-ac40-cb147bc1b64c,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-f22e5d93-caaf-4729-a94d-977e48d34b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-e5be361a-894c-41cf-8148-840579d07268,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-07116ee3-bf1f-4591-8a0e-1c9cddcf082c,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-eef024f7-512d-4599-8975-80f2addc80ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-0e9b34b6-b9d8-4d92-9fd1-7964ab058600,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-76a8b947-6559-4576-8c2e-705eee6895f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-d3f7b228-36a7-4a7f-b42d-0faa9a5a61e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691789714-172.17.0.12-1595575024825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37143,DS-557890a8-db62-46c8-9955-2477155ba604,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-78b0f90c-628d-481a-9da3-23531c75c4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-451057fb-46ed-4076-a176-1b047f675f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-9518d16d-f558-4520-b622-c85a332459d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-5db4e287-40a0-45a9-8516-53774416bd29,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-192a36ed-710f-4687-a6b7-cdc2bb7e3cec,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-9164f28f-3449-4488-acc2-dad326e51936,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-3f4a159a-8f50-4975-9734-ec2b55eb3e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1691789714-172.17.0.12-1595575024825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37143,DS-557890a8-db62-46c8-9955-2477155ba604,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-78b0f90c-628d-481a-9da3-23531c75c4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-451057fb-46ed-4076-a176-1b047f675f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-9518d16d-f558-4520-b622-c85a332459d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-5db4e287-40a0-45a9-8516-53774416bd29,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-192a36ed-710f-4687-a6b7-cdc2bb7e3cec,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-9164f28f-3449-4488-acc2-dad326e51936,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-3f4a159a-8f50-4975-9734-ec2b55eb3e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302140167-172.17.0.12-1595575209028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42407,DS-4fafa113-7f77-402a-99e6-d6b68f476221,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-e25eebe8-d649-4e28-9895-845d848d480f,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-e69599ae-c420-47c7-bbd8-7d616bcf46c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-300913bb-a79f-4452-8a62-4cd06b75f4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-628b808a-958e-450f-bc64-d2434a057cec,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-a8f2a8dc-fcb2-4870-ab35-8d1d14b43980,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-e57b4322-7aa0-45ec-8bee-dbcb80b7bf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-2c5be172-56f4-4b06-84e4-f856935d9ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1302140167-172.17.0.12-1595575209028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42407,DS-4fafa113-7f77-402a-99e6-d6b68f476221,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-e25eebe8-d649-4e28-9895-845d848d480f,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-e69599ae-c420-47c7-bbd8-7d616bcf46c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-300913bb-a79f-4452-8a62-4cd06b75f4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-628b808a-958e-450f-bc64-d2434a057cec,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-a8f2a8dc-fcb2-4870-ab35-8d1d14b43980,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-e57b4322-7aa0-45ec-8bee-dbcb80b7bf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-2c5be172-56f4-4b06-84e4-f856935d9ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769538620-172.17.0.12-1595575492938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45542,DS-63281b37-f9af-4b9a-baf9-280fb418cf36,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-e832a376-a339-47fe-ba7b-b3c3e6026f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-fb6c7b60-1861-4aad-864e-4d132c5286fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-c3afc6c2-9fe7-4088-99dd-5a5aba8dd174,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-dcacfe0e-6c7d-4919-a6d9-60be19ec3093,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-6212e65b-e8b6-422c-85d4-3adc9b1bd53f,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-3e6dd1c1-80a3-41c8-a586-2f6d04ba42f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-770bb337-a38d-41f7-b6b3-7572fafb7ca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-769538620-172.17.0.12-1595575492938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45542,DS-63281b37-f9af-4b9a-baf9-280fb418cf36,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-e832a376-a339-47fe-ba7b-b3c3e6026f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46200,DS-fb6c7b60-1861-4aad-864e-4d132c5286fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-c3afc6c2-9fe7-4088-99dd-5a5aba8dd174,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-dcacfe0e-6c7d-4919-a6d9-60be19ec3093,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-6212e65b-e8b6-422c-85d4-3adc9b1bd53f,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-3e6dd1c1-80a3-41c8-a586-2f6d04ba42f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-770bb337-a38d-41f7-b6b3-7572fafb7ca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434929896-172.17.0.12-1595575890530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39155,DS-dd00dd38-fe0b-4ad4-ba72-eca610387073,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-6735849f-0760-4a6f-92d0-d010941cf38c,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-434fed42-ef49-410a-9ca5-ed8e020f7bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-bf1bc382-b6f6-4032-a0bd-1cd71a2759de,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-0a3f8ba8-cf9b-4ac6-b3f6-6f5f51b16995,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-ab66d516-969d-43b5-95d9-aaea1b49b3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-8a5cdc4b-686b-4a9c-9f2f-1d96855d2d15,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-78443c92-b976-4126-a422-553488b3b86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1434929896-172.17.0.12-1595575890530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39155,DS-dd00dd38-fe0b-4ad4-ba72-eca610387073,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-6735849f-0760-4a6f-92d0-d010941cf38c,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-434fed42-ef49-410a-9ca5-ed8e020f7bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-bf1bc382-b6f6-4032-a0bd-1cd71a2759de,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-0a3f8ba8-cf9b-4ac6-b3f6-6f5f51b16995,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-ab66d516-969d-43b5-95d9-aaea1b49b3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-8a5cdc4b-686b-4a9c-9f2f-1d96855d2d15,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-78443c92-b976-4126-a422-553488b3b86b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1773506233-172.17.0.12-1595576417401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34382,DS-dd67d600-ea92-4503-838d-cd428867d8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-10e981e2-7d96-4c44-9e71-038cdeb87731,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-45adc78f-4f77-4bf8-88e4-5453369f54f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-41fd3bb2-4b86-4b73-a623-9381de0de506,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-baf95ac4-3a7d-486f-906a-f12595f4b4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-154136b9-f920-408f-9bd3-3c9d6c58535b,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-15212a41-9ac0-4237-a62c-2a68f49676ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-08cd1e90-ffa8-4b42-a4aa-882a0ecee1ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1773506233-172.17.0.12-1595576417401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34382,DS-dd67d600-ea92-4503-838d-cd428867d8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-10e981e2-7d96-4c44-9e71-038cdeb87731,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-45adc78f-4f77-4bf8-88e4-5453369f54f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-41fd3bb2-4b86-4b73-a623-9381de0de506,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-baf95ac4-3a7d-486f-906a-f12595f4b4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-154136b9-f920-408f-9bd3-3c9d6c58535b,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-15212a41-9ac0-4237-a62c-2a68f49676ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-08cd1e90-ffa8-4b42-a4aa-882a0ecee1ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544716546-172.17.0.12-1595576868649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43403,DS-d814edf2-1487-4cc5-9cac-7728f7fbc239,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-c6fdbb76-53f1-45da-a892-36b46fc76d26,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-364df6b6-120e-4906-bb2d-3c6deab19c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-2ae78302-877e-47b7-a582-fcaf2481f2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-6f43811d-adf7-4ac0-8428-ade1f55f99a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-1a362f80-6622-4d27-aa4b-7bfb6d605c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-19b0f40c-50d0-4582-ac5f-50b1df7f6202,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-615cca5a-f84d-44fa-9209-199323355ca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544716546-172.17.0.12-1595576868649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43403,DS-d814edf2-1487-4cc5-9cac-7728f7fbc239,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-c6fdbb76-53f1-45da-a892-36b46fc76d26,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-364df6b6-120e-4906-bb2d-3c6deab19c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-2ae78302-877e-47b7-a582-fcaf2481f2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-6f43811d-adf7-4ac0-8428-ade1f55f99a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-1a362f80-6622-4d27-aa4b-7bfb6d605c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-19b0f40c-50d0-4582-ac5f-50b1df7f6202,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-615cca5a-f84d-44fa-9209-199323355ca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109631566-172.17.0.12-1595577462050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-d3d794b8-55ef-4e3d-8349-ea9278bb4991,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-a8b209a3-21c6-4647-8386-9d08805544a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-e78e8478-eac0-4169-9c56-0d822e413538,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-2220ca72-bcfc-4501-b55d-5e51c62f179d,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-1c40b858-27f4-4037-a41a-81faa165ac47,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-a917832b-2b89-441f-9b8a-686a106c9d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-29daae4b-7337-4ea5-9df7-43460a49dd12,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-49f22468-f1de-4e6c-b626-9e4960044740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109631566-172.17.0.12-1595577462050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-d3d794b8-55ef-4e3d-8349-ea9278bb4991,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-a8b209a3-21c6-4647-8386-9d08805544a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-e78e8478-eac0-4169-9c56-0d822e413538,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-2220ca72-bcfc-4501-b55d-5e51c62f179d,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-1c40b858-27f4-4037-a41a-81faa165ac47,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-a917832b-2b89-441f-9b8a-686a106c9d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-29daae4b-7337-4ea5-9df7-43460a49dd12,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-49f22468-f1de-4e6c-b626-9e4960044740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116306032-172.17.0.12-1595577534695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42790,DS-b5e2f1fd-3a19-42e3-a5d8-3d9c68027752,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-c4bf5427-0de4-4650-86fb-f0dc22ee006d,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-3117c866-36cc-4e34-9e11-dbdc58d66147,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-ee7dffee-2e39-4ba7-bbb1-21aa634e2977,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-15bad46f-512d-4345-9528-647e2f6ccae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-f5374744-4290-44a6-907e-b1d25bf1b8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-f0ac6cb0-9cc4-46e8-8d0b-89abd8c0d5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-c40f2a00-611d-4a1a-b5ee-fa387e77dfc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116306032-172.17.0.12-1595577534695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42790,DS-b5e2f1fd-3a19-42e3-a5d8-3d9c68027752,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-c4bf5427-0de4-4650-86fb-f0dc22ee006d,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-3117c866-36cc-4e34-9e11-dbdc58d66147,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-ee7dffee-2e39-4ba7-bbb1-21aa634e2977,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-15bad46f-512d-4345-9528-647e2f6ccae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-f5374744-4290-44a6-907e-b1d25bf1b8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-f0ac6cb0-9cc4-46e8-8d0b-89abd8c0d5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-c40f2a00-611d-4a1a-b5ee-fa387e77dfc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235717513-172.17.0.12-1595577573926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37912,DS-b65cddf6-3c9f-4ec9-9afa-0585d5c5c0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-f40c7ef7-20d3-401f-976d-735866b044de,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-fc99490e-3796-413c-8b21-ec12b8bbfe7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-54da71c6-da40-494a-8dcb-749d87b368cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-61ae5af7-5a36-4a81-950b-0da6b8d91acd,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-579a38e1-7f96-4281-9b17-f888b00f3c30,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-3ddda90d-630a-44ff-b622-90159ae5bcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-7d40e348-2223-4245-ad38-520d9e36d87f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235717513-172.17.0.12-1595577573926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37912,DS-b65cddf6-3c9f-4ec9-9afa-0585d5c5c0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-f40c7ef7-20d3-401f-976d-735866b044de,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-fc99490e-3796-413c-8b21-ec12b8bbfe7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-54da71c6-da40-494a-8dcb-749d87b368cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-61ae5af7-5a36-4a81-950b-0da6b8d91acd,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-579a38e1-7f96-4281-9b17-f888b00f3c30,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-3ddda90d-630a-44ff-b622-90159ae5bcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-7d40e348-2223-4245-ad38-520d9e36d87f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:NameNode
v1: 45
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491345654-172.17.0.12-1595577639423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43553,DS-6a145bb4-a672-4b6d-88ca-5958355780cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-55f68fae-4b44-48c2-b7d2-8207f40564f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-d4278bdb-d314-4603-8142-948201f61cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-6926c694-c0e7-4137-914e-f729d601e09d,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-23b8ad0e-0967-4529-93a1-7b91901a1d78,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-d157c04e-a99b-4397-8490-ff1869306278,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-6c2a9002-a178-4251-919b-e540bc40b729,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-7e5b6679-ebb7-4788-9e04-dd18a01200ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491345654-172.17.0.12-1595577639423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43553,DS-6a145bb4-a672-4b6d-88ca-5958355780cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-55f68fae-4b44-48c2-b7d2-8207f40564f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-d4278bdb-d314-4603-8142-948201f61cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-6926c694-c0e7-4137-914e-f729d601e09d,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-23b8ad0e-0967-4529-93a1-7b91901a1d78,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-d157c04e-a99b-4397-8490-ff1869306278,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-6c2a9002-a178-4251-919b-e540bc40b729,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-7e5b6679-ebb7-4788-9e04-dd18a01200ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5360
