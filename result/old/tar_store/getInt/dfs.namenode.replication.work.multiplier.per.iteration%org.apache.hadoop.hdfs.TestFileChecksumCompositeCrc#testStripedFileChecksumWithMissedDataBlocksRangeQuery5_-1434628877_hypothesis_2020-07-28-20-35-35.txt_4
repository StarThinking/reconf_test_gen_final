reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457765171-172.17.0.15-1595969174863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36333,DS-f31e02eb-a6df-4f74-a307-7bfef8cad7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-0cee763f-22d1-41bd-b713-823208f2617b,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-c347660c-4341-4c8e-80c0-b35b2d896b07,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-738760cc-fd26-424c-bef1-e663e8568679,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-b843dfc7-01f2-439f-b119-37a7744ee09c,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-39f796a1-2f53-4cb0-8b91-b20ea1328c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-dbc0dbd1-082f-458d-a0d6-a54e4eb52671,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-9767244c-b55f-40da-acf6-5d06b864e9fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457765171-172.17.0.15-1595969174863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36333,DS-f31e02eb-a6df-4f74-a307-7bfef8cad7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-0cee763f-22d1-41bd-b713-823208f2617b,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-c347660c-4341-4c8e-80c0-b35b2d896b07,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-738760cc-fd26-424c-bef1-e663e8568679,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-b843dfc7-01f2-439f-b119-37a7744ee09c,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-39f796a1-2f53-4cb0-8b91-b20ea1328c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-dbc0dbd1-082f-458d-a0d6-a54e4eb52671,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-9767244c-b55f-40da-acf6-5d06b864e9fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875668291-172.17.0.15-1595969248689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-8c71532a-1b56-4b1c-9beb-0730bbfaaedc,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-33ac9a6d-65db-4e5a-a4a9-175afe03ab19,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-4c7f3b5a-8360-4293-9521-a1c2cd106b78,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-d2dd5c78-49cb-4b49-983b-72b860d84dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-16e858f2-fae1-45ab-99ca-989df2dd9452,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-48ade8bf-e1d3-4244-a550-21da48052b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-cf4dcd1a-0e9c-4af8-8190-5c528a95701a,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-aa1964ad-c193-462d-bf1c-8d9d36221b2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1875668291-172.17.0.15-1595969248689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35806,DS-8c71532a-1b56-4b1c-9beb-0730bbfaaedc,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-33ac9a6d-65db-4e5a-a4a9-175afe03ab19,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-4c7f3b5a-8360-4293-9521-a1c2cd106b78,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-d2dd5c78-49cb-4b49-983b-72b860d84dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-16e858f2-fae1-45ab-99ca-989df2dd9452,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-48ade8bf-e1d3-4244-a550-21da48052b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-cf4dcd1a-0e9c-4af8-8190-5c528a95701a,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-aa1964ad-c193-462d-bf1c-8d9d36221b2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80766606-172.17.0.15-1595969481950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39961,DS-f4618256-b514-4849-bc05-a632c1b45548,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-a7c296f8-1258-4bf8-a70d-36147f2b705e,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-6979fa95-8fe7-47dc-b2c5-03ccde0649d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-acb96e98-0c79-4834-be7a-8debdeb31ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-26efcf9a-52fe-48e4-adda-431d5a20b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-f2b0675f-c81f-4543-b1e0-97700d5a1193,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-9951dc34-ec3d-489f-b331-356d78f20958,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-bb6ad878-242d-496e-8cfc-9e730e052048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80766606-172.17.0.15-1595969481950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39961,DS-f4618256-b514-4849-bc05-a632c1b45548,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-a7c296f8-1258-4bf8-a70d-36147f2b705e,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-6979fa95-8fe7-47dc-b2c5-03ccde0649d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-acb96e98-0c79-4834-be7a-8debdeb31ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-26efcf9a-52fe-48e4-adda-431d5a20b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-f2b0675f-c81f-4543-b1e0-97700d5a1193,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-9951dc34-ec3d-489f-b331-356d78f20958,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-bb6ad878-242d-496e-8cfc-9e730e052048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436371567-172.17.0.15-1595969592757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35970,DS-5bf3e50d-33d6-4f8a-9d69-7e4713234868,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-497aa9d6-5689-428c-b2d2-acd4a1667d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-374166cc-61e0-4c36-a34f-c0686e28fe00,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-92233bf3-c20f-45d2-a692-0fdb85b11248,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-105fcda2-8730-40ff-b7e3-1dd4f3f73fee,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-bc074e2e-72cd-40b5-af77-2dabb73b0b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-eb258cff-7e0b-4bdf-ab43-f6e5af61d066,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-a92be5f0-b8b9-48f7-b87e-7d857c9e3b32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-436371567-172.17.0.15-1595969592757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35970,DS-5bf3e50d-33d6-4f8a-9d69-7e4713234868,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-497aa9d6-5689-428c-b2d2-acd4a1667d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-374166cc-61e0-4c36-a34f-c0686e28fe00,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-92233bf3-c20f-45d2-a692-0fdb85b11248,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-105fcda2-8730-40ff-b7e3-1dd4f3f73fee,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-bc074e2e-72cd-40b5-af77-2dabb73b0b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-eb258cff-7e0b-4bdf-ab43-f6e5af61d066,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-a92be5f0-b8b9-48f7-b87e-7d857c9e3b32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71426552-172.17.0.15-1595970060924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45446,DS-8f7761c0-ae20-4d78-ab32-388f25e2ba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-37b679e2-b3c5-4ef0-9cd2-9baee866b7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-54b09471-8a8b-4103-b6cb-3eb0d6013fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-19a8d3a2-eab9-42f5-97f2-b7871186a9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-dcd0962b-173d-4162-8256-bc3de95e37da,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-04636a78-9ea2-4d75-812b-fd1db59f4ead,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-11d5f5fa-1df6-4d54-b82e-087c27ec1c08,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-d7b4a37c-fe9e-41bf-80a7-6ea344cc9aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71426552-172.17.0.15-1595970060924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45446,DS-8f7761c0-ae20-4d78-ab32-388f25e2ba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-37b679e2-b3c5-4ef0-9cd2-9baee866b7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-54b09471-8a8b-4103-b6cb-3eb0d6013fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-19a8d3a2-eab9-42f5-97f2-b7871186a9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-dcd0962b-173d-4162-8256-bc3de95e37da,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-04636a78-9ea2-4d75-812b-fd1db59f4ead,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-11d5f5fa-1df6-4d54-b82e-087c27ec1c08,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-d7b4a37c-fe9e-41bf-80a7-6ea344cc9aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774827692-172.17.0.15-1595970537857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39353,DS-99f41649-a8a7-4659-9f96-507bc4d4cea4,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-9a8c227e-492b-44c5-9107-99cdf9f09a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-c152d438-7293-415d-b972-76128eb39f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-5da7f47e-24e5-4f4a-bbb6-682e8b88da63,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-e8d850db-4e44-4350-84cc-a238f17ba9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-ca3ab4c2-261c-44ea-a022-9f89605aaa11,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-68d1d7ed-f721-4b64-9d09-2444a27d1b39,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-24d54d60-a98f-4950-9428-4ff7928a39f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774827692-172.17.0.15-1595970537857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39353,DS-99f41649-a8a7-4659-9f96-507bc4d4cea4,DISK], DatanodeInfoWithStorage[127.0.0.1:42922,DS-9a8c227e-492b-44c5-9107-99cdf9f09a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-c152d438-7293-415d-b972-76128eb39f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35430,DS-5da7f47e-24e5-4f4a-bbb6-682e8b88da63,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-e8d850db-4e44-4350-84cc-a238f17ba9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-ca3ab4c2-261c-44ea-a022-9f89605aaa11,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-68d1d7ed-f721-4b64-9d09-2444a27d1b39,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-24d54d60-a98f-4950-9428-4ff7928a39f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337212357-172.17.0.15-1595970577408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44304,DS-29c018d6-ee3e-4977-ba1d-86e554ddd3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-0488c834-a5e1-4cbc-950a-5fcc9c7c1daf,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-2434fcc9-a8bf-44a5-9610-f09b4294c91b,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-d5398ab1-34f7-468f-99d8-23cddee798de,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-52862e68-df5b-4363-b7b9-6a4fcaad30ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-68ad7671-0244-4266-b5cd-37e6ac552436,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-539a5921-f4a3-45bf-a1be-7179ec2ea843,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-09e7258e-1fe7-4f60-8fa6-807c62bc1891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337212357-172.17.0.15-1595970577408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44304,DS-29c018d6-ee3e-4977-ba1d-86e554ddd3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-0488c834-a5e1-4cbc-950a-5fcc9c7c1daf,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-2434fcc9-a8bf-44a5-9610-f09b4294c91b,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-d5398ab1-34f7-468f-99d8-23cddee798de,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-52862e68-df5b-4363-b7b9-6a4fcaad30ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-68ad7671-0244-4266-b5cd-37e6ac552436,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-539a5921-f4a3-45bf-a1be-7179ec2ea843,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-09e7258e-1fe7-4f60-8fa6-807c62bc1891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238109557-172.17.0.15-1595970766578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41095,DS-6f4ee4d7-5c83-4d4c-ab7d-45044f5c5405,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-a96e561a-6ac5-4bf7-bc26-ebdb0432dd82,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-ab11d106-058f-4125-9e3c-9bcaf1613b74,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-00a7c482-1ec0-40b2-9e54-3fa645897ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-a39a73a6-fcb9-4c45-be8c-add65eaaf831,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-a435752b-b64b-44e0-b067-08066afb7d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-d04e1d0d-a965-4f64-95f0-aecb09750c60,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-fab381b3-c7be-4abd-9882-4fb1a6be899f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-238109557-172.17.0.15-1595970766578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41095,DS-6f4ee4d7-5c83-4d4c-ab7d-45044f5c5405,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-a96e561a-6ac5-4bf7-bc26-ebdb0432dd82,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-ab11d106-058f-4125-9e3c-9bcaf1613b74,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-00a7c482-1ec0-40b2-9e54-3fa645897ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-a39a73a6-fcb9-4c45-be8c-add65eaaf831,DISK], DatanodeInfoWithStorage[127.0.0.1:46475,DS-a435752b-b64b-44e0-b067-08066afb7d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-d04e1d0d-a965-4f64-95f0-aecb09750c60,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-fab381b3-c7be-4abd-9882-4fb1a6be899f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360167223-172.17.0.15-1595970874463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36481,DS-2ae4eccd-6bd3-4207-8e9d-8436b7ac5358,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-64d8f3e1-5e40-48ad-ac98-f6a62752390d,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-5bb133a5-bd33-4a10-baa3-d765ccc1e2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-119c19af-aa68-40b1-9f4b-881822b7b184,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-7df47678-16c3-4719-b982-d4de457dd712,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-da380923-b89d-4374-ad57-afd457b2adfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-03061616-8469-433d-a879-a979bedc289f,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-264ce049-5dfa-4322-8d44-aaf9907140be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360167223-172.17.0.15-1595970874463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36481,DS-2ae4eccd-6bd3-4207-8e9d-8436b7ac5358,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-64d8f3e1-5e40-48ad-ac98-f6a62752390d,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-5bb133a5-bd33-4a10-baa3-d765ccc1e2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-119c19af-aa68-40b1-9f4b-881822b7b184,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-7df47678-16c3-4719-b982-d4de457dd712,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-da380923-b89d-4374-ad57-afd457b2adfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-03061616-8469-433d-a879-a979bedc289f,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-264ce049-5dfa-4322-8d44-aaf9907140be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845948527-172.17.0.15-1595971294137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41357,DS-3b65a0c8-2ebc-46e2-b548-8446ae620f95,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-fecb3093-b3dd-4969-a380-fc82ca984b12,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-d26642b7-a070-4aed-9d7e-46d6de72e01a,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-7cad7c13-6cc3-4e35-8157-f58cfc2cdbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-3d5f7e6f-e048-4680-b17a-bde968b77bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-abb22a2b-c697-4214-bcd8-8c731eca7a18,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-97170a7d-9e90-422a-8f09-3865c64aa8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-30abb781-fe5d-4a4f-a365-753f90234bcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845948527-172.17.0.15-1595971294137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41357,DS-3b65a0c8-2ebc-46e2-b548-8446ae620f95,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-fecb3093-b3dd-4969-a380-fc82ca984b12,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-d26642b7-a070-4aed-9d7e-46d6de72e01a,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-7cad7c13-6cc3-4e35-8157-f58cfc2cdbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-3d5f7e6f-e048-4680-b17a-bde968b77bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-abb22a2b-c697-4214-bcd8-8c731eca7a18,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-97170a7d-9e90-422a-8f09-3865c64aa8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-30abb781-fe5d-4a4f-a365-753f90234bcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380731239-172.17.0.15-1595971442333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-03e66dde-08e8-4a57-b83f-2478c38edc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-0b47a400-c1dd-4570-8039-4971fa491cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-3cc0de16-0051-48b7-91b7-e887c067537e,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-9ecfb716-a5c1-4dcd-be31-0deb348b86ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-175316c3-d192-4497-8c7a-bada30533649,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-096474a9-a5c2-42f3-b5e6-793072cb687c,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-6f19a667-ad05-4a3e-bce5-2f553054d77e,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-a03ed4ae-3d52-4b54-850d-f8d131927802,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380731239-172.17.0.15-1595971442333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-03e66dde-08e8-4a57-b83f-2478c38edc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-0b47a400-c1dd-4570-8039-4971fa491cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-3cc0de16-0051-48b7-91b7-e887c067537e,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-9ecfb716-a5c1-4dcd-be31-0deb348b86ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-175316c3-d192-4497-8c7a-bada30533649,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-096474a9-a5c2-42f3-b5e6-793072cb687c,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-6f19a667-ad05-4a3e-bce5-2f553054d77e,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-a03ed4ae-3d52-4b54-850d-f8d131927802,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072883942-172.17.0.15-1595972002258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36786,DS-b9fc77c7-6548-4b04-8b8a-1037d5a43e40,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-b02e9392-26e9-461d-a755-1bca2ce4045b,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-4911a88a-bbc1-4820-ad04-6227ed520c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-2c347f47-1385-4997-aabd-65a396c672e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-d71310cc-2868-47f3-96b9-30841536357c,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-0c54fda5-54a6-4374-835e-f342074dddbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-2da02b0d-e265-4113-8bcc-cc5b2716c42f,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-60211261-d27c-4c73-a1e5-f7d7acfd4eb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072883942-172.17.0.15-1595972002258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36786,DS-b9fc77c7-6548-4b04-8b8a-1037d5a43e40,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-b02e9392-26e9-461d-a755-1bca2ce4045b,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-4911a88a-bbc1-4820-ad04-6227ed520c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-2c347f47-1385-4997-aabd-65a396c672e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41798,DS-d71310cc-2868-47f3-96b9-30841536357c,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-0c54fda5-54a6-4374-835e-f342074dddbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-2da02b0d-e265-4113-8bcc-cc5b2716c42f,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-60211261-d27c-4c73-a1e5-f7d7acfd4eb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734469013-172.17.0.15-1595972231758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42412,DS-0f5688d3-ea86-4f42-968d-9c23cb28a48c,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-e8ac29ee-a40c-49a8-879d-fec277c4e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-1d88308d-308a-49d1-a8f5-6ef4a8499b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-d2a62b8a-45d0-4c04-872e-091a53cb248c,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-f0b80aa9-5bb6-4154-8d35-c7aec655d83f,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-d213bd04-2f03-4fdf-b6c8-34e081857bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-58a39c59-65c9-4030-bc6b-4863854ad69f,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-24cf98d3-6033-4672-a8c5-773aff93f995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734469013-172.17.0.15-1595972231758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42412,DS-0f5688d3-ea86-4f42-968d-9c23cb28a48c,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-e8ac29ee-a40c-49a8-879d-fec277c4e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-1d88308d-308a-49d1-a8f5-6ef4a8499b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-d2a62b8a-45d0-4c04-872e-091a53cb248c,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-f0b80aa9-5bb6-4154-8d35-c7aec655d83f,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-d213bd04-2f03-4fdf-b6c8-34e081857bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-58a39c59-65c9-4030-bc6b-4863854ad69f,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-24cf98d3-6033-4672-a8c5-773aff93f995,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367951137-172.17.0.15-1595972728901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44814,DS-f62ecfaf-6169-49cb-b43b-5117d4f3fcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-ee261f31-b8f6-4282-b1f9-65500499aaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-4cbe462d-9f56-4604-8d5a-0c66b189c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-ca78b786-21ff-484c-96dd-47b40b9e845d,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-0b7579cb-161e-458d-b7b5-6af8bb7920d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-acabd455-10ab-44eb-9ef1-2c243009982b,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-0a23fc39-19bc-40cb-b21f-7cb30ee16d89,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-dd295041-bd86-4287-b53f-3030eb5e6422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367951137-172.17.0.15-1595972728901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44814,DS-f62ecfaf-6169-49cb-b43b-5117d4f3fcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-ee261f31-b8f6-4282-b1f9-65500499aaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-4cbe462d-9f56-4604-8d5a-0c66b189c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-ca78b786-21ff-484c-96dd-47b40b9e845d,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-0b7579cb-161e-458d-b7b5-6af8bb7920d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-acabd455-10ab-44eb-9ef1-2c243009982b,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-0a23fc39-19bc-40cb-b21f-7cb30ee16d89,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-dd295041-bd86-4287-b53f-3030eb5e6422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961274855-172.17.0.15-1595973398113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42224,DS-92dd5013-aaa2-4ecf-aa31-21279d732885,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-d0e4d8bd-ff69-4708-ae4c-f9292a98d6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-460d8efc-a73b-4bc1-ad3d-ab9293193e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-c536daa4-080e-4be8-a6b8-2089e7fcb8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-51d75f25-e243-4fac-b587-473516330314,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-8e806f08-81ac-446e-afcf-0cadc54133ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-b9683730-7939-4803-b883-3f85a64a7e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-0885afc6-7646-40d6-8038-484dd2b2324e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961274855-172.17.0.15-1595973398113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42224,DS-92dd5013-aaa2-4ecf-aa31-21279d732885,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-d0e4d8bd-ff69-4708-ae4c-f9292a98d6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-460d8efc-a73b-4bc1-ad3d-ab9293193e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-c536daa4-080e-4be8-a6b8-2089e7fcb8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-51d75f25-e243-4fac-b587-473516330314,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-8e806f08-81ac-446e-afcf-0cadc54133ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-b9683730-7939-4803-b883-3f85a64a7e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-0885afc6-7646-40d6-8038-484dd2b2324e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5346
