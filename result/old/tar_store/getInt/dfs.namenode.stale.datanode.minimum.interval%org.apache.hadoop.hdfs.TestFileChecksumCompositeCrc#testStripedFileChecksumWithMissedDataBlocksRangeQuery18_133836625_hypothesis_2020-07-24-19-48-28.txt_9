reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945834-172.17.0.11-1595620186631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45715,DS-5cdd00d1-e519-43d4-b428-84759c0c61ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-5ac0b236-293c-47d5-aa46-1609c6925447,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-87928983-3567-405f-a77e-34c4fb545eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-54de3f55-39a9-4a38-a7e0-98926289cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-e0b9a2b1-72a5-4670-8b76-9af7d0956ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-f3445cde-b57a-4fb2-b83d-0db189619319,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-d8409dc0-2001-40e3-b363-59f6e37966ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-b68cfb31-2965-4a4c-9393-50182757a6ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945834-172.17.0.11-1595620186631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45715,DS-5cdd00d1-e519-43d4-b428-84759c0c61ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-5ac0b236-293c-47d5-aa46-1609c6925447,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-87928983-3567-405f-a77e-34c4fb545eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-54de3f55-39a9-4a38-a7e0-98926289cb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-e0b9a2b1-72a5-4670-8b76-9af7d0956ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-f3445cde-b57a-4fb2-b83d-0db189619319,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-d8409dc0-2001-40e3-b363-59f6e37966ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-b68cfb31-2965-4a4c-9393-50182757a6ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1654232038-172.17.0.11-1595620528996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35968,DS-d8fda2e7-a4be-4665-b699-4a66c189250f,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-cacbd303-0ffe-42a0-84d7-51c5a8e3bb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-c5276470-e62d-4b08-a575-36e261414720,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-54ecbaff-0796-465e-9398-ef0d3b35f83d,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-dcc3e5ee-34dd-4ce3-9b99-c1babb87c98c,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-1948f6d2-ec6e-4f08-88a3-7db38b6e2f28,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-99700680-057a-482d-bc75-1093b9d875aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-0e34a162-6c64-4b5e-9cff-59bc4a78d470,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1654232038-172.17.0.11-1595620528996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35968,DS-d8fda2e7-a4be-4665-b699-4a66c189250f,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-cacbd303-0ffe-42a0-84d7-51c5a8e3bb4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-c5276470-e62d-4b08-a575-36e261414720,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-54ecbaff-0796-465e-9398-ef0d3b35f83d,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-dcc3e5ee-34dd-4ce3-9b99-c1babb87c98c,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-1948f6d2-ec6e-4f08-88a3-7db38b6e2f28,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-99700680-057a-482d-bc75-1093b9d875aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-0e34a162-6c64-4b5e-9cff-59bc4a78d470,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530584190-172.17.0.11-1595620561872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45569,DS-74cef415-8897-4da6-b66b-cccd3e699e05,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-4154d141-49d7-4376-82e7-44f4f9a6011f,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-5fef22a2-6fd4-4faf-afde-1012dffbdda7,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-5046633d-6d9b-419f-a62f-19edf45d2665,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-beb3e7bc-80ad-42c3-84e6-b308285054af,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-1d12443d-b5e3-492c-b07d-bc687b72b932,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-b0f3ab68-2e46-447e-86cf-25fd321d2091,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-99b420eb-4a07-4fc4-84a9-246c5101ad6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1530584190-172.17.0.11-1595620561872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45569,DS-74cef415-8897-4da6-b66b-cccd3e699e05,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-4154d141-49d7-4376-82e7-44f4f9a6011f,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-5fef22a2-6fd4-4faf-afde-1012dffbdda7,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-5046633d-6d9b-419f-a62f-19edf45d2665,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-beb3e7bc-80ad-42c3-84e6-b308285054af,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-1d12443d-b5e3-492c-b07d-bc687b72b932,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-b0f3ab68-2e46-447e-86cf-25fd321d2091,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-99b420eb-4a07-4fc4-84a9-246c5101ad6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380476440-172.17.0.11-1595620602807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45301,DS-4447f96a-5293-4a8c-a4e9-329785a8c284,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-a9bb16c1-018c-40e8-809b-cda472f99997,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-1ea0efd6-12b3-4ea0-a1cf-cd078edc431c,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-4982803b-c680-443d-9048-d8fef94510f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-e71c8c9b-148d-41f8-82da-cd599ac3e861,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-803219d8-3698-4717-b765-fb1acc82c825,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-cdd27718-4a80-4f28-8a4f-300dd84bb73f,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-58543ef9-b7f9-4cd2-9489-a3e400f0c25b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-380476440-172.17.0.11-1595620602807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45301,DS-4447f96a-5293-4a8c-a4e9-329785a8c284,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-a9bb16c1-018c-40e8-809b-cda472f99997,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-1ea0efd6-12b3-4ea0-a1cf-cd078edc431c,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-4982803b-c680-443d-9048-d8fef94510f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-e71c8c9b-148d-41f8-82da-cd599ac3e861,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-803219d8-3698-4717-b765-fb1acc82c825,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-cdd27718-4a80-4f28-8a4f-300dd84bb73f,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-58543ef9-b7f9-4cd2-9489-a3e400f0c25b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-418022278-172.17.0.11-1595620709247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34116,DS-519cd6d9-ddbb-4343-993d-3de3e293f8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-944c89e7-b35e-4836-b2f0-744b8e9f13da,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-93ef2790-9ca8-4ed6-a759-0190f92336ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-bc47462c-2423-48d7-9a54-976334c29bab,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-801643f0-1003-4388-bec7-d75b5131e3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-e4ae4c54-17ff-4191-9597-6b5ac95be5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-52985a69-edc0-42dd-bfcc-33b5a4a32e14,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-4d9e43b3-539e-4069-a47c-6a83c297aade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-418022278-172.17.0.11-1595620709247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34116,DS-519cd6d9-ddbb-4343-993d-3de3e293f8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-944c89e7-b35e-4836-b2f0-744b8e9f13da,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-93ef2790-9ca8-4ed6-a759-0190f92336ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-bc47462c-2423-48d7-9a54-976334c29bab,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-801643f0-1003-4388-bec7-d75b5131e3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-e4ae4c54-17ff-4191-9597-6b5ac95be5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35483,DS-52985a69-edc0-42dd-bfcc-33b5a4a32e14,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-4d9e43b3-539e-4069-a47c-6a83c297aade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706208829-172.17.0.11-1595621472651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39656,DS-7ad0d8ef-246b-413b-9fa7-1fc801ca9e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-b62d36ec-3f16-454a-a8e1-2c90bf1ae582,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-6e590204-aa13-4c18-804c-d6221a4005f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-b29cb0ad-8b94-4986-8b90-8cb5f2831085,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-67ac2891-b26f-4ffa-9c26-d9be70ddc6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-d7827d01-6cf7-4163-9e6c-2965bc17b4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-388c201a-1665-4d03-a291-5886a9856df0,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-9572a7a2-21b3-43e8-b8ea-fac5ebb99e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706208829-172.17.0.11-1595621472651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39656,DS-7ad0d8ef-246b-413b-9fa7-1fc801ca9e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-b62d36ec-3f16-454a-a8e1-2c90bf1ae582,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-6e590204-aa13-4c18-804c-d6221a4005f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42343,DS-b29cb0ad-8b94-4986-8b90-8cb5f2831085,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-67ac2891-b26f-4ffa-9c26-d9be70ddc6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-d7827d01-6cf7-4163-9e6c-2965bc17b4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-388c201a-1665-4d03-a291-5886a9856df0,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-9572a7a2-21b3-43e8-b8ea-fac5ebb99e06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209670710-172.17.0.11-1595621676261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42545,DS-aff890aa-7677-4b3f-a364-32b093a4f024,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-f1ebbc18-9bc4-478b-b265-a72c37c59285,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-e1994c72-02b9-4a37-979c-f44ac90af052,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-13eafef0-8c69-4265-8dca-6972ab3409f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-1d217aaf-8bc7-484f-9faf-2a03b6251b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-cb33dd94-6f13-47d3-a25c-011548af1c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-31486892-f73b-4052-a78e-ce9c6849b0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-f318913b-7960-4364-914e-c383f799d12d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209670710-172.17.0.11-1595621676261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42545,DS-aff890aa-7677-4b3f-a364-32b093a4f024,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-f1ebbc18-9bc4-478b-b265-a72c37c59285,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-e1994c72-02b9-4a37-979c-f44ac90af052,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-13eafef0-8c69-4265-8dca-6972ab3409f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-1d217aaf-8bc7-484f-9faf-2a03b6251b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-cb33dd94-6f13-47d3-a25c-011548af1c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-31486892-f73b-4052-a78e-ce9c6849b0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-f318913b-7960-4364-914e-c383f799d12d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670324186-172.17.0.11-1595621744175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33690,DS-09cead77-e8f0-4340-9b2c-1c3889b6acc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-f672bd23-bfd7-4701-9f2b-e4ad3f9e1077,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-d4285dfe-06f4-4e9d-aed9-7e91595896e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-61fb2d24-fd64-4715-8fd4-208e7567d02f,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-d81fdbd9-04a4-4c1e-9253-2979788dce5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-790b99ba-fbdd-454d-9fb4-629ff39bfa97,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-20fb3fd4-b904-4e5c-91fc-ae18615a2488,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-e284552c-1cfa-48c5-9a3e-ece8a4e8ed1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670324186-172.17.0.11-1595621744175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33690,DS-09cead77-e8f0-4340-9b2c-1c3889b6acc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-f672bd23-bfd7-4701-9f2b-e4ad3f9e1077,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-d4285dfe-06f4-4e9d-aed9-7e91595896e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-61fb2d24-fd64-4715-8fd4-208e7567d02f,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-d81fdbd9-04a4-4c1e-9253-2979788dce5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-790b99ba-fbdd-454d-9fb4-629ff39bfa97,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-20fb3fd4-b904-4e5c-91fc-ae18615a2488,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-e284552c-1cfa-48c5-9a3e-ece8a4e8ed1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574642794-172.17.0.11-1595621848671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46510,DS-b1f7385f-c5be-4ba8-b3f0-9d85183536b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-f9a3ab76-4b29-45a7-ab05-1a3b3d211635,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-c52235ab-cfb9-435c-a1f5-4d57664ef278,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-7b0ac4ae-dcb6-408d-9b17-8881e92eb2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-00ea3374-0171-4173-9149-49233076f1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-4bef53a6-7f7e-4591-aeac-8ec2fe4ac918,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-a640b76a-a20b-4719-bdab-c3dedd315f76,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-26c5dcfa-8a83-4bb5-952e-5b064243b08f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574642794-172.17.0.11-1595621848671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46510,DS-b1f7385f-c5be-4ba8-b3f0-9d85183536b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-f9a3ab76-4b29-45a7-ab05-1a3b3d211635,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-c52235ab-cfb9-435c-a1f5-4d57664ef278,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-7b0ac4ae-dcb6-408d-9b17-8881e92eb2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-00ea3374-0171-4173-9149-49233076f1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-4bef53a6-7f7e-4591-aeac-8ec2fe4ac918,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-a640b76a-a20b-4719-bdab-c3dedd315f76,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-26c5dcfa-8a83-4bb5-952e-5b064243b08f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115782641-172.17.0.11-1595621881050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46702,DS-9a0f0c4d-53a9-4703-b9ed-57f5159576b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-45ec14bf-86de-4814-8934-fbdf58e05799,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-bea9102b-410d-4a25-9f34-80ef3b1ddd78,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-4f556417-ba00-4e8a-8632-b00b3856fb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-483e3b6d-f5a1-43a1-a0cb-762d5bc4edf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-60583b06-6cbc-4654-90e7-3f1fb6d0bdac,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-703f98d4-e940-47b5-a291-108a43c0231f,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-105b1f07-99a8-4af1-852c-faa125279094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115782641-172.17.0.11-1595621881050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46702,DS-9a0f0c4d-53a9-4703-b9ed-57f5159576b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-45ec14bf-86de-4814-8934-fbdf58e05799,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-bea9102b-410d-4a25-9f34-80ef3b1ddd78,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-4f556417-ba00-4e8a-8632-b00b3856fb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-483e3b6d-f5a1-43a1-a0cb-762d5bc4edf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-60583b06-6cbc-4654-90e7-3f1fb6d0bdac,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-703f98d4-e940-47b5-a291-108a43c0231f,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-105b1f07-99a8-4af1-852c-faa125279094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597245151-172.17.0.11-1595621919134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45588,DS-a41a0b10-937b-43dc-8a5f-9eb3beb7acf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-d7ff0e15-ab68-4b0d-8a05-845f72a03948,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-e58cfbfa-79e5-4ae7-95d5-a15549620070,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-4e015ea4-5d60-4f54-88cc-8ee7c35013c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-4ca485d5-ca62-4d58-80ed-49530b185878,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-0a95cd62-1c19-42b0-b0a6-16571de57168,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-0902d4ee-ede0-4a7f-8624-0f48d7df8642,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-e5822d63-8827-47ff-b558-12e3f91417cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597245151-172.17.0.11-1595621919134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45588,DS-a41a0b10-937b-43dc-8a5f-9eb3beb7acf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-d7ff0e15-ab68-4b0d-8a05-845f72a03948,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-e58cfbfa-79e5-4ae7-95d5-a15549620070,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-4e015ea4-5d60-4f54-88cc-8ee7c35013c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-4ca485d5-ca62-4d58-80ed-49530b185878,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-0a95cd62-1c19-42b0-b0a6-16571de57168,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-0902d4ee-ede0-4a7f-8624-0f48d7df8642,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-e5822d63-8827-47ff-b558-12e3f91417cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890921712-172.17.0.11-1595621992189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36589,DS-daeca724-b424-4241-9af6-b52fe784b6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-0000f259-ef4f-4ea0-ac6d-e87d854a5f38,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-ebc4581d-290f-4122-84fa-97fb80cd62aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-2fc86200-f7a1-4c3f-8053-036dba7f9740,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-2fa843ae-f4e0-4548-bf0e-34cc364a3388,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-879da118-01fa-48bd-abec-d799c0d5e855,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-c7239ee1-c160-4765-8ec2-7cc0c54274f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-12cb43c1-dcb5-4421-a08c-0d7b232b72bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890921712-172.17.0.11-1595621992189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36589,DS-daeca724-b424-4241-9af6-b52fe784b6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-0000f259-ef4f-4ea0-ac6d-e87d854a5f38,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-ebc4581d-290f-4122-84fa-97fb80cd62aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-2fc86200-f7a1-4c3f-8053-036dba7f9740,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-2fa843ae-f4e0-4548-bf0e-34cc364a3388,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-879da118-01fa-48bd-abec-d799c0d5e855,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-c7239ee1-c160-4765-8ec2-7cc0c54274f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-12cb43c1-dcb5-4421-a08c-0d7b232b72bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924009458-172.17.0.11-1595622455822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-49830ce0-c92b-48f3-b846-146b821bd3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-e8affbec-02b1-4040-9c78-4bdf5acc54b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-d5d1ee3e-3b0d-440b-9b9b-c7d156a8bf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-b9eaf076-9f2f-49e9-ba2e-62429e7e1738,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-e70fbfa3-8b92-4791-85b0-b8e6ab4f2cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-bf448c5a-55be-40f1-98ad-fadff6ffbb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-7f570699-0fdb-43be-bd0d-9027579b803d,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-f62a1e83-dcc8-4332-815d-b3795c46e1ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924009458-172.17.0.11-1595622455822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-49830ce0-c92b-48f3-b846-146b821bd3b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-e8affbec-02b1-4040-9c78-4bdf5acc54b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-d5d1ee3e-3b0d-440b-9b9b-c7d156a8bf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-b9eaf076-9f2f-49e9-ba2e-62429e7e1738,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-e70fbfa3-8b92-4791-85b0-b8e6ab4f2cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-bf448c5a-55be-40f1-98ad-fadff6ffbb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-7f570699-0fdb-43be-bd0d-9027579b803d,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-f62a1e83-dcc8-4332-815d-b3795c46e1ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220573627-172.17.0.11-1595622788947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36487,DS-a02707cf-f89d-4888-a8ef-4b1647040066,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-6800c76a-0aee-475e-b830-fc72d5b08d30,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-6cd3f049-a9e3-486c-8074-23cd9749628f,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-52f1dc42-efe8-431f-983f-0b38de4baf01,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-86d067b0-02b8-46c5-b43a-caa33b58b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-545e573b-5873-4e88-8d90-14167f1ab47b,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-1caa5ae5-69c4-4eff-a526-a7f1727717ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-9429d882-441d-4c3c-9343-41ab8a5ba37a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220573627-172.17.0.11-1595622788947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36487,DS-a02707cf-f89d-4888-a8ef-4b1647040066,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-6800c76a-0aee-475e-b830-fc72d5b08d30,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-6cd3f049-a9e3-486c-8074-23cd9749628f,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-52f1dc42-efe8-431f-983f-0b38de4baf01,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-86d067b0-02b8-46c5-b43a-caa33b58b83f,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-545e573b-5873-4e88-8d90-14167f1ab47b,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-1caa5ae5-69c4-4eff-a526-a7f1727717ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-9429d882-441d-4c3c-9343-41ab8a5ba37a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301074491-172.17.0.11-1595622824279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35637,DS-aefd5090-0a04-4e5c-998b-59a6f8d75161,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-38d1011b-de40-476b-8125-a4e1c6fb151f,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-b0e18d4a-78f1-4545-91c7-9d7599fc187e,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-c6537c7b-735e-485c-83cb-4e3f9ec4865b,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-7b26718a-baf4-4d6d-afc2-b649e5d5e459,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-81c8e390-1eee-4929-acb3-569a1251c572,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-a3f265c6-a5fb-4e94-85ec-9e673609b8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-0bdf0a1f-264b-4d09-bebc-889584744433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-301074491-172.17.0.11-1595622824279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35637,DS-aefd5090-0a04-4e5c-998b-59a6f8d75161,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-38d1011b-de40-476b-8125-a4e1c6fb151f,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-b0e18d4a-78f1-4545-91c7-9d7599fc187e,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-c6537c7b-735e-485c-83cb-4e3f9ec4865b,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-7b26718a-baf4-4d6d-afc2-b649e5d5e459,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-81c8e390-1eee-4929-acb3-569a1251c572,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-a3f265c6-a5fb-4e94-85ec-9e673609b8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-0bdf0a1f-264b-4d09-bebc-889584744433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980872317-172.17.0.11-1595622897415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38357,DS-c13865a2-65f9-46f1-b6d3-7193ecc44c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-c93ba1f0-717b-4182-a4e2-5b2ebf95a63b,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-327b6f93-3efb-4875-968e-774d5a74e3af,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-8c9f233c-8b30-44da-9285-166f23be40bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-d9b75fd8-0f07-44ce-b403-7a55daffa0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-257ffc6d-7fef-4ddd-9486-25da3282e6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-1acf2aab-3e4d-439b-991d-73cfe7c97c48,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-f9f55ec7-616d-4e70-b970-98d47723008b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980872317-172.17.0.11-1595622897415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38357,DS-c13865a2-65f9-46f1-b6d3-7193ecc44c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-c93ba1f0-717b-4182-a4e2-5b2ebf95a63b,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-327b6f93-3efb-4875-968e-774d5a74e3af,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-8c9f233c-8b30-44da-9285-166f23be40bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-d9b75fd8-0f07-44ce-b403-7a55daffa0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-257ffc6d-7fef-4ddd-9486-25da3282e6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-1acf2aab-3e4d-439b-991d-73cfe7c97c48,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-f9f55ec7-616d-4e70-b970-98d47723008b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580394542-172.17.0.11-1595622933442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33568,DS-0ec0e935-48fc-4b60-8ec2-157883c64e15,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-b72c317a-1242-49fa-9bf0-34d18756fbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-06ed9d0f-c8f9-4262-9c2a-d19c412b6703,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-e24645f5-d3cc-42d8-982b-bfe6955dd507,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-72c1faf2-8dfd-4aaf-b823-d1d0ac0603ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-422af525-93eb-40a4-bbe5-8bb43ff6af7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-0c2f7f33-9ded-4dec-b0a4-6484cfb108c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-37004f22-5963-4ba9-8441-08d53091bb0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580394542-172.17.0.11-1595622933442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33568,DS-0ec0e935-48fc-4b60-8ec2-157883c64e15,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-b72c317a-1242-49fa-9bf0-34d18756fbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-06ed9d0f-c8f9-4262-9c2a-d19c412b6703,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-e24645f5-d3cc-42d8-982b-bfe6955dd507,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-72c1faf2-8dfd-4aaf-b823-d1d0ac0603ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-422af525-93eb-40a4-bbe5-8bb43ff6af7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-0c2f7f33-9ded-4dec-b0a4-6484cfb108c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-37004f22-5963-4ba9-8441-08d53091bb0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1884639551-172.17.0.11-1595623362069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46808,DS-e1b62db7-88b5-4a28-81f9-3d5e7664faec,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-c53d65d0-e6f3-4eb6-b076-8304109d6bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-746b0407-a68f-466d-bcd6-1073c2a66118,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-60e32da7-7b46-479b-92e4-31cddda8e1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-293dff99-d089-460e-b9a4-0542fdd7b826,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-a49dd610-e639-44da-a8d2-4b03899e3dec,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-a749038b-4864-4e5a-aca0-cdbe29d356f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-f3de6565-deac-4a17-b691-af33b167708d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1884639551-172.17.0.11-1595623362069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46808,DS-e1b62db7-88b5-4a28-81f9-3d5e7664faec,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-c53d65d0-e6f3-4eb6-b076-8304109d6bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-746b0407-a68f-466d-bcd6-1073c2a66118,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-60e32da7-7b46-479b-92e4-31cddda8e1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-293dff99-d089-460e-b9a4-0542fdd7b826,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-a49dd610-e639-44da-a8d2-4b03899e3dec,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-a749038b-4864-4e5a-aca0-cdbe29d356f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-f3de6565-deac-4a17-b691-af33b167708d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921815041-172.17.0.11-1595623604473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45397,DS-a4392890-6f22-4712-a36c-7ed0cdd3008a,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-600d4998-e5ce-43b4-9d4f-a6e5b90ca13b,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-5c803c63-54b2-445c-a540-f276707577c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-9a782e57-f9d5-46c1-a5cd-1a8b44bb6c53,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-f01ee6d2-e907-4fdb-8e7d-9acb3a4f2165,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-552777e4-e5fa-462b-8ad9-d057b0d8474d,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-fa9bbd00-7c2f-40fa-b71f-8a274fef9fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-508588ef-4338-4653-a680-6cfc3274a8b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-921815041-172.17.0.11-1595623604473:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45397,DS-a4392890-6f22-4712-a36c-7ed0cdd3008a,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-600d4998-e5ce-43b4-9d4f-a6e5b90ca13b,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-5c803c63-54b2-445c-a540-f276707577c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-9a782e57-f9d5-46c1-a5cd-1a8b44bb6c53,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-f01ee6d2-e907-4fdb-8e7d-9acb3a4f2165,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-552777e4-e5fa-462b-8ad9-d057b0d8474d,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-fa9bbd00-7c2f-40fa-b71f-8a274fef9fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-508588ef-4338-4653-a680-6cfc3274a8b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490851828-172.17.0.11-1595624198854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-48676fe7-db4e-494e-986e-4f95b2e39dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-f89c7d9c-e4d4-40cf-a23f-71a6d3608376,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-1673b10e-8165-42d0-bc73-14085cfcd678,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-4b0c0af5-b532-4d6d-90e9-2d226f756e37,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-131dc72b-a638-45ee-ab4c-e01648b75e00,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-7b4a77c6-be2c-4273-8d3e-60c74d5e2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-8b02ed0c-7d62-464a-9d83-3acdc8e9f2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-d2edb350-f78e-487a-b64a-e20be28a25f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-490851828-172.17.0.11-1595624198854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-48676fe7-db4e-494e-986e-4f95b2e39dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-f89c7d9c-e4d4-40cf-a23f-71a6d3608376,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-1673b10e-8165-42d0-bc73-14085cfcd678,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-4b0c0af5-b532-4d6d-90e9-2d226f756e37,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-131dc72b-a638-45ee-ab4c-e01648b75e00,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-7b4a77c6-be2c-4273-8d3e-60c74d5e2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-8b02ed0c-7d62-464a-9d83-3acdc8e9f2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-d2edb350-f78e-487a-b64a-e20be28a25f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744163569-172.17.0.11-1595624451093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37268,DS-bac15d21-645a-4d50-b1e5-bd523d7f42f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-9768f214-25e5-4fbc-b7f0-c9e41284d34a,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-989e7a6d-adce-4631-9104-355b0dcb7476,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-06dfabb9-4f17-4d65-ba59-87848d55fb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-bd4e0670-d22c-4ffd-a43c-58a8b8dcb16b,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-f44ac6b5-6c4b-49a3-94c7-12d4aa6a8ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-79682bd7-0829-4bfd-af64-fa838af866b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-36cb7d5c-f164-47cb-a832-f20458f9e509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1744163569-172.17.0.11-1595624451093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37268,DS-bac15d21-645a-4d50-b1e5-bd523d7f42f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-9768f214-25e5-4fbc-b7f0-c9e41284d34a,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-989e7a6d-adce-4631-9104-355b0dcb7476,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-06dfabb9-4f17-4d65-ba59-87848d55fb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-bd4e0670-d22c-4ffd-a43c-58a8b8dcb16b,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-f44ac6b5-6c4b-49a3-94c7-12d4aa6a8ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-79682bd7-0829-4bfd-af64-fa838af866b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-36cb7d5c-f164-47cb-a832-f20458f9e509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549672286-172.17.0.11-1595624587627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40740,DS-81b03049-9562-4e3a-8548-77a9b64acb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-2eb5c6f0-39c0-4478-b40f-ef51b208cc54,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-07bab4fc-001f-4016-87e8-64cb1917837e,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-eab4abc5-4aa1-4de5-862e-1dee643578d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-a07dccb3-4f9b-4d54-9e26-34979d40a929,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-117ce30c-6a7c-40d7-96d4-6dc8e5fadd96,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-2b578dd6-4b60-4122-8895-add225259ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-9c28389b-68c1-4c81-b007-a4bf2181d574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1549672286-172.17.0.11-1595624587627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40740,DS-81b03049-9562-4e3a-8548-77a9b64acb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-2eb5c6f0-39c0-4478-b40f-ef51b208cc54,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-07bab4fc-001f-4016-87e8-64cb1917837e,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-eab4abc5-4aa1-4de5-862e-1dee643578d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-a07dccb3-4f9b-4d54-9e26-34979d40a929,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-117ce30c-6a7c-40d7-96d4-6dc8e5fadd96,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-2b578dd6-4b60-4122-8895-add225259ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-9c28389b-68c1-4c81-b007-a4bf2181d574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.stale.datanode.minimum.interval
component: hdfs:NameNode
v1: 4
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970867801-172.17.0.11-1595625184750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46855,DS-94799ab7-fcc9-40ce-a0fd-8f66892ddd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-06c3dfd4-0230-4c37-8a9e-6280b0303d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-bce40c4d-0afe-452b-876e-cd927e44e6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-d05023a7-5328-4b87-b7ec-2bfba3f97ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-b15978a7-6bcd-4b8c-862e-e979ce7033da,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-b9e448ec-16a1-4900-b7a4-8430d1144cec,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-f59f6d51-a827-4e64-a702-38ad7d0ebb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-d648d867-6c6b-44a2-b962-4544947a6d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970867801-172.17.0.11-1595625184750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46855,DS-94799ab7-fcc9-40ce-a0fd-8f66892ddd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-06c3dfd4-0230-4c37-8a9e-6280b0303d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-bce40c4d-0afe-452b-876e-cd927e44e6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-d05023a7-5328-4b87-b7ec-2bfba3f97ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-b15978a7-6bcd-4b8c-862e-e979ce7033da,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-b9e448ec-16a1-4900-b7a4-8430d1144cec,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-f59f6d51-a827-4e64-a702-38ad7d0ebb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-d648d867-6c6b-44a2-b962-4544947a6d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5193
