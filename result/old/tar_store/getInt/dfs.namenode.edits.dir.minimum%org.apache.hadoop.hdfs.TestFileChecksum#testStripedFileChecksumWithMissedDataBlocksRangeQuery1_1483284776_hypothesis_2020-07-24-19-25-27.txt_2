reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384037846-172.17.0.2-1595619174018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40087,DS-4b905995-6a31-4d3a-a983-2dfd19e920a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-01bc9dc0-f092-4277-95ff-9696bd69c61a,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-47e36dff-2d2f-43df-8a43-d3b2a9c543d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-fa003dc0-6357-421c-9283-ef3445d6905f,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-53d8dea1-f083-4dac-9d53-51f04fc64cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-30906bd0-892e-464f-aa00-2fd77eee4d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-d994e880-9ae7-4284-949e-23a187aa43ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-70eea0d2-8165-47c5-8130-c579f960728d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384037846-172.17.0.2-1595619174018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40087,DS-4b905995-6a31-4d3a-a983-2dfd19e920a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-01bc9dc0-f092-4277-95ff-9696bd69c61a,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-47e36dff-2d2f-43df-8a43-d3b2a9c543d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-fa003dc0-6357-421c-9283-ef3445d6905f,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-53d8dea1-f083-4dac-9d53-51f04fc64cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-30906bd0-892e-464f-aa00-2fd77eee4d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-d994e880-9ae7-4284-949e-23a187aa43ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-70eea0d2-8165-47c5-8130-c579f960728d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274199204-172.17.0.2-1595619387443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41080,DS-ddd3123b-ad2a-4e25-8a5c-85640bdd00e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-11e3f5aa-1be5-4966-a424-cf88c805b5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-84a59d84-c16c-459f-a798-54a73a28c9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-25ce252e-4158-4494-8ec0-6d9e5bfc7007,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-e65d842e-24b3-4976-971b-f898cb1a83b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-84bfbe98-e8f2-46fa-9a68-17fcf6311d14,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-634fbc62-3b5d-4380-a093-285e7e342ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-4378132d-2ed1-414e-bcd7-bcd4a4b73de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1274199204-172.17.0.2-1595619387443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41080,DS-ddd3123b-ad2a-4e25-8a5c-85640bdd00e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-11e3f5aa-1be5-4966-a424-cf88c805b5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-84a59d84-c16c-459f-a798-54a73a28c9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-25ce252e-4158-4494-8ec0-6d9e5bfc7007,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-e65d842e-24b3-4976-971b-f898cb1a83b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-84bfbe98-e8f2-46fa-9a68-17fcf6311d14,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-634fbc62-3b5d-4380-a093-285e7e342ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-4378132d-2ed1-414e-bcd7-bcd4a4b73de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493763506-172.17.0.2-1595619511987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39431,DS-379daae5-1c9a-41a1-ac91-b265dbfd81ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-c50f8595-77a3-4e73-98ca-b0ae6ce0fffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-9b700edb-0a0b-4e6e-845c-dbead1f447aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-4074a9ff-9d56-425e-a1b6-94073bc51a44,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-a2f3018d-19d7-4e73-9bba-f8295920c550,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-0a5db9e6-ede8-4264-9f54-ea7dc5e1cfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-82c7f66e-24b9-41a1-92c0-638be7a50a38,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-2c8ef99c-f3fb-4233-b2f2-3ed9ea29c9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493763506-172.17.0.2-1595619511987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39431,DS-379daae5-1c9a-41a1-ac91-b265dbfd81ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-c50f8595-77a3-4e73-98ca-b0ae6ce0fffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-9b700edb-0a0b-4e6e-845c-dbead1f447aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40609,DS-4074a9ff-9d56-425e-a1b6-94073bc51a44,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-a2f3018d-19d7-4e73-9bba-f8295920c550,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-0a5db9e6-ede8-4264-9f54-ea7dc5e1cfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45863,DS-82c7f66e-24b9-41a1-92c0-638be7a50a38,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-2c8ef99c-f3fb-4233-b2f2-3ed9ea29c9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175084133-172.17.0.2-1595619730036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35397,DS-2f438aa3-6851-40eb-a65c-31b354702b79,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-fd16c46c-b782-4493-b4e5-8ce6bdb1fb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-02b1a6a8-2f41-423a-86d4-f296883ba97d,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-f9959e61-f823-48df-b874-1928e3f8aaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-7c1be622-fd3b-4beb-99ff-7227715fa9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-9faf0713-b14f-4be0-8c71-cc9493979903,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-b545209b-5708-418b-99e9-24cb0652b089,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-42ca6179-a3c2-4c22-bd8a-c2e1894f38a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175084133-172.17.0.2-1595619730036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35397,DS-2f438aa3-6851-40eb-a65c-31b354702b79,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-fd16c46c-b782-4493-b4e5-8ce6bdb1fb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-02b1a6a8-2f41-423a-86d4-f296883ba97d,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-f9959e61-f823-48df-b874-1928e3f8aaf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-7c1be622-fd3b-4beb-99ff-7227715fa9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-9faf0713-b14f-4be0-8c71-cc9493979903,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-b545209b-5708-418b-99e9-24cb0652b089,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-42ca6179-a3c2-4c22-bd8a-c2e1894f38a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995758750-172.17.0.2-1595621042438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45402,DS-661befa5-58fa-4662-be91-de8dd446a5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-18034edb-7521-4cdf-a1ee-c76cb77edb29,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-bbeb11ab-3a17-4311-97b9-5cd9cafd74fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-697d6c7e-8525-456e-a53d-99ac382e3ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-afc2a8ab-c985-40a8-82dc-d6518877291d,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-c358ecc4-c12d-4590-94cc-fcb9fe6215f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-6047bd67-8ca3-455d-98f4-1b831e84e19f,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-ee7d06b3-1aec-4816-b9e6-77bfd10afd6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995758750-172.17.0.2-1595621042438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45402,DS-661befa5-58fa-4662-be91-de8dd446a5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-18034edb-7521-4cdf-a1ee-c76cb77edb29,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-bbeb11ab-3a17-4311-97b9-5cd9cafd74fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-697d6c7e-8525-456e-a53d-99ac382e3ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-afc2a8ab-c985-40a8-82dc-d6518877291d,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-c358ecc4-c12d-4590-94cc-fcb9fe6215f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-6047bd67-8ca3-455d-98f4-1b831e84e19f,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-ee7d06b3-1aec-4816-b9e6-77bfd10afd6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970625440-172.17.0.2-1595621259225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39524,DS-f55ead13-ccc0-43f6-8b60-03ee5897f63b,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-286c8c1b-6f3e-46b1-9e2d-f5b78c7eef00,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-e9493566-9f96-43ce-a698-c4c78c9db437,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-c633e0a0-0fa5-42fe-ac3e-a551c789a4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-d676f2cb-0636-42cf-b0f4-ee99afa13b67,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-d8947eb7-8a4a-4c30-9eb8-dbc010d59f49,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-511abb03-3cd0-46fe-8be1-f979d053d688,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-90896a7a-93eb-4aec-8edf-55718548010b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970625440-172.17.0.2-1595621259225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39524,DS-f55ead13-ccc0-43f6-8b60-03ee5897f63b,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-286c8c1b-6f3e-46b1-9e2d-f5b78c7eef00,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-e9493566-9f96-43ce-a698-c4c78c9db437,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-c633e0a0-0fa5-42fe-ac3e-a551c789a4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-d676f2cb-0636-42cf-b0f4-ee99afa13b67,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-d8947eb7-8a4a-4c30-9eb8-dbc010d59f49,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-511abb03-3cd0-46fe-8be1-f979d053d688,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-90896a7a-93eb-4aec-8edf-55718548010b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546339558-172.17.0.2-1595621420027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34643,DS-51948024-9176-4163-b658-d188f825ac28,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-b6cfa98e-dcc8-4d8f-8014-8ba855f4626d,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-b582a9c5-8402-49c0-867d-babfb3d0d8de,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-59fc9ced-b0f4-4e6f-8bfb-e4363e87af88,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-458b3d61-f536-49c2-8731-a061d05d84b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-838c7b4e-5211-432a-94e6-ee2642a3cdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-c54d9f64-d4c5-4421-90e1-c71742d271ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-0b584e12-f7e8-45a4-9a96-4dbf86b0eedf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546339558-172.17.0.2-1595621420027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34643,DS-51948024-9176-4163-b658-d188f825ac28,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-b6cfa98e-dcc8-4d8f-8014-8ba855f4626d,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-b582a9c5-8402-49c0-867d-babfb3d0d8de,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-59fc9ced-b0f4-4e6f-8bfb-e4363e87af88,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-458b3d61-f536-49c2-8731-a061d05d84b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-838c7b4e-5211-432a-94e6-ee2642a3cdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-c54d9f64-d4c5-4421-90e1-c71742d271ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-0b584e12-f7e8-45a4-9a96-4dbf86b0eedf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752305321-172.17.0.2-1595622002003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38666,DS-58b46626-6e89-40d0-84f1-f8d6575d9bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-ce2cf4da-ff6d-4445-a2da-d30c3201c1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-ec2376d5-d650-4d19-8ee5-d7ca4c0ec407,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-b11f29e9-cd01-494c-8a45-22ec9a6f2749,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-af7691ea-681b-4ed2-aea4-f7b4ff36b081,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-5ea7f0ca-6dd7-49c4-9947-4973619781ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-8f599fc7-c0ad-4c20-a1c0-3d9f752927b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-8dc29167-0118-4d3c-b82b-eb00d549af08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752305321-172.17.0.2-1595622002003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38666,DS-58b46626-6e89-40d0-84f1-f8d6575d9bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-ce2cf4da-ff6d-4445-a2da-d30c3201c1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-ec2376d5-d650-4d19-8ee5-d7ca4c0ec407,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-b11f29e9-cd01-494c-8a45-22ec9a6f2749,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-af7691ea-681b-4ed2-aea4-f7b4ff36b081,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-5ea7f0ca-6dd7-49c4-9947-4973619781ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-8f599fc7-c0ad-4c20-a1c0-3d9f752927b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-8dc29167-0118-4d3c-b82b-eb00d549af08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748218475-172.17.0.2-1595622133902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40506,DS-7c688a39-c865-4db2-9516-acacd7bb3029,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-9d1b83a5-dedd-46f6-8e2b-cb5cffbc48fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-d30e340f-cb9d-4335-b866-d0e5b1dce856,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-349d813b-1d69-4338-8c3d-2e2525459726,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-8fe360a1-7065-41a8-91a4-5b0a0e4fb803,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-6b074678-12b4-4877-a9f8-411fa6923d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-a6025d12-eaed-40c1-aa6b-a9420b2638c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-3177baa2-00e5-4f9f-a181-f9ec4773b83c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748218475-172.17.0.2-1595622133902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40506,DS-7c688a39-c865-4db2-9516-acacd7bb3029,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-9d1b83a5-dedd-46f6-8e2b-cb5cffbc48fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-d30e340f-cb9d-4335-b866-d0e5b1dce856,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-349d813b-1d69-4338-8c3d-2e2525459726,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-8fe360a1-7065-41a8-91a4-5b0a0e4fb803,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-6b074678-12b4-4877-a9f8-411fa6923d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-a6025d12-eaed-40c1-aa6b-a9420b2638c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-3177baa2-00e5-4f9f-a181-f9ec4773b83c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315243339-172.17.0.2-1595622315419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33587,DS-16b52e19-79db-4734-85ea-f69a68db6ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-972c17df-39b3-41e5-94ef-01f141c1a89e,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-0abc7bda-485f-44e8-b5e4-4070180056b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-73a0fcd3-79cc-466a-aa65-c394c1ec8dac,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-22f48686-0351-407a-872e-3ad6da0f22e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-0e660489-3422-4873-a4aa-83981797e404,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-9014692d-ea1c-413c-9882-5ecfc192112c,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-ce5aa193-95dc-4587-8bd3-6306b1e1a626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315243339-172.17.0.2-1595622315419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33587,DS-16b52e19-79db-4734-85ea-f69a68db6ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-972c17df-39b3-41e5-94ef-01f141c1a89e,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-0abc7bda-485f-44e8-b5e4-4070180056b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-73a0fcd3-79cc-466a-aa65-c394c1ec8dac,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-22f48686-0351-407a-872e-3ad6da0f22e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-0e660489-3422-4873-a4aa-83981797e404,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-9014692d-ea1c-413c-9882-5ecfc192112c,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-ce5aa193-95dc-4587-8bd3-6306b1e1a626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892231578-172.17.0.2-1595622344089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41124,DS-31dc0a59-1243-4e0a-8728-838e8f8d1adf,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-0341c1a1-01cd-459f-a4cc-289f1e305694,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-d27eb57c-a224-4344-aa44-b28c71747e01,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-0f57fbbd-6d3b-46f3-a31a-865842a4f4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-cca6abda-c958-4495-bcfb-a662db055f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-2768b5ba-f4b9-4722-9612-68d57fa9f92a,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-3d47143d-eec3-423a-b99e-f917d62bc085,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-7f426b6b-f930-4388-8af9-ccbf5265a757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892231578-172.17.0.2-1595622344089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41124,DS-31dc0a59-1243-4e0a-8728-838e8f8d1adf,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-0341c1a1-01cd-459f-a4cc-289f1e305694,DISK], DatanodeInfoWithStorage[127.0.0.1:41833,DS-d27eb57c-a224-4344-aa44-b28c71747e01,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-0f57fbbd-6d3b-46f3-a31a-865842a4f4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-cca6abda-c958-4495-bcfb-a662db055f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-2768b5ba-f4b9-4722-9612-68d57fa9f92a,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-3d47143d-eec3-423a-b99e-f917d62bc085,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-7f426b6b-f930-4388-8af9-ccbf5265a757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256764951-172.17.0.2-1595622777444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33612,DS-5736ea35-950d-4690-a835-a753915220b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-b6d1599a-6ab4-4e32-ba8a-10e363719926,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-36f9320b-9a55-43b6-9623-6ef3b86fb8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-96c40778-6fcf-4a92-bcef-45a3086bd4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-0d644d0d-5a6b-4ee4-8d60-539ccb165a68,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-98d0b405-ed03-4b8a-8ded-373af1db9940,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-d0def0da-255f-41a7-9159-4c164fbc32eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-3546cdb7-e551-444f-bd3e-0cead5a68e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1256764951-172.17.0.2-1595622777444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33612,DS-5736ea35-950d-4690-a835-a753915220b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-b6d1599a-6ab4-4e32-ba8a-10e363719926,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-36f9320b-9a55-43b6-9623-6ef3b86fb8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-96c40778-6fcf-4a92-bcef-45a3086bd4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-0d644d0d-5a6b-4ee4-8d60-539ccb165a68,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-98d0b405-ed03-4b8a-8ded-373af1db9940,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-d0def0da-255f-41a7-9159-4c164fbc32eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-3546cdb7-e551-444f-bd3e-0cead5a68e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.dir.minimum
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251085591-172.17.0.2-1595623173607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33984,DS-f7d78103-eab3-47ee-b59b-4fa5664a3918,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-3ce67ce8-8f89-44ac-8182-018d1d9a25ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-c0d397ad-e2d9-4ef6-8e72-3db520539aee,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-5e27c5c4-e101-48d2-8be8-f6954ef6adc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-e8592a4d-0171-418a-a0e8-8ec66b74afd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-01411e86-de7c-481d-bbe8-6059aea931b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-c34df331-79e9-40ee-b0a2-46be5e74e5db,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-bfbe8737-988f-491a-8570-1dab3a9ddd61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251085591-172.17.0.2-1595623173607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33984,DS-f7d78103-eab3-47ee-b59b-4fa5664a3918,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-3ce67ce8-8f89-44ac-8182-018d1d9a25ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-c0d397ad-e2d9-4ef6-8e72-3db520539aee,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-5e27c5c4-e101-48d2-8be8-f6954ef6adc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-e8592a4d-0171-418a-a0e8-8ec66b74afd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-01411e86-de7c-481d-bbe8-6059aea931b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-c34df331-79e9-40ee-b0a2-46be5e74e5db,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-bfbe8737-988f-491a-8570-1dab3a9ddd61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 4572
