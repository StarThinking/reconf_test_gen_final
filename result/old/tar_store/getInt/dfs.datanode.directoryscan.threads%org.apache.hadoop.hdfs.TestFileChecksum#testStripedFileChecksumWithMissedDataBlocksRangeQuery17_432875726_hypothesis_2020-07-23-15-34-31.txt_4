reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178230122-172.17.0.11-1595519020453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42098,DS-7bfa070d-b980-43f7-8522-c65e07db952a,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-5aefe94a-b835-4da0-85cf-78b6a1b40cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-7edad327-9492-4e87-8a0c-5dd9299aac08,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-0ff19283-2d88-450c-8978-f6806b24cc32,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-5738e570-e016-4e79-9baf-00c9f9e53c91,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-f92834c5-59e7-45f4-beda-62e1681546a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-6ae833ed-5107-4285-88ed-f1876364edc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-b0f12da1-34ab-4e0f-a315-604c85ba260a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178230122-172.17.0.11-1595519020453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42098,DS-7bfa070d-b980-43f7-8522-c65e07db952a,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-5aefe94a-b835-4da0-85cf-78b6a1b40cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-7edad327-9492-4e87-8a0c-5dd9299aac08,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-0ff19283-2d88-450c-8978-f6806b24cc32,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-5738e570-e016-4e79-9baf-00c9f9e53c91,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-f92834c5-59e7-45f4-beda-62e1681546a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-6ae833ed-5107-4285-88ed-f1876364edc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-b0f12da1-34ab-4e0f-a315-604c85ba260a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559062824-172.17.0.11-1595519664583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33841,DS-c7cb4946-0c70-48d2-9675-3f2984c25f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-614912d2-b5e8-4eaa-865d-a17c1039c0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-4949127e-3924-4f8f-bff7-5c08f7be8676,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-d16cd66c-eb11-4904-9006-83c5dc0fb121,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-d6643e05-2990-4596-85da-cc92767c4e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-7438719b-3b3f-4a31-94c2-3cecfa0723de,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-2926935e-58a3-445e-99d5-a3ad9ba7ec36,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-f8fd69a0-f64b-45c8-9b33-f40724c2b336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559062824-172.17.0.11-1595519664583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33841,DS-c7cb4946-0c70-48d2-9675-3f2984c25f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-614912d2-b5e8-4eaa-865d-a17c1039c0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-4949127e-3924-4f8f-bff7-5c08f7be8676,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-d16cd66c-eb11-4904-9006-83c5dc0fb121,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-d6643e05-2990-4596-85da-cc92767c4e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-7438719b-3b3f-4a31-94c2-3cecfa0723de,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-2926935e-58a3-445e-99d5-a3ad9ba7ec36,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-f8fd69a0-f64b-45c8-9b33-f40724c2b336,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893104041-172.17.0.11-1595520106472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38052,DS-18be1357-a583-4fc7-b19a-67a0f72b0545,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-8592ddd9-c8ec-402d-ab89-3742b63fd217,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-ea7b187a-1483-4562-a1df-816b0d8dd6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-8833a931-fde2-42f4-a6fd-e271b531eeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-d653c783-7fe8-4801-9801-0d6ae044539f,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-8828408d-537a-4707-8ef5-a2453d8cd8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-ff8d77f0-f4a7-417d-b00b-fefa406e3ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-95ea633e-2744-4894-aaec-55b77f19075e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893104041-172.17.0.11-1595520106472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38052,DS-18be1357-a583-4fc7-b19a-67a0f72b0545,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-8592ddd9-c8ec-402d-ab89-3742b63fd217,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-ea7b187a-1483-4562-a1df-816b0d8dd6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-8833a931-fde2-42f4-a6fd-e271b531eeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-d653c783-7fe8-4801-9801-0d6ae044539f,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-8828408d-537a-4707-8ef5-a2453d8cd8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-ff8d77f0-f4a7-417d-b00b-fefa406e3ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-95ea633e-2744-4894-aaec-55b77f19075e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-633581214-172.17.0.11-1595520501398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45048,DS-3cca15d8-4950-4495-93c3-6cca21eff55d,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-c24b46b1-9d1a-4779-ab3f-eb5a1dcf16f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-22fe3bbc-b597-47f3-97b8-84922e9a1c09,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-9228e687-262a-4094-84ff-cc714bf0eb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-ccfa92d9-71e4-44b5-a1c3-15649fd22881,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-fc1f9f56-8655-4555-92d6-81d597f4da27,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-931d35ed-2b2b-4d3f-83b9-56f4dd2df0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-a62d6ead-e313-4adf-a76a-046871fc30f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-633581214-172.17.0.11-1595520501398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45048,DS-3cca15d8-4950-4495-93c3-6cca21eff55d,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-c24b46b1-9d1a-4779-ab3f-eb5a1dcf16f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-22fe3bbc-b597-47f3-97b8-84922e9a1c09,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-9228e687-262a-4094-84ff-cc714bf0eb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-ccfa92d9-71e4-44b5-a1c3-15649fd22881,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-fc1f9f56-8655-4555-92d6-81d597f4da27,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-931d35ed-2b2b-4d3f-83b9-56f4dd2df0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-a62d6ead-e313-4adf-a76a-046871fc30f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544179089-172.17.0.11-1595521027450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-bcb0a326-8276-4670-914b-bd5cc6673144,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-1716d259-209b-498d-b867-fad249f2e3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-87cc6dd1-a23a-49c4-a3db-025c11e9ba68,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-29ea64f8-6932-4c08-b6ad-aa1fd26208b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-49fd9b57-77dd-4041-b88c-61f87ade4d83,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-27a72d62-2090-4d2f-b31b-a14c88368e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-3930eacc-e74f-44c5-81af-c6046d0cfae3,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-0f31fd57-eb22-425d-8965-6f9c3b15d3ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-544179089-172.17.0.11-1595521027450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-bcb0a326-8276-4670-914b-bd5cc6673144,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-1716d259-209b-498d-b867-fad249f2e3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-87cc6dd1-a23a-49c4-a3db-025c11e9ba68,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-29ea64f8-6932-4c08-b6ad-aa1fd26208b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-49fd9b57-77dd-4041-b88c-61f87ade4d83,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-27a72d62-2090-4d2f-b31b-a14c88368e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-3930eacc-e74f-44c5-81af-c6046d0cfae3,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-0f31fd57-eb22-425d-8965-6f9c3b15d3ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873336594-172.17.0.11-1595521283320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34503,DS-cc7f65df-e3fa-47d8-a4c8-e911bcd2a002,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-e16ac7a0-a1d6-4bc6-a523-d08c6f369eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-f055e4ee-42ea-414e-bd3a-ebc17f411700,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-7c26c739-b361-4366-8d8a-f47c8bdd54dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-1a0c9bce-3a82-435a-ade7-381485ac37a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-8fdc403d-5c0a-4a80-9a1d-5f891a585383,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-0acba0c4-1931-44c2-abdf-b9b6dd818f85,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-ba08fb77-2089-4a8a-9bcf-1f16c1a3fd4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873336594-172.17.0.11-1595521283320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34503,DS-cc7f65df-e3fa-47d8-a4c8-e911bcd2a002,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-e16ac7a0-a1d6-4bc6-a523-d08c6f369eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-f055e4ee-42ea-414e-bd3a-ebc17f411700,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-7c26c739-b361-4366-8d8a-f47c8bdd54dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-1a0c9bce-3a82-435a-ade7-381485ac37a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-8fdc403d-5c0a-4a80-9a1d-5f891a585383,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-0acba0c4-1931-44c2-abdf-b9b6dd818f85,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-ba08fb77-2089-4a8a-9bcf-1f16c1a3fd4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217956138-172.17.0.11-1595521322133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38005,DS-116d682a-5732-4d1c-998b-3c85e411bb91,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-4c10b759-d34a-4fbf-8f74-247e0076fa64,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-b5b0e532-78f9-461f-8b3a-dbb4608d7465,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-582e5cc6-921e-4faf-af4e-e6cbf2fcd080,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-ab151f1b-c9f8-4bc5-a902-f4c2fc7e0287,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-c77db099-7769-46c8-a46d-0c651a8b8758,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-3eb96fad-a706-4636-8c5c-23222a69d519,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-12656112-edc0-4c8f-bed0-0974669a0794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217956138-172.17.0.11-1595521322133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38005,DS-116d682a-5732-4d1c-998b-3c85e411bb91,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-4c10b759-d34a-4fbf-8f74-247e0076fa64,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-b5b0e532-78f9-461f-8b3a-dbb4608d7465,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-582e5cc6-921e-4faf-af4e-e6cbf2fcd080,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-ab151f1b-c9f8-4bc5-a902-f4c2fc7e0287,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-c77db099-7769-46c8-a46d-0c651a8b8758,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-3eb96fad-a706-4636-8c5c-23222a69d519,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-12656112-edc0-4c8f-bed0-0974669a0794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370586604-172.17.0.11-1595521622051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46118,DS-199dbe03-ed90-45df-9277-e2d2b9f2f326,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-89c416cd-32a4-4f2a-9aac-cab08a86e702,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-e8ede828-d735-43ff-aedb-5b12081c7e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-07169ed8-9c0f-47dd-b99d-74ca52e9c025,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-f30e176f-4c61-4fd8-a1d7-bf944ab49ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-4696dd41-50a7-4263-b319-2f8a5639310f,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-997f0dc6-5fb9-463b-8d04-b9103221bd09,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-8955a82d-88a4-4a15-b540-99c0cd659640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370586604-172.17.0.11-1595521622051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46118,DS-199dbe03-ed90-45df-9277-e2d2b9f2f326,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-89c416cd-32a4-4f2a-9aac-cab08a86e702,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-e8ede828-d735-43ff-aedb-5b12081c7e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37763,DS-07169ed8-9c0f-47dd-b99d-74ca52e9c025,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-f30e176f-4c61-4fd8-a1d7-bf944ab49ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-4696dd41-50a7-4263-b319-2f8a5639310f,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-997f0dc6-5fb9-463b-8d04-b9103221bd09,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-8955a82d-88a4-4a15-b540-99c0cd659640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61017327-172.17.0.11-1595521722225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43875,DS-a06ee209-cd8e-4f7c-9fa2-c1c86c6a0535,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-11a10d64-93b8-46c4-a115-d5aadb4c27c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-3830d21a-3add-46d0-a2f9-d5eeb183fca7,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-29e80643-ecf6-42e0-b078-a3532f482283,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-a3d8b280-f913-44ce-96a6-e9c9ecf3086a,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-1c7b866a-fc05-478a-8383-9e5e546943f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-7ea4b2aa-536f-4318-b8b0-b09ec697be26,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-dcd60223-9e48-44ab-9a72-ec2c7c90b281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61017327-172.17.0.11-1595521722225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43875,DS-a06ee209-cd8e-4f7c-9fa2-c1c86c6a0535,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-11a10d64-93b8-46c4-a115-d5aadb4c27c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40461,DS-3830d21a-3add-46d0-a2f9-d5eeb183fca7,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-29e80643-ecf6-42e0-b078-a3532f482283,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-a3d8b280-f913-44ce-96a6-e9c9ecf3086a,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-1c7b866a-fc05-478a-8383-9e5e546943f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-7ea4b2aa-536f-4318-b8b0-b09ec697be26,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-dcd60223-9e48-44ab-9a72-ec2c7c90b281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978353660-172.17.0.11-1595522054116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44041,DS-439ca397-2a15-43c3-bbfb-673d50e8370f,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-f349bf87-f361-485b-bac0-2d1de1e47693,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-cf9e0f0d-c3c5-49cc-958b-13bc2f575339,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-e673433e-3c38-4080-9f1d-42ac20b2eb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-fb4d6b74-3df1-48e9-a621-91daa5dec2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-e1ae5635-6df7-490a-9449-884e83f7b6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-c63d1469-02ce-40ca-a25d-7bd1017dd45a,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-49d07384-8d42-4a14-9444-af6d77c93c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-978353660-172.17.0.11-1595522054116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44041,DS-439ca397-2a15-43c3-bbfb-673d50e8370f,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-f349bf87-f361-485b-bac0-2d1de1e47693,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-cf9e0f0d-c3c5-49cc-958b-13bc2f575339,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-e673433e-3c38-4080-9f1d-42ac20b2eb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-fb4d6b74-3df1-48e9-a621-91daa5dec2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-e1ae5635-6df7-490a-9449-884e83f7b6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-c63d1469-02ce-40ca-a25d-7bd1017dd45a,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-49d07384-8d42-4a14-9444-af6d77c93c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464324354-172.17.0.11-1595522489027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32917,DS-17274dc5-2e1d-417d-9882-399529956f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-3f5dd228-dee3-48f3-97c8-b1180399a6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-794c96fe-3b09-422a-96ba-cc0d555b5b19,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-8df7e818-18a3-4838-9776-629ad2b2c80d,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-341f8865-e37c-49e6-9023-7472f282c2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-f427099e-4688-4ac6-aada-223f5498baf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-8c7469d8-8a5e-4333-8318-6c8caacd3e31,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-4a0714fb-eb11-4404-a085-feb6c279273d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464324354-172.17.0.11-1595522489027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32917,DS-17274dc5-2e1d-417d-9882-399529956f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-3f5dd228-dee3-48f3-97c8-b1180399a6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-794c96fe-3b09-422a-96ba-cc0d555b5b19,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-8df7e818-18a3-4838-9776-629ad2b2c80d,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-341f8865-e37c-49e6-9023-7472f282c2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-f427099e-4688-4ac6-aada-223f5498baf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-8c7469d8-8a5e-4333-8318-6c8caacd3e31,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-4a0714fb-eb11-4404-a085-feb6c279273d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 10
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988950124-172.17.0.11-1595522931240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40189,DS-7ce6bbf6-b065-43b8-87e6-0346aeef75c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-8c671439-40e8-49dd-8277-5d68d0185373,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-785288d7-14de-4627-8800-ab1c5b50f430,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-fa75164e-ec9d-4f03-a890-60b594b58546,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-a0577d8e-921f-472b-9496-276315978bde,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-47212cc5-1eda-40f9-92cb-8ba7879ceb97,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-b0a3805c-a196-4e1a-b265-a304f0605254,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-6b692081-cb22-4356-9268-e5e78985757a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988950124-172.17.0.11-1595522931240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40189,DS-7ce6bbf6-b065-43b8-87e6-0346aeef75c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37416,DS-8c671439-40e8-49dd-8277-5d68d0185373,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-785288d7-14de-4627-8800-ab1c5b50f430,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-fa75164e-ec9d-4f03-a890-60b594b58546,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-a0577d8e-921f-472b-9496-276315978bde,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-47212cc5-1eda-40f9-92cb-8ba7879ceb97,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-b0a3805c-a196-4e1a-b265-a304f0605254,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-6b692081-cb22-4356-9268-e5e78985757a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 4901
