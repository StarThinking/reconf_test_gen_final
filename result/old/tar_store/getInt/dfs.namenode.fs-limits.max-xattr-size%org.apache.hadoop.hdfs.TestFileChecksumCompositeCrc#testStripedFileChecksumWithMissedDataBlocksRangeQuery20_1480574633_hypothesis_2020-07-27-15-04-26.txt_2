reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118112045-172.17.0.18-1595862317746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43326,DS-877b42ce-9f1f-4648-97e0-d778e5b003ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-d90663e6-94dc-45bc-adbc-b59a1819c68c,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-5e2beaa3-3f6f-4c20-9f44-3ea35153a687,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-9860f9a9-40f1-4a47-8bd5-e481b13d7be0,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-29a171f2-616d-4c19-895c-f10daab71cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-fe2f560f-7b81-46bd-9b63-1741ab9a216d,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-220c68f2-7e57-4a3f-80f6-05bb5143ff06,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-68b4ee13-7f1b-4a25-b715-ed71b6a4a038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118112045-172.17.0.18-1595862317746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43326,DS-877b42ce-9f1f-4648-97e0-d778e5b003ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-d90663e6-94dc-45bc-adbc-b59a1819c68c,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-5e2beaa3-3f6f-4c20-9f44-3ea35153a687,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-9860f9a9-40f1-4a47-8bd5-e481b13d7be0,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-29a171f2-616d-4c19-895c-f10daab71cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-fe2f560f-7b81-46bd-9b63-1741ab9a216d,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-220c68f2-7e57-4a3f-80f6-05bb5143ff06,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-68b4ee13-7f1b-4a25-b715-ed71b6a4a038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1207667208-172.17.0.18-1595862354541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44824,DS-f1b57e2d-8925-40d8-b45c-d5e32afb701f,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-8802073c-1610-49de-9ec2-b7eb7c71c9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-6ca91194-4fb0-411a-b654-6f0be7ccb487,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-a85e427d-ce74-48e3-80a0-1220a0f6913c,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-6cca155d-0b82-4dfd-84aa-b9b7937f7484,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-68f7f8d3-d746-461f-b8d5-6ca7c5e9bcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-d6fa8c3a-5fbc-4058-883c-f43fcb7be29a,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-b70e1531-d399-4e39-864e-f5bba09a4ffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1207667208-172.17.0.18-1595862354541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44824,DS-f1b57e2d-8925-40d8-b45c-d5e32afb701f,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-8802073c-1610-49de-9ec2-b7eb7c71c9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-6ca91194-4fb0-411a-b654-6f0be7ccb487,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-a85e427d-ce74-48e3-80a0-1220a0f6913c,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-6cca155d-0b82-4dfd-84aa-b9b7937f7484,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-68f7f8d3-d746-461f-b8d5-6ca7c5e9bcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39793,DS-d6fa8c3a-5fbc-4058-883c-f43fcb7be29a,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-b70e1531-d399-4e39-864e-f5bba09a4ffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142369344-172.17.0.18-1595862793431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43725,DS-a9f6d90c-7078-4fa1-b576-d6760cf1a4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-bef17869-7b24-4988-a400-8315e9f2dc19,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-46157da0-6bfd-440d-8855-c01c0ed2a89e,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-1248eeb0-114c-4f12-b285-6bfcf8256e38,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-ab57028c-582d-4036-896d-e13d081d3383,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-b20dcb93-e1a3-40d5-a7d7-1b1714335381,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-23fc63fc-518f-47ef-82fe-87090efc0b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-7a880976-bbca-49b5-aa0b-d5ddb10f5aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1142369344-172.17.0.18-1595862793431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43725,DS-a9f6d90c-7078-4fa1-b576-d6760cf1a4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-bef17869-7b24-4988-a400-8315e9f2dc19,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-46157da0-6bfd-440d-8855-c01c0ed2a89e,DISK], DatanodeInfoWithStorage[127.0.0.1:42238,DS-1248eeb0-114c-4f12-b285-6bfcf8256e38,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-ab57028c-582d-4036-896d-e13d081d3383,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-b20dcb93-e1a3-40d5-a7d7-1b1714335381,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-23fc63fc-518f-47ef-82fe-87090efc0b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-7a880976-bbca-49b5-aa0b-d5ddb10f5aa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610923471-172.17.0.18-1595863229296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45349,DS-8d001113-8c0a-488f-ad91-e428582b3d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-0b2fee58-03c2-42dc-a29d-c632e626be6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-13b00d24-8879-41ec-8616-dbc7f4474cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-dd97c201-a072-47e2-98b7-fb223e196bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-fc5e2206-cdbe-4360-9b05-0a108b89949f,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-04cdc664-7a99-484a-be5e-83464f429a51,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-c1860675-5806-40ba-b4ab-976165a87a68,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-15aae6c2-99c8-4e44-98c9-c7f63f7c2a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610923471-172.17.0.18-1595863229296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45349,DS-8d001113-8c0a-488f-ad91-e428582b3d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-0b2fee58-03c2-42dc-a29d-c632e626be6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-13b00d24-8879-41ec-8616-dbc7f4474cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-dd97c201-a072-47e2-98b7-fb223e196bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-fc5e2206-cdbe-4360-9b05-0a108b89949f,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-04cdc664-7a99-484a-be5e-83464f429a51,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-c1860675-5806-40ba-b4ab-976165a87a68,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-15aae6c2-99c8-4e44-98c9-c7f63f7c2a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52636136-172.17.0.18-1595863360445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45578,DS-5e428c20-a1d3-40df-9a0d-71592613a450,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-f13ca84c-0e70-427a-9f8d-f73176f17d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-3c932a82-9fae-44aa-9b91-92faee70604d,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-7fad3c30-664d-4576-b5b6-14ceb61767f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-dee00ba7-1f6d-49d6-a597-f0387f2b613a,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-68fe6d69-5a07-4748-b789-6b8ef2898ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-10897f41-c2a8-472a-9791-7d155ce408c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-7b64d060-4800-421d-8af3-9de0cc60938d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52636136-172.17.0.18-1595863360445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45578,DS-5e428c20-a1d3-40df-9a0d-71592613a450,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-f13ca84c-0e70-427a-9f8d-f73176f17d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-3c932a82-9fae-44aa-9b91-92faee70604d,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-7fad3c30-664d-4576-b5b6-14ceb61767f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-dee00ba7-1f6d-49d6-a597-f0387f2b613a,DISK], DatanodeInfoWithStorage[127.0.0.1:35060,DS-68fe6d69-5a07-4748-b789-6b8ef2898ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-10897f41-c2a8-472a-9791-7d155ce408c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-7b64d060-4800-421d-8af3-9de0cc60938d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-704827787-172.17.0.18-1595863579320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33814,DS-bec8053e-f2fa-4b8e-975f-6f95cf74e22b,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-d50c8a39-3f32-4494-83f2-de6853dc8c66,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-615798a9-7c10-4cfe-be74-44a3c7374ece,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-27fe29d2-bfc9-4808-bf82-ee85589f7301,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-67e3c770-682a-4361-a0ca-e731f2fd0a97,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-4a92d9b3-5219-45e3-9dcc-df2e2bfdde8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-7696b9c0-ade8-4114-9b6f-a3475237023b,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-ca4826e2-b7c2-432e-97ca-6cdcb61af392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-704827787-172.17.0.18-1595863579320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33814,DS-bec8053e-f2fa-4b8e-975f-6f95cf74e22b,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-d50c8a39-3f32-4494-83f2-de6853dc8c66,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-615798a9-7c10-4cfe-be74-44a3c7374ece,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-27fe29d2-bfc9-4808-bf82-ee85589f7301,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-67e3c770-682a-4361-a0ca-e731f2fd0a97,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-4a92d9b3-5219-45e3-9dcc-df2e2bfdde8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-7696b9c0-ade8-4114-9b6f-a3475237023b,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-ca4826e2-b7c2-432e-97ca-6cdcb61af392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-875637827-172.17.0.18-1595863791912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-c3380b1b-7207-4098-bcb5-b9b083e485ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-73cdc232-daf9-4714-9cab-0e3c51964523,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-f7f5886b-bebb-48b9-b6cc-0a486e0a1c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-c8dd141c-7f63-4f75-a918-62644e158725,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-a4945363-130b-4120-ad13-b9e2ddb86b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-55ef2aa5-6a1b-4ff1-8c68-16d56d619c30,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-2d6646e4-ac6d-4447-a538-dea226dc4dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-6f20dfae-8521-455a-a3cf-43cf8ad21c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-875637827-172.17.0.18-1595863791912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-c3380b1b-7207-4098-bcb5-b9b083e485ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-73cdc232-daf9-4714-9cab-0e3c51964523,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-f7f5886b-bebb-48b9-b6cc-0a486e0a1c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-c8dd141c-7f63-4f75-a918-62644e158725,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-a4945363-130b-4120-ad13-b9e2ddb86b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-55ef2aa5-6a1b-4ff1-8c68-16d56d619c30,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-2d6646e4-ac6d-4447-a538-dea226dc4dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-6f20dfae-8521-455a-a3cf-43cf8ad21c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871005380-172.17.0.18-1595864119689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37156,DS-d29e92d9-0e99-45a7-8e60-232752449040,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-18a0773a-ee9c-455f-b861-732ad2122f21,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-22e4debe-dcd7-468b-bbb4-abe130c1ec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-e7ade2c1-4262-486a-b4e8-6cbd6b8b0d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-57b62511-759b-484f-ac06-92a5bb940944,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-7029debe-795d-47ad-b567-a9c6870cf827,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-8c628ddc-a880-4cf2-84d9-85f402683d36,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-0eedec32-55d1-4800-aa53-5d3b160dcc55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871005380-172.17.0.18-1595864119689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37156,DS-d29e92d9-0e99-45a7-8e60-232752449040,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-18a0773a-ee9c-455f-b861-732ad2122f21,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-22e4debe-dcd7-468b-bbb4-abe130c1ec8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-e7ade2c1-4262-486a-b4e8-6cbd6b8b0d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-57b62511-759b-484f-ac06-92a5bb940944,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-7029debe-795d-47ad-b567-a9c6870cf827,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-8c628ddc-a880-4cf2-84d9-85f402683d36,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-0eedec32-55d1-4800-aa53-5d3b160dcc55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794119047-172.17.0.18-1595864309725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38226,DS-70fe9137-bd61-40ee-abce-067afd837a78,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-3067c7ca-8a5f-4623-8cc8-e9fcc56c36fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-2eb4a71e-592d-4301-a798-4e74c6798050,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-32570511-fd3e-4d31-989d-cac77958eea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-d9fa7419-0820-46c2-b953-bb97a5c57083,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-d0a39b0b-0fc9-4b25-bc8a-15d4a2cb6cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-55e4bad8-d522-4c28-968a-0b7a2d34166a,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-8246a952-69ce-4833-b953-aba83e559295,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794119047-172.17.0.18-1595864309725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38226,DS-70fe9137-bd61-40ee-abce-067afd837a78,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-3067c7ca-8a5f-4623-8cc8-e9fcc56c36fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-2eb4a71e-592d-4301-a798-4e74c6798050,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-32570511-fd3e-4d31-989d-cac77958eea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-d9fa7419-0820-46c2-b953-bb97a5c57083,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-d0a39b0b-0fc9-4b25-bc8a-15d4a2cb6cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-55e4bad8-d522-4c28-968a-0b7a2d34166a,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-8246a952-69ce-4833-b953-aba83e559295,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966965157-172.17.0.18-1595864348661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-7af801b1-6d06-401f-aeda-8b38a305222c,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-9f0ab545-95fe-4ad3-8494-364bad5382e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-e3abc448-96c4-4d41-8795-a0f1e4ee3d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-1a9d26e8-7474-42b2-ac68-4ddf29e9a0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-4b33e01f-ce65-424c-ba32-5b9d630d80d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-fde8519c-5f6f-40e6-a33f-18dcad9a7fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-d26ad940-647a-4d18-9d89-3309b93057d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-a2fb255b-5a30-42c7-9f76-f0a0eae76532,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966965157-172.17.0.18-1595864348661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-7af801b1-6d06-401f-aeda-8b38a305222c,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-9f0ab545-95fe-4ad3-8494-364bad5382e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-e3abc448-96c4-4d41-8795-a0f1e4ee3d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-1a9d26e8-7474-42b2-ac68-4ddf29e9a0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-4b33e01f-ce65-424c-ba32-5b9d630d80d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-fde8519c-5f6f-40e6-a33f-18dcad9a7fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-d26ad940-647a-4d18-9d89-3309b93057d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-a2fb255b-5a30-42c7-9f76-f0a0eae76532,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894999122-172.17.0.18-1595864526643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36172,DS-071a32af-8551-4717-85e4-46207fb4ede8,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-364da4ca-bbb5-48b4-be39-af5efafcd1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-1368cf8a-d08a-4aac-91c3-1e66ef2c7dac,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-52d89025-8dff-41de-9eaf-e2d22b4972c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-7690e900-aa1c-4697-bdeb-25dd5f93c3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-6f4a2019-57bb-4881-8559-67fe6b3715fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-2c3081b5-f514-4baa-a371-015694710a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-8bcd9a35-d751-4829-a306-0eea978d79bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894999122-172.17.0.18-1595864526643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36172,DS-071a32af-8551-4717-85e4-46207fb4ede8,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-364da4ca-bbb5-48b4-be39-af5efafcd1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-1368cf8a-d08a-4aac-91c3-1e66ef2c7dac,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-52d89025-8dff-41de-9eaf-e2d22b4972c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-7690e900-aa1c-4697-bdeb-25dd5f93c3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-6f4a2019-57bb-4881-8559-67fe6b3715fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-2c3081b5-f514-4baa-a371-015694710a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-8bcd9a35-d751-4829-a306-0eea978d79bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1467756012-172.17.0.18-1595864992182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35514,DS-99a35304-7822-4a99-8a70-f61d0eaf6e03,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-95a7514f-2ebc-444b-98fe-a6c1184f7f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-fd2bfccb-655d-4923-9475-58426d51d0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-886e5148-aafa-4133-8b36-ff59939c77e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-23598d07-685a-4bfe-95a9-b56909745bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-4f9dff04-a6b7-40ac-8abc-db16c526aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-32ea1784-5972-4b44-bf0e-f6343ea08589,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-69f66dd9-3aad-4cf1-a7f0-bf13b08fffca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1467756012-172.17.0.18-1595864992182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35514,DS-99a35304-7822-4a99-8a70-f61d0eaf6e03,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-95a7514f-2ebc-444b-98fe-a6c1184f7f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-fd2bfccb-655d-4923-9475-58426d51d0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-886e5148-aafa-4133-8b36-ff59939c77e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-23598d07-685a-4bfe-95a9-b56909745bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-4f9dff04-a6b7-40ac-8abc-db16c526aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-32ea1784-5972-4b44-bf0e-f6343ea08589,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-69f66dd9-3aad-4cf1-a7f0-bf13b08fffca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784186085-172.17.0.18-1595865091780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-38ef1734-7ca8-48cf-92e7-ea5cff89df41,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-ae8ae232-613d-4b22-96d1-16deee56ad5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-a441131f-3822-4585-ada4-51ae43973a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-fe78e03e-c54e-42cb-97c8-c03740089fee,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-f919bb29-6491-4997-abd3-80e99bd8c82d,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-eeb18a02-ba8e-4f2b-bb30-5c779ebb835f,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-bc1e031b-b948-40c0-98ec-e30880c0a34e,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-e376cdcf-e793-4b41-9158-48b699422c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784186085-172.17.0.18-1595865091780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-38ef1734-7ca8-48cf-92e7-ea5cff89df41,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-ae8ae232-613d-4b22-96d1-16deee56ad5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-a441131f-3822-4585-ada4-51ae43973a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-fe78e03e-c54e-42cb-97c8-c03740089fee,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-f919bb29-6491-4997-abd3-80e99bd8c82d,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-eeb18a02-ba8e-4f2b-bb30-5c779ebb835f,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-bc1e031b-b948-40c0-98ec-e30880c0a34e,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-e376cdcf-e793-4b41-9158-48b699422c6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939292009-172.17.0.18-1595865259738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33219,DS-a4d730e8-2f2e-4521-9a32-e2b49444419f,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-05cfd995-33e6-435f-bbcd-39760cace630,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-3b2504fc-f360-4535-9f9e-12dd5d987309,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-bb197d0e-1542-4cbb-b686-b627301457ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-ed447461-3201-48ba-aef1-50edd64bb997,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-397d46a6-1e09-4f53-a056-a0cf93aa783a,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-980ae629-1a6c-4b97-9595-8fce6db34286,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-4397478e-e693-4213-ac11-32fb444e950e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939292009-172.17.0.18-1595865259738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33219,DS-a4d730e8-2f2e-4521-9a32-e2b49444419f,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-05cfd995-33e6-435f-bbcd-39760cace630,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-3b2504fc-f360-4535-9f9e-12dd5d987309,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-bb197d0e-1542-4cbb-b686-b627301457ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-ed447461-3201-48ba-aef1-50edd64bb997,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-397d46a6-1e09-4f53-a056-a0cf93aa783a,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-980ae629-1a6c-4b97-9595-8fce6db34286,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-4397478e-e693-4213-ac11-32fb444e950e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1992947361-172.17.0.18-1595865795857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43882,DS-82d8469c-53fc-48e0-8266-ce02e8ca6dce,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-15ec3e74-0c03-4e48-8932-b825b9084f99,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-7d356a26-772f-4aa6-bc0b-594fa641899e,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-cf75abe8-0e3d-48a4-9d1a-cc43bc45119b,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-6ee53a0c-e645-4162-9a8b-1ad61b1fdbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-f8c38f09-ee94-484e-8ce5-c7fa86ae1a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-946ba95f-7129-49dc-815a-704c7a66b477,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-68326d47-cbc8-4c59-87d9-2a1cec40c57a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1992947361-172.17.0.18-1595865795857:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43882,DS-82d8469c-53fc-48e0-8266-ce02e8ca6dce,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-15ec3e74-0c03-4e48-8932-b825b9084f99,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-7d356a26-772f-4aa6-bc0b-594fa641899e,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-cf75abe8-0e3d-48a4-9d1a-cc43bc45119b,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-6ee53a0c-e645-4162-9a8b-1ad61b1fdbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-f8c38f09-ee94-484e-8ce5-c7fa86ae1a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-946ba95f-7129-49dc-815a-704c7a66b477,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-68326d47-cbc8-4c59-87d9-2a1cec40c57a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2282253-172.17.0.18-1595865924454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-2e9ab8cd-7ef0-425e-bf6e-b88192edf3df,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-90f6ff65-e0c3-4452-b148-483c27a94e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-76d9ec78-91a9-4b60-9f34-21e7611d4b12,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-a0e965bd-2793-40d4-941c-e36636033ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-58d27651-e6e9-43a1-a80a-c7ad95bc3cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-2fda950b-127e-496a-8133-a1241ec57d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-cf51e24c-b32e-484f-892f-1fa4a30b3c11,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-4174228a-c4c3-42fb-a4eb-53c281621b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2282253-172.17.0.18-1595865924454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-2e9ab8cd-7ef0-425e-bf6e-b88192edf3df,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-90f6ff65-e0c3-4452-b148-483c27a94e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-76d9ec78-91a9-4b60-9f34-21e7611d4b12,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-a0e965bd-2793-40d4-941c-e36636033ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-58d27651-e6e9-43a1-a80a-c7ad95bc3cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-2fda950b-127e-496a-8133-a1241ec57d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-cf51e24c-b32e-484f-892f-1fa4a30b3c11,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-4174228a-c4c3-42fb-a4eb-53c281621b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216061986-172.17.0.18-1595865957138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35108,DS-c661fb2f-be9c-4ff6-8413-7d2e40c9aecc,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-df4190c7-45fe-439b-84a9-a07267db4855,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-73bc0838-a944-467a-b29f-29c0cc88274d,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-ac3eaf5c-9b48-4ee5-a4fc-10d06868de4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-8869f31c-3b8b-4f07-addd-3bf7127c3791,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-1e505936-c5c3-42cd-aee8-8cc38b38aaab,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-cb30c503-9bc6-4e72-9c25-37f1cb25914a,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-f4d9d6c7-c63c-41f6-888d-d876f3f221ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216061986-172.17.0.18-1595865957138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35108,DS-c661fb2f-be9c-4ff6-8413-7d2e40c9aecc,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-df4190c7-45fe-439b-84a9-a07267db4855,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-73bc0838-a944-467a-b29f-29c0cc88274d,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-ac3eaf5c-9b48-4ee5-a4fc-10d06868de4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-8869f31c-3b8b-4f07-addd-3bf7127c3791,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-1e505936-c5c3-42cd-aee8-8cc38b38aaab,DISK], DatanodeInfoWithStorage[127.0.0.1:34326,DS-cb30c503-9bc6-4e72-9c25-37f1cb25914a,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-f4d9d6c7-c63c-41f6-888d-d876f3f221ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893908426-172.17.0.18-1595866221298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34491,DS-cb472e83-354d-4454-910a-95b9ec9fbafd,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-eebc7b24-d4e9-40df-9576-222b67f97a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-b7be55b2-8b0f-482e-8e3b-5e4665918269,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-7a8a8c0d-7aea-4afe-a5cb-3f822eaaa758,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-39f4c4a0-bac0-47c4-a9b1-5cc2ca013dda,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-ea72008d-87be-4199-a1e7-bdb677922655,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-4fb25698-deaf-498f-b5d5-5290d22c04a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-e4892c60-9ae9-4c94-9561-355d65f79d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893908426-172.17.0.18-1595866221298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34491,DS-cb472e83-354d-4454-910a-95b9ec9fbafd,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-eebc7b24-d4e9-40df-9576-222b67f97a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-b7be55b2-8b0f-482e-8e3b-5e4665918269,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-7a8a8c0d-7aea-4afe-a5cb-3f822eaaa758,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-39f4c4a0-bac0-47c4-a9b1-5cc2ca013dda,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-ea72008d-87be-4199-a1e7-bdb677922655,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-4fb25698-deaf-498f-b5d5-5290d22c04a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-e4892c60-9ae9-4c94-9561-355d65f79d47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582284783-172.17.0.18-1595866889126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39612,DS-b4c8dcdc-1792-482e-80d1-7913ff5af31b,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-6981a1b2-a831-4adb-88af-46fddf90064d,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-490b4700-c37e-4cd7-9a4d-b3831e773f74,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-a5bc155c-f4ca-495f-9eab-b3ebe8a98a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-cc2cdae9-b233-4430-88fa-1940644a5bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-ba24d1fd-d8f8-4f43-b97d-362679733c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-a7b4467d-d315-4770-a833-aed7e49f88bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-e9f7b8ed-0ddd-4f8a-832b-f257b0b62282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582284783-172.17.0.18-1595866889126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39612,DS-b4c8dcdc-1792-482e-80d1-7913ff5af31b,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-6981a1b2-a831-4adb-88af-46fddf90064d,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-490b4700-c37e-4cd7-9a4d-b3831e773f74,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-a5bc155c-f4ca-495f-9eab-b3ebe8a98a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-cc2cdae9-b233-4430-88fa-1940644a5bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-ba24d1fd-d8f8-4f43-b97d-362679733c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-a7b4467d-d315-4770-a833-aed7e49f88bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45391,DS-e9f7b8ed-0ddd-4f8a-832b-f257b0b62282,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188433146-172.17.0.18-1595867050527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45360,DS-35f3ea3d-6485-4027-acc2-509fa5567459,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-a127e2ec-3eb3-42e5-b546-a4d6cf6c2734,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-f7f8d1bc-b328-4092-a7be-ad57ddde4b61,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-d82d308e-62b9-4751-9920-ef6cc38e709a,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-14f7f1b2-213d-4202-a62a-9cf2898a6794,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-38d586af-9180-4a29-9f55-53ba211d2c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-ce1ce825-3700-4560-a66b-55adaa8d09ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-ff87db05-ba88-455b-accd-88051edd1902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188433146-172.17.0.18-1595867050527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45360,DS-35f3ea3d-6485-4027-acc2-509fa5567459,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-a127e2ec-3eb3-42e5-b546-a4d6cf6c2734,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-f7f8d1bc-b328-4092-a7be-ad57ddde4b61,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-d82d308e-62b9-4751-9920-ef6cc38e709a,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-14f7f1b2-213d-4202-a62a-9cf2898a6794,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-38d586af-9180-4a29-9f55-53ba211d2c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-ce1ce825-3700-4560-a66b-55adaa8d09ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-ff87db05-ba88-455b-accd-88051edd1902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattr-size
component: hdfs:NameNode
v1: 16384
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590726327-172.17.0.18-1595867220081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33424,DS-cec8889c-70ef-4fda-854e-562a38b8e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-4ed727a9-76d0-4617-ae5a-067c02374c34,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-65466c46-ca37-406b-ba12-3caa21d294c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-23654a5b-b94b-4745-994c-4c7c058fea15,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-58e4a924-fa07-4f67-a08b-8b2d636dd596,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-311d0e29-037c-4541-92b8-c257ccc1ad2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-641ef17e-7613-4192-b8e0-ab8f9ec9b2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-552d36f2-b783-45f6-ba8a-abacc98ff478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590726327-172.17.0.18-1595867220081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33424,DS-cec8889c-70ef-4fda-854e-562a38b8e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-4ed727a9-76d0-4617-ae5a-067c02374c34,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-65466c46-ca37-406b-ba12-3caa21d294c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-23654a5b-b94b-4745-994c-4c7c058fea15,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-58e4a924-fa07-4f67-a08b-8b2d636dd596,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-311d0e29-037c-4541-92b8-c257ccc1ad2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-641ef17e-7613-4192-b8e0-ab8f9ec9b2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-552d36f2-b783-45f6-ba8a-abacc98ff478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5154
