reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790313687-172.17.0.3-1595635826472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46307,DS-0f5d33f9-97b5-4137-a93b-1dbc8a24ad22,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-f85bc8a3-5733-4add-b01d-d89a6875e8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-ba2e00e1-6adf-4270-856a-0d9b13b004b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-d3110310-6ff8-49ea-a956-f1d08f7369c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-9067864f-5c9c-475b-af98-e94b04e07373,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-e06da103-62ce-4a98-a9b0-3213247d02c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-8fb3fd81-5c3b-4be0-9d5c-202b5f5f40fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-026f9551-4897-44a3-ac28-307626c4353f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790313687-172.17.0.3-1595635826472:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46307,DS-0f5d33f9-97b5-4137-a93b-1dbc8a24ad22,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-f85bc8a3-5733-4add-b01d-d89a6875e8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-ba2e00e1-6adf-4270-856a-0d9b13b004b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-d3110310-6ff8-49ea-a956-f1d08f7369c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-9067864f-5c9c-475b-af98-e94b04e07373,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-e06da103-62ce-4a98-a9b0-3213247d02c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-8fb3fd81-5c3b-4be0-9d5c-202b5f5f40fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-026f9551-4897-44a3-ac28-307626c4353f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571849527-172.17.0.3-1595635973882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37434,DS-bf1e00fc-74d5-410a-b195-c822df6b38b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-c79777af-0bda-40aa-9128-6f9ce4111a63,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-78f6e41d-b3c8-4772-8e82-f72fb495c3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-4f6c3d28-f366-4769-98aa-edda96722fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-c514c94f-ebf2-42ef-92dd-77c73eaa812d,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-d2bda55c-bc53-406b-9c4a-37657daa6368,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-1ca62650-4eb1-4651-9df1-f05bee4d7f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-d0f2f39f-c53c-405d-b8cc-d7d61b812177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571849527-172.17.0.3-1595635973882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37434,DS-bf1e00fc-74d5-410a-b195-c822df6b38b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-c79777af-0bda-40aa-9128-6f9ce4111a63,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-78f6e41d-b3c8-4772-8e82-f72fb495c3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-4f6c3d28-f366-4769-98aa-edda96722fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-c514c94f-ebf2-42ef-92dd-77c73eaa812d,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-d2bda55c-bc53-406b-9c4a-37657daa6368,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-1ca62650-4eb1-4651-9df1-f05bee4d7f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-d0f2f39f-c53c-405d-b8cc-d7d61b812177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006065278-172.17.0.3-1595637180951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44721,DS-8ac69234-0347-4ec1-8210-37daa6fcdba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-0f729dab-4319-4fda-9c8d-8d0d167d5b56,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-283a4303-821f-4af0-b024-a0dbcb81a16d,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-080f8f36-25e0-4cbb-af77-02f23577ba43,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-399ab178-5bdb-4aab-8d95-12404157f22c,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-45a4f78e-34ce-4aab-9ce4-d8bcf686bf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-f0c8583e-343c-41ce-85dd-611a16a2ecc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-b908d57f-e293-43f4-87e7-ace9ba0a143f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006065278-172.17.0.3-1595637180951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44721,DS-8ac69234-0347-4ec1-8210-37daa6fcdba7,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-0f729dab-4319-4fda-9c8d-8d0d167d5b56,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-283a4303-821f-4af0-b024-a0dbcb81a16d,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-080f8f36-25e0-4cbb-af77-02f23577ba43,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-399ab178-5bdb-4aab-8d95-12404157f22c,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-45a4f78e-34ce-4aab-9ce4-d8bcf686bf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-f0c8583e-343c-41ce-85dd-611a16a2ecc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-b908d57f-e293-43f4-87e7-ace9ba0a143f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675695259-172.17.0.3-1595637214570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39642,DS-db1b24e9-7673-4664-ba1f-cdf8e700f16e,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-604328ba-ad9d-41d1-a077-06f11248b7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-3a42adad-dda5-41fd-ada7-44e384406f23,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-37a36a57-e567-4a98-b3d4-d709fde76820,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-af8624b8-c588-4b11-8954-7ef17972fbee,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-7cb84bc6-13ff-4786-aa44-e1207252d3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-c80e0908-5edb-48c7-b3bb-09ea28fab732,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-b81d2aa1-d657-4ea3-bbb6-29b064eb1c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-675695259-172.17.0.3-1595637214570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39642,DS-db1b24e9-7673-4664-ba1f-cdf8e700f16e,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-604328ba-ad9d-41d1-a077-06f11248b7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-3a42adad-dda5-41fd-ada7-44e384406f23,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-37a36a57-e567-4a98-b3d4-d709fde76820,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-af8624b8-c588-4b11-8954-7ef17972fbee,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-7cb84bc6-13ff-4786-aa44-e1207252d3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-c80e0908-5edb-48c7-b3bb-09ea28fab732,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-b81d2aa1-d657-4ea3-bbb6-29b064eb1c86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245827609-172.17.0.3-1595637755155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-98237d96-3761-4cf6-bc6c-f64ce5121569,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-451e746a-23ad-4cdc-b7fb-a265ae54771a,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-86144982-7f26-44d7-8e75-b822cf2266be,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-beb5b8db-f981-4ec1-8f8d-c6a25c6091a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-7b145d6a-2601-47b6-9e89-8dccbc0acbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-9fe29edd-7058-4dbd-b0e1-72a990a1c3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-65adf250-dab5-499b-8556-fe050754301a,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-e1e58cd0-fbcc-473b-81bf-660ee6760575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245827609-172.17.0.3-1595637755155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-98237d96-3761-4cf6-bc6c-f64ce5121569,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-451e746a-23ad-4cdc-b7fb-a265ae54771a,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-86144982-7f26-44d7-8e75-b822cf2266be,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-beb5b8db-f981-4ec1-8f8d-c6a25c6091a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-7b145d6a-2601-47b6-9e89-8dccbc0acbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-9fe29edd-7058-4dbd-b0e1-72a990a1c3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-65adf250-dab5-499b-8556-fe050754301a,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-e1e58cd0-fbcc-473b-81bf-660ee6760575,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486624484-172.17.0.3-1595637832357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45985,DS-77321cf4-9df6-4206-8c53-94b839a8e25d,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-0a421f5a-aa1f-44c4-abfd-eea92c7e01dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-c59a545f-4328-4245-a353-a88a53343fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-a312037a-2565-4a4a-a80a-d28b94b4e6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-57901b19-9596-4eb6-bcb5-e90e131820c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-81bf68c8-9f44-49c3-9da3-bee1eef3489e,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-a9573143-38e7-4ee0-aeba-7e411e409760,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-f82e507f-377c-4ddd-8c9b-cefbc2bdebae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486624484-172.17.0.3-1595637832357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45985,DS-77321cf4-9df6-4206-8c53-94b839a8e25d,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-0a421f5a-aa1f-44c4-abfd-eea92c7e01dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-c59a545f-4328-4245-a353-a88a53343fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-a312037a-2565-4a4a-a80a-d28b94b4e6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-57901b19-9596-4eb6-bcb5-e90e131820c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-81bf68c8-9f44-49c3-9da3-bee1eef3489e,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-a9573143-38e7-4ee0-aeba-7e411e409760,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-f82e507f-377c-4ddd-8c9b-cefbc2bdebae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45922293-172.17.0.3-1595638173758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34545,DS-966ea7a9-3d68-428a-b660-3537767f24f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-6eedf70f-2287-413f-bb9a-69a60e47d155,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-5ab27f6e-1ad1-42d2-a19e-e288130d99c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-e6138830-4b28-4393-ba7c-5c203b788834,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-c291cb1f-4c57-44ed-851e-0887c37af808,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-ac8c321f-a9c0-4d69-ae07-d89616e079c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-248f374c-5694-424b-ada8-7baff3c3b4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-b2a1fad5-dde4-4531-ace8-37e725c02f10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45922293-172.17.0.3-1595638173758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34545,DS-966ea7a9-3d68-428a-b660-3537767f24f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-6eedf70f-2287-413f-bb9a-69a60e47d155,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-5ab27f6e-1ad1-42d2-a19e-e288130d99c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-e6138830-4b28-4393-ba7c-5c203b788834,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-c291cb1f-4c57-44ed-851e-0887c37af808,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-ac8c321f-a9c0-4d69-ae07-d89616e079c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-248f374c-5694-424b-ada8-7baff3c3b4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-b2a1fad5-dde4-4531-ace8-37e725c02f10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1692063168-172.17.0.3-1595638245197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37988,DS-b925423b-43c6-4a49-a66c-cce025ae338d,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-6b52f691-bb28-4e16-9a5c-3d346d737fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-53334af1-4cf0-488b-95a8-da2023ae1a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-ec439779-d648-48ac-8af9-1c86c7ab18b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-85a12fe8-76ae-4d9c-bfb1-b606332a04e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-10015f08-1068-431b-b0dd-a36139daf240,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-3d059738-3490-4ed8-90e1-db90b0ee08f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-08f16e21-b96f-4c9a-9c2a-fbac8a5ade46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1692063168-172.17.0.3-1595638245197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37988,DS-b925423b-43c6-4a49-a66c-cce025ae338d,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-6b52f691-bb28-4e16-9a5c-3d346d737fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-53334af1-4cf0-488b-95a8-da2023ae1a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-ec439779-d648-48ac-8af9-1c86c7ab18b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-85a12fe8-76ae-4d9c-bfb1-b606332a04e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-10015f08-1068-431b-b0dd-a36139daf240,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-3d059738-3490-4ed8-90e1-db90b0ee08f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-08f16e21-b96f-4c9a-9c2a-fbac8a5ade46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008836548-172.17.0.3-1595638473703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-db3eb694-4800-4a14-ae6b-8b059d28f5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-b9769ea5-f1dc-466b-9516-0be29aa9ceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-422d11c6-25dd-4e1e-b654-4ac7f7b9bdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-65204e71-70cc-4e7f-be16-f2bdb7357e28,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-0e56627f-74fd-45f8-8366-af4e3194a3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-bbc4b8b8-da62-4b9b-be50-748527d7e93c,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-bafe547a-5c4a-493f-bb3a-d723cbd709ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-4b594540-35de-4ef8-b241-568ebc018a6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008836548-172.17.0.3-1595638473703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-db3eb694-4800-4a14-ae6b-8b059d28f5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-b9769ea5-f1dc-466b-9516-0be29aa9ceb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-422d11c6-25dd-4e1e-b654-4ac7f7b9bdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-65204e71-70cc-4e7f-be16-f2bdb7357e28,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-0e56627f-74fd-45f8-8366-af4e3194a3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-bbc4b8b8-da62-4b9b-be50-748527d7e93c,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-bafe547a-5c4a-493f-bb3a-d723cbd709ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-4b594540-35de-4ef8-b241-568ebc018a6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980251477-172.17.0.3-1595638508654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34527,DS-f96795bd-b5ca-49bf-973f-c7b96ef8dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-a0b03bf2-7f0e-4a09-b532-989c0e73b91a,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-c7584330-559b-474a-94c9-aa5b8060d553,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-a8efb999-70c3-4772-870b-2c2fcaba08d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-a795b4ba-581f-40ca-b9d2-657b0871dcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-95b09eb7-a26a-43fe-a8e7-98ea8742cd96,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-f26423e6-03db-4a84-bac2-ca5b8977ed53,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-32eb3a2a-e954-423f-94c1-9517d0ac1442,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980251477-172.17.0.3-1595638508654:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34527,DS-f96795bd-b5ca-49bf-973f-c7b96ef8dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-a0b03bf2-7f0e-4a09-b532-989c0e73b91a,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-c7584330-559b-474a-94c9-aa5b8060d553,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-a8efb999-70c3-4772-870b-2c2fcaba08d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-a795b4ba-581f-40ca-b9d2-657b0871dcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-95b09eb7-a26a-43fe-a8e7-98ea8742cd96,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-f26423e6-03db-4a84-bac2-ca5b8977ed53,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-32eb3a2a-e954-423f-94c1-9517d0ac1442,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-366326377-172.17.0.3-1595638732736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37120,DS-a94ca0f4-c3b8-4423-b552-c8b0c315bf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-ac0537f4-36cf-4f1d-851a-f2f7c78b845a,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-490df11f-c301-46d0-a36a-6722b1d9983a,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-058f6cf4-900b-43c6-81b1-2a86f47bbea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-42ed7941-7fd0-42ed-b9d5-90a6a46e4406,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-b1133752-fc08-461e-9fb6-c30c1eae6db6,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-e787b16d-dcf1-40e4-af21-96fb1f592ace,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-2e38e0bf-384e-4546-906b-c5f2cc2ce81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-366326377-172.17.0.3-1595638732736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37120,DS-a94ca0f4-c3b8-4423-b552-c8b0c315bf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-ac0537f4-36cf-4f1d-851a-f2f7c78b845a,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-490df11f-c301-46d0-a36a-6722b1d9983a,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-058f6cf4-900b-43c6-81b1-2a86f47bbea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-42ed7941-7fd0-42ed-b9d5-90a6a46e4406,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-b1133752-fc08-461e-9fb6-c30c1eae6db6,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-e787b16d-dcf1-40e4-af21-96fb1f592ace,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-2e38e0bf-384e-4546-906b-c5f2cc2ce81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254674831-172.17.0.3-1595640054736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45204,DS-053681fa-1dd9-4639-8f86-02ade0894bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-bfc28c40-3103-4cc0-ae7e-fec4efce04eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-f1e78502-af4b-42ed-997a-8f4fc083b905,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-7f4b8ced-1b4c-45a4-84a8-5f155a852974,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-30325c87-9874-423d-a9ce-09a1a427ea57,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-e278b8dc-4af8-4591-92b1-045e694f99f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-5c72b5b5-ce63-47ef-8967-1336ebdd806e,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-536f6f36-6668-4ea2-9f95-0d405e206e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254674831-172.17.0.3-1595640054736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45204,DS-053681fa-1dd9-4639-8f86-02ade0894bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-bfc28c40-3103-4cc0-ae7e-fec4efce04eb,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-f1e78502-af4b-42ed-997a-8f4fc083b905,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-7f4b8ced-1b4c-45a4-84a8-5f155a852974,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-30325c87-9874-423d-a9ce-09a1a427ea57,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-e278b8dc-4af8-4591-92b1-045e694f99f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-5c72b5b5-ce63-47ef-8967-1336ebdd806e,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-536f6f36-6668-4ea2-9f95-0d405e206e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5587
