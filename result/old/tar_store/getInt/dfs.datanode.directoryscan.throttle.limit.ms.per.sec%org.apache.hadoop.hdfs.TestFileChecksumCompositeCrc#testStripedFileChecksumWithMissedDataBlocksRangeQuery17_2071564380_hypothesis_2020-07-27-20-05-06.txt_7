reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861783027-172.17.0.15-1595880346301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36037,DS-66cf7ebc-1833-49f8-ad11-419b7cdc4809,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-505592b5-efc1-443e-a222-499515ca8a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-89c3ec03-0825-4862-83fd-30960c72a95d,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-eabb913b-9d00-4db9-b67f-13a7baea9eff,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-fcf2abef-36b9-4e43-853a-0354b4c7f571,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-7848019e-d618-4e04-83cd-c3a0de877b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-def63bcb-e03b-493a-8be1-4a91caeea769,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-6a8e2e0b-0c70-47a8-9fc3-45b2d0b841b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1861783027-172.17.0.15-1595880346301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36037,DS-66cf7ebc-1833-49f8-ad11-419b7cdc4809,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-505592b5-efc1-443e-a222-499515ca8a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-89c3ec03-0825-4862-83fd-30960c72a95d,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-eabb913b-9d00-4db9-b67f-13a7baea9eff,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-fcf2abef-36b9-4e43-853a-0354b4c7f571,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-7848019e-d618-4e04-83cd-c3a0de877b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-def63bcb-e03b-493a-8be1-4a91caeea769,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-6a8e2e0b-0c70-47a8-9fc3-45b2d0b841b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453776086-172.17.0.15-1595880485295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42851,DS-0e08f967-bf3f-4c01-9733-3c32bc77e209,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-ffaa4d71-c243-4a54-8bda-2a444b16d02f,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-c0124f89-2052-4a4f-b6c7-eeae6216148f,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-e2f9aed8-e43b-4ef0-afa6-b41e4ae4158d,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-cc428f76-3773-4b1e-8bbf-0b5afa309146,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-daa25fee-8e0a-4638-9924-d6c552a0e1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-d69c79cc-7766-47e2-af40-992da2aca061,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-e3462cb2-dbad-4ff7-8e9d-080f9d5df686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453776086-172.17.0.15-1595880485295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42851,DS-0e08f967-bf3f-4c01-9733-3c32bc77e209,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-ffaa4d71-c243-4a54-8bda-2a444b16d02f,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-c0124f89-2052-4a4f-b6c7-eeae6216148f,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-e2f9aed8-e43b-4ef0-afa6-b41e4ae4158d,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-cc428f76-3773-4b1e-8bbf-0b5afa309146,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-daa25fee-8e0a-4638-9924-d6c552a0e1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-d69c79cc-7766-47e2-af40-992da2aca061,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-e3462cb2-dbad-4ff7-8e9d-080f9d5df686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1004487123-172.17.0.15-1595880583432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41828,DS-1d0c728a-24d6-4954-bb74-0181d04bab60,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-83e0a5c2-f7a5-4e1b-96ee-5672bd7bd7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-374778b7-c227-43d6-9d26-b2b6dcb8a7be,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-2cf226c9-ce00-4750-9bec-604d5ecf6817,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-1ba16c45-5e31-4083-9490-b464fdf08bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-8f8ec188-2664-4f58-8921-f3791ccd88bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-23981159-7121-4eb4-9ea9-eb154f97c5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-1e349dcd-34be-4d4f-ba04-314af142ad95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1004487123-172.17.0.15-1595880583432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41828,DS-1d0c728a-24d6-4954-bb74-0181d04bab60,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-83e0a5c2-f7a5-4e1b-96ee-5672bd7bd7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-374778b7-c227-43d6-9d26-b2b6dcb8a7be,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-2cf226c9-ce00-4750-9bec-604d5ecf6817,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-1ba16c45-5e31-4083-9490-b464fdf08bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-8f8ec188-2664-4f58-8921-f3791ccd88bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-23981159-7121-4eb4-9ea9-eb154f97c5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-1e349dcd-34be-4d4f-ba04-314af142ad95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991646252-172.17.0.15-1595880989437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44356,DS-41fcdf0f-50a5-4420-93e0-e9f8ef4dfe79,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-0afaa44d-ed17-489a-9eb5-2f26a268333a,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-ba23f238-b63c-4de6-b9b9-5852589e37b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-0f88a21b-3b34-4b14-8192-1eca810719f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-e4e8c34f-eebe-469b-9797-0a6cb8231ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-b719c719-d5df-4849-9dcc-f345efc3a6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-ee1a13e6-92ed-4e90-81e6-abc22ed30b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-fbd0b054-dd5a-41f4-a8ad-16425da4c9b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991646252-172.17.0.15-1595880989437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44356,DS-41fcdf0f-50a5-4420-93e0-e9f8ef4dfe79,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-0afaa44d-ed17-489a-9eb5-2f26a268333a,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-ba23f238-b63c-4de6-b9b9-5852589e37b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-0f88a21b-3b34-4b14-8192-1eca810719f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-e4e8c34f-eebe-469b-9797-0a6cb8231ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-b719c719-d5df-4849-9dcc-f345efc3a6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-ee1a13e6-92ed-4e90-81e6-abc22ed30b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43890,DS-fbd0b054-dd5a-41f4-a8ad-16425da4c9b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054502762-172.17.0.15-1595881024526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35106,DS-4f35e1c1-2e83-48cc-94f7-321b1dc352ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-ba420abb-5fc9-4fa9-b2cf-33348b792b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-9b753e59-bdf5-49f5-a6fc-d334d4c239ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-7659d18f-3fd9-4409-a6ee-c90f1d5f2380,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-a89eeaf0-161a-46d4-b6dc-45cf31fc1b80,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-416fb35b-1bb9-41a0-bcce-0b9b84cba9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-aadd69d8-925f-41b2-9dcc-070472bf4955,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-eb1e5a52-88fb-4a3d-9b67-3aa2f1dfaf56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2054502762-172.17.0.15-1595881024526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35106,DS-4f35e1c1-2e83-48cc-94f7-321b1dc352ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-ba420abb-5fc9-4fa9-b2cf-33348b792b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-9b753e59-bdf5-49f5-a6fc-d334d4c239ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-7659d18f-3fd9-4409-a6ee-c90f1d5f2380,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-a89eeaf0-161a-46d4-b6dc-45cf31fc1b80,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-416fb35b-1bb9-41a0-bcce-0b9b84cba9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-aadd69d8-925f-41b2-9dcc-070472bf4955,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-eb1e5a52-88fb-4a3d-9b67-3aa2f1dfaf56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384860076-172.17.0.15-1595881131099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45135,DS-4cc2b826-aaed-4fde-88ad-910c0acec1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-fee68963-62b9-44db-ae23-ad56b2e4a891,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-237e3f71-443a-460d-810d-7d5926630824,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-6e364b78-5564-47b4-9344-39f88c08815b,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-21fad617-8d97-40c6-b5f8-77fbd9b37039,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-2621d6da-c2d3-45fd-a2b1-98aee70917a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-a501f2c8-869e-4e90-91a9-4ed4e189ddea,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-9c9df4a1-6e26-4282-aa56-f2a45c299a46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384860076-172.17.0.15-1595881131099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45135,DS-4cc2b826-aaed-4fde-88ad-910c0acec1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-fee68963-62b9-44db-ae23-ad56b2e4a891,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-237e3f71-443a-460d-810d-7d5926630824,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-6e364b78-5564-47b4-9344-39f88c08815b,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-21fad617-8d97-40c6-b5f8-77fbd9b37039,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-2621d6da-c2d3-45fd-a2b1-98aee70917a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-a501f2c8-869e-4e90-91a9-4ed4e189ddea,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-9c9df4a1-6e26-4282-aa56-f2a45c299a46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143358968-172.17.0.15-1595881169686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37045,DS-cb766310-7061-4fbd-a89b-4f4038afdd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-a63963d7-57af-4455-849f-39b3f843f5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-8c9e465e-7339-4a47-94c0-25f638f1352e,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-949f1da4-7e5b-4e2e-8ffd-f22c589ddcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-88520aaa-8378-4a9e-8727-7c865605fd52,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-c842ac5f-8dc6-474b-beff-c54dee78efab,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-b533438c-ce42-4022-96e9-a31fb538fcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-d43170ab-6054-42df-b144-a0f4e4a10a1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143358968-172.17.0.15-1595881169686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37045,DS-cb766310-7061-4fbd-a89b-4f4038afdd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-a63963d7-57af-4455-849f-39b3f843f5e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-8c9e465e-7339-4a47-94c0-25f638f1352e,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-949f1da4-7e5b-4e2e-8ffd-f22c589ddcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-88520aaa-8378-4a9e-8727-7c865605fd52,DISK], DatanodeInfoWithStorage[127.0.0.1:36390,DS-c842ac5f-8dc6-474b-beff-c54dee78efab,DISK], DatanodeInfoWithStorage[127.0.0.1:39204,DS-b533438c-ce42-4022-96e9-a31fb538fcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-d43170ab-6054-42df-b144-a0f4e4a10a1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1594782608-172.17.0.15-1595882119792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46702,DS-d4ba7399-49d5-4962-8fdd-50b3774a4890,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-906e4c92-207f-4357-8721-2b8ffd0fd4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-57022c92-ae14-4eb8-8807-0b9fe8c8b315,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-eb95f5e2-4313-4f06-8307-364a1a7648ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-948a0d8c-64d8-4c96-91f4-3116ea47893f,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-e7a28537-f6bc-4f37-b7c4-38bf83d19972,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-ef257ad5-4cc6-495d-bb8f-afe921691416,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-df9df5f4-eb26-4f63-b309-1c81b219263e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1594782608-172.17.0.15-1595882119792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46702,DS-d4ba7399-49d5-4962-8fdd-50b3774a4890,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-906e4c92-207f-4357-8721-2b8ffd0fd4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-57022c92-ae14-4eb8-8807-0b9fe8c8b315,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-eb95f5e2-4313-4f06-8307-364a1a7648ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-948a0d8c-64d8-4c96-91f4-3116ea47893f,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-e7a28537-f6bc-4f37-b7c4-38bf83d19972,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-ef257ad5-4cc6-495d-bb8f-afe921691416,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-df9df5f4-eb26-4f63-b309-1c81b219263e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266570136-172.17.0.15-1595882149966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35030,DS-274afcef-e074-40d8-8e53-649944a9e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-a6b1683b-7556-43eb-8602-a010b67a62ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-0344427c-890f-4c1c-bafe-fb93c5e40d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-89dcc147-f226-4278-9321-e1a022c15ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-abec4da8-fa94-44ce-ab89-a008c7d2fea4,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-e8f46571-18e5-4d60-8209-6aad1e31fdba,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-c23fdea1-a458-4d2e-833d-60eaee76e203,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-506da047-7732-469c-a0a6-cb1862a55327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266570136-172.17.0.15-1595882149966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35030,DS-274afcef-e074-40d8-8e53-649944a9e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-a6b1683b-7556-43eb-8602-a010b67a62ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-0344427c-890f-4c1c-bafe-fb93c5e40d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-89dcc147-f226-4278-9321-e1a022c15ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-abec4da8-fa94-44ce-ab89-a008c7d2fea4,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-e8f46571-18e5-4d60-8209-6aad1e31fdba,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-c23fdea1-a458-4d2e-833d-60eaee76e203,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-506da047-7732-469c-a0a6-cb1862a55327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969353706-172.17.0.15-1595882214795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-a5e053af-eead-424c-bf94-fc45a9dda9af,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-fd3dda35-75f8-41b1-a669-8e89bb5e98d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-7014ad6f-c05d-49f4-8bce-9e96855e2971,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-31efc705-a6b7-49ea-97b9-0a5b94b0b336,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-15a2cfa4-bec3-456d-b40a-d4443463bfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-e839e5f4-f59b-45a3-a575-eb094766298d,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-6325d89e-ba25-436c-b5f7-4ccddb1c8c89,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-2daf6ab3-5c98-4506-b2a4-834b3889f5ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969353706-172.17.0.15-1595882214795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43741,DS-a5e053af-eead-424c-bf94-fc45a9dda9af,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-fd3dda35-75f8-41b1-a669-8e89bb5e98d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-7014ad6f-c05d-49f4-8bce-9e96855e2971,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-31efc705-a6b7-49ea-97b9-0a5b94b0b336,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-15a2cfa4-bec3-456d-b40a-d4443463bfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-e839e5f4-f59b-45a3-a575-eb094766298d,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-6325d89e-ba25-436c-b5f7-4ccddb1c8c89,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-2daf6ab3-5c98-4506-b2a4-834b3889f5ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-368695895-172.17.0.15-1595882334031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36817,DS-09f05d3a-246b-44cb-8f05-ba2eb474c35e,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-043950b4-a366-405e-b4a7-9f967e31ae89,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-5c835fe8-7ca1-4d76-a0e9-e5fd450a37f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-85424e42-ae6c-4174-9150-075e147f7e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-5646b2a0-1cf0-4fdc-80c5-b979efaf32c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-96f32016-a114-4dea-a2b8-6b9f3118351f,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-f069df52-31dc-4fc0-b1c3-27c6e6a00f52,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-8d997457-f07f-437b-9d14-77ce07f12804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-368695895-172.17.0.15-1595882334031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36817,DS-09f05d3a-246b-44cb-8f05-ba2eb474c35e,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-043950b4-a366-405e-b4a7-9f967e31ae89,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-5c835fe8-7ca1-4d76-a0e9-e5fd450a37f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-85424e42-ae6c-4174-9150-075e147f7e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-5646b2a0-1cf0-4fdc-80c5-b979efaf32c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-96f32016-a114-4dea-a2b8-6b9f3118351f,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-f069df52-31dc-4fc0-b1c3-27c6e6a00f52,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-8d997457-f07f-437b-9d14-77ce07f12804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-263227036-172.17.0.15-1595882919884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33403,DS-f06c3f2d-3e8a-4827-b9a6-295370215b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-d6a99e39-0763-4de2-8f88-8db2184cfd30,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-3e6f25c8-3fec-4b1c-abd2-cb49e98d2493,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-b5d9e2f5-0049-4966-b3f8-48d8ac69baf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-d2fa0358-84a3-4847-98de-7ad09eabe0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-2abfabb3-3f5d-434c-9d14-80cb9640368b,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-e7a57aa9-2c9f-4c9e-8b11-b28df1da0684,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-81932d06-71ee-4aaa-ab0a-1595df945a18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-263227036-172.17.0.15-1595882919884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33403,DS-f06c3f2d-3e8a-4827-b9a6-295370215b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-d6a99e39-0763-4de2-8f88-8db2184cfd30,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-3e6f25c8-3fec-4b1c-abd2-cb49e98d2493,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-b5d9e2f5-0049-4966-b3f8-48d8ac69baf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-d2fa0358-84a3-4847-98de-7ad09eabe0f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-2abfabb3-3f5d-434c-9d14-80cb9640368b,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-e7a57aa9-2c9f-4c9e-8b11-b28df1da0684,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-81932d06-71ee-4aaa-ab0a-1595df945a18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818359690-172.17.0.15-1595883057813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34228,DS-85c1c546-6872-4550-b704-e8e0182d42e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-5824dfe1-b721-4f00-a966-f802a09a03a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-b71c8d66-bce0-4039-9eb5-6c85dc1de062,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-c2c8e12a-c8b6-4396-b30e-48bb21a13bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-9327a17d-2ecd-4904-b58c-9a64e7fde3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-4eba4ed7-f881-4536-990d-381c72631379,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-980fa0b8-ab1d-4dce-9191-af4d71be5110,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-0c4bd1aa-e317-4239-8e07-3a6d52f13fc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818359690-172.17.0.15-1595883057813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34228,DS-85c1c546-6872-4550-b704-e8e0182d42e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-5824dfe1-b721-4f00-a966-f802a09a03a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-b71c8d66-bce0-4039-9eb5-6c85dc1de062,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-c2c8e12a-c8b6-4396-b30e-48bb21a13bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-9327a17d-2ecd-4904-b58c-9a64e7fde3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-4eba4ed7-f881-4536-990d-381c72631379,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-980fa0b8-ab1d-4dce-9191-af4d71be5110,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-0c4bd1aa-e317-4239-8e07-3a6d52f13fc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2013381782-172.17.0.15-1595883187450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37338,DS-c050fc10-649d-4a36-818f-282091fe5220,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-27a221ab-9b72-4d33-b8e8-1ce323debbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-c5f4f4c1-15be-42b2-8be4-4862fa5eaf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-47123937-13f3-4077-b4ba-1159375224eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-6f9a2a5d-a4ee-45ee-be17-5eb229a016b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-0dd9b7be-e64f-4737-9b01-4ae53d708722,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-0ffcd0a6-bbf3-4337-be1f-76a75a77878f,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-6dc82613-beb4-4a1d-b9ca-53dae4087829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2013381782-172.17.0.15-1595883187450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37338,DS-c050fc10-649d-4a36-818f-282091fe5220,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-27a221ab-9b72-4d33-b8e8-1ce323debbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-c5f4f4c1-15be-42b2-8be4-4862fa5eaf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-47123937-13f3-4077-b4ba-1159375224eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-6f9a2a5d-a4ee-45ee-be17-5eb229a016b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-0dd9b7be-e64f-4737-9b01-4ae53d708722,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-0ffcd0a6-bbf3-4337-be1f-76a75a77878f,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-6dc82613-beb4-4a1d-b9ca-53dae4087829,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65643422-172.17.0.15-1595883261242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41201,DS-b99d6ac9-66a3-4108-9861-4ef9c6c3c995,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-f21dd601-bd84-40dd-843a-f9dac4d7ac3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-c8445bba-674d-4e38-b9d2-3bcf3c2052af,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-a4977f6b-c070-43bc-94dc-db70570db6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-15df7f7b-04b1-4cdb-b203-0e0b3f282cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-3c1e8846-922d-4adc-8594-1a3f2cb6289a,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-0c0890c9-b4ba-4123-bb9a-e3b75359c906,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-255e6766-b1c8-4657-9ed5-71c1b766ff5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65643422-172.17.0.15-1595883261242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41201,DS-b99d6ac9-66a3-4108-9861-4ef9c6c3c995,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-f21dd601-bd84-40dd-843a-f9dac4d7ac3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-c8445bba-674d-4e38-b9d2-3bcf3c2052af,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-a4977f6b-c070-43bc-94dc-db70570db6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-15df7f7b-04b1-4cdb-b203-0e0b3f282cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-3c1e8846-922d-4adc-8594-1a3f2cb6289a,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-0c0890c9-b4ba-4123-bb9a-e3b75359c906,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-255e6766-b1c8-4657-9ed5-71c1b766ff5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542814736-172.17.0.15-1595883356277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44751,DS-ce998862-1f21-4e68-a39a-656908542164,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-2189cd70-a650-478c-874b-1fba5fc34b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-c5a37fd8-7f67-49f7-950d-577764ccb634,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-e1984979-7415-4a25-b7a2-c8d13cc9de7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-392063ff-6e3c-4083-a570-1f6f57e8a588,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-43288de8-2841-4372-8947-348cefeeedae,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-0ef3a613-8846-4a1a-9cd0-e13df4edadf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-afaf2bce-e227-4d7e-88e0-6bea1b719c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-542814736-172.17.0.15-1595883356277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44751,DS-ce998862-1f21-4e68-a39a-656908542164,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-2189cd70-a650-478c-874b-1fba5fc34b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-c5a37fd8-7f67-49f7-950d-577764ccb634,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-e1984979-7415-4a25-b7a2-c8d13cc9de7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-392063ff-6e3c-4083-a570-1f6f57e8a588,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-43288de8-2841-4372-8947-348cefeeedae,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-0ef3a613-8846-4a1a-9cd0-e13df4edadf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-afaf2bce-e227-4d7e-88e0-6bea1b719c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111270313-172.17.0.15-1595884262814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-ae7b13e7-d383-489a-8d68-882efee59b52,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-6d25c784-31e1-4d35-8503-b4f7f3d40f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-b4aecb63-03be-4752-98aa-123141500b83,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-cf887e10-39fd-45ba-a979-76f202aeb5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-bb13853c-4637-4df5-bea0-a67f57d949a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-7e0f5d8d-5144-4cad-8572-7e725d98e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-170f24af-145d-41b0-b48a-dc502bb25f00,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-bc7693a1-6c55-4e0b-bcf5-3beaa14831a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2111270313-172.17.0.15-1595884262814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-ae7b13e7-d383-489a-8d68-882efee59b52,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-6d25c784-31e1-4d35-8503-b4f7f3d40f17,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-b4aecb63-03be-4752-98aa-123141500b83,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-cf887e10-39fd-45ba-a979-76f202aeb5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-bb13853c-4637-4df5-bea0-a67f57d949a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-7e0f5d8d-5144-4cad-8572-7e725d98e6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-170f24af-145d-41b0-b48a-dc502bb25f00,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-bc7693a1-6c55-4e0b-bcf5-3beaa14831a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098181840-172.17.0.15-1595884474183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34509,DS-0530ca18-dfbd-405b-a96d-a65a74da830f,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-07517b04-27ce-4d04-9d2d-bd3b8366aa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-5da13fa0-4362-4424-af7f-6b558b2e3be5,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-6f3217e2-52ef-4852-ad04-f25c1ed2eceb,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-ea13f1a9-56f6-4519-bec3-15bb2a994e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-5b40ec23-c06a-4c22-a823-e8b5ecbad136,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-ec48f26f-a11d-4469-aa03-ae037248afbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-ba9fcb9a-675c-4611-9044-860f0438c8df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098181840-172.17.0.15-1595884474183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34509,DS-0530ca18-dfbd-405b-a96d-a65a74da830f,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-07517b04-27ce-4d04-9d2d-bd3b8366aa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-5da13fa0-4362-4424-af7f-6b558b2e3be5,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-6f3217e2-52ef-4852-ad04-f25c1ed2eceb,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-ea13f1a9-56f6-4519-bec3-15bb2a994e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-5b40ec23-c06a-4c22-a823-e8b5ecbad136,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-ec48f26f-a11d-4469-aa03-ae037248afbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-ba9fcb9a-675c-4611-9044-860f0438c8df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862226049-172.17.0.15-1595884667389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38640,DS-3d6675e7-5b35-46d3-8dda-f1db1001682f,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-9203c9fc-f631-4d10-bf9b-0be1189a0b78,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-841df5de-29ec-4125-b144-605d04cd2f44,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-813e22d7-3eda-4e9c-af6d-486a10f1a19e,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-4c5237b6-e6dc-4cd1-8ba9-2eb2674dc88b,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-9071f7cf-37f4-4a59-8985-ed60ab124f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-a42b2bfc-1198-42cb-8063-84a0e7560675,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-994d94e6-acda-40e8-8356-26659d931c49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862226049-172.17.0.15-1595884667389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38640,DS-3d6675e7-5b35-46d3-8dda-f1db1001682f,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-9203c9fc-f631-4d10-bf9b-0be1189a0b78,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-841df5de-29ec-4125-b144-605d04cd2f44,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-813e22d7-3eda-4e9c-af6d-486a10f1a19e,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-4c5237b6-e6dc-4cd1-8ba9-2eb2674dc88b,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-9071f7cf-37f4-4a59-8985-ed60ab124f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-a42b2bfc-1198-42cb-8063-84a0e7560675,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-994d94e6-acda-40e8-8356-26659d931c49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213023674-172.17.0.15-1595885060055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-94e6aff4-a4d5-448b-9aa3-32a9282f4303,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-e345f0d0-c73a-46f5-aaae-43d309d99d47,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-061577ae-65b4-4e62-9aea-01c69587b726,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-5bbbf640-f892-4e50-ad2b-e0b8f52cf8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-6772e896-1bd0-4258-93c0-41167505d60a,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-fb866a7f-deaa-46b0-bcd6-cdc3f1d94195,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-6dd0a562-0f92-4ee8-a2d2-bf0e67da33ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-e9573f4c-1658-46b7-bc1d-c3876edff986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-213023674-172.17.0.15-1595885060055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-94e6aff4-a4d5-448b-9aa3-32a9282f4303,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-e345f0d0-c73a-46f5-aaae-43d309d99d47,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-061577ae-65b4-4e62-9aea-01c69587b726,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-5bbbf640-f892-4e50-ad2b-e0b8f52cf8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-6772e896-1bd0-4258-93c0-41167505d60a,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-fb866a7f-deaa-46b0-bcd6-cdc3f1d94195,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-6dd0a562-0f92-4ee8-a2d2-bf0e67da33ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-e9573f4c-1658-46b7-bc1d-c3876edff986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642342373-172.17.0.15-1595885223764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37989,DS-34890881-40de-49c1-81ec-efb296e9edb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-7287d109-e044-4431-bb44-04b8f08a17f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-fd894a17-9a9e-45d0-88cf-36d116603817,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-f815575c-252f-4818-b436-30c44907bb63,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-f956faee-66a4-4034-83d2-51893e0c4265,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-6a4248a7-fdac-4265-bbb3-d8d54f2b5074,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-d90a961f-197a-402f-a160-9cf4b6a8bc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-eaf12a7f-64bd-4fdd-bfb6-6c1b6cab6290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1642342373-172.17.0.15-1595885223764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37989,DS-34890881-40de-49c1-81ec-efb296e9edb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-7287d109-e044-4431-bb44-04b8f08a17f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-fd894a17-9a9e-45d0-88cf-36d116603817,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-f815575c-252f-4818-b436-30c44907bb63,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-f956faee-66a4-4034-83d2-51893e0c4265,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-6a4248a7-fdac-4265-bbb3-d8d54f2b5074,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-d90a961f-197a-402f-a160-9cf4b6a8bc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-eaf12a7f-64bd-4fdd-bfb6-6c1b6cab6290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5052
