reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687224533-172.17.0.5-1596006416950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38503,DS-19edd1c5-a10f-4519-8068-b4dca6baa7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-b3555bde-b20e-4bc8-adcc-d5dc4894bd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-3f414c46-7d41-4c01-ace2-3876c4922267,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-3bf75d38-f9df-4f55-a3c5-a97c4cefca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-8be3d327-2a93-4a47-807b-62b8cbe6508a,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-a65f6d83-b5f0-42af-be68-040236d46345,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-af93e711-0c69-4694-bd8a-a6d35fa87a12,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-2a41074b-d6ba-4e89-bfed-565475e14e46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687224533-172.17.0.5-1596006416950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38503,DS-19edd1c5-a10f-4519-8068-b4dca6baa7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-b3555bde-b20e-4bc8-adcc-d5dc4894bd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-3f414c46-7d41-4c01-ace2-3876c4922267,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-3bf75d38-f9df-4f55-a3c5-a97c4cefca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-8be3d327-2a93-4a47-807b-62b8cbe6508a,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-a65f6d83-b5f0-42af-be68-040236d46345,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-af93e711-0c69-4694-bd8a-a6d35fa87a12,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-2a41074b-d6ba-4e89-bfed-565475e14e46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455013457-172.17.0.5-1596006917173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37677,DS-dd9d8a73-9066-485e-9eee-75a47f71a25d,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-ec794d48-eef0-43a1-8167-7f5620339c09,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-2cfb3bf6-7ae3-4d22-b601-8ae503e78a14,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-6e783c38-bac6-4ab2-b651-15389c34f7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-9e4b20df-7829-46c8-8524-652976ae1a96,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-60391c7b-c002-4d7a-bed0-a9bbfcdd9034,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-8f14c12f-8801-4d9c-935d-fac7f1378c16,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-4ab6b50d-1ffe-472d-91d0-4769ab58a9d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455013457-172.17.0.5-1596006917173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37677,DS-dd9d8a73-9066-485e-9eee-75a47f71a25d,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-ec794d48-eef0-43a1-8167-7f5620339c09,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-2cfb3bf6-7ae3-4d22-b601-8ae503e78a14,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-6e783c38-bac6-4ab2-b651-15389c34f7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-9e4b20df-7829-46c8-8524-652976ae1a96,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-60391c7b-c002-4d7a-bed0-a9bbfcdd9034,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-8f14c12f-8801-4d9c-935d-fac7f1378c16,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-4ab6b50d-1ffe-472d-91d0-4769ab58a9d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854195825-172.17.0.5-1596007453553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33332,DS-6842ec7e-6fe0-4bad-8eec-f6aa9adc27d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-8bdc2530-3c31-4035-a67d-156d0f03ba18,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-bb2f9ccb-96f1-4041-b6df-7b4d049775a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-df21864f-ff54-4aad-b293-3cbca1bbec9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-553240bc-7746-4169-b6f3-f89af369e66d,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-abe53a03-88b4-4c6a-ab3c-b330f94aedb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-97ce9c8c-978d-4532-bf33-e2c7e2b79da5,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-253cd342-eaba-4b15-b943-61a4331adc9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854195825-172.17.0.5-1596007453553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33332,DS-6842ec7e-6fe0-4bad-8eec-f6aa9adc27d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-8bdc2530-3c31-4035-a67d-156d0f03ba18,DISK], DatanodeInfoWithStorage[127.0.0.1:34295,DS-bb2f9ccb-96f1-4041-b6df-7b4d049775a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-df21864f-ff54-4aad-b293-3cbca1bbec9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-553240bc-7746-4169-b6f3-f89af369e66d,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-abe53a03-88b4-4c6a-ab3c-b330f94aedb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-97ce9c8c-978d-4532-bf33-e2c7e2b79da5,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-253cd342-eaba-4b15-b943-61a4331adc9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413296305-172.17.0.5-1596007575502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33118,DS-68b109b7-2e12-4a7c-9f6f-63f1eb72beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-563b8129-e6ca-44dc-b927-94d8752350c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-962db096-c700-4193-9982-dd1b2bf38283,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-26998bdb-5736-4436-990b-426837c9ecec,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-62a292fc-2de4-478a-9a8b-8ebdb023029b,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-2e2fcabc-9054-4c77-8693-02e107097592,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-bfcb8d6f-29ee-4cea-a81f-28837e4a8213,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-40ca37ef-0b6c-4a08-a977-d970631d8a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413296305-172.17.0.5-1596007575502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33118,DS-68b109b7-2e12-4a7c-9f6f-63f1eb72beb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-563b8129-e6ca-44dc-b927-94d8752350c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-962db096-c700-4193-9982-dd1b2bf38283,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-26998bdb-5736-4436-990b-426837c9ecec,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-62a292fc-2de4-478a-9a8b-8ebdb023029b,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-2e2fcabc-9054-4c77-8693-02e107097592,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-bfcb8d6f-29ee-4cea-a81f-28837e4a8213,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-40ca37ef-0b6c-4a08-a977-d970631d8a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908954340-172.17.0.5-1596008467007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40491,DS-3107a723-a7b4-47ca-8c6d-727682e9db32,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-f9e40a2f-70b2-41ba-8987-6e1c609a77f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-7ce632cd-6bfd-4195-bc57-d6ed9cb1bb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-21e98c3b-f115-4ed8-b337-6daf12de7298,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-9ba4ee3a-6eab-4e15-8fc2-e30d17abaee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-e53a6cb8-1602-452e-b46a-6e8d53f2c47c,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-87d9528a-5334-4054-a293-45a80e586218,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-7b8008a6-157b-4106-8d95-6a326cdf9d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908954340-172.17.0.5-1596008467007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40491,DS-3107a723-a7b4-47ca-8c6d-727682e9db32,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-f9e40a2f-70b2-41ba-8987-6e1c609a77f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-7ce632cd-6bfd-4195-bc57-d6ed9cb1bb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-21e98c3b-f115-4ed8-b337-6daf12de7298,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-9ba4ee3a-6eab-4e15-8fc2-e30d17abaee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-e53a6cb8-1602-452e-b46a-6e8d53f2c47c,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-87d9528a-5334-4054-a293-45a80e586218,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-7b8008a6-157b-4106-8d95-6a326cdf9d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517715230-172.17.0.5-1596008753052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41680,DS-ec978df0-5194-42a6-8040-6026eafd6e00,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-29627eb5-76be-4c81-a831-80d9dc63451c,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-873fa30a-237f-465d-b8dc-189b93b9158a,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-fcd738c6-6881-4603-883a-e8a3672dbece,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-fe4f16c1-44bc-491b-924a-09db417ac2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-1408a785-f0c2-469d-9bee-e18ddb423b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-18f59a81-b125-4edf-b8da-65b1bf7dc315,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-3492d5da-d715-4dff-a642-6edbc059eb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517715230-172.17.0.5-1596008753052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41680,DS-ec978df0-5194-42a6-8040-6026eafd6e00,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-29627eb5-76be-4c81-a831-80d9dc63451c,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-873fa30a-237f-465d-b8dc-189b93b9158a,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-fcd738c6-6881-4603-883a-e8a3672dbece,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-fe4f16c1-44bc-491b-924a-09db417ac2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-1408a785-f0c2-469d-9bee-e18ddb423b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-18f59a81-b125-4edf-b8da-65b1bf7dc315,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-3492d5da-d715-4dff-a642-6edbc059eb94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036745962-172.17.0.5-1596008915357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46567,DS-f71d7717-e2f2-4ee8-9d24-4df9a132e35f,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-e2b7b323-2bfc-47de-83a2-fd8f08ef6df5,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-aa35f36c-3db2-4668-83bc-3efff3050bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-3d00850c-b8f3-48e4-88c0-2c1488d06651,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-ce61ed2c-9aed-40d7-8e2e-e59d754acc91,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-0bba3825-7441-4fe7-966e-dec71825a7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-b0123cc7-8f45-4c0b-b4f1-10d6c98fb07e,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-3184a076-dad5-49ee-9009-642e2f4ab517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036745962-172.17.0.5-1596008915357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46567,DS-f71d7717-e2f2-4ee8-9d24-4df9a132e35f,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-e2b7b323-2bfc-47de-83a2-fd8f08ef6df5,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-aa35f36c-3db2-4668-83bc-3efff3050bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-3d00850c-b8f3-48e4-88c0-2c1488d06651,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-ce61ed2c-9aed-40d7-8e2e-e59d754acc91,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-0bba3825-7441-4fe7-966e-dec71825a7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-b0123cc7-8f45-4c0b-b4f1-10d6c98fb07e,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-3184a076-dad5-49ee-9009-642e2f4ab517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780478914-172.17.0.5-1596009349897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-66436636-84a0-4ac4-b619-16717316046e,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-a90536da-55f0-4c57-81ae-15549914e426,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-1fd6aeb2-f1b3-4ea5-b498-0f89df33d4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-c5471df1-eb6c-4b94-bf01-9a986d71fee2,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-317d0407-916b-4156-a0c4-ab2b3b12e737,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-35a8ae7c-ac5b-4384-9826-20c47bed7445,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-44413efb-7731-420c-a373-9ffd799b5e89,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-f61472a6-6ace-4dd5-9346-50654fad9956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780478914-172.17.0.5-1596009349897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-66436636-84a0-4ac4-b619-16717316046e,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-a90536da-55f0-4c57-81ae-15549914e426,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-1fd6aeb2-f1b3-4ea5-b498-0f89df33d4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-c5471df1-eb6c-4b94-bf01-9a986d71fee2,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-317d0407-916b-4156-a0c4-ab2b3b12e737,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-35a8ae7c-ac5b-4384-9826-20c47bed7445,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-44413efb-7731-420c-a373-9ffd799b5e89,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-f61472a6-6ace-4dd5-9346-50654fad9956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054041457-172.17.0.5-1596009424840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39182,DS-7b80a657-8971-4c06-a786-a47a6c222a86,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-fd25bc1d-39fe-478b-9636-2c1a9d72e293,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-ae5d6dc9-b040-4e4c-9b84-1d61af0a6ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-31182ee2-2af7-418d-a5a7-cee5386324c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-b869e41b-1d82-41df-a7ff-edbd0311cc09,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-ce8a4353-8556-4bd3-a11f-c47a5207106e,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-629ce06b-87a1-4e19-ad26-1404e9abb4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-6a5dbac4-4452-4302-91d4-32212f5a3287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054041457-172.17.0.5-1596009424840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39182,DS-7b80a657-8971-4c06-a786-a47a6c222a86,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-fd25bc1d-39fe-478b-9636-2c1a9d72e293,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-ae5d6dc9-b040-4e4c-9b84-1d61af0a6ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-31182ee2-2af7-418d-a5a7-cee5386324c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-b869e41b-1d82-41df-a7ff-edbd0311cc09,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-ce8a4353-8556-4bd3-a11f-c47a5207106e,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-629ce06b-87a1-4e19-ad26-1404e9abb4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-6a5dbac4-4452-4302-91d4-32212f5a3287,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135662250-172.17.0.5-1596009598730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45161,DS-ccb00be1-8066-4406-86a5-8882cd23207e,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-375347be-9254-43a3-a34a-e3aa01579f92,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-31b2d5f3-89a0-438b-8761-d2c019d09c40,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-1e7aaa70-dda1-41ab-bc62-cbcdbdfe481f,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-4c9beaa7-f3ea-4527-9df9-864c7c328082,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-6790422e-b0f4-42b1-8f9b-fbcfcca886bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-1a703be3-76e5-4d08-9c68-c80f2ed96d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-e920c421-0227-427b-a7b4-7778f1057e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135662250-172.17.0.5-1596009598730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45161,DS-ccb00be1-8066-4406-86a5-8882cd23207e,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-375347be-9254-43a3-a34a-e3aa01579f92,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-31b2d5f3-89a0-438b-8761-d2c019d09c40,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-1e7aaa70-dda1-41ab-bc62-cbcdbdfe481f,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-4c9beaa7-f3ea-4527-9df9-864c7c328082,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-6790422e-b0f4-42b1-8f9b-fbcfcca886bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-1a703be3-76e5-4d08-9c68-c80f2ed96d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-e920c421-0227-427b-a7b4-7778f1057e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795518831-172.17.0.5-1596009739643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42617,DS-13710452-23ce-48c6-bf61-716b5d34dd07,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-25ea8ceb-8355-4083-a37c-01bfbf88be9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-34aa1493-631f-4f9e-800a-69b8454bc351,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-257cf4a8-3cfc-4272-9527-2619a2462045,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-e70ed9db-f8c7-44b2-928b-6d352ed4e23e,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-487681fd-81ec-4186-bab4-06fda0ec2bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-94ff43ef-3590-42fe-9f68-2be9b5c98c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-c9a574f0-a318-4773-8d8e-14778d611241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795518831-172.17.0.5-1596009739643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42617,DS-13710452-23ce-48c6-bf61-716b5d34dd07,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-25ea8ceb-8355-4083-a37c-01bfbf88be9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-34aa1493-631f-4f9e-800a-69b8454bc351,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-257cf4a8-3cfc-4272-9527-2619a2462045,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-e70ed9db-f8c7-44b2-928b-6d352ed4e23e,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-487681fd-81ec-4186-bab4-06fda0ec2bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-94ff43ef-3590-42fe-9f68-2be9b5c98c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-c9a574f0-a318-4773-8d8e-14778d611241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-621133308-172.17.0.5-1596009950691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40852,DS-a64c5dcb-84b1-4f10-a813-476483c63cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-602e5c24-93d0-442d-a96f-8a820e9b5da6,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-c3a259cc-6bcb-4b70-a7fa-9b05a6fbfdba,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-7e231cf2-c985-49f8-afdf-a84d6d68f6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-010377d4-5050-4356-8fe2-41aab8755ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-00af4016-4659-4505-a16e-68fd2bd1221e,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-8b66ff7c-25d4-4a2a-a64c-499fdbf9aebd,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-0cd75c55-9bdc-4609-a519-2b23be05cd84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-621133308-172.17.0.5-1596009950691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40852,DS-a64c5dcb-84b1-4f10-a813-476483c63cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-602e5c24-93d0-442d-a96f-8a820e9b5da6,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-c3a259cc-6bcb-4b70-a7fa-9b05a6fbfdba,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-7e231cf2-c985-49f8-afdf-a84d6d68f6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-010377d4-5050-4356-8fe2-41aab8755ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-00af4016-4659-4505-a16e-68fd2bd1221e,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-8b66ff7c-25d4-4a2a-a64c-499fdbf9aebd,DISK], DatanodeInfoWithStorage[127.0.0.1:38165,DS-0cd75c55-9bdc-4609-a519-2b23be05cd84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112010040-172.17.0.5-1596010196340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40462,DS-c1bb849e-4d92-48b7-a0ec-7ac29541ff95,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-c9c95b9d-8220-43e7-a19f-a9680d787751,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-b14d898d-656c-4b96-877f-fa12a2cb7cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-c48918c4-bf43-453e-8a8e-5aea17af5db8,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-3c3155f3-b776-40b1-a3fa-5327bccd4c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-39c18f0b-67eb-480b-8268-2f5f9565521e,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-fb8419ca-91f3-402a-897e-c19b0798aa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-fe4543c8-38a3-4966-b1dd-c882e6904d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112010040-172.17.0.5-1596010196340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40462,DS-c1bb849e-4d92-48b7-a0ec-7ac29541ff95,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-c9c95b9d-8220-43e7-a19f-a9680d787751,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-b14d898d-656c-4b96-877f-fa12a2cb7cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-c48918c4-bf43-453e-8a8e-5aea17af5db8,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-3c3155f3-b776-40b1-a3fa-5327bccd4c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-39c18f0b-67eb-480b-8268-2f5f9565521e,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-fb8419ca-91f3-402a-897e-c19b0798aa1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-fe4543c8-38a3-4966-b1dd-c882e6904d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003880551-172.17.0.5-1596010272054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40033,DS-a3b49855-ea0e-4f53-91eb-1aa6a7543403,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-89614877-0de8-4570-8063-9f4fce7becb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-f0625927-0149-4c6d-bb2c-a2130806f529,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-9a3aee5b-acf7-49c4-9d10-2865d8c27e60,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-5db4b5e1-62fe-4b8a-b2e3-0f515f6c1045,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-3556283b-5b39-4a07-bb5a-06084769c0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-a71390c5-09f2-4a4a-af0d-891476ab365e,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-6740109e-9350-4c5a-a100-cc42de72409e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003880551-172.17.0.5-1596010272054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40033,DS-a3b49855-ea0e-4f53-91eb-1aa6a7543403,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-89614877-0de8-4570-8063-9f4fce7becb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-f0625927-0149-4c6d-bb2c-a2130806f529,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-9a3aee5b-acf7-49c4-9d10-2865d8c27e60,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-5db4b5e1-62fe-4b8a-b2e3-0f515f6c1045,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-3556283b-5b39-4a07-bb5a-06084769c0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-a71390c5-09f2-4a4a-af0d-891476ab365e,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-6740109e-9350-4c5a-a100-cc42de72409e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 216000s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924136756-172.17.0.5-1596010376412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41007,DS-3ce40124-2afd-4261-b7c6-ca584b7ad01e,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-e46a2f59-dcaf-4707-80eb-d44586044c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-3ad53d8e-3d20-4134-aa7a-a16072ada2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-f9bb95bb-bb0e-4ce9-bf08-01df33882685,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-8ff0814e-4b2c-4da8-ab22-4609848629ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-505678c7-e620-425d-847e-7b7685ee3020,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-a36f9863-e31a-4af9-a16a-5c4f5f93e1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-ad331c5d-2de1-465c-8b96-0696ba756b6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924136756-172.17.0.5-1596010376412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41007,DS-3ce40124-2afd-4261-b7c6-ca584b7ad01e,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-e46a2f59-dcaf-4707-80eb-d44586044c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-3ad53d8e-3d20-4134-aa7a-a16072ada2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-f9bb95bb-bb0e-4ce9-bf08-01df33882685,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-8ff0814e-4b2c-4da8-ab22-4609848629ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-505678c7-e620-425d-847e-7b7685ee3020,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-a36f9863-e31a-4af9-a16a-5c4f5f93e1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-ad331c5d-2de1-465c-8b96-0696ba756b6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5027
