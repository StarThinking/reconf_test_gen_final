reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283497754-172.17.0.5-1596056233869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41296,DS-9e6e594f-dc52-48b1-9398-236d549d58ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-5c6d07be-34b2-49db-9bc3-6feca7140228,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-2027c457-0855-4ac8-a25e-dd75d0ba5c07,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-805a1fca-57dc-4328-a2a1-f165c96882a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-62cf167b-36d5-43f2-9d30-6208fa507c90,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-f28467de-6f58-411c-92ee-0b95ee7dca07,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-27f69c30-7816-4e02-ad5b-3cc3a13532c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-50b6d445-28c5-4a7e-8703-cbb9e4c34ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283497754-172.17.0.5-1596056233869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41296,DS-9e6e594f-dc52-48b1-9398-236d549d58ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-5c6d07be-34b2-49db-9bc3-6feca7140228,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-2027c457-0855-4ac8-a25e-dd75d0ba5c07,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-805a1fca-57dc-4328-a2a1-f165c96882a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-62cf167b-36d5-43f2-9d30-6208fa507c90,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-f28467de-6f58-411c-92ee-0b95ee7dca07,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-27f69c30-7816-4e02-ad5b-3cc3a13532c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-50b6d445-28c5-4a7e-8703-cbb9e4c34ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110043546-172.17.0.5-1596056274425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33372,DS-ac3b4a07-8c77-42bc-a979-042f0def8f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-165a7458-3e23-418f-9ab7-737d4f943b02,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-b3d68284-843c-4f69-9c51-2e452f2058fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-771489e0-128d-42cd-b80f-7e8eeb7efd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-10b8bf34-9a16-4549-99fc-942794565204,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-e7bcd67b-243d-4cb0-84a2-cccb1338e55d,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-93582e21-a213-49c6-b5e5-727245bf1943,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-56537204-8d2a-4248-9734-ea3cc6a26c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2110043546-172.17.0.5-1596056274425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33372,DS-ac3b4a07-8c77-42bc-a979-042f0def8f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-165a7458-3e23-418f-9ab7-737d4f943b02,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-b3d68284-843c-4f69-9c51-2e452f2058fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-771489e0-128d-42cd-b80f-7e8eeb7efd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-10b8bf34-9a16-4549-99fc-942794565204,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-e7bcd67b-243d-4cb0-84a2-cccb1338e55d,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-93582e21-a213-49c6-b5e5-727245bf1943,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-56537204-8d2a-4248-9734-ea3cc6a26c07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238530980-172.17.0.5-1596056521213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-152ecb20-65af-4506-8485-00ef87827c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-49f16067-885a-4610-ab18-e0d567a8db36,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-0b84721a-a67a-43b8-8501-281c4a084903,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-575f7f92-4de5-49aa-ab9f-bfc49c1fd665,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-115e5cb8-d8f5-408d-ab32-600eb0f257e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-f74c6975-d493-4be1-884a-109837ae26c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-d1f2ca93-04b6-4165-8685-283926c1872c,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-78f264d8-10a4-4fce-9f2b-f0d8c5fe5ae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238530980-172.17.0.5-1596056521213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37709,DS-152ecb20-65af-4506-8485-00ef87827c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40474,DS-49f16067-885a-4610-ab18-e0d567a8db36,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-0b84721a-a67a-43b8-8501-281c4a084903,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-575f7f92-4de5-49aa-ab9f-bfc49c1fd665,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-115e5cb8-d8f5-408d-ab32-600eb0f257e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-f74c6975-d493-4be1-884a-109837ae26c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-d1f2ca93-04b6-4165-8685-283926c1872c,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-78f264d8-10a4-4fce-9f2b-f0d8c5fe5ae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802543133-172.17.0.5-1596056707305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41995,DS-1058b6d5-2dd7-4594-8a69-24b5499edb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-25220ce8-1ba4-4bba-9cdc-01744cfc4a80,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-699f4532-fbb6-4eea-aa6d-f04a84c72e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-e177668a-f6b6-4087-b43d-72d121737761,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-b70011c0-6aba-4110-9ea2-e56528397810,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-20ca9986-f69f-4276-8588-338dbdb159e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-95a9b422-f43b-48f2-9b3a-5a9583d3e189,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-97bb9508-aa85-4a65-90a6-79a5a00a1203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802543133-172.17.0.5-1596056707305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41995,DS-1058b6d5-2dd7-4594-8a69-24b5499edb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-25220ce8-1ba4-4bba-9cdc-01744cfc4a80,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-699f4532-fbb6-4eea-aa6d-f04a84c72e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-e177668a-f6b6-4087-b43d-72d121737761,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-b70011c0-6aba-4110-9ea2-e56528397810,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-20ca9986-f69f-4276-8588-338dbdb159e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-95a9b422-f43b-48f2-9b3a-5a9583d3e189,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-97bb9508-aa85-4a65-90a6-79a5a00a1203,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220510639-172.17.0.5-1596057111720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34190,DS-db3a832e-ace6-4e24-9677-fb26266e6a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-cf434409-d1ac-465b-bb0c-ebbd36fc90e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-22b5ceb0-965b-4535-aa16-588aeb4d7979,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-c4225ea3-ddfb-448f-a0b8-25d0c955fee3,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-b9f6c3c4-b37a-425c-acdc-b98dc99679cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-4cf98e04-2845-4c19-83b7-4018662ad4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-b3e0ff34-09ba-4cb7-84c1-4e3273f521da,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-4f382f29-9b16-4761-84a9-c318367f9d6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220510639-172.17.0.5-1596057111720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34190,DS-db3a832e-ace6-4e24-9677-fb26266e6a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-cf434409-d1ac-465b-bb0c-ebbd36fc90e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-22b5ceb0-965b-4535-aa16-588aeb4d7979,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-c4225ea3-ddfb-448f-a0b8-25d0c955fee3,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-b9f6c3c4-b37a-425c-acdc-b98dc99679cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-4cf98e04-2845-4c19-83b7-4018662ad4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-b3e0ff34-09ba-4cb7-84c1-4e3273f521da,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-4f382f29-9b16-4761-84a9-c318367f9d6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754512907-172.17.0.5-1596057260031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44317,DS-36809ac3-a442-4cfe-8292-6abd528ae0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-ced016ee-112a-412d-9980-76c50134d87a,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-d53b85f9-b4af-4c0f-8c72-b5946c1e9865,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-dcdade0a-e7d6-4a77-af75-3737ea5525df,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-85af61d6-6483-4549-b259-05ceef60fefc,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-38a66b6a-27b9-4975-9392-376871d9ede7,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-1a16b430-4f90-4539-9304-b4a391006ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-7fa421ef-5344-48a2-a5cd-dd9f69d8eb20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754512907-172.17.0.5-1596057260031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44317,DS-36809ac3-a442-4cfe-8292-6abd528ae0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-ced016ee-112a-412d-9980-76c50134d87a,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-d53b85f9-b4af-4c0f-8c72-b5946c1e9865,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-dcdade0a-e7d6-4a77-af75-3737ea5525df,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-85af61d6-6483-4549-b259-05ceef60fefc,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-38a66b6a-27b9-4975-9392-376871d9ede7,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-1a16b430-4f90-4539-9304-b4a391006ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-7fa421ef-5344-48a2-a5cd-dd9f69d8eb20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074638823-172.17.0.5-1596057505197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-9ab0917b-e7a1-4993-bc0a-658abaf165e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-0e74259d-828b-453c-817a-f8469baedf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-d1950f5d-a942-4f74-831c-f60988de094a,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-68c5d396-71f0-4a4d-9cd3-bcd97d04b863,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-06e41653-ad27-4fc6-a1f5-d354e9181f66,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-34a3f887-fc75-4e29-ace8-913dd168a5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-5cae1f85-0ae7-4127-b0c0-1499dc3fc0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-7da17318-561a-4cc3-97c6-e68bc8afeaff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074638823-172.17.0.5-1596057505197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-9ab0917b-e7a1-4993-bc0a-658abaf165e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-0e74259d-828b-453c-817a-f8469baedf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-d1950f5d-a942-4f74-831c-f60988de094a,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-68c5d396-71f0-4a4d-9cd3-bcd97d04b863,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-06e41653-ad27-4fc6-a1f5-d354e9181f66,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-34a3f887-fc75-4e29-ace8-913dd168a5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-5cae1f85-0ae7-4127-b0c0-1499dc3fc0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-7da17318-561a-4cc3-97c6-e68bc8afeaff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474874658-172.17.0.5-1596057599466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42881,DS-969df182-f6d5-4516-8c25-c495e8a0bae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-e196efba-83c5-442c-818e-d073cde46880,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-bb853ef1-4a37-4ed2-a711-40874e892a35,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-51bdeeb4-f13c-4ce1-969d-a83dd409e72b,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-f80914ec-b238-4ead-b1a4-463a16c235d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-aecf7023-97ab-4e26-a724-a844faf99dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-bdd98431-8698-4517-b46e-e85b8b6f2e81,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-37e02ad4-e314-4544-9469-cb8e0c156b21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1474874658-172.17.0.5-1596057599466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42881,DS-969df182-f6d5-4516-8c25-c495e8a0bae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-e196efba-83c5-442c-818e-d073cde46880,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-bb853ef1-4a37-4ed2-a711-40874e892a35,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-51bdeeb4-f13c-4ce1-969d-a83dd409e72b,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-f80914ec-b238-4ead-b1a4-463a16c235d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-aecf7023-97ab-4e26-a724-a844faf99dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-bdd98431-8698-4517-b46e-e85b8b6f2e81,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-37e02ad4-e314-4544-9469-cb8e0c156b21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993493447-172.17.0.5-1596057829041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36809,DS-d539cf3d-32f6-46ea-8cb4-a149af1763af,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-17cc76b2-31d8-4266-8d32-e752fcaf2d41,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-5d2c12ee-7d8e-483f-93af-5d67b69fad64,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-ca3d4a3f-5db3-4043-a8d5-6b63dee083ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-3ce4933f-caf2-43f4-b509-e774c84df2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-f1447a07-608d-431a-98be-c781bce8a71a,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-5c0ca7fb-f62e-4a0d-ab85-9b3c65033f25,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-df0546ec-d200-4035-8555-af8a841cf635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1993493447-172.17.0.5-1596057829041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36809,DS-d539cf3d-32f6-46ea-8cb4-a149af1763af,DISK], DatanodeInfoWithStorage[127.0.0.1:40423,DS-17cc76b2-31d8-4266-8d32-e752fcaf2d41,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-5d2c12ee-7d8e-483f-93af-5d67b69fad64,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-ca3d4a3f-5db3-4043-a8d5-6b63dee083ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-3ce4933f-caf2-43f4-b509-e774c84df2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-f1447a07-608d-431a-98be-c781bce8a71a,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-5c0ca7fb-f62e-4a0d-ab85-9b3c65033f25,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-df0546ec-d200-4035-8555-af8a841cf635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722311580-172.17.0.5-1596057935381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46080,DS-f9402438-3e2d-43f4-9421-07e8184e70fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-57d03a8a-ae3a-4c99-bef7-af3033c60b22,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-2c389c4c-5f8f-4492-9168-ff43e3a80a62,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-9ec54ef2-829a-4799-8a2a-57be33f9c244,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-89075eb9-c0e5-4cca-96be-0960800d3357,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-9e1b4735-cfe2-47f3-8265-b2de2689df79,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-b01e768e-dfc8-4882-9bd8-c35b06f56395,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-780e7ec1-cfd1-4dbd-a413-80b82e2bfc0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722311580-172.17.0.5-1596057935381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46080,DS-f9402438-3e2d-43f4-9421-07e8184e70fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-57d03a8a-ae3a-4c99-bef7-af3033c60b22,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-2c389c4c-5f8f-4492-9168-ff43e3a80a62,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-9ec54ef2-829a-4799-8a2a-57be33f9c244,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-89075eb9-c0e5-4cca-96be-0960800d3357,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-9e1b4735-cfe2-47f3-8265-b2de2689df79,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-b01e768e-dfc8-4882-9bd8-c35b06f56395,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-780e7ec1-cfd1-4dbd-a413-80b82e2bfc0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809548947-172.17.0.5-1596058168357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36689,DS-d64d061d-6c6c-4546-9e2c-a9fe5a036e65,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-d5484601-6655-4df5-a48c-0305181a2e62,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-1b0b4dd0-0fdd-4f79-98a7-3ffd9bf981da,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-a72dd98b-c628-467c-876f-35f35efd2166,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-d1e89c71-0065-4183-b240-d0291eda9023,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-4cbe8f93-6380-4586-8aed-e88682b5da90,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-9417257f-8ca1-49bd-8e40-5e843b10cfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-bdefe8b7-f3d3-42c3-9622-403e578eb59d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809548947-172.17.0.5-1596058168357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36689,DS-d64d061d-6c6c-4546-9e2c-a9fe5a036e65,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-d5484601-6655-4df5-a48c-0305181a2e62,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-1b0b4dd0-0fdd-4f79-98a7-3ffd9bf981da,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-a72dd98b-c628-467c-876f-35f35efd2166,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-d1e89c71-0065-4183-b240-d0291eda9023,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-4cbe8f93-6380-4586-8aed-e88682b5da90,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-9417257f-8ca1-49bd-8e40-5e843b10cfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-bdefe8b7-f3d3-42c3-9622-403e578eb59d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774616383-172.17.0.5-1596058686413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39620,DS-c14745b7-9d73-4f21-9821-afdce4c150dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-9c0c3502-3b46-433f-bef4-7afed7d569b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-b8b0de7f-d299-438b-8df5-3ad21b12aa69,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-5f804686-3190-4d27-a989-0fe141cb51fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-f181037d-03bd-4efc-b911-a34e894179d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-a8749e86-d9ac-41a3-b059-6ad474d0c55e,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-df3795ee-42c5-43cb-b1c0-e160c292bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-6384314b-fdef-4246-807d-9f168658bf2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774616383-172.17.0.5-1596058686413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39620,DS-c14745b7-9d73-4f21-9821-afdce4c150dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-9c0c3502-3b46-433f-bef4-7afed7d569b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-b8b0de7f-d299-438b-8df5-3ad21b12aa69,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-5f804686-3190-4d27-a989-0fe141cb51fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-f181037d-03bd-4efc-b911-a34e894179d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-a8749e86-d9ac-41a3-b059-6ad474d0c55e,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-df3795ee-42c5-43cb-b1c0-e160c292bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-6384314b-fdef-4246-807d-9f168658bf2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-390109729-172.17.0.5-1596058885071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33206,DS-ea933442-eb0d-461f-8b47-69666e62b3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-bc5c4668-4098-4cae-8614-241ff6ec260f,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-92fdf235-311c-4fb1-9162-c527c18d90d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-37af7db0-e8c5-4292-b876-c41b6eaddfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-d04f842b-9277-4f50-85ed-72c86d665e27,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-439dc248-cb5b-462f-ac4c-93ecba8e8a60,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-c7cc1fba-04b0-4bfe-9e05-0533cb00a4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-03e1974f-eedb-4e43-be56-1be0faadaac0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-390109729-172.17.0.5-1596058885071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33206,DS-ea933442-eb0d-461f-8b47-69666e62b3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-bc5c4668-4098-4cae-8614-241ff6ec260f,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-92fdf235-311c-4fb1-9162-c527c18d90d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-37af7db0-e8c5-4292-b876-c41b6eaddfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-d04f842b-9277-4f50-85ed-72c86d665e27,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-439dc248-cb5b-462f-ac4c-93ecba8e8a60,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-c7cc1fba-04b0-4bfe-9e05-0533cb00a4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-03e1974f-eedb-4e43-be56-1be0faadaac0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1233126071-172.17.0.5-1596059074683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46525,DS-2e5c9d5c-5bee-4708-a83e-cd38b8edeca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-5584de54-8c25-44e7-a575-91e685452dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-1abf490b-222e-4da0-b2e0-e8584fa7b2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-13d288d3-20b0-41fc-a6d6-03f2207ff61b,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-5992d71a-8f09-462a-9136-0af670ae8a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-da9b4664-2616-445e-9a6a-a7343878c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-f42adcf8-5e0d-481c-b591-2a04e46203f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-98ae0983-6ea0-45c7-bdf2-1a7783869687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1233126071-172.17.0.5-1596059074683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46525,DS-2e5c9d5c-5bee-4708-a83e-cd38b8edeca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-5584de54-8c25-44e7-a575-91e685452dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-1abf490b-222e-4da0-b2e0-e8584fa7b2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-13d288d3-20b0-41fc-a6d6-03f2207ff61b,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-5992d71a-8f09-462a-9136-0af670ae8a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-da9b4664-2616-445e-9a6a-a7343878c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-f42adcf8-5e0d-481c-b591-2a04e46203f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-98ae0983-6ea0-45c7-bdf2-1a7783869687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438047934-172.17.0.5-1596059316873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43586,DS-0dc83524-56f0-4a66-8bca-7bb545d1059a,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-6fb5ea55-855a-4e92-8bcc-f99f8ad1e190,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-6c4e4af4-24bb-470e-9095-9a78f4b3487b,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-32462023-9b38-4a0e-b3a5-bedfedd81265,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-77711b64-9a47-4bb2-9ece-5464c899e751,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-e5ec3625-8164-45d9-8e01-8b09fc684cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-3f94deaf-04db-4d4a-bac4-07fcc5b88472,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-635be886-20d0-4376-ab02-8aff1c4c8684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438047934-172.17.0.5-1596059316873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43586,DS-0dc83524-56f0-4a66-8bca-7bb545d1059a,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-6fb5ea55-855a-4e92-8bcc-f99f8ad1e190,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-6c4e4af4-24bb-470e-9095-9a78f4b3487b,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-32462023-9b38-4a0e-b3a5-bedfedd81265,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-77711b64-9a47-4bb2-9ece-5464c899e751,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-e5ec3625-8164-45d9-8e01-8b09fc684cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-3f94deaf-04db-4d4a-bac4-07fcc5b88472,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-635be886-20d0-4376-ab02-8aff1c4c8684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640440174-172.17.0.5-1596059501515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35120,DS-df118571-1f1c-45de-ac4e-96921d83a63a,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-2afad923-51ce-48f8-aee4-0cdc0e80257e,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-a28557e9-1b49-4e47-be94-7effcc359606,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-f6643a4f-93f9-4f08-9817-3a84260db5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-fa479999-097d-4154-9895-993147c5b7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-b3a46740-da08-4081-b66a-ab61b1c0a113,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-e9efa288-b758-4692-85dc-dd866cf9d506,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-b86fbe44-038b-472a-a867-ea98f8818d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640440174-172.17.0.5-1596059501515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35120,DS-df118571-1f1c-45de-ac4e-96921d83a63a,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-2afad923-51ce-48f8-aee4-0cdc0e80257e,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-a28557e9-1b49-4e47-be94-7effcc359606,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-f6643a4f-93f9-4f08-9817-3a84260db5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-fa479999-097d-4154-9895-993147c5b7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37352,DS-b3a46740-da08-4081-b66a-ab61b1c0a113,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-e9efa288-b758-4692-85dc-dd866cf9d506,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-b86fbe44-038b-472a-a867-ea98f8818d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760273497-172.17.0.5-1596059644362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46001,DS-fd3ba61e-cb2a-4725-939d-95102f73beff,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-d753ebb9-d62b-4eec-ba63-08880dddd061,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-d6eda3dc-54e4-4b8a-8c20-2710b67fdf06,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-9c4f9e88-9f27-4be9-b108-3a8f592e2f87,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-d38549ea-04bf-488e-9179-2b87f35e2765,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-990d279a-c5be-40dd-9484-1bb25c3f7434,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-fbab96e1-a70a-43eb-b6c0-ce0cc77927e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-274a6faa-3caf-4826-a232-6354cc92b011,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760273497-172.17.0.5-1596059644362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46001,DS-fd3ba61e-cb2a-4725-939d-95102f73beff,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-d753ebb9-d62b-4eec-ba63-08880dddd061,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-d6eda3dc-54e4-4b8a-8c20-2710b67fdf06,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-9c4f9e88-9f27-4be9-b108-3a8f592e2f87,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-d38549ea-04bf-488e-9179-2b87f35e2765,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-990d279a-c5be-40dd-9484-1bb25c3f7434,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-fbab96e1-a70a-43eb-b6c0-ce0cc77927e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-274a6faa-3caf-4826-a232-6354cc92b011,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067096887-172.17.0.5-1596060467916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44173,DS-145a1e86-6fb3-4863-9c58-def7ed5348ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-b3556987-3dae-4aa8-abc9-107d48e5c745,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-568da430-384a-4c40-8c00-120907cfc2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-ebd358f4-5b47-49e5-b3ef-9b15135c0d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-6bb08941-4918-4f5c-9397-e9eb67b4fb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-a8d5cbb4-abf1-419c-b09d-daf675e08bff,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-22e2abcd-05d8-4f58-8be8-f0d581b4ecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-d50ff6fb-3f98-4225-8655-15cc7cc7188e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067096887-172.17.0.5-1596060467916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44173,DS-145a1e86-6fb3-4863-9c58-def7ed5348ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-b3556987-3dae-4aa8-abc9-107d48e5c745,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-568da430-384a-4c40-8c00-120907cfc2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-ebd358f4-5b47-49e5-b3ef-9b15135c0d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-6bb08941-4918-4f5c-9397-e9eb67b4fb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-a8d5cbb4-abf1-419c-b09d-daf675e08bff,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-22e2abcd-05d8-4f58-8be8-f0d581b4ecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-d50ff6fb-3f98-4225-8655-15cc7cc7188e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391341791-172.17.0.5-1596061513510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-80c82b0b-8738-4b78-845d-1ba0eb0aad6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-8182e3bd-f100-49ec-bae8-7557cc7f6e31,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-ba14f905-2738-4af2-a53c-d7f71b6d7a38,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-d7a5ced8-5ecc-485a-bd99-6f77e578533e,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-39dd3466-d4a1-4986-a42e-5d508ac3a9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-f36ad904-b5a3-4468-959d-b633ec0c9d09,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-ae45c897-a421-4b5b-9320-851d8e7eadea,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-8ae4b14f-b28e-4574-9837-aa5175862f8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391341791-172.17.0.5-1596061513510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-80c82b0b-8738-4b78-845d-1ba0eb0aad6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-8182e3bd-f100-49ec-bae8-7557cc7f6e31,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-ba14f905-2738-4af2-a53c-d7f71b6d7a38,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-d7a5ced8-5ecc-485a-bd99-6f77e578533e,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-39dd3466-d4a1-4986-a42e-5d508ac3a9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-f36ad904-b5a3-4468-959d-b633ec0c9d09,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-ae45c897-a421-4b5b-9320-851d8e7eadea,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-8ae4b14f-b28e-4574-9837-aa5175862f8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:NameNode
v1: 10
v2: 480000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245813475-172.17.0.5-1596062581894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34508,DS-3b9718b5-c06b-4b64-81b5-404788942e75,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-74c7703f-9ef4-469d-92c7-58bc3a77ae7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-ea56a648-2f95-4536-a5ad-389f37bbafb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-902c6c65-7eb9-4af5-8c03-baa5a871dc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-e2a34461-cfd5-4b22-86d9-2429e4c48e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-1d76595b-af33-44f0-8f0d-b3a4158d14f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-d0a18959-aba8-48ea-b45b-8c1e2910c2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-d0c971a7-14e2-4f37-b5fa-c7be68d65486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245813475-172.17.0.5-1596062581894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34508,DS-3b9718b5-c06b-4b64-81b5-404788942e75,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-74c7703f-9ef4-469d-92c7-58bc3a77ae7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-ea56a648-2f95-4536-a5ad-389f37bbafb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-902c6c65-7eb9-4af5-8c03-baa5a871dc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-e2a34461-cfd5-4b22-86d9-2429e4c48e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-1d76595b-af33-44f0-8f0d-b3a4158d14f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-d0a18959-aba8-48ea-b45b-8c1e2910c2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-d0c971a7-14e2-4f37-b5fa-c7be68d65486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6889
