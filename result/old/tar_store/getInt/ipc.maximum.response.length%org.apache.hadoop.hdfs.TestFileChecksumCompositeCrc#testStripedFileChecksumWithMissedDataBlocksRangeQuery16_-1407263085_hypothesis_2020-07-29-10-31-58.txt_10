reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2052408471-172.17.0.12-1596018797271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42246,DS-ac8000a3-d6ea-42ae-a3ae-e8500fa81e12,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-4f42487f-61b4-44dd-b2d1-5fb970d9ddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-ae3a4f79-5dee-49b2-a527-1a609ed4b0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-fdaeab80-b356-4a8b-9b49-6fcb2a067296,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-995a6700-f1b6-4c09-8986-2a232e391653,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-452e7c6f-230e-46a9-a70f-8703f4236891,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-1bd7f049-798e-4bac-8a1a-fe436150ca38,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-6dc6110c-9880-4941-925b-5d92f71b5ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2052408471-172.17.0.12-1596018797271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42246,DS-ac8000a3-d6ea-42ae-a3ae-e8500fa81e12,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-4f42487f-61b4-44dd-b2d1-5fb970d9ddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-ae3a4f79-5dee-49b2-a527-1a609ed4b0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-fdaeab80-b356-4a8b-9b49-6fcb2a067296,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-995a6700-f1b6-4c09-8986-2a232e391653,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-452e7c6f-230e-46a9-a70f-8703f4236891,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-1bd7f049-798e-4bac-8a1a-fe436150ca38,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-6dc6110c-9880-4941-925b-5d92f71b5ebf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292585419-172.17.0.12-1596019262306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41336,DS-b0ba4909-d74b-4e4f-8690-37346c9e48f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-4e2b0369-d860-42a4-b6c7-c028dc74f2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-1a2c76ec-953e-42f8-a32f-36d4936dd994,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-b110f7f4-f067-48a7-9242-95b937f57acb,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-645d26e5-231e-44d7-924e-81e4d7b1fd34,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-689d8e2b-6ec7-4f4d-b21e-c64485ddbf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-fb8aa0aa-1e50-4757-acc3-061c9e57b28b,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-6d4ddd2d-723e-4e5b-b1ef-8771677be3fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292585419-172.17.0.12-1596019262306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41336,DS-b0ba4909-d74b-4e4f-8690-37346c9e48f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-4e2b0369-d860-42a4-b6c7-c028dc74f2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-1a2c76ec-953e-42f8-a32f-36d4936dd994,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-b110f7f4-f067-48a7-9242-95b937f57acb,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-645d26e5-231e-44d7-924e-81e4d7b1fd34,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-689d8e2b-6ec7-4f4d-b21e-c64485ddbf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-fb8aa0aa-1e50-4757-acc3-061c9e57b28b,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-6d4ddd2d-723e-4e5b-b1ef-8771677be3fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264901469-172.17.0.12-1596019531239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34555,DS-8358a8ac-04fb-4250-b895-d1903881e161,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-bddf81c5-7c6a-45b3-996a-8d15f1c8a1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-19923c80-88f5-4654-887a-fe29aa00249a,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-e2d79628-eb77-44ae-b027-2a020c8c4813,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-ad1645ff-cffa-4445-bcf8-6bd03e85b42c,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-e02f2d06-29ee-45a3-8ce5-3aaa679cfb19,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-e1336506-1c91-4426-b451-0c206fe8bc88,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-b5fce16a-515b-47a1-828c-7f2babbae35e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264901469-172.17.0.12-1596019531239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34555,DS-8358a8ac-04fb-4250-b895-d1903881e161,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-bddf81c5-7c6a-45b3-996a-8d15f1c8a1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-19923c80-88f5-4654-887a-fe29aa00249a,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-e2d79628-eb77-44ae-b027-2a020c8c4813,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-ad1645ff-cffa-4445-bcf8-6bd03e85b42c,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-e02f2d06-29ee-45a3-8ce5-3aaa679cfb19,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-e1336506-1c91-4426-b451-0c206fe8bc88,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-b5fce16a-515b-47a1-828c-7f2babbae35e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560367922-172.17.0.12-1596019558824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-1f8f4d5b-63ad-4b14-b82f-33796df8c363,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-172e237e-2a34-4aa6-95d9-b40012bc41a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-239f8847-d079-4b6b-b6f5-4319d4cedc13,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-be7eb5eb-3367-4149-9adf-90760b52b6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-b1371bea-6092-4536-b1ed-dc38049334b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-ccd850be-b3e7-4362-9c39-e86b0f393b42,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-967f40cd-3df0-4591-8205-6d5d41886493,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-650d672d-e8e6-4c80-a265-409a7d5858cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560367922-172.17.0.12-1596019558824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-1f8f4d5b-63ad-4b14-b82f-33796df8c363,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-172e237e-2a34-4aa6-95d9-b40012bc41a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-239f8847-d079-4b6b-b6f5-4319d4cedc13,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-be7eb5eb-3367-4149-9adf-90760b52b6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-b1371bea-6092-4536-b1ed-dc38049334b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-ccd850be-b3e7-4362-9c39-e86b0f393b42,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-967f40cd-3df0-4591-8205-6d5d41886493,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-650d672d-e8e6-4c80-a265-409a7d5858cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367838641-172.17.0.12-1596019728189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39406,DS-3e8450c7-f032-46e3-a2c2-cb86420f7afe,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-d1833d88-2f97-4177-919f-dc36e726d783,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-54dae235-d8d1-415f-a19c-2a11907e6666,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-9c199e39-04e2-4273-8949-62111a97413a,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-5f1d3dce-18ac-4028-bdb5-bd323f73718d,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-74b94799-c9de-4759-ae8e-dfd0c0e1f56b,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-96242ebe-c3d9-42c1-bab5-1fb7fb4c094a,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-f83d30c5-e640-4f34-b591-4551579f07ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367838641-172.17.0.12-1596019728189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39406,DS-3e8450c7-f032-46e3-a2c2-cb86420f7afe,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-d1833d88-2f97-4177-919f-dc36e726d783,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-54dae235-d8d1-415f-a19c-2a11907e6666,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-9c199e39-04e2-4273-8949-62111a97413a,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-5f1d3dce-18ac-4028-bdb5-bd323f73718d,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-74b94799-c9de-4759-ae8e-dfd0c0e1f56b,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-96242ebe-c3d9-42c1-bab5-1fb7fb4c094a,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-f83d30c5-e640-4f34-b591-4551579f07ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-551873587-172.17.0.12-1596020505796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45093,DS-824d6d41-482c-47b8-9927-cb5135476cae,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-4379d0b6-da50-4e86-b584-5d807da7bfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-6a82ce58-ef7a-4659-9a75-116af93c8779,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-68858151-2f04-4d26-96c4-26a20cd572d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-d74830eb-16e9-483c-816b-55c637b4f9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-edcfd816-3365-4dc8-9613-6970f022bffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-8f87d3da-6701-4f5a-82d7-ad4b45cec03c,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-47885290-4167-4ba5-86c0-9b5619a635fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-551873587-172.17.0.12-1596020505796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45093,DS-824d6d41-482c-47b8-9927-cb5135476cae,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-4379d0b6-da50-4e86-b584-5d807da7bfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-6a82ce58-ef7a-4659-9a75-116af93c8779,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-68858151-2f04-4d26-96c4-26a20cd572d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-d74830eb-16e9-483c-816b-55c637b4f9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-edcfd816-3365-4dc8-9613-6970f022bffe,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-8f87d3da-6701-4f5a-82d7-ad4b45cec03c,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-47885290-4167-4ba5-86c0-9b5619a635fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-561876115-172.17.0.12-1596020675745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44247,DS-59a1ed9c-6fe6-449e-b697-80df0ae342d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-19b65866-139f-4404-970e-1f11d294c767,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-38f20f97-3314-41e0-9be1-4220faf94a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-e6a77cdd-9fb2-4b02-8209-067b3ca8986e,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-cc614625-35c3-4648-8380-16e2844487e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-c2555a9f-d857-4c1e-b7cd-9ad07afb30b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-05d112b8-dd54-4f18-8b29-5b8959de9a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-87989ece-543a-447d-b7d9-8e8960fba8c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-561876115-172.17.0.12-1596020675745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44247,DS-59a1ed9c-6fe6-449e-b697-80df0ae342d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-19b65866-139f-4404-970e-1f11d294c767,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-38f20f97-3314-41e0-9be1-4220faf94a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-e6a77cdd-9fb2-4b02-8209-067b3ca8986e,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-cc614625-35c3-4648-8380-16e2844487e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-c2555a9f-d857-4c1e-b7cd-9ad07afb30b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-05d112b8-dd54-4f18-8b29-5b8959de9a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-87989ece-543a-447d-b7d9-8e8960fba8c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173833374-172.17.0.12-1596021189638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37540,DS-99c34fc8-8961-4730-bd8b-04ac879b5ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-89db8dc0-d637-4e61-96d9-ba5a0108d3da,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-4809ee47-58b0-414f-9efd-ad47ca0e2ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-511b6f86-e699-4fc0-9ea9-e6a9869cb413,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-ed860389-08bc-4eea-bfb7-d3fe96b7adee,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-44cfa2b4-fde2-4078-890a-ee31033fedf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-c5e760da-7243-4aa5-a0c9-78b726815a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-1a9f638d-e431-4c09-93aa-045917100883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173833374-172.17.0.12-1596021189638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37540,DS-99c34fc8-8961-4730-bd8b-04ac879b5ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-89db8dc0-d637-4e61-96d9-ba5a0108d3da,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-4809ee47-58b0-414f-9efd-ad47ca0e2ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-511b6f86-e699-4fc0-9ea9-e6a9869cb413,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-ed860389-08bc-4eea-bfb7-d3fe96b7adee,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-44cfa2b4-fde2-4078-890a-ee31033fedf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-c5e760da-7243-4aa5-a0c9-78b726815a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-1a9f638d-e431-4c09-93aa-045917100883,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634908131-172.17.0.12-1596021398211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40200,DS-c1a67251-94d8-4e1f-8d6a-2fa9a2b7f9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-1d4846fb-e95f-4c21-b2ce-3bb07a608b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-e1e4206f-737b-432b-9f11-396ef5381ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-2ae6d724-7c60-4712-bb18-bf8ffada44fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-ac195077-0bc6-45b9-8100-c0a43e835f76,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-4d655d2e-bff7-4228-ac90-bc10403a9750,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-b4620ae7-c17a-4e0e-87d8-52b966cdee60,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-b3fea613-4637-4513-9778-602bb50faefc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634908131-172.17.0.12-1596021398211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40200,DS-c1a67251-94d8-4e1f-8d6a-2fa9a2b7f9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-1d4846fb-e95f-4c21-b2ce-3bb07a608b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-e1e4206f-737b-432b-9f11-396ef5381ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-2ae6d724-7c60-4712-bb18-bf8ffada44fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-ac195077-0bc6-45b9-8100-c0a43e835f76,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-4d655d2e-bff7-4228-ac90-bc10403a9750,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-b4620ae7-c17a-4e0e-87d8-52b966cdee60,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-b3fea613-4637-4513-9778-602bb50faefc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941728677-172.17.0.12-1596021431012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39538,DS-70cd8b3e-7255-49bd-9c31-b8ae0a77fa54,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-071284a8-aca7-4f92-a996-6efbb0ce4f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-bada7a5d-55b0-44c1-891f-1f2cc961f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-8be528d5-e094-4d10-a690-30b84f1e677d,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-b816b5de-6cfb-4838-9e36-c79ab898c98d,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-a2cca763-5573-4928-b184-ab60755872ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-1b449c63-dbcf-42f7-8d85-5b1b4cdbd495,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-379ee245-b133-4175-b79e-aa058b6ab95a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941728677-172.17.0.12-1596021431012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39538,DS-70cd8b3e-7255-49bd-9c31-b8ae0a77fa54,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-071284a8-aca7-4f92-a996-6efbb0ce4f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-bada7a5d-55b0-44c1-891f-1f2cc961f4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-8be528d5-e094-4d10-a690-30b84f1e677d,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-b816b5de-6cfb-4838-9e36-c79ab898c98d,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-a2cca763-5573-4928-b184-ab60755872ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-1b449c63-dbcf-42f7-8d85-5b1b4cdbd495,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-379ee245-b133-4175-b79e-aa058b6ab95a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539868120-172.17.0.12-1596021783435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-983db355-15e7-4b68-9ab5-496cfce3be2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-144d5fdb-2e42-403e-b1ca-95b445dac426,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-95943f11-81bd-4b3f-9545-da63d6c63a69,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-bc03c2f5-f1a3-4c60-ac5e-78521d829824,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-90efae1f-e927-4a11-a587-17ec1a576f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-d8a67388-c975-4824-9c52-156c3fe33a32,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-679fc4ea-53f5-434e-b9b9-8bfc23a8a687,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-785d03a5-0504-47ff-9677-1007d17d8b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-539868120-172.17.0.12-1596021783435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37594,DS-983db355-15e7-4b68-9ab5-496cfce3be2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-144d5fdb-2e42-403e-b1ca-95b445dac426,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-95943f11-81bd-4b3f-9545-da63d6c63a69,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-bc03c2f5-f1a3-4c60-ac5e-78521d829824,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-90efae1f-e927-4a11-a587-17ec1a576f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-d8a67388-c975-4824-9c52-156c3fe33a32,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-679fc4ea-53f5-434e-b9b9-8bfc23a8a687,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-785d03a5-0504-47ff-9677-1007d17d8b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226931081-172.17.0.12-1596023329500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41236,DS-021ecd7b-a20f-4f52-9fe3-91386ecb07d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-924f5130-3be5-43c6-bfda-e587f418766a,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-43fdf1b6-db76-45ca-95a4-402e28a5e02d,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-4e1e0e1a-afa9-439c-8ef5-8f0030cd72e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-9be93409-b76d-4d24-93e4-3a198a4254eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-c33d01ea-c176-437c-b0f6-122b97a28f31,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-3bf4b384-8740-4ca7-85c8-1cea92bbac65,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-128f6075-9a86-49e0-94f4-d2f54c31ee4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1226931081-172.17.0.12-1596023329500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41236,DS-021ecd7b-a20f-4f52-9fe3-91386ecb07d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-924f5130-3be5-43c6-bfda-e587f418766a,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-43fdf1b6-db76-45ca-95a4-402e28a5e02d,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-4e1e0e1a-afa9-439c-8ef5-8f0030cd72e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-9be93409-b76d-4d24-93e4-3a198a4254eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-c33d01ea-c176-437c-b0f6-122b97a28f31,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-3bf4b384-8740-4ca7-85c8-1cea92bbac65,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-128f6075-9a86-49e0-94f4-d2f54c31ee4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421928774-172.17.0.12-1596023508274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38013,DS-3a02bee1-e783-42e4-9428-517a7dc363bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-4eb134ea-cd9a-4f5c-ae3e-b1c47f5a74a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-d7fb082e-41b2-4973-84df-32775e230cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-d3dac316-9098-4a2d-9ca4-8e4285d202ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-e5cc2101-6cc7-4369-af08-04008a713c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-4f3f2e04-2fc7-40b1-a59f-b75a2b1fa4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-d26989b0-4732-4fe1-995a-7f554dcade97,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-2ff62b9f-a5e7-4aa6-9701-bd0fa9db61bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421928774-172.17.0.12-1596023508274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38013,DS-3a02bee1-e783-42e4-9428-517a7dc363bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-4eb134ea-cd9a-4f5c-ae3e-b1c47f5a74a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-d7fb082e-41b2-4973-84df-32775e230cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-d3dac316-9098-4a2d-9ca4-8e4285d202ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-e5cc2101-6cc7-4369-af08-04008a713c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-4f3f2e04-2fc7-40b1-a59f-b75a2b1fa4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-d26989b0-4732-4fe1-995a-7f554dcade97,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-2ff62b9f-a5e7-4aa6-9701-bd0fa9db61bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72332961-172.17.0.12-1596023605311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36112,DS-6b1f52f0-160e-441d-877b-a89cd31eb5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-54e4e705-d8a7-4ebb-b899-02bcd01e8d22,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-dc7fec0c-0b9b-429a-9b4f-e22cca46390b,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-2053f820-b0a9-452a-ae23-54491abaa67c,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-6bab376a-dff7-404f-b011-f77776565f61,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-6676d7bb-4f91-4c14-b22f-ab69fd010545,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-7a4712ed-3090-4a09-bfd3-739af70818b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-fc07f165-f4f0-43ba-aad6-6980fa6ccf75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72332961-172.17.0.12-1596023605311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36112,DS-6b1f52f0-160e-441d-877b-a89cd31eb5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-54e4e705-d8a7-4ebb-b899-02bcd01e8d22,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-dc7fec0c-0b9b-429a-9b4f-e22cca46390b,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-2053f820-b0a9-452a-ae23-54491abaa67c,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-6bab376a-dff7-404f-b011-f77776565f61,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-6676d7bb-4f91-4c14-b22f-ab69fd010545,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-7a4712ed-3090-4a09-bfd3-739af70818b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-fc07f165-f4f0-43ba-aad6-6980fa6ccf75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5079
