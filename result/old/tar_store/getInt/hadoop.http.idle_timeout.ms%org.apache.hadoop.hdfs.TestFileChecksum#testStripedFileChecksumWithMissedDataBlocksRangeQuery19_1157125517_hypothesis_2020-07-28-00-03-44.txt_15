reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537378427-172.17.0.19-1595894816922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39296,DS-4956b8e8-9af0-4a69-b98e-be7df4fc2e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-82f46a7d-2639-4109-b8bb-830c5d250ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-a5a2741a-e5e8-45e1-b558-4d0269b3c763,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-59ddbb6b-590c-4839-b59d-5af8144f31be,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-b2ae7686-8611-443f-8823-79989828af82,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-7d15bc3d-a0d8-479f-8a4e-391a1d2ad24d,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-2d7915a4-79ee-4c37-95bd-64aa42282e37,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-614b5151-ec60-4518-8d50-b08b35907c58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537378427-172.17.0.19-1595894816922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39296,DS-4956b8e8-9af0-4a69-b98e-be7df4fc2e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-82f46a7d-2639-4109-b8bb-830c5d250ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-a5a2741a-e5e8-45e1-b558-4d0269b3c763,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-59ddbb6b-590c-4839-b59d-5af8144f31be,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-b2ae7686-8611-443f-8823-79989828af82,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-7d15bc3d-a0d8-479f-8a4e-391a1d2ad24d,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-2d7915a4-79ee-4c37-95bd-64aa42282e37,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-614b5151-ec60-4518-8d50-b08b35907c58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211236402-172.17.0.19-1595894955725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41297,DS-15af3c0e-bb1a-4652-b838-f7208dff6e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-595933ee-3d93-40e2-8bb1-a6879dc28b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-6f14dd9e-b5bc-4fea-894e-3069febd4ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-1795f812-a5e4-41f8-a9f3-e0fb05a27804,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-678355d8-b0d1-4ec8-be58-ce84fc8f0f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-6a02e953-9950-44f2-a763-cba8cc07b4af,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-4546de2b-8424-457e-9fe9-6076ffcce61f,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-abdaea32-ac0b-4e00-8ab7-3baa27f68f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211236402-172.17.0.19-1595894955725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41297,DS-15af3c0e-bb1a-4652-b838-f7208dff6e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-595933ee-3d93-40e2-8bb1-a6879dc28b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-6f14dd9e-b5bc-4fea-894e-3069febd4ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-1795f812-a5e4-41f8-a9f3-e0fb05a27804,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-678355d8-b0d1-4ec8-be58-ce84fc8f0f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-6a02e953-9950-44f2-a763-cba8cc07b4af,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-4546de2b-8424-457e-9fe9-6076ffcce61f,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-abdaea32-ac0b-4e00-8ab7-3baa27f68f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-500809567-172.17.0.19-1595895638123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46300,DS-d17843f7-01d8-484a-aeb4-404718573e18,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-681ea3b3-257b-4f20-bdb2-330fd7239b12,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-71c10557-647f-47a2-98e4-c4ceba471eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-0904f6c2-7025-45e2-89bb-d0693a2a0f46,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-e36f28f2-5773-4181-841c-5fe6f4399568,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-29e579d9-6dc8-484b-9e7f-88217a5b97cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-6f0027ed-eb01-4751-b5fe-4961e6eb7fce,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-671b1ac1-4a52-4d50-bcc2-0f510fbdbe6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-500809567-172.17.0.19-1595895638123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46300,DS-d17843f7-01d8-484a-aeb4-404718573e18,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-681ea3b3-257b-4f20-bdb2-330fd7239b12,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-71c10557-647f-47a2-98e4-c4ceba471eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-0904f6c2-7025-45e2-89bb-d0693a2a0f46,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-e36f28f2-5773-4181-841c-5fe6f4399568,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-29e579d9-6dc8-484b-9e7f-88217a5b97cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-6f0027ed-eb01-4751-b5fe-4961e6eb7fce,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-671b1ac1-4a52-4d50-bcc2-0f510fbdbe6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1661337210-172.17.0.19-1595896204057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41416,DS-be8ac3e2-bb75-45f0-97cf-63c8af105e60,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-b8053882-b886-4139-a621-d3917d85901d,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-4c9814ba-0092-4cef-b557-d23bfe49e1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-58b8ab6b-cc98-4b4e-b510-ffc4df58fa62,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-9d3e90be-7ac2-456a-9330-f73e09e09a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-7b67f745-286a-43aa-940f-ef4286c63596,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-b0b85219-c226-4405-ac7f-a91ed6585a83,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-9c118bac-61e9-4b38-beca-54f2a0af5507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1661337210-172.17.0.19-1595896204057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41416,DS-be8ac3e2-bb75-45f0-97cf-63c8af105e60,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-b8053882-b886-4139-a621-d3917d85901d,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-4c9814ba-0092-4cef-b557-d23bfe49e1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-58b8ab6b-cc98-4b4e-b510-ffc4df58fa62,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-9d3e90be-7ac2-456a-9330-f73e09e09a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-7b67f745-286a-43aa-940f-ef4286c63596,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-b0b85219-c226-4405-ac7f-a91ed6585a83,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-9c118bac-61e9-4b38-beca-54f2a0af5507,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649667571-172.17.0.19-1595897193801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46627,DS-738b0a9d-696d-460c-a99c-162e899c239d,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-7b46708a-55bf-4392-b179-85fe85843da8,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-cc50b22c-9117-401a-9d1a-3d298baf9b59,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-68083133-641e-4430-8b77-a2c4caba25b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-fd34d19f-2ae5-45ae-b299-f0f5669b2086,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-5469ccc5-c6b8-4220-82e0-498675172bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-1d352fb5-7dbc-401e-a8a0-eee5102b7c74,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-4219ce9d-6651-4840-8022-1f680fac65c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649667571-172.17.0.19-1595897193801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46627,DS-738b0a9d-696d-460c-a99c-162e899c239d,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-7b46708a-55bf-4392-b179-85fe85843da8,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-cc50b22c-9117-401a-9d1a-3d298baf9b59,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-68083133-641e-4430-8b77-a2c4caba25b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-fd34d19f-2ae5-45ae-b299-f0f5669b2086,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-5469ccc5-c6b8-4220-82e0-498675172bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-1d352fb5-7dbc-401e-a8a0-eee5102b7c74,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-4219ce9d-6651-4840-8022-1f680fac65c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579328867-172.17.0.19-1595897222528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36143,DS-55a6ed18-eaef-43f4-8176-0f8bee1df664,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-db7cf40d-9c34-4567-9f65-2608452645fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-04ea1e78-5513-4689-8121-dc96ce38c3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-a2a74f76-cbbe-4fcf-b01a-3b6141b349e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-641ad7bb-b55a-4f34-b419-8e1d71a304ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-39f5da7b-fa19-4436-8c80-5baed9445d08,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-93dabfbc-18ab-4bb7-92c0-7aee7d9bfd68,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-46559418-6c4f-4d1b-8917-c469405402f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579328867-172.17.0.19-1595897222528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36143,DS-55a6ed18-eaef-43f4-8176-0f8bee1df664,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-db7cf40d-9c34-4567-9f65-2608452645fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-04ea1e78-5513-4689-8121-dc96ce38c3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33799,DS-a2a74f76-cbbe-4fcf-b01a-3b6141b349e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-641ad7bb-b55a-4f34-b419-8e1d71a304ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-39f5da7b-fa19-4436-8c80-5baed9445d08,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-93dabfbc-18ab-4bb7-92c0-7aee7d9bfd68,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-46559418-6c4f-4d1b-8917-c469405402f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2062968549-172.17.0.19-1595897286248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34776,DS-a1f9616d-0642-4593-a8c9-e40dd2ae6c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-79107f7c-9c3f-4307-b6d7-c0bcdd70b47f,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-f7386403-017f-4d40-b74f-bb27e6cd505e,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-0e299a1f-74cf-49da-b8c3-33a3947209ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-852abe74-fbee-4fce-ab3d-3b4ab7939a19,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-c00dc010-0851-4cfb-a172-0d7c2979fa07,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-b7c9de91-cc2a-4eab-aa4d-5d3d12588f93,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-3d563d5c-fd19-41c3-ae37-087aba300f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2062968549-172.17.0.19-1595897286248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34776,DS-a1f9616d-0642-4593-a8c9-e40dd2ae6c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-79107f7c-9c3f-4307-b6d7-c0bcdd70b47f,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-f7386403-017f-4d40-b74f-bb27e6cd505e,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-0e299a1f-74cf-49da-b8c3-33a3947209ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-852abe74-fbee-4fce-ab3d-3b4ab7939a19,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-c00dc010-0851-4cfb-a172-0d7c2979fa07,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-b7c9de91-cc2a-4eab-aa4d-5d3d12588f93,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-3d563d5c-fd19-41c3-ae37-087aba300f29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888956176-172.17.0.19-1595897313821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37888,DS-3e212393-e68b-42db-8c21-a7ee901102df,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-7d7defb0-0f4e-4712-b2ac-ddf000c6f70c,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-1d970882-6463-42b1-b90d-192b5a0439c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-86e99982-801e-4790-8e87-b5f6be8a8a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-c8bb12d1-be3e-4d9e-aa0d-ea299a84b2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-62a32640-b2aa-42f0-852b-11b9e6e44b95,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-4aee539a-70c2-48da-8a76-1f09709ddc44,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-a86d80fc-f418-406e-adc7-b98bf7fbc560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888956176-172.17.0.19-1595897313821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37888,DS-3e212393-e68b-42db-8c21-a7ee901102df,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-7d7defb0-0f4e-4712-b2ac-ddf000c6f70c,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-1d970882-6463-42b1-b90d-192b5a0439c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-86e99982-801e-4790-8e87-b5f6be8a8a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36197,DS-c8bb12d1-be3e-4d9e-aa0d-ea299a84b2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-62a32640-b2aa-42f0-852b-11b9e6e44b95,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-4aee539a-70c2-48da-8a76-1f09709ddc44,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-a86d80fc-f418-406e-adc7-b98bf7fbc560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1673858805-172.17.0.19-1595897352795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39239,DS-0f72e888-320e-4c01-8230-b00c9604a1be,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-2291e0fe-5b9e-4e10-a2d7-e19503f08f13,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-a2a4e652-7a45-4ee4-af66-28cd81c4a163,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-98cc101d-839b-40a9-9fe6-0e695caf827f,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-f2452561-5309-4222-a743-37812a2bead0,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-12596764-4b80-497b-89b6-1490ee1842ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-b1ba49db-9b2d-4fb2-a40a-0b5a455464f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-884f181a-1c6a-4560-98ba-61269d4b1e91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1673858805-172.17.0.19-1595897352795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39239,DS-0f72e888-320e-4c01-8230-b00c9604a1be,DISK], DatanodeInfoWithStorage[127.0.0.1:41792,DS-2291e0fe-5b9e-4e10-a2d7-e19503f08f13,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-a2a4e652-7a45-4ee4-af66-28cd81c4a163,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-98cc101d-839b-40a9-9fe6-0e695caf827f,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-f2452561-5309-4222-a743-37812a2bead0,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-12596764-4b80-497b-89b6-1490ee1842ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-b1ba49db-9b2d-4fb2-a40a-0b5a455464f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-884f181a-1c6a-4560-98ba-61269d4b1e91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829670559-172.17.0.19-1595897849682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46140,DS-945c4737-9ffa-497f-ab08-de7e045a7681,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-57179437-3a00-47c6-96bd-777fec6f8f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-06876f88-5d9f-4ca4-8d01-79f42dfbb9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-52f5303d-e217-4026-acdc-1bc33fe46ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-224612e3-4a58-4389-abab-8cf57db43078,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-ff83522e-121c-44ab-8ec4-facf54ba3383,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-3eb90c71-4f4e-4d09-bff7-ce3528b087d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-644bec55-2c8d-46ad-99e9-7bf6e20440bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829670559-172.17.0.19-1595897849682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46140,DS-945c4737-9ffa-497f-ab08-de7e045a7681,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-57179437-3a00-47c6-96bd-777fec6f8f34,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-06876f88-5d9f-4ca4-8d01-79f42dfbb9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-52f5303d-e217-4026-acdc-1bc33fe46ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-224612e3-4a58-4389-abab-8cf57db43078,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-ff83522e-121c-44ab-8ec4-facf54ba3383,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-3eb90c71-4f4e-4d09-bff7-ce3528b087d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-644bec55-2c8d-46ad-99e9-7bf6e20440bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287027430-172.17.0.19-1595898580281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35477,DS-317dc5c3-7ff8-43c2-9ec7-211f857a3ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-c1c63966-9db0-4a80-b737-8b66a44b4faf,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-32b4b4aa-62d9-40f0-864e-9402422b54cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-f974ed4a-f45b-4bfb-9980-562c34deaadb,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-9b79f569-2b76-425b-9774-43f54c7bbcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-9417fa27-3c1c-40be-9c43-113ea8d607f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-dbe33744-ff0b-4e89-b600-c366d8505248,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-992aeb0b-dae6-4994-94aa-8e0603c68ee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-287027430-172.17.0.19-1595898580281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35477,DS-317dc5c3-7ff8-43c2-9ec7-211f857a3ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-c1c63966-9db0-4a80-b737-8b66a44b4faf,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-32b4b4aa-62d9-40f0-864e-9402422b54cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-f974ed4a-f45b-4bfb-9980-562c34deaadb,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-9b79f569-2b76-425b-9774-43f54c7bbcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-9417fa27-3c1c-40be-9c43-113ea8d607f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-dbe33744-ff0b-4e89-b600-c366d8505248,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-992aeb0b-dae6-4994-94aa-8e0603c68ee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626812247-172.17.0.19-1595898896556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41484,DS-668828a4-bb0c-4dac-bd65-b9d4dd464385,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-aa04418b-9397-4f0d-9e84-8fb6a0fc227b,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-1993047f-f55d-46aa-a9e4-e62bb6bddfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-22fa0f4f-e448-4f11-802d-ac56096efb74,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-86214049-055e-4a23-9ad4-fe12b7a3f77a,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-065f3f65-5e9c-4e90-983a-2ff0cbb64928,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-1007e6e5-fbd0-4da4-a3ce-cfb99350c9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-5731cf32-bd26-4215-b85c-fa8569b3670d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626812247-172.17.0.19-1595898896556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41484,DS-668828a4-bb0c-4dac-bd65-b9d4dd464385,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-aa04418b-9397-4f0d-9e84-8fb6a0fc227b,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-1993047f-f55d-46aa-a9e4-e62bb6bddfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-22fa0f4f-e448-4f11-802d-ac56096efb74,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-86214049-055e-4a23-9ad4-fe12b7a3f77a,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-065f3f65-5e9c-4e90-983a-2ff0cbb64928,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-1007e6e5-fbd0-4da4-a3ce-cfb99350c9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-5731cf32-bd26-4215-b85c-fa8569b3670d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225224653-172.17.0.19-1595899153467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39282,DS-f8e05101-5486-471b-b7be-c1ef0018f912,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-ad706eff-0c2c-4fcc-9893-df0ee7c9a4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-5e75e1d2-d989-46a3-96b0-fd0ecaa1eb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-c6fcdda3-5d07-4196-8569-36335f7327ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-9a8b6c6f-6ff4-4379-94a2-469e30ef1385,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-f7576bd3-3c03-4633-b373-a1e6e50a2d51,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-3d766111-2b49-4769-a580-611d67af8587,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-284df6c9-5718-4395-bf01-b6b42136d90d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225224653-172.17.0.19-1595899153467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39282,DS-f8e05101-5486-471b-b7be-c1ef0018f912,DISK], DatanodeInfoWithStorage[127.0.0.1:44864,DS-ad706eff-0c2c-4fcc-9893-df0ee7c9a4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-5e75e1d2-d989-46a3-96b0-fd0ecaa1eb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-c6fcdda3-5d07-4196-8569-36335f7327ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-9a8b6c6f-6ff4-4379-94a2-469e30ef1385,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-f7576bd3-3c03-4633-b373-a1e6e50a2d51,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-3d766111-2b49-4769-a580-611d67af8587,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-284df6c9-5718-4395-bf01-b6b42136d90d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799441988-172.17.0.19-1595899267731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34639,DS-4b1a1539-8ccb-4395-9ab1-7f1a1456b84f,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-c632b309-95b0-40c4-94c4-1c4fb77c6ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-d3069bb5-2a5e-4a41-9bb3-f96bf70712a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-9f4ce656-1fe9-4349-865d-f68ba97115a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-176411ea-c359-4125-90e8-ba43454afb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-897b2f9f-3386-4b48-b658-548fc6122c80,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-cf88530c-502e-4d01-ad76-123dd0a0e455,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-c8afb40b-fa58-4765-b617-5f80255d2214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799441988-172.17.0.19-1595899267731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34639,DS-4b1a1539-8ccb-4395-9ab1-7f1a1456b84f,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-c632b309-95b0-40c4-94c4-1c4fb77c6ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-d3069bb5-2a5e-4a41-9bb3-f96bf70712a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-9f4ce656-1fe9-4349-865d-f68ba97115a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-176411ea-c359-4125-90e8-ba43454afb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-897b2f9f-3386-4b48-b658-548fc6122c80,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-cf88530c-502e-4d01-ad76-123dd0a0e455,DISK], DatanodeInfoWithStorage[127.0.0.1:36502,DS-c8afb40b-fa58-4765-b617-5f80255d2214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748574705-172.17.0.19-1595899300331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39071,DS-26bbd87f-7add-4984-b0e2-295421dfee4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-0ce9857c-9c89-4176-b89a-026474150200,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-07c56a8a-1707-4911-8aaa-3c0b381d6029,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-74da55ec-0a37-474c-b1cd-f12ec8ee604d,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-575566ba-239b-457b-8d10-ad1de61e6dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-90dab198-ba02-4fb3-bc40-5e2d915d8526,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-0ca8967a-83c9-42dd-8828-9dcdadcebfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-c169a1ab-be7d-4a3c-aee1-f148a32a3de2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1748574705-172.17.0.19-1595899300331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39071,DS-26bbd87f-7add-4984-b0e2-295421dfee4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-0ce9857c-9c89-4176-b89a-026474150200,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-07c56a8a-1707-4911-8aaa-3c0b381d6029,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-74da55ec-0a37-474c-b1cd-f12ec8ee604d,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-575566ba-239b-457b-8d10-ad1de61e6dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-90dab198-ba02-4fb3-bc40-5e2d915d8526,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-0ca8967a-83c9-42dd-8828-9dcdadcebfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-c169a1ab-be7d-4a3c-aee1-f148a32a3de2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-522828789-172.17.0.19-1595899439260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36477,DS-d18384b4-e3f1-4a5d-b94f-b1f76b8ff6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-abc3f2ee-955a-445e-9718-9786f65b76b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-995ba6ea-5ef9-4fa1-b608-af82a008e549,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-208cd51c-134a-4813-adfa-7891dc9c4d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-e864fc5e-ecaf-48c6-87a3-7bc50ae03c24,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-9b45d141-8dc7-466b-9dcb-acd8844859f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-a01e4c7b-c2c8-4fc3-919d-46054a9040b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-3c326638-e6c0-4af0-b8d6-131bd1edb177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-522828789-172.17.0.19-1595899439260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36477,DS-d18384b4-e3f1-4a5d-b94f-b1f76b8ff6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-abc3f2ee-955a-445e-9718-9786f65b76b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-995ba6ea-5ef9-4fa1-b608-af82a008e549,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-208cd51c-134a-4813-adfa-7891dc9c4d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-e864fc5e-ecaf-48c6-87a3-7bc50ae03c24,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-9b45d141-8dc7-466b-9dcb-acd8844859f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-a01e4c7b-c2c8-4fc3-919d-46054a9040b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-3c326638-e6c0-4af0-b8d6-131bd1edb177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5307
