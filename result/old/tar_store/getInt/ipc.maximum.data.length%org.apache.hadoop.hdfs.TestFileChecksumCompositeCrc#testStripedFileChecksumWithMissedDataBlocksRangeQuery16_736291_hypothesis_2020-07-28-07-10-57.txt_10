reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634490591-172.17.0.7-1595920420453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40297,DS-e9d45117-3ca5-4449-925a-84e8dee79ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-7dae53f0-327b-4cf3-b5e4-a3ead01863bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-189eb7dc-e595-4603-aa9f-0b70a30c9be2,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-51922d27-6c3c-4626-b3a2-350c0b4ecba3,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-976fcf8c-022c-4664-bcb6-03f1f92be9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-73fb241b-c76c-478c-929c-63f91b4063c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-637451df-daca-4130-955d-616481e5fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-17d99541-ef6a-4f1e-ac17-146c199f233b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1634490591-172.17.0.7-1595920420453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40297,DS-e9d45117-3ca5-4449-925a-84e8dee79ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-7dae53f0-327b-4cf3-b5e4-a3ead01863bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-189eb7dc-e595-4603-aa9f-0b70a30c9be2,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-51922d27-6c3c-4626-b3a2-350c0b4ecba3,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-976fcf8c-022c-4664-bcb6-03f1f92be9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-73fb241b-c76c-478c-929c-63f91b4063c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-637451df-daca-4130-955d-616481e5fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-17d99541-ef6a-4f1e-ac17-146c199f233b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442628126-172.17.0.7-1595920728121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43815,DS-a5b55d55-cb11-40ad-a64c-69c1cfdcefe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-2fa4ad79-9373-470f-835f-6308a56cc00e,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-8cc80e6e-573f-4ddb-a939-0757ef936cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-084c0ffd-abdd-4696-a8df-127365249b12,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-d14df71a-ac39-4892-8a39-62bb48844c91,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-f584827f-6581-44ee-b629-2da6c9f9c630,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-296bf2a9-6975-4638-8998-20b267d3b45d,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-6ad80cdf-2a14-4751-8353-adbc106fbeee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442628126-172.17.0.7-1595920728121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43815,DS-a5b55d55-cb11-40ad-a64c-69c1cfdcefe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-2fa4ad79-9373-470f-835f-6308a56cc00e,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-8cc80e6e-573f-4ddb-a939-0757ef936cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-084c0ffd-abdd-4696-a8df-127365249b12,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-d14df71a-ac39-4892-8a39-62bb48844c91,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-f584827f-6581-44ee-b629-2da6c9f9c630,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-296bf2a9-6975-4638-8998-20b267d3b45d,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-6ad80cdf-2a14-4751-8353-adbc106fbeee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826487775-172.17.0.7-1595921088394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45201,DS-b0dbb4da-6559-4310-bfe4-a743c8b1abed,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-9d77d670-3585-489c-b9c5-ceb3bc28d79f,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-f49ab0fe-8c23-4e56-8e2c-68f50f129427,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-ab388273-3261-431e-ad2c-eccf8642c72c,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-26acebf1-95ed-46f3-9885-f7d79cb6c89f,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-c0ae5846-a7ac-4dae-ae77-3ddb4c33bcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-4ef2dd97-9a7f-4160-b7fe-0c654302a0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-ca229a02-a7b5-4c05-ba02-78d2eb03abf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826487775-172.17.0.7-1595921088394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45201,DS-b0dbb4da-6559-4310-bfe4-a743c8b1abed,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-9d77d670-3585-489c-b9c5-ceb3bc28d79f,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-f49ab0fe-8c23-4e56-8e2c-68f50f129427,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-ab388273-3261-431e-ad2c-eccf8642c72c,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-26acebf1-95ed-46f3-9885-f7d79cb6c89f,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-c0ae5846-a7ac-4dae-ae77-3ddb4c33bcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-4ef2dd97-9a7f-4160-b7fe-0c654302a0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-ca229a02-a7b5-4c05-ba02-78d2eb03abf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508815383-172.17.0.7-1595921237225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38659,DS-d60e7177-f422-4e52-9a97-4a29a9df29eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-d6b02d1f-f554-46b1-b24f-c2e9407795e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-f6f003ba-8595-4323-ade9-0ee922e884d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-5df9ec0d-682a-4e6f-afce-e4b32307fd78,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-7422f3bd-5e2e-4459-ae63-383920cb0c89,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-8216fa08-c237-4d44-b675-136f7614659d,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-8fe0019e-0655-4d1b-9ca1-685ba2aa8b86,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-04173fd1-70fb-49b8-b939-2710aeb6b43e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508815383-172.17.0.7-1595921237225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38659,DS-d60e7177-f422-4e52-9a97-4a29a9df29eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-d6b02d1f-f554-46b1-b24f-c2e9407795e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-f6f003ba-8595-4323-ade9-0ee922e884d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-5df9ec0d-682a-4e6f-afce-e4b32307fd78,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-7422f3bd-5e2e-4459-ae63-383920cb0c89,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-8216fa08-c237-4d44-b675-136f7614659d,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-8fe0019e-0655-4d1b-9ca1-685ba2aa8b86,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-04173fd1-70fb-49b8-b939-2710aeb6b43e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807313122-172.17.0.7-1595921515553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46174,DS-2ccef7fa-f746-4ea7-a228-52fd5b8c5edd,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-501cde70-ba15-4aa2-9be8-e3f6d08b6e30,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-b8f2ddbc-e6f0-4b9d-a590-c9e420f87e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-01534e77-77d6-41f6-b80a-6ca66ec4284c,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-3272828f-04c5-402b-a89c-7af32709b6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-373d1526-cd08-4966-926a-6a7f7a4a9d47,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-22ec0d75-c0c0-4232-8fda-bac8857c3351,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-26ddffab-383d-4da7-a019-043b543ccb4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807313122-172.17.0.7-1595921515553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46174,DS-2ccef7fa-f746-4ea7-a228-52fd5b8c5edd,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-501cde70-ba15-4aa2-9be8-e3f6d08b6e30,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-b8f2ddbc-e6f0-4b9d-a590-c9e420f87e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-01534e77-77d6-41f6-b80a-6ca66ec4284c,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-3272828f-04c5-402b-a89c-7af32709b6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-373d1526-cd08-4966-926a-6a7f7a4a9d47,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-22ec0d75-c0c0-4232-8fda-bac8857c3351,DISK], DatanodeInfoWithStorage[127.0.0.1:41970,DS-26ddffab-383d-4da7-a019-043b543ccb4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005840034-172.17.0.7-1595922282097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36449,DS-827f480d-f013-4ebc-8a81-350ffc1e1df8,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-850bfafa-5795-4b50-9dd3-a8dabc2dcaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-5717005b-0547-4986-bb85-fa028fcdac99,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-9681515e-fde8-4830-8598-51621d3f79cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-401cd03c-838b-486c-88b7-b366a20a2fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-47448c0a-9c19-4e30-8b68-7b55c00525c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-95e42bfe-0dad-4594-9522-d6c798dbf5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-fa3e2798-b27d-480c-9436-10cddb1dd627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005840034-172.17.0.7-1595922282097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36449,DS-827f480d-f013-4ebc-8a81-350ffc1e1df8,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-850bfafa-5795-4b50-9dd3-a8dabc2dcaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-5717005b-0547-4986-bb85-fa028fcdac99,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-9681515e-fde8-4830-8598-51621d3f79cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-401cd03c-838b-486c-88b7-b366a20a2fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:40878,DS-47448c0a-9c19-4e30-8b68-7b55c00525c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-95e42bfe-0dad-4594-9522-d6c798dbf5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-fa3e2798-b27d-480c-9436-10cddb1dd627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960074688-172.17.0.7-1595922534298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34400,DS-b2269ecc-832c-4bda-a3dd-73f9fe83ffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-9002c663-c2f7-4fe9-b8e8-768b8fe7db8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-64d325c2-47bd-4b83-90a1-31247a243e46,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-c4e34057-5e7f-4a31-8705-de05d4d25df0,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-814ae17d-045c-40f5-9c67-98db7abe5844,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-9fc99099-16d5-4ff4-9e9d-5ae2dcef693d,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-614edc8e-90ca-49a0-9c78-662bee59d5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-19a94d81-13b6-4fa2-9063-33fb5f32e597,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960074688-172.17.0.7-1595922534298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34400,DS-b2269ecc-832c-4bda-a3dd-73f9fe83ffe7,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-9002c663-c2f7-4fe9-b8e8-768b8fe7db8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-64d325c2-47bd-4b83-90a1-31247a243e46,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-c4e34057-5e7f-4a31-8705-de05d4d25df0,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-814ae17d-045c-40f5-9c67-98db7abe5844,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-9fc99099-16d5-4ff4-9e9d-5ae2dcef693d,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-614edc8e-90ca-49a0-9c78-662bee59d5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-19a94d81-13b6-4fa2-9063-33fb5f32e597,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1236129782-172.17.0.7-1595922567462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32940,DS-f98a015c-dad3-4e8d-a849-a135404abf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-ec5108a2-4358-4506-b6db-762a6868ca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-a962522d-36f4-46fd-b246-a9b569632b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-d82e356e-31ef-488c-bb2b-129c0857034c,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-7e53d351-718a-496f-9514-dc7a23bd012e,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-554bca3f-a660-4498-8cc9-a0fb947d34bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-43da5f47-e607-4329-b355-372cdb2a0e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-e925eb28-bbf7-440e-ad43-4405b8e8d4ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1236129782-172.17.0.7-1595922567462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32940,DS-f98a015c-dad3-4e8d-a849-a135404abf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-ec5108a2-4358-4506-b6db-762a6868ca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-a962522d-36f4-46fd-b246-a9b569632b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-d82e356e-31ef-488c-bb2b-129c0857034c,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-7e53d351-718a-496f-9514-dc7a23bd012e,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-554bca3f-a660-4498-8cc9-a0fb947d34bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36527,DS-43da5f47-e607-4329-b355-372cdb2a0e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-e925eb28-bbf7-440e-ad43-4405b8e8d4ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313842393-172.17.0.7-1595922950564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45668,DS-f6a13d44-28a5-482d-919a-c917808230e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-01a0c7e7-e6ea-47fa-974f-8832fa6b0160,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-190856d6-baf9-424f-9e7b-a9f0aa905716,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-7ad78503-d53f-418c-ada2-180296e7690c,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-d64ac950-5570-4f8c-bed8-7cb07533f111,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-ffda933c-1841-4ce3-b9be-f42f428220dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-d48c816c-5775-41d4-8b31-403da173eb26,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-544f45d5-eab0-42c1-abf0-8e720f67a354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313842393-172.17.0.7-1595922950564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45668,DS-f6a13d44-28a5-482d-919a-c917808230e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-01a0c7e7-e6ea-47fa-974f-8832fa6b0160,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-190856d6-baf9-424f-9e7b-a9f0aa905716,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-7ad78503-d53f-418c-ada2-180296e7690c,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-d64ac950-5570-4f8c-bed8-7cb07533f111,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-ffda933c-1841-4ce3-b9be-f42f428220dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-d48c816c-5775-41d4-8b31-403da173eb26,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-544f45d5-eab0-42c1-abf0-8e720f67a354,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955579307-172.17.0.7-1595922981032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39042,DS-a5f5272d-02d2-4411-83f9-7839fa4e57c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-5988cab1-3443-4cb7-aee8-92d34a65416d,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-0ae5d626-ce3d-4dbc-ad27-443094d84742,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-538f056c-058f-47d8-a472-dab86125dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-22cf9394-0c35-4d96-9d4c-b6f341ebec29,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-fb69cf29-e16f-4ec9-b752-61db32f5a1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-e4c3ac41-a79e-4efc-95a6-94f9db2797df,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-94bb2944-f7dd-4d1b-8ddd-d47868311e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1955579307-172.17.0.7-1595922981032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39042,DS-a5f5272d-02d2-4411-83f9-7839fa4e57c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-5988cab1-3443-4cb7-aee8-92d34a65416d,DISK], DatanodeInfoWithStorage[127.0.0.1:38133,DS-0ae5d626-ce3d-4dbc-ad27-443094d84742,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-538f056c-058f-47d8-a472-dab86125dcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-22cf9394-0c35-4d96-9d4c-b6f341ebec29,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-fb69cf29-e16f-4ec9-b752-61db32f5a1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-e4c3ac41-a79e-4efc-95a6-94f9db2797df,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-94bb2944-f7dd-4d1b-8ddd-d47868311e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832837446-172.17.0.7-1595923052417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44886,DS-2c2ee7d7-5bf7-44f7-b74b-ce28d6f50f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-78e52bc8-3122-4d73-addb-30d290367d84,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-39e0dff4-3aee-40c9-a3f8-d2b85bbb5ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-8d045ae8-d418-40af-9141-9bc10d8a2772,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-ca2ba875-538b-443d-9e00-55ef26da2210,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-9d588b8b-defb-4323-845c-eeb5e58c6e75,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-e7b3835c-0b80-4bb4-81d5-adfa9cdd0b90,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-532003c9-1623-4910-9f30-12a744682100,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832837446-172.17.0.7-1595923052417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44886,DS-2c2ee7d7-5bf7-44f7-b74b-ce28d6f50f11,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-78e52bc8-3122-4d73-addb-30d290367d84,DISK], DatanodeInfoWithStorage[127.0.0.1:41251,DS-39e0dff4-3aee-40c9-a3f8-d2b85bbb5ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-8d045ae8-d418-40af-9141-9bc10d8a2772,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-ca2ba875-538b-443d-9e00-55ef26da2210,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-9d588b8b-defb-4323-845c-eeb5e58c6e75,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-e7b3835c-0b80-4bb4-81d5-adfa9cdd0b90,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-532003c9-1623-4910-9f30-12a744682100,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040071826-172.17.0.7-1595923381303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45560,DS-70f35acb-bb8d-4c7a-abf5-ee5930987f80,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-e70d7a01-2a40-4ea2-a1e2-e171c189eb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-81b365f7-c8b4-4351-b52f-2a71c5f9db3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-fc05080f-101e-409e-8dcb-0c3c71ba275e,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-cc3ef2f0-b30f-49f1-975d-e9f06e1b68b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-6d7dd54a-d4cd-4f92-8117-06a0702d82ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-1010e0c4-bf3b-4d4a-b5f2-8775422034ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-d558c486-552f-4471-8189-e477d7cce02a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1040071826-172.17.0.7-1595923381303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45560,DS-70f35acb-bb8d-4c7a-abf5-ee5930987f80,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-e70d7a01-2a40-4ea2-a1e2-e171c189eb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-81b365f7-c8b4-4351-b52f-2a71c5f9db3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-fc05080f-101e-409e-8dcb-0c3c71ba275e,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-cc3ef2f0-b30f-49f1-975d-e9f06e1b68b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-6d7dd54a-d4cd-4f92-8117-06a0702d82ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-1010e0c4-bf3b-4d4a-b5f2-8775422034ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-d558c486-552f-4471-8189-e477d7cce02a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2120563656-172.17.0.7-1595923718030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36874,DS-fbf51b7d-5ffb-4705-b437-7e12008bcd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-8400ab47-bfab-4508-9ee6-038e733e441e,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-816979a8-6dd7-4932-bc1e-9c5f1239a695,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-2fc3b9a0-df3a-4b39-a438-8c702fb7cde4,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-c6cc1a61-b356-4810-acef-15ac37c50c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-e6effeb4-b9b2-49a5-986b-9daa3720e99b,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-f8138a4a-d04c-4e34-bf67-8efccf41bd39,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-775dd711-1040-4238-8444-1083d2745619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2120563656-172.17.0.7-1595923718030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36874,DS-fbf51b7d-5ffb-4705-b437-7e12008bcd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-8400ab47-bfab-4508-9ee6-038e733e441e,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-816979a8-6dd7-4932-bc1e-9c5f1239a695,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-2fc3b9a0-df3a-4b39-a438-8c702fb7cde4,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-c6cc1a61-b356-4810-acef-15ac37c50c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-e6effeb4-b9b2-49a5-986b-9daa3720e99b,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-f8138a4a-d04c-4e34-bf67-8efccf41bd39,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-775dd711-1040-4238-8444-1083d2745619,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682914685-172.17.0.7-1595924078194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45129,DS-5311fbec-fe5d-4212-ba50-0dc8639950d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-e8596251-81f3-464f-80e3-177d305c43c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-546c5cc4-a15f-403c-b9e3-de9ccce8b293,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-54f2ef37-f66f-4856-bca5-0e2aa27a0e22,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-f9462c47-7954-4fe0-bb8a-4502e1731d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-55fd8741-6844-4905-a810-72c2f664b0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-98bb6b29-c1cc-4779-ada9-8abf2e3fbe38,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-37fe5fe7-48eb-4a40-81b2-557ff2ee31aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682914685-172.17.0.7-1595924078194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45129,DS-5311fbec-fe5d-4212-ba50-0dc8639950d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-e8596251-81f3-464f-80e3-177d305c43c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-546c5cc4-a15f-403c-b9e3-de9ccce8b293,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-54f2ef37-f66f-4856-bca5-0e2aa27a0e22,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-f9462c47-7954-4fe0-bb8a-4502e1731d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-55fd8741-6844-4905-a810-72c2f664b0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-98bb6b29-c1cc-4779-ada9-8abf2e3fbe38,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-37fe5fe7-48eb-4a40-81b2-557ff2ee31aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043061059-172.17.0.7-1595924260994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41221,DS-680d7d1e-c45f-43e0-b1eb-f7f7d2a4643a,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-03c14665-3788-4325-aa5c-884c82d730df,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-bfb8f48f-5c10-415a-828e-3f15024484ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-c4dea402-960a-41c7-91a0-6ce65b0271b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-dc7bd667-08f1-41bd-92f9-35903f90fecb,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-840af39b-fa26-483a-817b-6c3011d56f03,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-28028773-6f3a-426d-ba94-3331118783b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-96a84a27-0625-4c73-aa2b-728439b5ab91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043061059-172.17.0.7-1595924260994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41221,DS-680d7d1e-c45f-43e0-b1eb-f7f7d2a4643a,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-03c14665-3788-4325-aa5c-884c82d730df,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-bfb8f48f-5c10-415a-828e-3f15024484ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-c4dea402-960a-41c7-91a0-6ce65b0271b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-dc7bd667-08f1-41bd-92f9-35903f90fecb,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-840af39b-fa26-483a-817b-6c3011d56f03,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-28028773-6f3a-426d-ba94-3331118783b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-96a84a27-0625-4c73-aa2b-728439b5ab91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-47565732-172.17.0.7-1595924413258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42681,DS-a4a2fa03-02d7-4ddf-947f-86fdb4a2677a,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-bfa81a04-967c-4742-b50f-b52ab2e4c169,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-e31e48d8-fa1b-4efa-ab90-17e6061a5c77,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-2b989352-61b0-4969-b0dc-b6ca184a51ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-7f956515-47d0-41cd-840c-be9d477ac300,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-944fb174-e430-4916-acd2-204e6775d89b,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-3e20a73b-df25-4c67-8dbb-c0d72a60ee7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-97355715-669f-4864-a1f0-bde129877bf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-47565732-172.17.0.7-1595924413258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42681,DS-a4a2fa03-02d7-4ddf-947f-86fdb4a2677a,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-bfa81a04-967c-4742-b50f-b52ab2e4c169,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-e31e48d8-fa1b-4efa-ab90-17e6061a5c77,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-2b989352-61b0-4969-b0dc-b6ca184a51ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-7f956515-47d0-41cd-840c-be9d477ac300,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-944fb174-e430-4916-acd2-204e6775d89b,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-3e20a73b-df25-4c67-8dbb-c0d72a60ee7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-97355715-669f-4864-a1f0-bde129877bf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960870618-172.17.0.7-1595924622513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37404,DS-34abe97c-d674-4dd6-abbf-28dee7cbd846,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-bc2ea208-da63-49a7-8e3f-844e13bfb8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-5bd667cf-7547-48ce-ad75-a06376c654b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-03704561-4bd5-409a-a95f-f98e9b812d44,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-04d90f5a-9b76-4eb2-8887-12ac4aeb8c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-6fc143fb-2a6a-4774-bcd7-6ede22e32cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-061cf487-ec09-40a0-87b3-bbf6e0798043,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-2445e1e3-20fc-4074-bd64-e25d64860781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960870618-172.17.0.7-1595924622513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37404,DS-34abe97c-d674-4dd6-abbf-28dee7cbd846,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-bc2ea208-da63-49a7-8e3f-844e13bfb8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-5bd667cf-7547-48ce-ad75-a06376c654b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-03704561-4bd5-409a-a95f-f98e9b812d44,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-04d90f5a-9b76-4eb2-8887-12ac4aeb8c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-6fc143fb-2a6a-4774-bcd7-6ede22e32cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-061cf487-ec09-40a0-87b3-bbf6e0798043,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-2445e1e3-20fc-4074-bd64-e25d64860781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508609045-172.17.0.7-1595924657649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37263,DS-ae5195c2-20c5-457c-8eaf-900490618750,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-72cb927b-911b-4678-a9b3-1fbc4748f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-b18fc463-09d4-436b-aa93-a35e6619ed18,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-6aaf402b-1bb6-4298-b935-741c6511c0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-6afbf608-be0d-4a3d-90c3-dd11492d2a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-684a5416-1f82-4632-b89d-fdd1af210ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-1eaffff3-8441-47fd-bd6b-5570372c6482,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-b5ca31a4-3b7d-43ee-997a-e6e8ce15b731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-508609045-172.17.0.7-1595924657649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37263,DS-ae5195c2-20c5-457c-8eaf-900490618750,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-72cb927b-911b-4678-a9b3-1fbc4748f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-b18fc463-09d4-436b-aa93-a35e6619ed18,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-6aaf402b-1bb6-4298-b935-741c6511c0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-6afbf608-be0d-4a3d-90c3-dd11492d2a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-684a5416-1f82-4632-b89d-fdd1af210ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-1eaffff3-8441-47fd-bd6b-5570372c6482,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-b5ca31a4-3b7d-43ee-997a-e6e8ce15b731,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807048922-172.17.0.7-1595924691212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39277,DS-cf156b8a-fdfc-4216-b4b6-80c6faeccb67,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-483e0818-b389-4e87-a735-ceddaaf05f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-8e0d1e7f-4976-4ecf-b0bc-a058988dd7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-0609aa8b-50bc-4bff-9ccf-1f8ed16758b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-89957fbf-1430-4a22-825d-a5280ac66727,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-01f8ac24-9f2d-459a-80c1-8b254ea41964,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-c67a6dff-3617-46bb-9d0a-52553cf60c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-94517b81-8227-4c7e-b472-fc09ef938f20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807048922-172.17.0.7-1595924691212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39277,DS-cf156b8a-fdfc-4216-b4b6-80c6faeccb67,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-483e0818-b389-4e87-a735-ceddaaf05f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-8e0d1e7f-4976-4ecf-b0bc-a058988dd7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-0609aa8b-50bc-4bff-9ccf-1f8ed16758b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-89957fbf-1430-4a22-825d-a5280ac66727,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-01f8ac24-9f2d-459a-80c1-8b254ea41964,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-c67a6dff-3617-46bb-9d0a-52553cf60c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-94517b81-8227-4c7e-b472-fc09ef938f20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1804747111-172.17.0.7-1595925044087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42322,DS-9ab27059-eae5-4780-9649-fc1b750832fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-45518657-48f9-44e6-a68d-dfc1d9a5887e,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-6ea3d133-fc10-424d-a3a6-0f5b50c2d84a,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-da56a12c-685f-428f-b09d-c27e75c7ed3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-de9bbc94-a316-4a38-bbda-d9d1544582cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-57c1710a-5273-4f19-951a-bca5a0f670b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-c83c72db-fd85-45a4-9666-2e964571fb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-dee3b00b-6b63-41de-8abb-4d6ab5c36d6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1804747111-172.17.0.7-1595925044087:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42322,DS-9ab27059-eae5-4780-9649-fc1b750832fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-45518657-48f9-44e6-a68d-dfc1d9a5887e,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-6ea3d133-fc10-424d-a3a6-0f5b50c2d84a,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-da56a12c-685f-428f-b09d-c27e75c7ed3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-de9bbc94-a316-4a38-bbda-d9d1544582cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-57c1710a-5273-4f19-951a-bca5a0f670b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-c83c72db-fd85-45a4-9666-2e964571fb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-dee3b00b-6b63-41de-8abb-4d6ab5c36d6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 8388608
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810223901-172.17.0.7-1595925548921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41207,DS-c5af4874-c079-43eb-adb6-74b939ba31e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-3bd5366c-9afb-4f1a-b7bd-f25213881536,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-63080914-4222-40d9-8d5f-1839a0370a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-761cd3c7-7dd4-40b3-a223-01730ce4af27,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-be0ee217-fd26-401c-bf20-881e6546517a,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-f1f5bb9a-bb2e-4a99-88f0-be7973cc3ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-7805e46a-b56b-4262-9a12-140c828e568f,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-25bad767-5be5-42f4-b181-228560e21881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810223901-172.17.0.7-1595925548921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41207,DS-c5af4874-c079-43eb-adb6-74b939ba31e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-3bd5366c-9afb-4f1a-b7bd-f25213881536,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-63080914-4222-40d9-8d5f-1839a0370a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-761cd3c7-7dd4-40b3-a223-01730ce4af27,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-be0ee217-fd26-401c-bf20-881e6546517a,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-f1f5bb9a-bb2e-4a99-88f0-be7973cc3ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-7805e46a-b56b-4262-9a12-140c828e568f,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-25bad767-5be5-42f4-b181-228560e21881,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5374
