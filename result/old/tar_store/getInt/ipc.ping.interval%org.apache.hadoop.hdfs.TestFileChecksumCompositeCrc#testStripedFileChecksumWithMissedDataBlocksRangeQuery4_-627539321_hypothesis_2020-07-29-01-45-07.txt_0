reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454265748-172.17.0.19-1595987290059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34346,DS-10585504-e545-4e2f-9dff-861d8562a7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-e752e590-7cea-4b90-924b-c81f72f3ffb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-afd797b3-97f4-4672-8268-74c9df50eb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-2528b068-d774-4f90-a7af-55c924870196,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-44fb8504-d892-4f13-9d13-bc0ef0dd97f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-5928a9ba-29e7-48cf-a9d2-e1637d817037,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-4a74f554-6d83-4a71-abb7-36e6bec31ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-a968fe66-5a82-440d-8280-b9ec58a97d9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454265748-172.17.0.19-1595987290059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34346,DS-10585504-e545-4e2f-9dff-861d8562a7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-e752e590-7cea-4b90-924b-c81f72f3ffb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-afd797b3-97f4-4672-8268-74c9df50eb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-2528b068-d774-4f90-a7af-55c924870196,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-44fb8504-d892-4f13-9d13-bc0ef0dd97f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-5928a9ba-29e7-48cf-a9d2-e1637d817037,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-4a74f554-6d83-4a71-abb7-36e6bec31ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-a968fe66-5a82-440d-8280-b9ec58a97d9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234118898-172.17.0.19-1595987762036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43620,DS-7fda6f76-660f-4422-8332-993b842f8a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-31aed378-9af9-4c5f-9450-501487de6d08,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-59246da4-7fd1-47d0-8ba7-f959cd66d5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-ae91bde1-f004-41d3-b44f-993cdd2cd044,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-0affffe2-7496-482b-9754-73727de0e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-f1f37c67-f3b5-4a98-a727-278e5e3c388f,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-a9c69d8e-5423-4439-979d-96dcdae19b72,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-063d2bf0-fe74-4313-bad4-6887ce9ef901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234118898-172.17.0.19-1595987762036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43620,DS-7fda6f76-660f-4422-8332-993b842f8a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-31aed378-9af9-4c5f-9450-501487de6d08,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-59246da4-7fd1-47d0-8ba7-f959cd66d5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-ae91bde1-f004-41d3-b44f-993cdd2cd044,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-0affffe2-7496-482b-9754-73727de0e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-f1f37c67-f3b5-4a98-a727-278e5e3c388f,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-a9c69d8e-5423-4439-979d-96dcdae19b72,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-063d2bf0-fe74-4313-bad4-6887ce9ef901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474806060-172.17.0.19-1595988215654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38755,DS-870f7c25-c781-4042-b3f5-75a297abe5da,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-599df563-f862-4aae-9c3d-982e55ef73dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-04e21b57-dacc-4f3f-be5f-f85e3bf71460,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-a6fa776d-8154-4c70-ad40-8bfcacd3e41c,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-545ff2b8-e006-44e1-b4f6-0bdefbe6bd06,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-88bf3dbf-5d4c-4d68-aed1-025ba9297cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-a04f31fc-b709-4aef-a987-140f98e36d26,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-dd07b051-098f-4ce8-b07d-5878b7028722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474806060-172.17.0.19-1595988215654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38755,DS-870f7c25-c781-4042-b3f5-75a297abe5da,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-599df563-f862-4aae-9c3d-982e55ef73dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-04e21b57-dacc-4f3f-be5f-f85e3bf71460,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-a6fa776d-8154-4c70-ad40-8bfcacd3e41c,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-545ff2b8-e006-44e1-b4f6-0bdefbe6bd06,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-88bf3dbf-5d4c-4d68-aed1-025ba9297cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-a04f31fc-b709-4aef-a987-140f98e36d26,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-dd07b051-098f-4ce8-b07d-5878b7028722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439396279-172.17.0.19-1595988247112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42239,DS-073cb026-4106-499f-8dce-9abba24768cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-43e431f3-fd8b-4c00-be2c-60c1cb7a499a,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-6fe6786f-f886-4883-8f03-e59feff0ca62,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-89b373c6-6cf9-4ed5-b8f5-464c9c702dee,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-f336cf5c-b91e-4a62-9408-307012e30dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-ef129f58-0a87-4ad7-8b94-272fb7b7ef85,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-26547d20-7b1d-41aa-bc6c-5082b0519bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-bd666af9-fbff-42ee-83b6-e41d572d54e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439396279-172.17.0.19-1595988247112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42239,DS-073cb026-4106-499f-8dce-9abba24768cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-43e431f3-fd8b-4c00-be2c-60c1cb7a499a,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-6fe6786f-f886-4883-8f03-e59feff0ca62,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-89b373c6-6cf9-4ed5-b8f5-464c9c702dee,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-f336cf5c-b91e-4a62-9408-307012e30dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-ef129f58-0a87-4ad7-8b94-272fb7b7ef85,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-26547d20-7b1d-41aa-bc6c-5082b0519bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-bd666af9-fbff-42ee-83b6-e41d572d54e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568369509-172.17.0.19-1595988658255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-41e9dca7-0c3f-48c4-84b5-0b41912a4c68,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-dcbee536-eef4-4200-9dd6-0e595cbdb9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-b1e36ef9-bf6d-4cb3-8389-025b08900d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-8fe6abdc-2556-4717-8199-12daecf7dc54,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-08dd22cb-600d-4f66-9217-13b348165ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-da06fe3d-5796-49c3-97f7-e55f113c245d,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-a1e65589-a19f-48a0-99ab-0c3f72d0105b,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-abe4a546-2220-4c68-b34f-bbabeb772a57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568369509-172.17.0.19-1595988658255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44276,DS-41e9dca7-0c3f-48c4-84b5-0b41912a4c68,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-dcbee536-eef4-4200-9dd6-0e595cbdb9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-b1e36ef9-bf6d-4cb3-8389-025b08900d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-8fe6abdc-2556-4717-8199-12daecf7dc54,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-08dd22cb-600d-4f66-9217-13b348165ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-da06fe3d-5796-49c3-97f7-e55f113c245d,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-a1e65589-a19f-48a0-99ab-0c3f72d0105b,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-abe4a546-2220-4c68-b34f-bbabeb772a57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687014616-172.17.0.19-1595988722410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38263,DS-383b4dae-ebdb-4425-8e52-fc1124880004,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-f58cb4c6-aaa5-4065-bc75-5c5da3e0cf21,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-a025c384-36ed-488c-b615-6ad89fcc92dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-4fae8199-226d-4547-8501-eb5e95028354,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-ea85a2e4-0fe9-401f-bdbb-023733e70d60,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-005fbbd4-308f-45da-bf2d-89b6a690befd,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-1027d513-e51d-4edd-8f2f-010db202586e,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-cfa49d85-51a7-4d2d-aabb-e4c5cb8c3202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687014616-172.17.0.19-1595988722410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38263,DS-383b4dae-ebdb-4425-8e52-fc1124880004,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-f58cb4c6-aaa5-4065-bc75-5c5da3e0cf21,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-a025c384-36ed-488c-b615-6ad89fcc92dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-4fae8199-226d-4547-8501-eb5e95028354,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-ea85a2e4-0fe9-401f-bdbb-023733e70d60,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-005fbbd4-308f-45da-bf2d-89b6a690befd,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-1027d513-e51d-4edd-8f2f-010db202586e,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-cfa49d85-51a7-4d2d-aabb-e4c5cb8c3202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774288439-172.17.0.19-1595989434496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39940,DS-c2fe536c-3c8c-4f35-af7a-1ee1779a5195,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-9d3dd0b4-9f18-46bc-a29a-dc67ccc7d50c,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-53218258-0276-4ed2-a391-e05de3aa1704,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-b42edfae-d2c5-47fe-8837-7504ace8ade8,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-065b2c65-a453-4e16-99f9-99aa2a670748,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-c3104d3e-e24e-4042-a2d8-79ddbe122252,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-258690de-02d4-41db-b5c5-95deeb020ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-2033700c-e33e-4b04-bb55-77e4772b8e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774288439-172.17.0.19-1595989434496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39940,DS-c2fe536c-3c8c-4f35-af7a-1ee1779a5195,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-9d3dd0b4-9f18-46bc-a29a-dc67ccc7d50c,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-53218258-0276-4ed2-a391-e05de3aa1704,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-b42edfae-d2c5-47fe-8837-7504ace8ade8,DISK], DatanodeInfoWithStorage[127.0.0.1:41264,DS-065b2c65-a453-4e16-99f9-99aa2a670748,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-c3104d3e-e24e-4042-a2d8-79ddbe122252,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-258690de-02d4-41db-b5c5-95deeb020ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-2033700c-e33e-4b04-bb55-77e4772b8e4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755707892-172.17.0.19-1595990114375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33737,DS-4018d7d3-6896-4472-9843-6d9fa1291024,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-7ee29379-1f16-4329-b152-7ec259f09a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-e4a5dccb-8410-4783-b4c3-5020c69028f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-abd11318-14b6-4c07-8b45-b5ab60564b81,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-1a2fee15-68a4-468d-b514-fa8f85e59ead,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-2d22fab0-54fd-41ed-ae38-2a257d309402,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-440a63f8-b860-4ac4-97dd-c4587c59a192,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-9a4d30e0-716b-4cae-a42f-87f85a8e8988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1755707892-172.17.0.19-1595990114375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33737,DS-4018d7d3-6896-4472-9843-6d9fa1291024,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-7ee29379-1f16-4329-b152-7ec259f09a64,DISK], DatanodeInfoWithStorage[127.0.0.1:40800,DS-e4a5dccb-8410-4783-b4c3-5020c69028f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-abd11318-14b6-4c07-8b45-b5ab60564b81,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-1a2fee15-68a4-468d-b514-fa8f85e59ead,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-2d22fab0-54fd-41ed-ae38-2a257d309402,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-440a63f8-b860-4ac4-97dd-c4587c59a192,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-9a4d30e0-716b-4cae-a42f-87f85a8e8988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146022324-172.17.0.19-1595991090258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43246,DS-a218385c-da1d-47e1-86a7-86acad375f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-02105eeb-d747-4992-bb76-1bd2b80c4df2,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-701d7ce7-d71d-4313-b5bc-b5b7154aea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-e00daed5-f6e8-4d67-b331-23fecd147552,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-ee6e8f9d-1a21-4c92-9c2e-4355ab673bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-9d71c705-8b5f-456d-b93d-8057ce5cd00a,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-d19a38d2-a839-446d-8c55-8583f3974549,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-86a1b54c-7bcc-4fb0-82e0-288565d606ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146022324-172.17.0.19-1595991090258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43246,DS-a218385c-da1d-47e1-86a7-86acad375f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-02105eeb-d747-4992-bb76-1bd2b80c4df2,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-701d7ce7-d71d-4313-b5bc-b5b7154aea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-e00daed5-f6e8-4d67-b331-23fecd147552,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-ee6e8f9d-1a21-4c92-9c2e-4355ab673bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-9d71c705-8b5f-456d-b93d-8057ce5cd00a,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-d19a38d2-a839-446d-8c55-8583f3974549,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-86a1b54c-7bcc-4fb0-82e0-288565d606ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636500150-172.17.0.19-1595991421344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33763,DS-ab94baa6-2d34-4e6f-9925-7b81abef8414,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-464c7043-7631-4e5b-b9f0-5a2b0624b3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-6c010811-aec3-4c5f-a8df-a56bc9fe58fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-1b9d7175-06a5-472c-9505-5f31fb85cb56,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-b064af4a-e8ab-4ae2-ba04-2854bc07535d,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-a08febd9-506e-431c-9e4e-d2fac8a11427,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-80686bda-4614-4201-9183-5598589b9ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-837b01c9-89a5-4894-b5ff-90427bdd6b53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636500150-172.17.0.19-1595991421344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33763,DS-ab94baa6-2d34-4e6f-9925-7b81abef8414,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-464c7043-7631-4e5b-b9f0-5a2b0624b3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-6c010811-aec3-4c5f-a8df-a56bc9fe58fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-1b9d7175-06a5-472c-9505-5f31fb85cb56,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-b064af4a-e8ab-4ae2-ba04-2854bc07535d,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-a08febd9-506e-431c-9e4e-d2fac8a11427,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-80686bda-4614-4201-9183-5598589b9ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-837b01c9-89a5-4894-b5ff-90427bdd6b53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501566555-172.17.0.19-1595991654951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41530,DS-c98c389d-5bde-4449-a6ea-7d73f402f394,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-dd8aa87c-7ce1-4978-ad42-78cc483508db,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-7e413cd8-66e8-42ad-bd87-8a0bb68bc943,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-40aa113c-b0bc-4f94-8756-c6c36c6d947c,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-4cfe81b0-dd2b-4567-82c8-bcccf2c53e82,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-5eeb17de-7e76-433d-bc32-80986ea8c02c,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-e406c210-5e33-46bd-91af-c8002e9c6e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-f5d998f6-350e-4a1a-b6ba-2a2a876f00ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501566555-172.17.0.19-1595991654951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41530,DS-c98c389d-5bde-4449-a6ea-7d73f402f394,DISK], DatanodeInfoWithStorage[127.0.0.1:43353,DS-dd8aa87c-7ce1-4978-ad42-78cc483508db,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-7e413cd8-66e8-42ad-bd87-8a0bb68bc943,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-40aa113c-b0bc-4f94-8756-c6c36c6d947c,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-4cfe81b0-dd2b-4567-82c8-bcccf2c53e82,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-5eeb17de-7e76-433d-bc32-80986ea8c02c,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-e406c210-5e33-46bd-91af-c8002e9c6e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-f5d998f6-350e-4a1a-b6ba-2a2a876f00ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576924105-172.17.0.19-1595991955603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45807,DS-6cfa7afd-7909-4493-8c74-3ff5dfdb782b,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-f2ed6e39-18d7-4670-a35d-0ce593fa882b,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-2549269e-2543-43f4-b4d5-63716bcf126b,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-79b8d10a-2392-4f62-b425-671c895728cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-58997750-32b3-4d11-a77a-adb6ec021af4,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-c503f83e-b5b4-4c09-806a-eb074c2140e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-4af7f6bd-ea34-486a-9e9e-19d2d98ee30a,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-b13b13b0-2132-49be-8515-04f2d6efd5d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576924105-172.17.0.19-1595991955603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45807,DS-6cfa7afd-7909-4493-8c74-3ff5dfdb782b,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-f2ed6e39-18d7-4670-a35d-0ce593fa882b,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-2549269e-2543-43f4-b4d5-63716bcf126b,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-79b8d10a-2392-4f62-b425-671c895728cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-58997750-32b3-4d11-a77a-adb6ec021af4,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-c503f83e-b5b4-4c09-806a-eb074c2140e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-4af7f6bd-ea34-486a-9e9e-19d2d98ee30a,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-b13b13b0-2132-49be-8515-04f2d6efd5d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215948710-172.17.0.19-1595991992690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33137,DS-4d45ef33-6ea5-4609-b594-98c5c657a0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-6769a5af-b5d6-4b58-a184-72ecd6c0c556,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-238fd440-d607-489d-9daf-0e4fe546f9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-28f668ee-25d6-454e-bfd8-770dc0a76875,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-6b441a98-fca9-4640-90fc-7b932e979770,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-66bb5f7f-bcdd-482c-b55b-37fcce0dddc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-65a5f465-311a-4974-ad4a-bbe969a1cd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-39242e8d-92a2-423c-bcd1-af971b733540,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215948710-172.17.0.19-1595991992690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33137,DS-4d45ef33-6ea5-4609-b594-98c5c657a0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45140,DS-6769a5af-b5d6-4b58-a184-72ecd6c0c556,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-238fd440-d607-489d-9daf-0e4fe546f9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-28f668ee-25d6-454e-bfd8-770dc0a76875,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-6b441a98-fca9-4640-90fc-7b932e979770,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-66bb5f7f-bcdd-482c-b55b-37fcce0dddc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-65a5f465-311a-4974-ad4a-bbe969a1cd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-39242e8d-92a2-423c-bcd1-af971b733540,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506527705-172.17.0.19-1595992073769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38790,DS-dc7f9b89-9932-464a-ac1d-5e290802389b,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-ad8d7a3c-467c-476f-96ea-8bf3720949af,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-654234e9-cbd5-4b24-9c90-2d188347dffe,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-90d3b6bf-d47f-40de-b50e-fc0f5a38014a,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-78f1a1f3-47e9-414f-946a-8281537118c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-3a6a11e6-3e41-44a0-9d60-fb01922ad426,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-3bb0dc3d-737e-4148-a8ac-1cd9d14325f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-965411ff-f4dd-4032-94bf-678735665c5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506527705-172.17.0.19-1595992073769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38790,DS-dc7f9b89-9932-464a-ac1d-5e290802389b,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-ad8d7a3c-467c-476f-96ea-8bf3720949af,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-654234e9-cbd5-4b24-9c90-2d188347dffe,DISK], DatanodeInfoWithStorage[127.0.0.1:36531,DS-90d3b6bf-d47f-40de-b50e-fc0f5a38014a,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-78f1a1f3-47e9-414f-946a-8281537118c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-3a6a11e6-3e41-44a0-9d60-fb01922ad426,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-3bb0dc3d-737e-4148-a8ac-1cd9d14325f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-965411ff-f4dd-4032-94bf-678735665c5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061094201-172.17.0.19-1595992151771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41796,DS-64f0288b-a03e-4b02-a424-dc22ddb03a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-2601b689-9b17-4897-a805-dd4a80dff39c,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-317e98f6-90c2-4a5a-b03e-36cb9f7d7954,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-30f1a1a4-a028-4934-975c-a13afeab6b44,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-e20c3cec-726e-4c84-8ad0-922b09ed7309,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-3cd2fe38-576a-4958-8c5f-02c44de4ebc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-6d2ddc65-4d54-41b9-a74b-0a8b2d872398,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-500bf83d-6dd6-409c-8247-f033aa9943ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061094201-172.17.0.19-1595992151771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41796,DS-64f0288b-a03e-4b02-a424-dc22ddb03a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-2601b689-9b17-4897-a805-dd4a80dff39c,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-317e98f6-90c2-4a5a-b03e-36cb9f7d7954,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-30f1a1a4-a028-4934-975c-a13afeab6b44,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-e20c3cec-726e-4c84-8ad0-922b09ed7309,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-3cd2fe38-576a-4958-8c5f-02c44de4ebc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-6d2ddc65-4d54-41b9-a74b-0a8b2d872398,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-500bf83d-6dd6-409c-8247-f033aa9943ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418999772-172.17.0.19-1595992188848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36630,DS-42a98322-064f-4ce8-9bdc-802549384d65,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-55c0b1e2-99c7-4896-9007-d8190ea7775a,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-54c2e559-fbf2-4032-8cab-a3ee00b597cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-7cb58a9f-b209-4220-b666-6aa5e0446ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-9d69078a-773b-4f8b-a65e-17520733475e,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-982122e2-46e2-4ac4-9707-85e37b66731d,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-710a32bd-c6df-49b6-bc8e-49a5b51c1927,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-25361c19-9eb9-4847-91d0-3060ffa301dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418999772-172.17.0.19-1595992188848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36630,DS-42a98322-064f-4ce8-9bdc-802549384d65,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-55c0b1e2-99c7-4896-9007-d8190ea7775a,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-54c2e559-fbf2-4032-8cab-a3ee00b597cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-7cb58a9f-b209-4220-b666-6aa5e0446ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-9d69078a-773b-4f8b-a65e-17520733475e,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-982122e2-46e2-4ac4-9707-85e37b66731d,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-710a32bd-c6df-49b6-bc8e-49a5b51c1927,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-25361c19-9eb9-4847-91d0-3060ffa301dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680433557-172.17.0.19-1595992303952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39748,DS-5d11d00f-641c-4f72-995e-def98571070d,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-6dd7c587-ee34-42b9-8115-b76163bd0c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-5a93878e-fc99-4e58-906e-9d7ceefe5d41,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-cba1fb59-341f-4e02-bdc7-a7fa0f4b0c10,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-097fe68c-e8f9-490b-a0c4-981cd3c52cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-434817cd-08b0-4201-88ef-bcf95e78d02f,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-77408aa4-53c1-472c-8fd1-a7e7eaa48625,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-18eb0676-12d7-4fab-a54b-175df7189a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680433557-172.17.0.19-1595992303952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39748,DS-5d11d00f-641c-4f72-995e-def98571070d,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-6dd7c587-ee34-42b9-8115-b76163bd0c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-5a93878e-fc99-4e58-906e-9d7ceefe5d41,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-cba1fb59-341f-4e02-bdc7-a7fa0f4b0c10,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-097fe68c-e8f9-490b-a0c4-981cd3c52cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-434817cd-08b0-4201-88ef-bcf95e78d02f,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-77408aa4-53c1-472c-8fd1-a7e7eaa48625,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-18eb0676-12d7-4fab-a54b-175df7189a3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 70000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158211017-172.17.0.19-1595992544823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34237,DS-9eb0b91e-19e0-492b-bb75-39af91773cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-e003fb33-7670-4f90-968e-7f7dbd5b8c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-654add5f-11a6-4c86-a84e-9797158a74e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-d5947d7d-09a1-47e3-a07b-76fb48ee17b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-8a158e42-d08d-4446-85f4-1bc8d19e1ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-b4b0cc23-ffdc-404a-82fe-d2dfc680a842,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-630a697c-58dd-4ddd-b50c-07a77397c29b,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-08b7e626-89c1-475f-a8ab-9afb8adb6dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158211017-172.17.0.19-1595992544823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34237,DS-9eb0b91e-19e0-492b-bb75-39af91773cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-e003fb33-7670-4f90-968e-7f7dbd5b8c81,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-654add5f-11a6-4c86-a84e-9797158a74e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-d5947d7d-09a1-47e3-a07b-76fb48ee17b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-8a158e42-d08d-4446-85f4-1bc8d19e1ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-b4b0cc23-ffdc-404a-82fe-d2dfc680a842,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-630a697c-58dd-4ddd-b50c-07a77397c29b,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-08b7e626-89c1-475f-a8ab-9afb8adb6dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5576
