reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327334135-172.17.0.3-1596017397905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-20392ff4-a8f3-4f46-bddc-5be761bedb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-aa1f677c-556f-4d02-9853-2f4e0e472e03,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-1e71c8fb-2b51-4d1d-96de-39a944663ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-9838d35e-a9e7-4c54-ba6d-a629768bbe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-2e3b0d58-f908-4f88-9bc4-fa84a4bd0439,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-780f5909-19d7-4273-a499-da0487fb3038,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-a8917582-fa20-49c4-828d-f832db28ae1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-844a9b93-d346-4884-b240-b086ba146b47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-327334135-172.17.0.3-1596017397905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-20392ff4-a8f3-4f46-bddc-5be761bedb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-aa1f677c-556f-4d02-9853-2f4e0e472e03,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-1e71c8fb-2b51-4d1d-96de-39a944663ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-9838d35e-a9e7-4c54-ba6d-a629768bbe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-2e3b0d58-f908-4f88-9bc4-fa84a4bd0439,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-780f5909-19d7-4273-a499-da0487fb3038,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-a8917582-fa20-49c4-828d-f832db28ae1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-844a9b93-d346-4884-b240-b086ba146b47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624840906-172.17.0.3-1596017640662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37988,DS-9f629d23-c968-4526-ba58-e3dc4e784385,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-d5c2cbae-3aea-4b08-bae8-2eef4294e8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-7851420b-2833-4393-a143-959ae1766ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-bc7af550-8e18-43b4-8d2b-4978cf3dae3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-184adac9-b171-4810-a582-f458e22856c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-b333b27f-494e-4e08-b001-f638626e02f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-b00fb501-a037-4d45-837c-c40f542054ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-6ecd564f-8524-4977-b829-e13b06003326,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624840906-172.17.0.3-1596017640662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37988,DS-9f629d23-c968-4526-ba58-e3dc4e784385,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-d5c2cbae-3aea-4b08-bae8-2eef4294e8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-7851420b-2833-4393-a143-959ae1766ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-bc7af550-8e18-43b4-8d2b-4978cf3dae3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-184adac9-b171-4810-a582-f458e22856c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-b333b27f-494e-4e08-b001-f638626e02f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-b00fb501-a037-4d45-837c-c40f542054ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-6ecd564f-8524-4977-b829-e13b06003326,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000327832-172.17.0.3-1596017785522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36267,DS-7043a416-1207-4a15-8abc-8954d47b7d07,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-25969790-748d-41bd-8617-c957c3b96d78,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-fe4401fe-e786-4dd1-87f7-a08e41a35dda,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-4a2c6e81-5b27-469a-a6b8-a281ac3bd3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-0be9757a-c221-4c30-b67e-fc01f7f7af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-f1e88ba5-339d-4d66-9cb7-87e46e12c175,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-4b8e5023-e5f5-4723-aba4-b83cc33bfcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-bece1b9b-2379-4faf-a8fe-1ea94bd91707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000327832-172.17.0.3-1596017785522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36267,DS-7043a416-1207-4a15-8abc-8954d47b7d07,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-25969790-748d-41bd-8617-c957c3b96d78,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-fe4401fe-e786-4dd1-87f7-a08e41a35dda,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-4a2c6e81-5b27-469a-a6b8-a281ac3bd3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40270,DS-0be9757a-c221-4c30-b67e-fc01f7f7af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-f1e88ba5-339d-4d66-9cb7-87e46e12c175,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-4b8e5023-e5f5-4723-aba4-b83cc33bfcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-bece1b9b-2379-4faf-a8fe-1ea94bd91707,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774033429-172.17.0.3-1596018724306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42203,DS-02482465-97f8-4f23-a3d2-317145e404b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-9e55d76b-b712-47df-a3d9-d15e6d7ec922,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-56fd1b92-5361-464f-b59f-57fef8c77773,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-2876c12b-c1c3-4460-a260-33cb690eee33,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-d1e7c9bf-ba4e-469f-bf9e-4a5212fa7752,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-4690d6db-e467-478d-92fe-5cd0f128bba8,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-09f714d5-89af-4b0e-af78-319a5a1dce7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-582552ca-a8a9-4347-b9a2-26f0689d6f80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774033429-172.17.0.3-1596018724306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42203,DS-02482465-97f8-4f23-a3d2-317145e404b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-9e55d76b-b712-47df-a3d9-d15e6d7ec922,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-56fd1b92-5361-464f-b59f-57fef8c77773,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-2876c12b-c1c3-4460-a260-33cb690eee33,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-d1e7c9bf-ba4e-469f-bf9e-4a5212fa7752,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-4690d6db-e467-478d-92fe-5cd0f128bba8,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-09f714d5-89af-4b0e-af78-319a5a1dce7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-582552ca-a8a9-4347-b9a2-26f0689d6f80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134083628-172.17.0.3-1596018844154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44546,DS-5b5bde60-90b4-4d3e-bc5f-cf3e1bfef66b,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-4f4ce241-112f-422a-8bac-dbbe025d3cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-35c89994-5561-4afd-b38a-287e91dbb333,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-fee6a7e8-46ff-4347-b1dd-0ec94c264583,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-e7fb493d-c863-4142-baa6-12e3eaef8274,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-e2e17409-8fd2-4842-899f-a8b1a22e9bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-159a6104-1f06-4e62-ac32-de22e7dced0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-f1734294-a779-4470-b1c5-8c2f0e1618bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134083628-172.17.0.3-1596018844154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44546,DS-5b5bde60-90b4-4d3e-bc5f-cf3e1bfef66b,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-4f4ce241-112f-422a-8bac-dbbe025d3cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-35c89994-5561-4afd-b38a-287e91dbb333,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-fee6a7e8-46ff-4347-b1dd-0ec94c264583,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-e7fb493d-c863-4142-baa6-12e3eaef8274,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-e2e17409-8fd2-4842-899f-a8b1a22e9bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-159a6104-1f06-4e62-ac32-de22e7dced0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-f1734294-a779-4470-b1c5-8c2f0e1618bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049754275-172.17.0.3-1596018987148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39477,DS-6df5f722-ba60-4a0f-8d9b-504b5a46431b,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-2f01a08a-4a1a-48ec-ad6e-42b69bcd35e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-4c3b097a-05e8-41e8-bc1a-4e5fe36e82b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-ef8c9d9e-5e41-4f44-9c95-69615a2176f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-b8d4fbf4-1515-4b5a-83fa-71f2b34b95a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-a287861b-5556-4b08-896e-d60c46aa3d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-0d59f9da-8712-4187-874f-d4b3a9f4bf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-3df45964-6a2e-41fc-abf4-aee304444300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049754275-172.17.0.3-1596018987148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39477,DS-6df5f722-ba60-4a0f-8d9b-504b5a46431b,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-2f01a08a-4a1a-48ec-ad6e-42b69bcd35e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-4c3b097a-05e8-41e8-bc1a-4e5fe36e82b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-ef8c9d9e-5e41-4f44-9c95-69615a2176f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-b8d4fbf4-1515-4b5a-83fa-71f2b34b95a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-a287861b-5556-4b08-896e-d60c46aa3d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-0d59f9da-8712-4187-874f-d4b3a9f4bf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-3df45964-6a2e-41fc-abf4-aee304444300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1363679204-172.17.0.3-1596019995156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42066,DS-58252be1-2e19-4519-ac25-3913833586ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-b3f99dcd-9fd5-4b3f-846b-34940717fe05,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-9f5de8a1-34aa-4042-9687-ead6048ac8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-fd23da57-9fb4-4016-9e0e-cc3e94d0bab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-d2892b27-ae9a-4e67-9d39-bc0392eb6993,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-f46bfd24-1545-4f2d-8da0-86bcfefab709,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-81d37d0b-ee92-4156-99dc-32cd33fe347d,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-eb3fb0fb-2f6d-4b64-a81b-916c228e0c09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1363679204-172.17.0.3-1596019995156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42066,DS-58252be1-2e19-4519-ac25-3913833586ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-b3f99dcd-9fd5-4b3f-846b-34940717fe05,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-9f5de8a1-34aa-4042-9687-ead6048ac8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-fd23da57-9fb4-4016-9e0e-cc3e94d0bab6,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-d2892b27-ae9a-4e67-9d39-bc0392eb6993,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-f46bfd24-1545-4f2d-8da0-86bcfefab709,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-81d37d0b-ee92-4156-99dc-32cd33fe347d,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-eb3fb0fb-2f6d-4b64-a81b-916c228e0c09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856459536-172.17.0.3-1596020089536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41142,DS-a27ccae5-37d2-4bdf-9cbe-05ff0edaf209,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-249d5dd4-4964-480d-88a6-a3c9d47656bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-1d00e28c-5edc-4d56-ab76-2d695cd104eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-be2a5242-60d2-4c6d-8533-f2ec11effccb,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-b52714c9-ca7d-47ea-ac76-b59c141ed07e,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-fba1d440-baf4-4fc7-a287-baf49d19ac90,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-a3593651-9661-4d8a-9636-8bec251fddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-5b021bd7-76ef-4daf-b4d7-3905eb1978fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856459536-172.17.0.3-1596020089536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41142,DS-a27ccae5-37d2-4bdf-9cbe-05ff0edaf209,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-249d5dd4-4964-480d-88a6-a3c9d47656bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-1d00e28c-5edc-4d56-ab76-2d695cd104eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-be2a5242-60d2-4c6d-8533-f2ec11effccb,DISK], DatanodeInfoWithStorage[127.0.0.1:33775,DS-b52714c9-ca7d-47ea-ac76-b59c141ed07e,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-fba1d440-baf4-4fc7-a287-baf49d19ac90,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-a3593651-9661-4d8a-9636-8bec251fddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-5b021bd7-76ef-4daf-b4d7-3905eb1978fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430157395-172.17.0.3-1596021180847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42952,DS-68537bc6-9dee-4166-864a-760cba506eac,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-678f4682-f921-4f0b-b21d-df6c2085dc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-a0fd489f-8bd9-49d6-a3af-ef4a6caf839a,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-86735334-7d2b-476a-b163-c6f2e9f39e57,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-63ff65cd-0258-41cf-9656-ff773938fe11,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-ab3828d3-bf59-4005-a894-1f70dea42642,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-cb052b60-3a74-43eb-84d4-6b0fbd3c0d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-1a2bfb4b-267d-48de-80d0-114d132903b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430157395-172.17.0.3-1596021180847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42952,DS-68537bc6-9dee-4166-864a-760cba506eac,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-678f4682-f921-4f0b-b21d-df6c2085dc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-a0fd489f-8bd9-49d6-a3af-ef4a6caf839a,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-86735334-7d2b-476a-b163-c6f2e9f39e57,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-63ff65cd-0258-41cf-9656-ff773938fe11,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-ab3828d3-bf59-4005-a894-1f70dea42642,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-cb052b60-3a74-43eb-84d4-6b0fbd3c0d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-1a2bfb4b-267d-48de-80d0-114d132903b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329735571-172.17.0.3-1596021985774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41205,DS-86687229-97b5-4965-9eef-2d404b240b28,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-140d30ca-29fd-42ae-bfe4-a1faa9059541,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-0e8e46c1-f11e-41d5-80bc-586e0545c3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-e58682c1-a020-437c-b4d1-45ad8f8a8f01,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-9b013053-3d82-4000-83af-691a30ed411f,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-49a263a9-e2fa-4ecd-b301-31ad2a427515,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-92e41127-5bde-432a-9561-be01adbd6885,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-20a75825-5a4e-4c60-8be5-d19ec1b47eaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1329735571-172.17.0.3-1596021985774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41205,DS-86687229-97b5-4965-9eef-2d404b240b28,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-140d30ca-29fd-42ae-bfe4-a1faa9059541,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-0e8e46c1-f11e-41d5-80bc-586e0545c3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-e58682c1-a020-437c-b4d1-45ad8f8a8f01,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-9b013053-3d82-4000-83af-691a30ed411f,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-49a263a9-e2fa-4ecd-b301-31ad2a427515,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-92e41127-5bde-432a-9561-be01adbd6885,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-20a75825-5a4e-4c60-8be5-d19ec1b47eaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098882151-172.17.0.3-1596022147416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38090,DS-527aa385-cc63-4b39-8067-bd4dda7783e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-6f8a7e9e-c3b0-4eb2-b471-2822d8c02c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-05b19e56-8ce8-4772-8e88-76c57b927d13,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-d56d64cb-7803-4051-ac75-0333a3d564eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-1aa12c15-2e20-4a93-8aa4-da5c1c80ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-18c41ad7-f1fe-4d9c-a371-87fa8dc63bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-1dddfee4-876e-44a6-98fd-14aed398607e,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-7f5eda09-e83a-4523-8288-422516c431af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098882151-172.17.0.3-1596022147416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38090,DS-527aa385-cc63-4b39-8067-bd4dda7783e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-6f8a7e9e-c3b0-4eb2-b471-2822d8c02c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-05b19e56-8ce8-4772-8e88-76c57b927d13,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-d56d64cb-7803-4051-ac75-0333a3d564eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-1aa12c15-2e20-4a93-8aa4-da5c1c80ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-18c41ad7-f1fe-4d9c-a371-87fa8dc63bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-1dddfee4-876e-44a6-98fd-14aed398607e,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-7f5eda09-e83a-4523-8288-422516c431af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5660
