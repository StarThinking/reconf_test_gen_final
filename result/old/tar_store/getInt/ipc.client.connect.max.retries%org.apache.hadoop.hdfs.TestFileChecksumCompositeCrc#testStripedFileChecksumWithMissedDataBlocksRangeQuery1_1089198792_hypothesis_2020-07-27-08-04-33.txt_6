reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957856140-172.17.0.8-1595837116646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39789,DS-94e10c93-b9cf-4aeb-9327-2d63410ce603,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-1f0d298d-ee73-47d9-9ab8-99a56f031301,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-50c688d5-63e5-42ba-b8bf-c6b938344a39,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-38e30b0e-78b1-449b-9a25-6bae6e8b8846,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-82df1ad9-8340-41a7-bb86-02e94c2fc04c,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-23b6ed99-a576-404c-80cb-69bf9974b96f,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-8671920c-1f7c-40be-9803-9a559e833d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-22b3de75-63a5-4e30-a531-74daa49ae732,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957856140-172.17.0.8-1595837116646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39789,DS-94e10c93-b9cf-4aeb-9327-2d63410ce603,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-1f0d298d-ee73-47d9-9ab8-99a56f031301,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-50c688d5-63e5-42ba-b8bf-c6b938344a39,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-38e30b0e-78b1-449b-9a25-6bae6e8b8846,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-82df1ad9-8340-41a7-bb86-02e94c2fc04c,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-23b6ed99-a576-404c-80cb-69bf9974b96f,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-8671920c-1f7c-40be-9803-9a559e833d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-22b3de75-63a5-4e30-a531-74daa49ae732,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1281609395-172.17.0.8-1595837257312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46295,DS-b4763968-cf7d-45df-9cdc-4aa6433959ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-eef9dbe9-41a0-4841-ad3f-e983cbadc0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-c40de565-3499-4e0c-8e04-23cdf9a6005e,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-d1751a24-2fd5-486f-885f-cd73a70f8705,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-11a676b8-dd4d-45fa-99b0-e2b828d34882,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-739b79d3-a6a3-49c2-93ab-012c60fe92f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-6be22e95-e8a3-414a-ae46-4062a24af1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-d455ca00-c6c9-4ccd-a09c-5d9e5f479d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1281609395-172.17.0.8-1595837257312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46295,DS-b4763968-cf7d-45df-9cdc-4aa6433959ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-eef9dbe9-41a0-4841-ad3f-e983cbadc0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-c40de565-3499-4e0c-8e04-23cdf9a6005e,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-d1751a24-2fd5-486f-885f-cd73a70f8705,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-11a676b8-dd4d-45fa-99b0-e2b828d34882,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-739b79d3-a6a3-49c2-93ab-012c60fe92f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-6be22e95-e8a3-414a-ae46-4062a24af1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-d455ca00-c6c9-4ccd-a09c-5d9e5f479d73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587525107-172.17.0.8-1595837803255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45251,DS-e1db74f5-044b-4944-b227-ef1423743333,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-2923f110-fae6-409c-94bb-c320c25cf8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-963ea22a-2b31-47a9-9a20-fb5c4598088d,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-d57ef88a-d3b0-47a5-8ddc-a26a71693eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-22eadb72-1fef-48f8-9c6c-d45efa45f416,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-17d5df2b-ba5a-4f28-b134-3353d28889c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-ed802f3b-ab77-44da-b720-466bb43c6323,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-82f1e84f-f694-4209-a318-e0791039860e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587525107-172.17.0.8-1595837803255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45251,DS-e1db74f5-044b-4944-b227-ef1423743333,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-2923f110-fae6-409c-94bb-c320c25cf8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-963ea22a-2b31-47a9-9a20-fb5c4598088d,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-d57ef88a-d3b0-47a5-8ddc-a26a71693eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-22eadb72-1fef-48f8-9c6c-d45efa45f416,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-17d5df2b-ba5a-4f28-b134-3353d28889c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-ed802f3b-ab77-44da-b720-466bb43c6323,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-82f1e84f-f694-4209-a318-e0791039860e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185615578-172.17.0.8-1595838487787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35539,DS-5745cadd-7ec7-4576-b9ea-a1c619ccb83c,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-02613e8a-deae-4621-bee9-8232dd830fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-ccde5daf-e658-4638-a4ac-0edf956bce3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-782e8adb-8d9e-494e-8b58-c77e7dc028c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-d1792192-5bde-43ef-b10c-725507a34313,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-cbfb05c7-1b7c-44bc-a4d3-3b7556662abf,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-4e5067da-7aa5-4ac4-856a-9b7b2bcd21c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-73d7ff83-51f6-46ec-b4d7-f35eb65fe9a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-185615578-172.17.0.8-1595838487787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35539,DS-5745cadd-7ec7-4576-b9ea-a1c619ccb83c,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-02613e8a-deae-4621-bee9-8232dd830fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-ccde5daf-e658-4638-a4ac-0edf956bce3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-782e8adb-8d9e-494e-8b58-c77e7dc028c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-d1792192-5bde-43ef-b10c-725507a34313,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-cbfb05c7-1b7c-44bc-a4d3-3b7556662abf,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-4e5067da-7aa5-4ac4-856a-9b7b2bcd21c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-73d7ff83-51f6-46ec-b4d7-f35eb65fe9a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615793532-172.17.0.8-1595838532693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-969756ff-a845-43c5-bb54-1b60e22602e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-d443538e-20e7-4981-b370-93421bc693f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-77d8060d-f6cc-4fb9-bcbb-ed42efd25b48,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-54393e26-3f37-4688-af8e-05dfbbd3890e,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-41491e9e-88a9-47d1-b106-5b755bd2fb54,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-0befefdc-7538-4310-be1e-a4d74e9587a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-d9686c56-879b-4d84-a68c-05db4a6839ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-939e8d93-93b8-4bce-b662-3a7eb216dd56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615793532-172.17.0.8-1595838532693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-969756ff-a845-43c5-bb54-1b60e22602e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-d443538e-20e7-4981-b370-93421bc693f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-77d8060d-f6cc-4fb9-bcbb-ed42efd25b48,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-54393e26-3f37-4688-af8e-05dfbbd3890e,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-41491e9e-88a9-47d1-b106-5b755bd2fb54,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-0befefdc-7538-4310-be1e-a4d74e9587a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-d9686c56-879b-4d84-a68c-05db4a6839ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-939e8d93-93b8-4bce-b662-3a7eb216dd56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223694227-172.17.0.8-1595838602755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34590,DS-22e69200-f13b-45a4-8175-3cb4c2878bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-cfd3c5ee-0daf-45b6-965a-90fa65acf2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-df36a7fe-0c96-4726-a9a4-87758403f0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-36334d57-3ba5-473f-be58-0bbe05b4f4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-2d085b97-fd57-4c53-946a-267b76d55600,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-fe558c11-ca20-4174-a159-4cbef519c152,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-b7d0bd48-29b9-44ce-9deb-cdb9ec88e350,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-10c1e68e-68a8-4d46-ae61-ffab1c118273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223694227-172.17.0.8-1595838602755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34590,DS-22e69200-f13b-45a4-8175-3cb4c2878bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-cfd3c5ee-0daf-45b6-965a-90fa65acf2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-df36a7fe-0c96-4726-a9a4-87758403f0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-36334d57-3ba5-473f-be58-0bbe05b4f4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-2d085b97-fd57-4c53-946a-267b76d55600,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-fe558c11-ca20-4174-a159-4cbef519c152,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-b7d0bd48-29b9-44ce-9deb-cdb9ec88e350,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-10c1e68e-68a8-4d46-ae61-ffab1c118273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817316226-172.17.0.8-1595838641699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42246,DS-56902d6c-7e44-4cd6-9295-0075c1387727,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-7ca8d727-dcbb-45a9-9302-7c3b0b35332e,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-fd7769d7-a9b6-4e20-89f3-2d6e24a4699f,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-10ee4d0d-cba0-44f9-aa7e-35f71fb9c6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-ed072cb2-0bac-480f-b8f0-7baf4ed28445,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-7bc7279b-245f-4018-90b2-f722923854b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-b85d5995-40a1-40df-b32e-716cfe6cbd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-15b3a327-cff3-4da4-97ac-c79d81018751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-817316226-172.17.0.8-1595838641699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42246,DS-56902d6c-7e44-4cd6-9295-0075c1387727,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-7ca8d727-dcbb-45a9-9302-7c3b0b35332e,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-fd7769d7-a9b6-4e20-89f3-2d6e24a4699f,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-10ee4d0d-cba0-44f9-aa7e-35f71fb9c6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-ed072cb2-0bac-480f-b8f0-7baf4ed28445,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-7bc7279b-245f-4018-90b2-f722923854b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-b85d5995-40a1-40df-b32e-716cfe6cbd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-15b3a327-cff3-4da4-97ac-c79d81018751,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665265285-172.17.0.8-1595838680159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41098,DS-db8a3214-f3a8-4929-bdbc-eb35d44dd2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-00d08935-5965-414b-80a5-f7e4bcb76e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-269bd0f0-de4f-4778-afe0-31065f483dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-93286caa-1c2b-43f6-9819-4e2c48529b10,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-d852b3de-96fd-4a26-9661-4ff4ad5dce84,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-93410415-3e8a-4a7a-ae9a-6a631c9ffa22,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-60ce4693-3048-41f5-978e-1c7aa6529685,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-4c440318-0a7e-4059-a900-1e89eecdc60a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665265285-172.17.0.8-1595838680159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41098,DS-db8a3214-f3a8-4929-bdbc-eb35d44dd2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-00d08935-5965-414b-80a5-f7e4bcb76e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-269bd0f0-de4f-4778-afe0-31065f483dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-93286caa-1c2b-43f6-9819-4e2c48529b10,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-d852b3de-96fd-4a26-9661-4ff4ad5dce84,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-93410415-3e8a-4a7a-ae9a-6a631c9ffa22,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-60ce4693-3048-41f5-978e-1c7aa6529685,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-4c440318-0a7e-4059-a900-1e89eecdc60a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317986857-172.17.0.8-1595839625873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42857,DS-7759a7d6-ad66-4489-b6eb-bc3d638415a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-19318b74-c61f-49bc-a74c-1e00e8187f39,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-024eec0d-8ff2-4419-89c9-d8fe19fb088f,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-821784b1-783e-4270-a10c-c597e989e4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-279560d4-4a0d-4c1d-b44a-2941ef441d94,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-a27cbdb3-2cfa-4c5a-95db-e4a7ed7a09bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-45bec5d0-919f-4528-a2f3-6af6108270bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-29225f98-4c40-4137-8ef4-270587f3a764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317986857-172.17.0.8-1595839625873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42857,DS-7759a7d6-ad66-4489-b6eb-bc3d638415a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-19318b74-c61f-49bc-a74c-1e00e8187f39,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-024eec0d-8ff2-4419-89c9-d8fe19fb088f,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-821784b1-783e-4270-a10c-c597e989e4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-279560d4-4a0d-4c1d-b44a-2941ef441d94,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-a27cbdb3-2cfa-4c5a-95db-e4a7ed7a09bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-45bec5d0-919f-4528-a2f3-6af6108270bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-29225f98-4c40-4137-8ef4-270587f3a764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855008412-172.17.0.8-1595841221139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39646,DS-ae98e094-da4b-4359-8f82-8cd45bac43cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-82a21568-b14d-46ac-bd27-78ab15cb47f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-4502b426-4a52-4c7c-aede-782b2a685df8,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-1c8971b9-de30-403f-ba2e-85ce39c5e8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-49236967-a718-4316-bd92-61deff0a2218,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-24adcd6a-5041-4a27-b20d-abc2dfe20930,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-ee5628ec-6035-4650-980a-265e30d39349,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-a8adca52-fd75-40a4-b178-2815776a0128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855008412-172.17.0.8-1595841221139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39646,DS-ae98e094-da4b-4359-8f82-8cd45bac43cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-82a21568-b14d-46ac-bd27-78ab15cb47f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-4502b426-4a52-4c7c-aede-782b2a685df8,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-1c8971b9-de30-403f-ba2e-85ce39c5e8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-49236967-a718-4316-bd92-61deff0a2218,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-24adcd6a-5041-4a27-b20d-abc2dfe20930,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-ee5628ec-6035-4650-980a-265e30d39349,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-a8adca52-fd75-40a4-b178-2815776a0128,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484313116-172.17.0.8-1595841409781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38195,DS-7a36b862-7919-49df-a462-3f6d1f14bda4,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-2cf2f234-1d65-4e53-b38d-8f6b326fb53d,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-92e226f8-2f40-449e-964d-933cffc5f574,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-10b9c95b-dc89-4f13-8741-cca4d70811ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-96d36964-cf32-4052-867f-5a6e6e5a7753,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-a11c5de6-7bdc-44a1-bf60-ec3771f7ced4,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-fec6881c-2701-455d-9044-0d39d55c6bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-8110e8c6-e218-4a92-9435-a9b4b013c5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484313116-172.17.0.8-1595841409781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38195,DS-7a36b862-7919-49df-a462-3f6d1f14bda4,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-2cf2f234-1d65-4e53-b38d-8f6b326fb53d,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-92e226f8-2f40-449e-964d-933cffc5f574,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-10b9c95b-dc89-4f13-8741-cca4d70811ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-96d36964-cf32-4052-867f-5a6e6e5a7753,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-a11c5de6-7bdc-44a1-bf60-ec3771f7ced4,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-fec6881c-2701-455d-9044-0d39d55c6bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-8110e8c6-e218-4a92-9435-a9b4b013c5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153341332-172.17.0.8-1595841954845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46430,DS-943797f7-4c81-4751-929b-9207a5f8d588,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-3917e3fe-b3c9-4090-99de-8b2b34a22757,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-3738b522-14e5-4d55-8eb3-5ef802d9b8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-4c74d0ed-8606-42cd-9055-834ba5844620,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-06932f7e-1094-45f2-a430-40bb53ac8aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-e612c600-c419-4850-b4cb-26848f382467,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-4b4b06db-272b-4ddc-a61b-cf1eaa58a8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-6ebd9a99-9345-4cb3-930a-eaa189d4213a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1153341332-172.17.0.8-1595841954845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46430,DS-943797f7-4c81-4751-929b-9207a5f8d588,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-3917e3fe-b3c9-4090-99de-8b2b34a22757,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-3738b522-14e5-4d55-8eb3-5ef802d9b8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-4c74d0ed-8606-42cd-9055-834ba5844620,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-06932f7e-1094-45f2-a430-40bb53ac8aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-e612c600-c419-4850-b4cb-26848f382467,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-4b4b06db-272b-4ddc-a61b-cf1eaa58a8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-6ebd9a99-9345-4cb3-930a-eaa189d4213a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098821374-172.17.0.8-1595842147912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35583,DS-989538f0-1a33-4038-bf05-75e342b525b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-d5eb3c6f-3d10-4d89-b922-88911ca1e2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-e449615f-2e67-4703-8109-38a5412d95de,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-2d45d7b7-c42d-4da4-8a60-b44e31db5fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-14331aa8-9960-4d74-83c7-d38e2b7d1987,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-f416e6bf-2165-49c6-bdaa-5f309dc88661,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-d5590c27-3067-4eb2-8ebd-bfbeef8536aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-4c1a3122-a8eb-4c4a-b840-627fd2bf8e10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098821374-172.17.0.8-1595842147912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35583,DS-989538f0-1a33-4038-bf05-75e342b525b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-d5eb3c6f-3d10-4d89-b922-88911ca1e2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-e449615f-2e67-4703-8109-38a5412d95de,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-2d45d7b7-c42d-4da4-8a60-b44e31db5fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-14331aa8-9960-4d74-83c7-d38e2b7d1987,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-f416e6bf-2165-49c6-bdaa-5f309dc88661,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-d5590c27-3067-4eb2-8ebd-bfbeef8536aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-4c1a3122-a8eb-4c4a-b840-627fd2bf8e10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9689216-172.17.0.8-1595842463180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45492,DS-cf452a5f-7df8-4b24-bd39-2c28d329a0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-1760f057-1931-49ca-8083-a5fec65f3b43,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-200f78a8-a238-4c1e-993a-c43d61bc3eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-212c9aeb-6595-4977-be10-d2ea2f0633a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-b57e1109-4dcf-443c-8a6a-bb8e1c2c6cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-7d2cefe0-c60b-4c78-abc2-4d24f2018ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-60ede38d-2465-4cbd-a12a-cbb54eabe1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-bedfe923-17a8-40e8-b9e3-1e65e9a3b0b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-9689216-172.17.0.8-1595842463180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45492,DS-cf452a5f-7df8-4b24-bd39-2c28d329a0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-1760f057-1931-49ca-8083-a5fec65f3b43,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-200f78a8-a238-4c1e-993a-c43d61bc3eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-212c9aeb-6595-4977-be10-d2ea2f0633a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-b57e1109-4dcf-443c-8a6a-bb8e1c2c6cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-7d2cefe0-c60b-4c78-abc2-4d24f2018ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-60ede38d-2465-4cbd-a12a-cbb54eabe1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-bedfe923-17a8-40e8-b9e3-1e65e9a3b0b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5448
