reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662847972-172.17.0.4-1595847598851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39803,DS-cff2dcfc-ee7b-4bf4-840f-d7089ac6e549,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-cf30a11d-3f89-42d6-b533-23e1316055d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-9ff03084-71cb-4bbf-a374-41798ad422b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-c41f4822-bdc3-4368-ae2c-82bfa469b34d,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-83251e5a-6d26-47fe-bd3d-792f6179d315,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-27844dd7-69e1-4487-aa42-d16f56e48d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-a801283a-2dbd-4873-a4b2-ffca35ca4b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-24c7a8f0-b590-461d-a3af-32b5d60d65ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662847972-172.17.0.4-1595847598851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39803,DS-cff2dcfc-ee7b-4bf4-840f-d7089ac6e549,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-cf30a11d-3f89-42d6-b533-23e1316055d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-9ff03084-71cb-4bbf-a374-41798ad422b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40072,DS-c41f4822-bdc3-4368-ae2c-82bfa469b34d,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-83251e5a-6d26-47fe-bd3d-792f6179d315,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-27844dd7-69e1-4487-aa42-d16f56e48d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-a801283a-2dbd-4873-a4b2-ffca35ca4b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-24c7a8f0-b590-461d-a3af-32b5d60d65ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224576986-172.17.0.4-1595848187571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34234,DS-890d06b7-9b58-4d21-b76a-9eadcd34f205,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-79ae4764-427d-4769-b34b-a90873eb463c,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-23e87699-e8fb-4084-8083-4dd4feb84c81,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-6fdffcdd-39fe-4977-9ab2-8e18c3ea8aac,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-27a59861-6f96-4b94-af82-24c50f7d5145,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-38ac02fe-a04e-4409-97b5-af9516a14b20,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-e8e98f90-8d2e-4410-afcd-880798ebc5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-d15a4b66-523c-4bea-8571-5e8f2f304034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1224576986-172.17.0.4-1595848187571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34234,DS-890d06b7-9b58-4d21-b76a-9eadcd34f205,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-79ae4764-427d-4769-b34b-a90873eb463c,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-23e87699-e8fb-4084-8083-4dd4feb84c81,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-6fdffcdd-39fe-4977-9ab2-8e18c3ea8aac,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-27a59861-6f96-4b94-af82-24c50f7d5145,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-38ac02fe-a04e-4409-97b5-af9516a14b20,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-e8e98f90-8d2e-4410-afcd-880798ebc5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-d15a4b66-523c-4bea-8571-5e8f2f304034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430798035-172.17.0.4-1595849558292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46683,DS-87a47515-fa5a-41d0-b5fe-cac11e6e2055,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-e945057f-0d7c-40b9-ab04-327767bba51b,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-084b931b-0ab1-45aa-91ec-f27059d84f55,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-9a886a8a-2f97-4543-b706-c1cdcc7f2b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-8bfc4e4a-cbde-4124-8c74-6e1cb1dca8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-a0ac41dd-0a0e-4005-8c2a-3eb6e58875af,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-9fd11459-6cdc-453d-866d-855759850d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-0266ce3e-46af-419f-b46a-cec80b94c4ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430798035-172.17.0.4-1595849558292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46683,DS-87a47515-fa5a-41d0-b5fe-cac11e6e2055,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-e945057f-0d7c-40b9-ab04-327767bba51b,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-084b931b-0ab1-45aa-91ec-f27059d84f55,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-9a886a8a-2f97-4543-b706-c1cdcc7f2b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-8bfc4e4a-cbde-4124-8c74-6e1cb1dca8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-a0ac41dd-0a0e-4005-8c2a-3eb6e58875af,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-9fd11459-6cdc-453d-866d-855759850d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-0266ce3e-46af-419f-b46a-cec80b94c4ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121069435-172.17.0.4-1595849980172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41703,DS-098715ae-e1dd-463f-b8ea-dd14c21b0741,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-9f0fbb7e-27bd-48f3-a44d-701370593c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-a9bf7e19-da78-493c-a963-3cda7ed3f2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-acb45fd4-afef-48c8-b074-11d2fdbc075b,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-01c339b9-c276-48df-9c2a-6e8a62a4fa68,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-19c74b56-d714-4edd-849d-353e95fa469e,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-0b888b48-d2af-4251-b017-006e17acbac1,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-6146cf05-5ddd-49aa-bf74-35030cd1cab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121069435-172.17.0.4-1595849980172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41703,DS-098715ae-e1dd-463f-b8ea-dd14c21b0741,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-9f0fbb7e-27bd-48f3-a44d-701370593c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-a9bf7e19-da78-493c-a963-3cda7ed3f2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-acb45fd4-afef-48c8-b074-11d2fdbc075b,DISK], DatanodeInfoWithStorage[127.0.0.1:43738,DS-01c339b9-c276-48df-9c2a-6e8a62a4fa68,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-19c74b56-d714-4edd-849d-353e95fa469e,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-0b888b48-d2af-4251-b017-006e17acbac1,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-6146cf05-5ddd-49aa-bf74-35030cd1cab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171925085-172.17.0.4-1595850130920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-8030a0d6-3d2d-46ec-a808-8d89aeafce45,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-314cc985-b6fa-4858-8a14-89a92e7b6962,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-719f9262-9774-4e89-abb4-24b61be6eaee,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-5b293511-fbe5-493a-ad24-13517ea0961e,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-6c3826bd-eaa6-45de-8e39-9b8d11cab794,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-b2624ebe-9550-45ca-9fd3-62049d6e2fff,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-dddefdcd-d41a-4e8c-8d2d-b5b51f7046bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-419667c5-27d4-4770-9a7d-a2a53bbfc4f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-171925085-172.17.0.4-1595850130920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-8030a0d6-3d2d-46ec-a808-8d89aeafce45,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-314cc985-b6fa-4858-8a14-89a92e7b6962,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-719f9262-9774-4e89-abb4-24b61be6eaee,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-5b293511-fbe5-493a-ad24-13517ea0961e,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-6c3826bd-eaa6-45de-8e39-9b8d11cab794,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-b2624ebe-9550-45ca-9fd3-62049d6e2fff,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-dddefdcd-d41a-4e8c-8d2d-b5b51f7046bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-419667c5-27d4-4770-9a7d-a2a53bbfc4f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367323011-172.17.0.4-1595850365247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34793,DS-85b5aa00-cf03-4526-9890-0a9d35d8f015,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-c6bbcca2-23bf-469b-ae3a-53b3c568f86b,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-115ceb86-49ac-430f-91bf-1cef0a9c0bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-b00367ff-73db-46a0-beac-58a6721e7571,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-2f9ca9b9-398c-4adc-94bd-ea406d7b4549,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-9b48b2b4-2ded-450a-b8a6-0b7acd39d294,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-bb6b4b53-b632-4aa1-b849-92f48e1120f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-098a8176-a793-49f5-9108-068a4e52b140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367323011-172.17.0.4-1595850365247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34793,DS-85b5aa00-cf03-4526-9890-0a9d35d8f015,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-c6bbcca2-23bf-469b-ae3a-53b3c568f86b,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-115ceb86-49ac-430f-91bf-1cef0a9c0bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-b00367ff-73db-46a0-beac-58a6721e7571,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-2f9ca9b9-398c-4adc-94bd-ea406d7b4549,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-9b48b2b4-2ded-450a-b8a6-0b7acd39d294,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-bb6b4b53-b632-4aa1-b849-92f48e1120f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-098a8176-a793-49f5-9108-068a4e52b140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531526743-172.17.0.4-1595850462618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39217,DS-af0cb63a-591a-4bf6-8e2c-28af4a434d64,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-8384c007-7e97-4d74-8c17-2b13dc284b58,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-c9e4f2f5-7572-449b-b57f-532808e03f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-c398a84f-d955-4872-b502-abbbce3d8614,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-d64d7002-b52c-4ce2-8f9f-126dd8798e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-63308328-bdd1-428f-b518-a4b5e428a06b,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-e50f49e7-fa9c-43d6-a2b4-7f23a457bcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-8a96faec-8214-4568-a2d0-a862a65d2b55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531526743-172.17.0.4-1595850462618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39217,DS-af0cb63a-591a-4bf6-8e2c-28af4a434d64,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-8384c007-7e97-4d74-8c17-2b13dc284b58,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-c9e4f2f5-7572-449b-b57f-532808e03f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-c398a84f-d955-4872-b502-abbbce3d8614,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-d64d7002-b52c-4ce2-8f9f-126dd8798e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-63308328-bdd1-428f-b518-a4b5e428a06b,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-e50f49e7-fa9c-43d6-a2b4-7f23a457bcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-8a96faec-8214-4568-a2d0-a862a65d2b55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295741714-172.17.0.4-1595851581056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36173,DS-7e5039bc-375f-4d37-8bbb-38b6051a710e,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-d39cb13f-14a3-422e-9237-f66332142452,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-cb9d1882-2f5a-4125-a7a2-06bb913ffd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-157116f4-9691-4e24-babc-ce621c68c2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-87a3adab-6e5d-4d86-926e-c0bd955fcd41,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-00cb038e-b25d-4a1a-a9a2-4ec6d67875d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-c6f5dd3b-31cf-4ba6-b88b-3f1f9e07cd51,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-e3248532-b976-4b8c-b602-8a1e763b00cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295741714-172.17.0.4-1595851581056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36173,DS-7e5039bc-375f-4d37-8bbb-38b6051a710e,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-d39cb13f-14a3-422e-9237-f66332142452,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-cb9d1882-2f5a-4125-a7a2-06bb913ffd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-157116f4-9691-4e24-babc-ce621c68c2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-87a3adab-6e5d-4d86-926e-c0bd955fcd41,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-00cb038e-b25d-4a1a-a9a2-4ec6d67875d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-c6f5dd3b-31cf-4ba6-b88b-3f1f9e07cd51,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-e3248532-b976-4b8c-b602-8a1e763b00cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 5000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965774225-172.17.0.4-1595851933628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35621,DS-ac2b3d5c-4bdb-4e90-bd62-bd86004e710f,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-d1f23c0c-ed12-4df6-b072-25a5fc5edc98,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-1e995e30-aace-412f-97c0-4c65c5d72ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-76263210-2cc6-4d8c-bd09-19922b37133b,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-66704ba4-bb79-4a21-ab77-9fe9ff7d226f,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-c2ae5cde-1f98-41f9-8196-0b48fe4a146f,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-77e808ba-3514-4aa9-9d50-d8df8ef248ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-119ffb9c-5812-46ea-a08c-8fb4ced5506f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965774225-172.17.0.4-1595851933628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35621,DS-ac2b3d5c-4bdb-4e90-bd62-bd86004e710f,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-d1f23c0c-ed12-4df6-b072-25a5fc5edc98,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-1e995e30-aace-412f-97c0-4c65c5d72ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-76263210-2cc6-4d8c-bd09-19922b37133b,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-66704ba4-bb79-4a21-ab77-9fe9ff7d226f,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-c2ae5cde-1f98-41f9-8196-0b48fe4a146f,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-77e808ba-3514-4aa9-9d50-d8df8ef248ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-119ffb9c-5812-46ea-a08c-8fb4ced5506f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 4881
