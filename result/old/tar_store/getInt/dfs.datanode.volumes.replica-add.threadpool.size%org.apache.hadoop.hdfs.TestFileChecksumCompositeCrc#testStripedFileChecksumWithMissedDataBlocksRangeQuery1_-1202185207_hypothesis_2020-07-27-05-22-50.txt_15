reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86647836-172.17.0.4-1595827424860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46520,DS-ce501842-2743-4227-8382-df491dcce174,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-174bc26d-bd74-472d-aedc-0759c55234a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-cf7d4602-8138-42c0-9531-9b81f1ae4a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-964e12be-aeb0-4f0e-a31f-7c15b1dc9d31,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-79bde0a4-2b6c-4789-885b-a8fccb8390cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-bb4c046c-530d-4119-aacf-42ee25f0e97a,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-75cb424a-d962-4302-a8e5-11a13403e89c,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-24f74302-a0ce-42ea-8b1a-02a4839887c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86647836-172.17.0.4-1595827424860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46520,DS-ce501842-2743-4227-8382-df491dcce174,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-174bc26d-bd74-472d-aedc-0759c55234a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-cf7d4602-8138-42c0-9531-9b81f1ae4a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-964e12be-aeb0-4f0e-a31f-7c15b1dc9d31,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-79bde0a4-2b6c-4789-885b-a8fccb8390cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-bb4c046c-530d-4119-aacf-42ee25f0e97a,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-75cb424a-d962-4302-a8e5-11a13403e89c,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-24f74302-a0ce-42ea-8b1a-02a4839887c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735931351-172.17.0.4-1595827685425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37494,DS-6d536d0e-696d-42c6-8675-7b4bff79d912,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-f3cc8b10-5113-4a4c-aae3-e72173f6c509,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-e189e2c2-475a-4501-9834-6cad30e1c783,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-db5f984a-d16b-421e-b9f7-e849acce1a88,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-b75fc33a-8412-4606-909d-50290536cfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-d0b26449-ed44-4a5a-99c7-3a81c9b5fa22,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-3e0c5e3a-7cd0-45e7-bbaa-6e09faa8512a,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-52c2ddcc-8a25-4f72-881d-1892b4bfff72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735931351-172.17.0.4-1595827685425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37494,DS-6d536d0e-696d-42c6-8675-7b4bff79d912,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-f3cc8b10-5113-4a4c-aae3-e72173f6c509,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-e189e2c2-475a-4501-9834-6cad30e1c783,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-db5f984a-d16b-421e-b9f7-e849acce1a88,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-b75fc33a-8412-4606-909d-50290536cfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-d0b26449-ed44-4a5a-99c7-3a81c9b5fa22,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-3e0c5e3a-7cd0-45e7-bbaa-6e09faa8512a,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-52c2ddcc-8a25-4f72-881d-1892b4bfff72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988882188-172.17.0.4-1595827799265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41918,DS-768df1d0-19c6-400b-a870-9d4b57d95d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-4976873d-d99f-4fca-9fe6-c76214548dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-36c3baea-df19-418e-a6c7-e9623c9d549a,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-740ed556-77f9-4899-a0ac-62c04c4050b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-fa55b297-1761-408b-a5a1-2193e03af0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-10f15168-c767-47b8-8904-978b5935f97c,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-59367319-6104-4a7c-9565-bf1a228751db,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-3fe424c5-dd59-43cb-b476-e6cbd9b60392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988882188-172.17.0.4-1595827799265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41918,DS-768df1d0-19c6-400b-a870-9d4b57d95d05,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-4976873d-d99f-4fca-9fe6-c76214548dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-36c3baea-df19-418e-a6c7-e9623c9d549a,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-740ed556-77f9-4899-a0ac-62c04c4050b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-fa55b297-1761-408b-a5a1-2193e03af0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-10f15168-c767-47b8-8904-978b5935f97c,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-59367319-6104-4a7c-9565-bf1a228751db,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-3fe424c5-dd59-43cb-b476-e6cbd9b60392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896714233-172.17.0.4-1595827833125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39566,DS-fa9167ab-4fad-41f9-b96d-cf7614686d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-94c32f85-ace3-4323-b135-8abffa262f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-41c3289f-6592-4d48-b57d-566a1a98c93d,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-7647454e-128c-4493-94af-122912c5d726,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-fd975a38-b6f3-429f-ba26-d6ece411f528,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-1d612bdc-5110-4fbf-b19e-9b07f545392f,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-7028d9a9-d397-40cd-aab8-d3955dfdebd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-d76b77ee-7780-49bd-9f83-1bb75f22fbe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896714233-172.17.0.4-1595827833125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39566,DS-fa9167ab-4fad-41f9-b96d-cf7614686d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-94c32f85-ace3-4323-b135-8abffa262f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-41c3289f-6592-4d48-b57d-566a1a98c93d,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-7647454e-128c-4493-94af-122912c5d726,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-fd975a38-b6f3-429f-ba26-d6ece411f528,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-1d612bdc-5110-4fbf-b19e-9b07f545392f,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-7028d9a9-d397-40cd-aab8-d3955dfdebd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-d76b77ee-7780-49bd-9f83-1bb75f22fbe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368319995-172.17.0.4-1595827975867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34943,DS-8aa7eb47-6265-4f6a-afbb-5c8292f9c9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-af1678bd-eff4-40c7-b43d-1e42e7e519a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-2027fef5-b00f-4ed4-91fa-13bc8dcfcb31,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-95594c2b-7bf5-4863-85f4-6c6aaa58f545,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-a7d22191-9500-4ca3-b55f-2cc9118b15c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-1de57b51-ae38-41d6-937d-4fa336474b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-7fc99fca-1891-44e2-9ee1-78a93c51c90d,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-cecd766c-2b2d-49a6-bdd0-3a76ab76208c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368319995-172.17.0.4-1595827975867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34943,DS-8aa7eb47-6265-4f6a-afbb-5c8292f9c9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-af1678bd-eff4-40c7-b43d-1e42e7e519a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-2027fef5-b00f-4ed4-91fa-13bc8dcfcb31,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-95594c2b-7bf5-4863-85f4-6c6aaa58f545,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-a7d22191-9500-4ca3-b55f-2cc9118b15c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-1de57b51-ae38-41d6-937d-4fa336474b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-7fc99fca-1891-44e2-9ee1-78a93c51c90d,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-cecd766c-2b2d-49a6-bdd0-3a76ab76208c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734032843-172.17.0.4-1595828135172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38036,DS-61e93902-3a06-470c-915d-a6a42b0f5d17,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-64a56786-d0bb-4a1d-bbab-cade129b6fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-d0ee98a7-be91-427d-8994-2a55309bcfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-478e8d9a-33ca-45d4-a2a6-f0b1f1b60157,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-bbf99087-ba26-4a7d-b605-0d39b35129d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-a05d0261-e568-424d-8984-8702410a7e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-019ee3c1-4d35-44a1-a72e-f242c7508aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-70c3f415-77ba-4155-bab8-dc12b6f7f24e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734032843-172.17.0.4-1595828135172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38036,DS-61e93902-3a06-470c-915d-a6a42b0f5d17,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-64a56786-d0bb-4a1d-bbab-cade129b6fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-d0ee98a7-be91-427d-8994-2a55309bcfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-478e8d9a-33ca-45d4-a2a6-f0b1f1b60157,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-bbf99087-ba26-4a7d-b605-0d39b35129d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-a05d0261-e568-424d-8984-8702410a7e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-019ee3c1-4d35-44a1-a72e-f242c7508aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-70c3f415-77ba-4155-bab8-dc12b6f7f24e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019380733-172.17.0.4-1595828323108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46871,DS-00554d7f-ee85-4713-9f3e-0acc7d7ad74d,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-286b71a3-ca3e-4bb6-9258-d53a1630d99b,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-4eea6eeb-3246-4792-bad6-8d2ed14ab433,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-c6e12249-09c3-4461-93cb-c56766c88a26,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-dc13c86f-985e-467f-8a64-1124407bb67c,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-e3de0718-a2e6-43e1-be9c-82075b4b55fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-2b628ad1-0cb8-46f2-88bc-6a382a29a9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-aeaa8ba2-fcea-43c5-b5e8-09a0209dae3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1019380733-172.17.0.4-1595828323108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46871,DS-00554d7f-ee85-4713-9f3e-0acc7d7ad74d,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-286b71a3-ca3e-4bb6-9258-d53a1630d99b,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-4eea6eeb-3246-4792-bad6-8d2ed14ab433,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-c6e12249-09c3-4461-93cb-c56766c88a26,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-dc13c86f-985e-467f-8a64-1124407bb67c,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-e3de0718-a2e6-43e1-be9c-82075b4b55fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-2b628ad1-0cb8-46f2-88bc-6a382a29a9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-aeaa8ba2-fcea-43c5-b5e8-09a0209dae3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137094605-172.17.0.4-1595828436314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45886,DS-1c0b58aa-bc17-4b08-b745-244733841482,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-827c2fb2-31a9-4896-a21f-612a42903ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-795d5e81-7af2-4190-b701-0fdfd0479448,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-db160c1a-fca1-44ea-b53b-ebe9d2a91505,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-c6cf6622-2b51-4523-b307-7321e40c9c81,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-8a999851-9492-4a1f-9b17-7f28ab38a695,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-76985a41-2574-4ece-98ea-f4e7c97b2fef,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-c24d72c9-5058-4eb9-9a27-0f6ad0d22cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137094605-172.17.0.4-1595828436314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45886,DS-1c0b58aa-bc17-4b08-b745-244733841482,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-827c2fb2-31a9-4896-a21f-612a42903ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-795d5e81-7af2-4190-b701-0fdfd0479448,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-db160c1a-fca1-44ea-b53b-ebe9d2a91505,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-c6cf6622-2b51-4523-b307-7321e40c9c81,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-8a999851-9492-4a1f-9b17-7f28ab38a695,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-76985a41-2574-4ece-98ea-f4e7c97b2fef,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-c24d72c9-5058-4eb9-9a27-0f6ad0d22cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539165391-172.17.0.4-1595828702731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36878,DS-d887f32f-f8f6-44ab-8155-807d3abf0b59,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-282ac324-a034-4f0d-b0cb-5321455f4389,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-dd6f144a-995d-4241-a3f3-25b700e781e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-469fd82e-c035-42a4-a2b0-9eda259769c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-300fef5b-8da9-4d29-aaa0-1ff1ad0c4423,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-0901d482-94cd-41e8-a3df-f2fc72e963e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-5dd6a932-0482-4828-b35f-38adeaaf7373,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-c469ed2f-65af-495c-88a9-4ec9f8d6ddbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539165391-172.17.0.4-1595828702731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36878,DS-d887f32f-f8f6-44ab-8155-807d3abf0b59,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-282ac324-a034-4f0d-b0cb-5321455f4389,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-dd6f144a-995d-4241-a3f3-25b700e781e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-469fd82e-c035-42a4-a2b0-9eda259769c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39184,DS-300fef5b-8da9-4d29-aaa0-1ff1ad0c4423,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-0901d482-94cd-41e8-a3df-f2fc72e963e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-5dd6a932-0482-4828-b35f-38adeaaf7373,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-c469ed2f-65af-495c-88a9-4ec9f8d6ddbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693862122-172.17.0.4-1595828827566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40683,DS-2910208b-1de1-4297-9faa-45e361e0c00a,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-213e8a1d-dd2e-4d4b-b0d5-81e9e57a1f54,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-91ae7610-36ce-440a-870f-8f9565571084,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-68867717-3906-4f3c-8fd6-83cb05d8c97b,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-fceef5d9-5059-4d9c-a4aa-9344aa29533c,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-9730b522-7fe7-41b2-835d-c1cc0e78d5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-73e8d33b-6104-4c2b-9e86-074433ac8a98,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-50cb1358-10db-41b5-9e06-14bf550d2013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693862122-172.17.0.4-1595828827566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40683,DS-2910208b-1de1-4297-9faa-45e361e0c00a,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-213e8a1d-dd2e-4d4b-b0d5-81e9e57a1f54,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-91ae7610-36ce-440a-870f-8f9565571084,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-68867717-3906-4f3c-8fd6-83cb05d8c97b,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-fceef5d9-5059-4d9c-a4aa-9344aa29533c,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-9730b522-7fe7-41b2-835d-c1cc0e78d5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-73e8d33b-6104-4c2b-9e86-074433ac8a98,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-50cb1358-10db-41b5-9e06-14bf550d2013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500067445-172.17.0.4-1595829100433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-6a0a7d4c-5df8-4deb-af29-638dae20dc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-fcdd43ef-420d-4385-bb06-93ae82f9b218,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-90fd6683-d025-4319-81bb-5ec175f7acf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-d7820bcf-48ff-4c9f-9b08-8e16b048fd99,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-f4cb5998-9bd8-4c3f-81cb-77cbd3ac1aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-c18f4f9a-2017-4211-ad6c-4a70959a9a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-fbedbcca-2674-40bc-9eb6-d36524751c23,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-0212a627-a7cb-455a-86d6-b716b0442e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500067445-172.17.0.4-1595829100433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-6a0a7d4c-5df8-4deb-af29-638dae20dc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-fcdd43ef-420d-4385-bb06-93ae82f9b218,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-90fd6683-d025-4319-81bb-5ec175f7acf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-d7820bcf-48ff-4c9f-9b08-8e16b048fd99,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-f4cb5998-9bd8-4c3f-81cb-77cbd3ac1aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-c18f4f9a-2017-4211-ad6c-4a70959a9a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-fbedbcca-2674-40bc-9eb6-d36524751c23,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-0212a627-a7cb-455a-86d6-b716b0442e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2122616863-172.17.0.4-1595830352021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32899,DS-2de6891f-24df-4fa9-b675-86699cab4208,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-924c20b0-ae53-48de-a8ed-ae2777834457,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-2bb5ab12-b020-468f-a9de-18af2e3232a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-277f0ca3-25e7-43de-ba2b-922cfaa91f97,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-6ea09223-77b2-47c1-b30f-dd6dc5a14780,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-a30613c5-9334-44ef-bd37-8bba1354006a,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-9146809f-e694-45d7-b1f5-ecf0957d0d08,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-0166898b-2f1a-4d04-a89e-a108dd0607f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2122616863-172.17.0.4-1595830352021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32899,DS-2de6891f-24df-4fa9-b675-86699cab4208,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-924c20b0-ae53-48de-a8ed-ae2777834457,DISK], DatanodeInfoWithStorage[127.0.0.1:32942,DS-2bb5ab12-b020-468f-a9de-18af2e3232a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-277f0ca3-25e7-43de-ba2b-922cfaa91f97,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-6ea09223-77b2-47c1-b30f-dd6dc5a14780,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-a30613c5-9334-44ef-bd37-8bba1354006a,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-9146809f-e694-45d7-b1f5-ecf0957d0d08,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-0166898b-2f1a-4d04-a89e-a108dd0607f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122313636-172.17.0.4-1595830542205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39041,DS-3d4014c4-04e3-4bac-9ecd-509fb3e2e41c,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-751aacb1-72cc-47d7-b82d-7d91cbd25ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-67c85c9a-9692-4ec1-8105-5646c35f4fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-4f234acf-5a7c-40a7-8be0-231abe924682,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-809a87eb-0350-4b61-bdb0-f99c63e7cd05,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-92d96779-1226-4fe7-aacd-e846195415c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-a12a9e68-fee3-4238-a055-3f2979c82370,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-f5ad5348-6c21-406e-8cb6-b6262f4895e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122313636-172.17.0.4-1595830542205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39041,DS-3d4014c4-04e3-4bac-9ecd-509fb3e2e41c,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-751aacb1-72cc-47d7-b82d-7d91cbd25ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-67c85c9a-9692-4ec1-8105-5646c35f4fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-4f234acf-5a7c-40a7-8be0-231abe924682,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-809a87eb-0350-4b61-bdb0-f99c63e7cd05,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-92d96779-1226-4fe7-aacd-e846195415c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-a12a9e68-fee3-4238-a055-3f2979c82370,DISK], DatanodeInfoWithStorage[127.0.0.1:41335,DS-f5ad5348-6c21-406e-8cb6-b6262f4895e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884408285-172.17.0.4-1595830932505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46542,DS-a20321af-7d25-4f9a-bf6b-54540dcd32cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-fdeabfba-2903-4fb7-8853-bee087639d84,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-126cb695-cb94-4cbe-8c37-fcb63d214529,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-651f4b61-81e8-474f-9cd7-47505fe4faa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-e74c7687-720e-4fce-8146-7836d1349f42,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-bde0bc13-2575-4e3b-9344-97cf59482a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-029e59c2-51ac-4853-bd1c-a1039a66952f,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-1d1ce140-db5c-416c-a022-cfd0c9eeeca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884408285-172.17.0.4-1595830932505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46542,DS-a20321af-7d25-4f9a-bf6b-54540dcd32cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-fdeabfba-2903-4fb7-8853-bee087639d84,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-126cb695-cb94-4cbe-8c37-fcb63d214529,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-651f4b61-81e8-474f-9cd7-47505fe4faa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-e74c7687-720e-4fce-8146-7836d1349f42,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-bde0bc13-2575-4e3b-9344-97cf59482a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-029e59c2-51ac-4853-bd1c-a1039a66952f,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-1d1ce140-db5c-416c-a022-cfd0c9eeeca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545661320-172.17.0.4-1595831106471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34092,DS-6ba63c49-adfc-4067-ad73-e3172764ae14,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-476580eb-4075-436d-89c1-a7fc7991127b,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-14663289-29ba-43a8-9211-f0c977012494,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-28a60028-6684-4d42-88bf-5fcbfebdc69c,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-bc60dfec-a6e6-4ebc-9334-c3001f35f6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-59fc777c-9b55-451b-9f39-26cde45c7ced,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-c2c8a3e7-90f9-4693-a772-2d7a0a5c2e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-ea7a8cd1-2e7e-4091-873e-609f5ba7a23e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545661320-172.17.0.4-1595831106471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34092,DS-6ba63c49-adfc-4067-ad73-e3172764ae14,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-476580eb-4075-436d-89c1-a7fc7991127b,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-14663289-29ba-43a8-9211-f0c977012494,DISK], DatanodeInfoWithStorage[127.0.0.1:43467,DS-28a60028-6684-4d42-88bf-5fcbfebdc69c,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-bc60dfec-a6e6-4ebc-9334-c3001f35f6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-59fc777c-9b55-451b-9f39-26cde45c7ced,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-c2c8a3e7-90f9-4693-a772-2d7a0a5c2e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-ea7a8cd1-2e7e-4091-873e-609f5ba7a23e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401104792-172.17.0.4-1595831379775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34688,DS-5baed878-938f-49f0-8205-cd3697973ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-c8febf37-83aa-48e2-ac65-f49d9019687d,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-30eac42a-acde-4a27-b118-b1d0bf4eaca8,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-d9aeb179-d2f5-4825-9352-30d59b307032,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-9cc8903a-a790-4560-9f8f-0996fc2be37d,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-481d7ea2-c9e1-4b8b-91e8-75f0b23d708f,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-21f5f315-3161-4943-b68f-5892b276b39f,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-24e1e6dd-3239-4ede-99f4-022a66fab2c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401104792-172.17.0.4-1595831379775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34688,DS-5baed878-938f-49f0-8205-cd3697973ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-c8febf37-83aa-48e2-ac65-f49d9019687d,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-30eac42a-acde-4a27-b118-b1d0bf4eaca8,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-d9aeb179-d2f5-4825-9352-30d59b307032,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-9cc8903a-a790-4560-9f8f-0996fc2be37d,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-481d7ea2-c9e1-4b8b-91e8-75f0b23d708f,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-21f5f315-3161-4943-b68f-5892b276b39f,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-24e1e6dd-3239-4ede-99f4-022a66fab2c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65654919-172.17.0.4-1595831616049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40728,DS-ae267a7a-f77c-42ba-be02-5a14077f054b,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-c4dd4f58-7aaa-41ab-b2fa-55bc80e6f9af,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-addd2d29-31ab-4973-b007-f030762686ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-4df28fd3-8665-498e-819a-56d33d4892ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-cdbc2f15-e102-432f-8bd4-eb0dbf4a8d03,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-3a36375d-fdd1-418b-86d7-edaae597c377,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-3d54b72f-f18c-4094-ae10-8edd929dbc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-c1692899-55fc-4dc9-ba1a-c2c9eb501ff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65654919-172.17.0.4-1595831616049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40728,DS-ae267a7a-f77c-42ba-be02-5a14077f054b,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-c4dd4f58-7aaa-41ab-b2fa-55bc80e6f9af,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-addd2d29-31ab-4973-b007-f030762686ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-4df28fd3-8665-498e-819a-56d33d4892ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-cdbc2f15-e102-432f-8bd4-eb0dbf4a8d03,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-3a36375d-fdd1-418b-86d7-edaae597c377,DISK], DatanodeInfoWithStorage[127.0.0.1:41101,DS-3d54b72f-f18c-4094-ae10-8edd929dbc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-c1692899-55fc-4dc9-ba1a-c2c9eb501ff3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298567972-172.17.0.4-1595832393379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38146,DS-6d8e34ec-80c6-4cf9-b272-bfa668c2d5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-68acd1ad-a466-41c4-93e0-1011cb3ba146,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-b9069d4c-b0df-4c01-bba2-81f2e318b029,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-30e7c4c9-1017-4e19-9cda-5ab636d70485,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-edc1e12e-4a53-4ce8-b598-7d0dfe98fea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-3014f284-e9ad-48e9-a6d7-079c309d75f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-9f7ceb0e-b2c2-40f8-a6a8-9a325a76f28a,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-78352442-c57f-4956-8a32-46e5d8212ab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298567972-172.17.0.4-1595832393379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38146,DS-6d8e34ec-80c6-4cf9-b272-bfa668c2d5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-68acd1ad-a466-41c4-93e0-1011cb3ba146,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-b9069d4c-b0df-4c01-bba2-81f2e318b029,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-30e7c4c9-1017-4e19-9cda-5ab636d70485,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-edc1e12e-4a53-4ce8-b598-7d0dfe98fea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-3014f284-e9ad-48e9-a6d7-079c309d75f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-9f7ceb0e-b2c2-40f8-a6a8-9a325a76f28a,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-78352442-c57f-4956-8a32-46e5d8212ab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374441114-172.17.0.4-1595832619585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46258,DS-013d3a81-d3e0-4aa5-8bf9-4c019472c9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-316715a8-23bc-41f2-9d55-2e054d04b7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-8ece2a40-7e2b-453b-808e-520b3956dc19,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-828dd74e-418c-4b9f-9050-d8e9042be9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-747d3cef-63c2-4ae6-b399-468985887ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-80f41f24-145f-4e12-b35e-713ded50e760,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-4b367d80-ae37-4b22-8486-bbe925aa1ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-26b41b1e-e360-4b99-ab44-457e5be8d762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374441114-172.17.0.4-1595832619585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46258,DS-013d3a81-d3e0-4aa5-8bf9-4c019472c9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-316715a8-23bc-41f2-9d55-2e054d04b7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-8ece2a40-7e2b-453b-808e-520b3956dc19,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-828dd74e-418c-4b9f-9050-d8e9042be9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-747d3cef-63c2-4ae6-b399-468985887ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-80f41f24-145f-4e12-b35e-713ded50e760,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-4b367d80-ae37-4b22-8486-bbe925aa1ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-26b41b1e-e360-4b99-ab44-457e5be8d762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 100
v2: 40
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314819324-172.17.0.4-1595832836265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41637,DS-a0782bfd-fc71-4b6d-a5ce-e28a8d7ca9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-5b3d0c11-ff61-4d9c-be0d-34e7870d6d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-fbabd7d8-c8f6-4ebf-85c3-b0b25383118e,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-7efbfa26-5c7e-43c9-9513-d5bc7af07149,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-f9b6fe83-2dd9-4a6b-95d2-64692ff63962,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-ae465579-d53e-401a-bd18-4da53dbbafbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-18c31de1-68fd-49b4-9fe3-b03c71d959d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-c731849b-51ea-4c32-be1c-4b470b05dae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314819324-172.17.0.4-1595832836265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41637,DS-a0782bfd-fc71-4b6d-a5ce-e28a8d7ca9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-5b3d0c11-ff61-4d9c-be0d-34e7870d6d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-fbabd7d8-c8f6-4ebf-85c3-b0b25383118e,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-7efbfa26-5c7e-43c9-9513-d5bc7af07149,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-f9b6fe83-2dd9-4a6b-95d2-64692ff63962,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-ae465579-d53e-401a-bd18-4da53dbbafbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-18c31de1-68fd-49b4-9fe3-b03c71d959d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-c731849b-51ea-4c32-be1c-4b470b05dae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5688
