reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847477330-172.17.0.4-1595972766582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33271,DS-a795adb7-fbcf-4ff3-b20a-4b89b810a2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-0d861eb3-0121-4463-87ca-1a09e32812b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-faf3417b-5eb1-49f7-a499-30abc8fb1498,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-19bc6a55-78a0-4eb5-8dbf-6d7bc7ddd8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-06626da1-cc98-477a-bde2-5503a0aee417,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-097af1d8-99c6-4a99-a077-2356395de6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-86ce4f2e-338b-4c38-80dd-d9c63f9ee811,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-97427353-1572-40f0-b2a6-373e354deae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847477330-172.17.0.4-1595972766582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33271,DS-a795adb7-fbcf-4ff3-b20a-4b89b810a2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-0d861eb3-0121-4463-87ca-1a09e32812b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-faf3417b-5eb1-49f7-a499-30abc8fb1498,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-19bc6a55-78a0-4eb5-8dbf-6d7bc7ddd8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-06626da1-cc98-477a-bde2-5503a0aee417,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-097af1d8-99c6-4a99-a077-2356395de6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-86ce4f2e-338b-4c38-80dd-d9c63f9ee811,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-97427353-1572-40f0-b2a6-373e354deae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155192096-172.17.0.4-1595972874305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-fb37cbbb-014a-4224-aed9-e5b8dbc0f719,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-2073ed73-bb68-4c03-93dd-08b15405603c,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-b6399e4f-4c2d-4483-8c0c-0bbfef202cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-2ffb7829-93fe-42b3-b2b0-9040ac356f93,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-72de9854-7216-4eb8-8f78-b3d47e63d462,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-6aa47bed-9f1e-4cef-bdb2-adc6d324b7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-6fd73d71-9284-4c1d-9a37-e3806770b489,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-ca6d9c24-c5cb-44d1-801c-93b22dd36387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155192096-172.17.0.4-1595972874305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-fb37cbbb-014a-4224-aed9-e5b8dbc0f719,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-2073ed73-bb68-4c03-93dd-08b15405603c,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-b6399e4f-4c2d-4483-8c0c-0bbfef202cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-2ffb7829-93fe-42b3-b2b0-9040ac356f93,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-72de9854-7216-4eb8-8f78-b3d47e63d462,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-6aa47bed-9f1e-4cef-bdb2-adc6d324b7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-6fd73d71-9284-4c1d-9a37-e3806770b489,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-ca6d9c24-c5cb-44d1-801c-93b22dd36387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618995378-172.17.0.4-1595972910016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44232,DS-1148a5d4-6f34-4ab4-afdc-c115d772500e,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-3a444484-58b5-4c2f-9af5-25fdeb1e7fde,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-b3fd7068-108e-493a-b21b-68f5b5ac6f05,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-7abc2007-5833-45ce-9cbe-76bec32a02c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-a5f47223-4452-4ce5-9442-f090cf7ea51e,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-1d6c5436-6509-4939-9f19-a48930ba2e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-5903ab3e-6fff-4667-bcc3-c3118b6252b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-3711622c-a940-47d6-82c9-bf5e87ee0642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618995378-172.17.0.4-1595972910016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44232,DS-1148a5d4-6f34-4ab4-afdc-c115d772500e,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-3a444484-58b5-4c2f-9af5-25fdeb1e7fde,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-b3fd7068-108e-493a-b21b-68f5b5ac6f05,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-7abc2007-5833-45ce-9cbe-76bec32a02c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-a5f47223-4452-4ce5-9442-f090cf7ea51e,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-1d6c5436-6509-4939-9f19-a48930ba2e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-5903ab3e-6fff-4667-bcc3-c3118b6252b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-3711622c-a940-47d6-82c9-bf5e87ee0642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392606736-172.17.0.4-1595972938331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41836,DS-f06db93d-fb90-4ad5-828d-e8a0f9ada29e,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-29f9b334-cfa5-4ce8-9277-d5390c4d15aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-e51b8de9-8cc7-42ed-bd38-0e38a635b760,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-634474a8-eb5b-4858-9221-9875fff6edc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-9abb373f-c249-4635-a411-677f79487e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-66fd1575-0d18-4562-a10a-c96368384e27,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-a160ecdb-0d32-4cd7-8d76-221daf2ce434,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-39c72ef4-1a20-438b-9b31-2d635ca2ba7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392606736-172.17.0.4-1595972938331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41836,DS-f06db93d-fb90-4ad5-828d-e8a0f9ada29e,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-29f9b334-cfa5-4ce8-9277-d5390c4d15aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-e51b8de9-8cc7-42ed-bd38-0e38a635b760,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-634474a8-eb5b-4858-9221-9875fff6edc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-9abb373f-c249-4635-a411-677f79487e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-66fd1575-0d18-4562-a10a-c96368384e27,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-a160ecdb-0d32-4cd7-8d76-221daf2ce434,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-39c72ef4-1a20-438b-9b31-2d635ca2ba7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492767715-172.17.0.4-1595973579223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39264,DS-1525d478-0b5b-4930-a254-e98609f62927,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-8a9e0c41-3bcd-4dab-996a-b3603e85ab55,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-b34c50d5-08b5-4048-877d-a042eed98d41,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-92f7724e-20d6-4dde-aaf4-061b42a1b8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-e681ae1e-a974-4cc6-984e-fdebe60770ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-a46159bf-6eda-4f0c-ab06-fe8d2988d7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-c7c888df-a6fc-4065-8058-54b32baff258,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-d559dec7-0168-44f2-9246-ce6b5ad5f638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492767715-172.17.0.4-1595973579223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39264,DS-1525d478-0b5b-4930-a254-e98609f62927,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-8a9e0c41-3bcd-4dab-996a-b3603e85ab55,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-b34c50d5-08b5-4048-877d-a042eed98d41,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-92f7724e-20d6-4dde-aaf4-061b42a1b8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-e681ae1e-a974-4cc6-984e-fdebe60770ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-a46159bf-6eda-4f0c-ab06-fe8d2988d7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-c7c888df-a6fc-4065-8058-54b32baff258,DISK], DatanodeInfoWithStorage[127.0.0.1:40344,DS-d559dec7-0168-44f2-9246-ce6b5ad5f638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393635070-172.17.0.4-1595973640175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36658,DS-7c40c5b2-1075-46a4-8d36-61b6e946d029,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-690e43cf-fe0a-4d62-8afc-33fd294fbbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-b6b72f5b-095c-47a7-b757-3dbf26364bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-340f9076-cb34-40bc-9d38-754d327c725e,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-7a8d972b-9eaa-448c-a69c-4ada962e7295,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-9302babb-d89f-4f60-979a-6e8b6dd0e0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-33fc6c06-ddbf-4e90-a274-765e84af3a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-22efea22-1675-4c45-a176-7ba4150f699b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393635070-172.17.0.4-1595973640175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36658,DS-7c40c5b2-1075-46a4-8d36-61b6e946d029,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-690e43cf-fe0a-4d62-8afc-33fd294fbbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-b6b72f5b-095c-47a7-b757-3dbf26364bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-340f9076-cb34-40bc-9d38-754d327c725e,DISK], DatanodeInfoWithStorage[127.0.0.1:40136,DS-7a8d972b-9eaa-448c-a69c-4ada962e7295,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-9302babb-d89f-4f60-979a-6e8b6dd0e0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-33fc6c06-ddbf-4e90-a274-765e84af3a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-22efea22-1675-4c45-a176-7ba4150f699b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867409883-172.17.0.4-1595973706055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35237,DS-12dead47-25b3-443b-a2e9-ba3574b81562,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-4d404d20-40e0-4b2a-8b26-ae5a73d40630,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-4ce427fe-d58e-4f11-82c6-58331df0f81d,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-84437ed5-c393-4071-98bd-8b03ec43b208,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-0c701f95-8136-4aa8-be24-37da5bb999aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-f87ee1a1-e55f-4335-a030-8702d7c1d27c,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-40cebe32-c3bc-49e2-9a0f-8d1e0a34eb36,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-2b1b01f2-8053-49c7-adec-9d1a1e5843f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867409883-172.17.0.4-1595973706055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35237,DS-12dead47-25b3-443b-a2e9-ba3574b81562,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-4d404d20-40e0-4b2a-8b26-ae5a73d40630,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-4ce427fe-d58e-4f11-82c6-58331df0f81d,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-84437ed5-c393-4071-98bd-8b03ec43b208,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-0c701f95-8136-4aa8-be24-37da5bb999aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-f87ee1a1-e55f-4335-a030-8702d7c1d27c,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-40cebe32-c3bc-49e2-9a0f-8d1e0a34eb36,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-2b1b01f2-8053-49c7-adec-9d1a1e5843f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-184127662-172.17.0.4-1595974203552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35494,DS-ecaa7905-f972-4aef-8ea0-ac00be8bd2db,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-4b27defc-eb84-426c-8719-eb629a9d5404,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-1cbc45ed-5965-408b-a725-e0f3d29de22b,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-128ef852-f28c-4f7c-b91e-267ded27a1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-c6538fa4-cb4b-418e-833e-7fe81575a9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-9bba37ac-a37d-4255-b4dc-d1738b8ca0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-7c99863b-c857-42ca-8ff7-93c07413aff2,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-6f1f1104-5d6e-46c1-9095-b02fbb1dbac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-184127662-172.17.0.4-1595974203552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35494,DS-ecaa7905-f972-4aef-8ea0-ac00be8bd2db,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-4b27defc-eb84-426c-8719-eb629a9d5404,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-1cbc45ed-5965-408b-a725-e0f3d29de22b,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-128ef852-f28c-4f7c-b91e-267ded27a1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-c6538fa4-cb4b-418e-833e-7fe81575a9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-9bba37ac-a37d-4255-b4dc-d1738b8ca0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-7c99863b-c857-42ca-8ff7-93c07413aff2,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-6f1f1104-5d6e-46c1-9095-b02fbb1dbac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491733181-172.17.0.4-1595974245391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-a4a3db1e-04ee-4c9d-8455-6adb38bb9e63,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-9375a480-29d1-45ad-a6fa-d467658aebd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-3f4f151e-4ee3-4a19-b374-cdbda090f6da,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-5e8b0aec-b131-4372-b8ab-8d7ec1809293,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-30ab7c65-0d39-4e4f-b33a-a417341701b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-e47e37d4-c4c9-4695-a412-58fb99c14f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-9d1611e8-cc32-4667-989b-b0000d215990,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-24f85fa9-bd12-4e1c-97fc-531a46096976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491733181-172.17.0.4-1595974245391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-a4a3db1e-04ee-4c9d-8455-6adb38bb9e63,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-9375a480-29d1-45ad-a6fa-d467658aebd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-3f4f151e-4ee3-4a19-b374-cdbda090f6da,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-5e8b0aec-b131-4372-b8ab-8d7ec1809293,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-30ab7c65-0d39-4e4f-b33a-a417341701b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-e47e37d4-c4c9-4695-a412-58fb99c14f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-9d1611e8-cc32-4667-989b-b0000d215990,DISK], DatanodeInfoWithStorage[127.0.0.1:41779,DS-24f85fa9-bd12-4e1c-97fc-531a46096976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777537251-172.17.0.4-1595974805875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-aa37e73f-34c0-4d0a-aba1-69031d7fd66d,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-802d3201-8185-4213-a12d-41c00931ea82,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-fbb2d1e4-234d-4fb5-b70e-264a340118f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-894b73f6-f472-4e1f-adc8-15a0140ec65b,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-dc21b333-9c59-460f-89e2-7766f223cdef,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-41621a5c-0544-42d9-8375-d39de94ef2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-acd33c74-9a0e-473a-bd7e-0f8360d91cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-f8e419f0-9a29-463d-9a10-2f34ff1d02a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777537251-172.17.0.4-1595974805875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-aa37e73f-34c0-4d0a-aba1-69031d7fd66d,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-802d3201-8185-4213-a12d-41c00931ea82,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-fbb2d1e4-234d-4fb5-b70e-264a340118f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-894b73f6-f472-4e1f-adc8-15a0140ec65b,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-dc21b333-9c59-460f-89e2-7766f223cdef,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-41621a5c-0544-42d9-8375-d39de94ef2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-acd33c74-9a0e-473a-bd7e-0f8360d91cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-f8e419f0-9a29-463d-9a10-2f34ff1d02a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207834521-172.17.0.4-1595974881764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41400,DS-be9a68fa-3f3f-4e30-92d3-cbb5e831b9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-22f2c9dd-44da-40e7-b412-ed28f3bc7e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-ae09e22f-b09f-4243-b9ca-a3bcb214f8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-fa8d74c4-2dd0-47fc-bd3a-574deba3cc84,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-210b2204-ee25-4d26-a76f-5a3ac0c6fd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-98b11316-445e-4d38-afa1-6ba066744b22,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-e41f70bd-fd32-40f3-9075-fc7f709dc8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-8071ce3a-2639-49f2-b4dd-0f744bc16147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207834521-172.17.0.4-1595974881764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41400,DS-be9a68fa-3f3f-4e30-92d3-cbb5e831b9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-22f2c9dd-44da-40e7-b412-ed28f3bc7e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36727,DS-ae09e22f-b09f-4243-b9ca-a3bcb214f8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-fa8d74c4-2dd0-47fc-bd3a-574deba3cc84,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-210b2204-ee25-4d26-a76f-5a3ac0c6fd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-98b11316-445e-4d38-afa1-6ba066744b22,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-e41f70bd-fd32-40f3-9075-fc7f709dc8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-8071ce3a-2639-49f2-b4dd-0f744bc16147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723162060-172.17.0.4-1595976324835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39488,DS-fbe88e23-59d6-4e51-83fc-2789a4041da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-0ebd2e55-aa57-44f0-a151-45deb4c8fe59,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-2b073bf9-da11-4bd7-9490-e8d2814a504c,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-816b26ff-c253-48e7-8368-e691a8a4587a,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-7b281c28-4fd8-4d67-b6b5-6cd437d52ada,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-9eeb8de1-9091-4310-ae12-11a6c64b78e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-8f609466-ce8c-4dae-b093-a0fb71ca6dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-03f4ce1c-588c-4b52-99e2-559bacf24819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723162060-172.17.0.4-1595976324835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39488,DS-fbe88e23-59d6-4e51-83fc-2789a4041da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-0ebd2e55-aa57-44f0-a151-45deb4c8fe59,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-2b073bf9-da11-4bd7-9490-e8d2814a504c,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-816b26ff-c253-48e7-8368-e691a8a4587a,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-7b281c28-4fd8-4d67-b6b5-6cd437d52ada,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-9eeb8de1-9091-4310-ae12-11a6c64b78e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-8f609466-ce8c-4dae-b093-a0fb71ca6dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-03f4ce1c-588c-4b52-99e2-559bacf24819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5587
