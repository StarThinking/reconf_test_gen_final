reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950793267-172.17.0.13-1595957050230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36304,DS-cce9f005-2309-4ecb-ae38-05be9aea9d38,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-f4b206ef-aa98-4a56-8fc0-e744679e06f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-8dfb0545-9853-4cb9-957a-52117134beb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-7be7f095-8468-42c9-98cd-ed3e8ccea1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-8fec4a20-52d7-4cc8-9974-be61867fb8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-a4b7d492-ba8f-4d7a-9b29-49df6ba6dbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-eb178dff-4ab5-4e31-b9d2-87727d0f7ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-6caa2477-c7c6-4c51-9c4d-3ff7af9c403f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950793267-172.17.0.13-1595957050230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36304,DS-cce9f005-2309-4ecb-ae38-05be9aea9d38,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-f4b206ef-aa98-4a56-8fc0-e744679e06f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-8dfb0545-9853-4cb9-957a-52117134beb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-7be7f095-8468-42c9-98cd-ed3e8ccea1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-8fec4a20-52d7-4cc8-9974-be61867fb8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-a4b7d492-ba8f-4d7a-9b29-49df6ba6dbdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-eb178dff-4ab5-4e31-b9d2-87727d0f7ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-6caa2477-c7c6-4c51-9c4d-3ff7af9c403f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636922194-172.17.0.13-1595957505341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42813,DS-708ae0ee-d93e-4487-8ce2-586e6eb9abce,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-e0305fa2-0955-43d1-8a08-c1cfc8dc0cec,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-fb67530b-52c1-4737-91d1-cdc453b3e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-e8b82501-d584-4bdc-9d37-70a178d38420,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-e7a63e47-09fd-4b50-8510-96cf163030da,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-f0477701-206b-480a-baca-92931bf1eef3,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-122ec563-ae8e-426b-ae94-afa42ee69831,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-ee51d8d3-8d03-449f-9d7f-bc403917bf69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636922194-172.17.0.13-1595957505341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42813,DS-708ae0ee-d93e-4487-8ce2-586e6eb9abce,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-e0305fa2-0955-43d1-8a08-c1cfc8dc0cec,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-fb67530b-52c1-4737-91d1-cdc453b3e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-e8b82501-d584-4bdc-9d37-70a178d38420,DISK], DatanodeInfoWithStorage[127.0.0.1:41973,DS-e7a63e47-09fd-4b50-8510-96cf163030da,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-f0477701-206b-480a-baca-92931bf1eef3,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-122ec563-ae8e-426b-ae94-afa42ee69831,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-ee51d8d3-8d03-449f-9d7f-bc403917bf69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894406168-172.17.0.13-1595957610094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39848,DS-964ebac1-17b4-48c3-9c68-a8f60ab0326d,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-9c9b3e5c-ed8c-4363-b2a4-5724841f8c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-5975d758-8405-4f24-954f-4562ac24e4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-98e592e5-f9a4-48a3-b4d4-5d301a65876a,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-55574e12-1a25-48ff-a5a1-5e16b81d889b,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-ea6da9f3-1104-411d-96b6-6456ba7b8ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-10950bc9-deed-4b80-8791-ba46de1c82b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-6757b657-a00d-413c-afdb-4016ce9d3d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894406168-172.17.0.13-1595957610094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39848,DS-964ebac1-17b4-48c3-9c68-a8f60ab0326d,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-9c9b3e5c-ed8c-4363-b2a4-5724841f8c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-5975d758-8405-4f24-954f-4562ac24e4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-98e592e5-f9a4-48a3-b4d4-5d301a65876a,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-55574e12-1a25-48ff-a5a1-5e16b81d889b,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-ea6da9f3-1104-411d-96b6-6456ba7b8ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-10950bc9-deed-4b80-8791-ba46de1c82b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-6757b657-a00d-413c-afdb-4016ce9d3d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814899414-172.17.0.13-1595957937100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34753,DS-692b271c-b2fd-4bb2-9310-2d372898e574,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-a72eb251-8c1f-44dc-be71-e81272fa2af2,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-fad1bb01-b57f-44f8-9321-9c719b72a9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-4f2dbd48-8535-46a3-9a96-31e441bd4d52,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-3093e61f-7aba-4d58-b32a-4346d7cd6261,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-4b39e4cf-12a9-40c3-8c4f-8aee72c51fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-aac2bdee-eddb-4428-a56e-77ce513590ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-efad5daa-9de8-45c4-8c25-85ba7b9f5b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814899414-172.17.0.13-1595957937100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34753,DS-692b271c-b2fd-4bb2-9310-2d372898e574,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-a72eb251-8c1f-44dc-be71-e81272fa2af2,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-fad1bb01-b57f-44f8-9321-9c719b72a9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-4f2dbd48-8535-46a3-9a96-31e441bd4d52,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-3093e61f-7aba-4d58-b32a-4346d7cd6261,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-4b39e4cf-12a9-40c3-8c4f-8aee72c51fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-aac2bdee-eddb-4428-a56e-77ce513590ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-efad5daa-9de8-45c4-8c25-85ba7b9f5b4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399704446-172.17.0.13-1595958078199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46579,DS-11cc6c7f-fbb6-464f-afd7-a3ddbe593cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-6ceabcc2-0ff4-4ccb-af35-8529ebbdc31e,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-e020b765-c330-4df9-b695-25a00cdf244f,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-bc3ae776-32b7-468d-8b0f-adaea7d413b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-0586d26e-f1de-4b33-82c8-071a7da0ebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-1b2f3136-3dab-40bb-bd8b-c289303c2373,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-25dcb577-d46e-4ed2-96b4-21ae01565b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-14baad79-0a89-48cb-8f94-bef7a7fe4ae1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399704446-172.17.0.13-1595958078199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46579,DS-11cc6c7f-fbb6-464f-afd7-a3ddbe593cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-6ceabcc2-0ff4-4ccb-af35-8529ebbdc31e,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-e020b765-c330-4df9-b695-25a00cdf244f,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-bc3ae776-32b7-468d-8b0f-adaea7d413b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-0586d26e-f1de-4b33-82c8-071a7da0ebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-1b2f3136-3dab-40bb-bd8b-c289303c2373,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-25dcb577-d46e-4ed2-96b4-21ae01565b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-14baad79-0a89-48cb-8f94-bef7a7fe4ae1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10779427-172.17.0.13-1595958263516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39122,DS-5cd27506-1ce8-44d1-aaeb-b34fdbc91c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-366ed19b-7c00-4c2b-b56a-9da23307301e,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-4b355fc4-0fb1-44f0-90bc-a729829f0e77,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-81d03a19-2256-4698-a781-31d443565944,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-121c0655-7e42-4bc4-b306-53b1a20bd67a,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-eb940510-7612-4c97-8b3c-a50a7ccd70e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-b6fac7ba-c4b6-4177-b95c-dee942e94cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-726b5f51-70ce-4383-aae3-ed950ae286b7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10779427-172.17.0.13-1595958263516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39122,DS-5cd27506-1ce8-44d1-aaeb-b34fdbc91c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-366ed19b-7c00-4c2b-b56a-9da23307301e,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-4b355fc4-0fb1-44f0-90bc-a729829f0e77,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-81d03a19-2256-4698-a781-31d443565944,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-121c0655-7e42-4bc4-b306-53b1a20bd67a,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-eb940510-7612-4c97-8b3c-a50a7ccd70e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-b6fac7ba-c4b6-4177-b95c-dee942e94cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-726b5f51-70ce-4383-aae3-ed950ae286b7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914620229-172.17.0.13-1595958339871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35465,DS-abe1d017-b909-4fff-9775-dec37585bfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-728bc12a-a8ae-48ff-86a5-af934fd98848,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-3a86f0b0-532a-4e56-911a-79d8698192e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-49f454d4-ed7b-4952-b295-fdd7b2f33703,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-9ec448a8-dfe0-4f6f-9a0c-64c5ccbec198,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-9a34698d-c1af-4a0a-88b3-074097f3339f,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-72dcd500-3495-4ce5-b633-eb9f8d39f8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-d2a7acf4-440a-4f1c-b326-ddf4c7409dfd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914620229-172.17.0.13-1595958339871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35465,DS-abe1d017-b909-4fff-9775-dec37585bfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-728bc12a-a8ae-48ff-86a5-af934fd98848,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-3a86f0b0-532a-4e56-911a-79d8698192e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-49f454d4-ed7b-4952-b295-fdd7b2f33703,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-9ec448a8-dfe0-4f6f-9a0c-64c5ccbec198,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-9a34698d-c1af-4a0a-88b3-074097f3339f,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-72dcd500-3495-4ce5-b633-eb9f8d39f8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-d2a7acf4-440a-4f1c-b326-ddf4c7409dfd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511682426-172.17.0.13-1595958500669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37632,DS-16cef53b-b42a-4167-afda-ac7b5c121dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-14cad058-780a-45b1-bdf3-ff777f13b1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-61b39d54-6443-407b-bc75-7dc9331182af,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-804bf627-510e-4527-9392-f9acdc51a8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-13855383-d31e-4970-9d63-9c9302d926e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-c903e3ff-3e99-43a5-b11d-96e5bf5c346f,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-2b50a111-a627-4b5f-a302-4a827a55221e,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-cf1bb023-494d-402c-b0b0-50c511184beb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511682426-172.17.0.13-1595958500669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37632,DS-16cef53b-b42a-4167-afda-ac7b5c121dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-14cad058-780a-45b1-bdf3-ff777f13b1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-61b39d54-6443-407b-bc75-7dc9331182af,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-804bf627-510e-4527-9392-f9acdc51a8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-13855383-d31e-4970-9d63-9c9302d926e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-c903e3ff-3e99-43a5-b11d-96e5bf5c346f,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-2b50a111-a627-4b5f-a302-4a827a55221e,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-cf1bb023-494d-402c-b0b0-50c511184beb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564380964-172.17.0.13-1595958543355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36795,DS-19f8df29-77eb-4113-af05-c7209f7f18f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-35064082-cbae-493a-b3eb-b21378f1c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-be7a4034-1c52-4d77-894a-49dfec9700c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-fe5728c6-1046-463a-92c6-f931d8d60ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-76751306-7364-491f-8fce-e3326fada213,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-5cdef9d0-5721-4c7d-b1dc-232ab1e8f644,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-d0e1fb90-a8be-43a5-be09-bd08f32b4262,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-3ba01f11-d8ce-4480-994b-f026f041c3f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564380964-172.17.0.13-1595958543355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36795,DS-19f8df29-77eb-4113-af05-c7209f7f18f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-35064082-cbae-493a-b3eb-b21378f1c1af,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-be7a4034-1c52-4d77-894a-49dfec9700c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-fe5728c6-1046-463a-92c6-f931d8d60ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-76751306-7364-491f-8fce-e3326fada213,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-5cdef9d0-5721-4c7d-b1dc-232ab1e8f644,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-d0e1fb90-a8be-43a5-be09-bd08f32b4262,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-3ba01f11-d8ce-4480-994b-f026f041c3f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823830397-172.17.0.13-1595958619342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40633,DS-7856a4d2-d953-4a51-96ea-61d6e27e5090,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-916c4745-f33d-4d32-a58c-a1aae4a420a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-c0378225-953d-469d-8cd1-63c005584fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-627f6862-d8f3-48e3-b3df-b633db7c8c32,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-da77498c-763a-4dbe-b059-0172fb410f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-cd8e9610-2692-429b-bd22-355b06f58786,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-89d80d34-eaaa-435e-a067-b0399322f4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-fd2ba389-bbac-4965-90e7-64ce2d82f85d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-823830397-172.17.0.13-1595958619342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40633,DS-7856a4d2-d953-4a51-96ea-61d6e27e5090,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-916c4745-f33d-4d32-a58c-a1aae4a420a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-c0378225-953d-469d-8cd1-63c005584fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36512,DS-627f6862-d8f3-48e3-b3df-b633db7c8c32,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-da77498c-763a-4dbe-b059-0172fb410f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-cd8e9610-2692-429b-bd22-355b06f58786,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-89d80d34-eaaa-435e-a067-b0399322f4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-fd2ba389-bbac-4965-90e7-64ce2d82f85d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979047800-172.17.0.13-1595958693904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35233,DS-0a11d85b-77a9-4628-84d1-f128b943e920,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-b211335f-84d6-4c90-8759-d4bc0c4eb6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-069d41ae-62cb-4a0a-aafb-7a8b6289f32c,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-f94aef7a-3067-4834-8a0d-183587542d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-4c5114f6-ccc1-4e55-a0de-1724d50063c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-1a2067a3-3e1d-4c9c-b80e-873edae1d3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-e3bbe7d8-af09-4b65-9286-a86433e43094,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-b164eae2-7a4b-47b4-86ac-195515e04226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979047800-172.17.0.13-1595958693904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35233,DS-0a11d85b-77a9-4628-84d1-f128b943e920,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-b211335f-84d6-4c90-8759-d4bc0c4eb6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-069d41ae-62cb-4a0a-aafb-7a8b6289f32c,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-f94aef7a-3067-4834-8a0d-183587542d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-4c5114f6-ccc1-4e55-a0de-1724d50063c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-1a2067a3-3e1d-4c9c-b80e-873edae1d3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-e3bbe7d8-af09-4b65-9286-a86433e43094,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-b164eae2-7a4b-47b4-86ac-195515e04226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680113312-172.17.0.13-1595958734037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44274,DS-6271291a-690f-4d8a-bbab-9ff7ad03510b,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-1370454f-0a09-41a9-8b55-51aa3ba84220,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-de8d591e-de00-45b3-88b6-ad3e893effb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-5b18084f-cd5d-48b4-ab42-21f104b5d9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-b158e956-32b2-4034-a592-6ed6ad80b1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-1f7d7559-053e-4d52-b464-5bb10f5ba9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-9361145f-c12c-4c94-a215-f20fe4179450,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-4d2bbafd-2964-4538-9b38-099bea86196c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680113312-172.17.0.13-1595958734037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44274,DS-6271291a-690f-4d8a-bbab-9ff7ad03510b,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-1370454f-0a09-41a9-8b55-51aa3ba84220,DISK], DatanodeInfoWithStorage[127.0.0.1:33562,DS-de8d591e-de00-45b3-88b6-ad3e893effb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-5b18084f-cd5d-48b4-ab42-21f104b5d9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-b158e956-32b2-4034-a592-6ed6ad80b1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-1f7d7559-053e-4d52-b464-5bb10f5ba9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37932,DS-9361145f-c12c-4c94-a215-f20fe4179450,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-4d2bbafd-2964-4538-9b38-099bea86196c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494660077-172.17.0.13-1595958959606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41607,DS-e77b146f-7abe-44b7-8c36-24ff495d12a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-c0ee812f-6abe-4eef-ab0b-2dc831bf7cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-24deb3dc-93aa-4086-a3fe-e2dd3e84a684,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-1dd52ad1-cbe7-4131-975d-9fc4913a3f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-060620a3-f8a6-433a-af82-8fbae2e7a6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-d15ae8f9-7304-433e-9bc8-2c709ff7ded6,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-06913fb2-145a-4692-87cc-71fabbd1e2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-00cb3a0d-0ba2-4083-9097-8d84849b3e9f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494660077-172.17.0.13-1595958959606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41607,DS-e77b146f-7abe-44b7-8c36-24ff495d12a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-c0ee812f-6abe-4eef-ab0b-2dc831bf7cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-24deb3dc-93aa-4086-a3fe-e2dd3e84a684,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-1dd52ad1-cbe7-4131-975d-9fc4913a3f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-060620a3-f8a6-433a-af82-8fbae2e7a6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-d15ae8f9-7304-433e-9bc8-2c709ff7ded6,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-06913fb2-145a-4692-87cc-71fabbd1e2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-00cb3a0d-0ba2-4083-9097-8d84849b3e9f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255455287-172.17.0.13-1595959000079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37255,DS-2d2f4a6a-26dd-416f-a4ec-6befeed39540,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-0a01d382-44f8-4c3f-9f53-a44a402ffa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-d7918360-3e6f-48c2-a6a7-69e22a3747b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-30314cb9-ac75-4f25-b6e8-eb4192a794bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-501ea354-b709-41b1-8c49-a881be49fbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-a8e488d1-75e9-4573-8a1b-170baa7c2a34,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-a4762654-e672-4b67-86e7-30d9cd6bd7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-ddb2c9bc-4e37-49ec-9368-7202d514c0d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255455287-172.17.0.13-1595959000079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37255,DS-2d2f4a6a-26dd-416f-a4ec-6befeed39540,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-0a01d382-44f8-4c3f-9f53-a44a402ffa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-d7918360-3e6f-48c2-a6a7-69e22a3747b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-30314cb9-ac75-4f25-b6e8-eb4192a794bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-501ea354-b709-41b1-8c49-a881be49fbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-a8e488d1-75e9-4573-8a1b-170baa7c2a34,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-a4762654-e672-4b67-86e7-30d9cd6bd7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-ddb2c9bc-4e37-49ec-9368-7202d514c0d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237456575-172.17.0.13-1595959082150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43848,DS-fcb96a87-c046-4c2b-b41f-3e029cbc97cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-04e961c9-2a2c-4b91-8864-cca6156931ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-c6fa7d58-6d26-4308-b535-09c1b1b4bbce,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-d087002f-881d-47c1-af02-024c4a4165b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-c41ea972-f29b-4eb4-9d97-c3a1aee04f39,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-62d3114d-6e56-44fe-9ffd-aa49a3787b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-425cb1e9-5290-4aa7-9aa8-b3f88ff4ec60,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-df231876-8c10-4906-be7d-ba6fb6e8d408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237456575-172.17.0.13-1595959082150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43848,DS-fcb96a87-c046-4c2b-b41f-3e029cbc97cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-04e961c9-2a2c-4b91-8864-cca6156931ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-c6fa7d58-6d26-4308-b535-09c1b1b4bbce,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-d087002f-881d-47c1-af02-024c4a4165b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-c41ea972-f29b-4eb4-9d97-c3a1aee04f39,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-62d3114d-6e56-44fe-9ffd-aa49a3787b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-425cb1e9-5290-4aa7-9aa8-b3f88ff4ec60,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-df231876-8c10-4906-be7d-ba6fb6e8d408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139634485-172.17.0.13-1595959230588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34309,DS-2179a5cb-ffff-4926-990a-623024ae819d,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-006d6f58-d61e-42cc-881c-a58214a08358,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-5b95e8ac-d7cc-461d-8bd2-6cc095f6cda5,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-0a956aae-f16c-454b-abd5-eb472d0ec83a,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-341b949d-c6af-439b-9f31-e7175b45fec8,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-b1880bba-ddc4-4127-8986-743aaa15378f,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-b160dec4-962e-4e63-a573-6b872683000c,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-08935b98-21e0-4975-8097-7bd75c4a58e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139634485-172.17.0.13-1595959230588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34309,DS-2179a5cb-ffff-4926-990a-623024ae819d,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-006d6f58-d61e-42cc-881c-a58214a08358,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-5b95e8ac-d7cc-461d-8bd2-6cc095f6cda5,DISK], DatanodeInfoWithStorage[127.0.0.1:33676,DS-0a956aae-f16c-454b-abd5-eb472d0ec83a,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-341b949d-c6af-439b-9f31-e7175b45fec8,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-b1880bba-ddc4-4127-8986-743aaa15378f,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-b160dec4-962e-4e63-a573-6b872683000c,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-08935b98-21e0-4975-8097-7bd75c4a58e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542919596-172.17.0.13-1595959546067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36825,DS-d3f45e20-da97-4e39-8b26-a9fc01becb46,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-41b81bdb-523d-441d-9d7d-2ce1556c0aca,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-beea0a81-91c3-4fcf-acda-f81b940783c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-9642038d-8c49-4c24-a8b1-73cb5c1dd8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-dd736da5-256b-4c27-a100-7cc54c29c775,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-46af4293-f391-4c5e-b11b-d9dcabe9715b,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-ff06f05b-aaee-4757-a17f-86bead936e29,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-941c7fcb-216f-44a3-931d-67998d712ee1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542919596-172.17.0.13-1595959546067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36825,DS-d3f45e20-da97-4e39-8b26-a9fc01becb46,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-41b81bdb-523d-441d-9d7d-2ce1556c0aca,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-beea0a81-91c3-4fcf-acda-f81b940783c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-9642038d-8c49-4c24-a8b1-73cb5c1dd8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-dd736da5-256b-4c27-a100-7cc54c29c775,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-46af4293-f391-4c5e-b11b-d9dcabe9715b,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-ff06f05b-aaee-4757-a17f-86bead936e29,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-941c7fcb-216f-44a3-931d-67998d712ee1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553748536-172.17.0.13-1595959707059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39383,DS-cb6f0a7c-965a-4437-b9d6-56738ae24f78,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-7cc2e276-d881-4b31-adde-f45e6fd250a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-0f8de9fb-3159-476f-b9e4-24c7c7f04d13,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-0c2eba72-45fc-4ca4-953e-a0e3ec6894be,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-08c81811-8e5c-4cb9-afa9-870b12a3c2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-eb64a479-36eb-4e14-bd4f-243e81d67e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-c3c8155b-63a0-48f2-95a7-053ab07c65fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-c921629c-4b66-47c7-8e20-2dd18a512f53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553748536-172.17.0.13-1595959707059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39383,DS-cb6f0a7c-965a-4437-b9d6-56738ae24f78,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-7cc2e276-d881-4b31-adde-f45e6fd250a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-0f8de9fb-3159-476f-b9e4-24c7c7f04d13,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-0c2eba72-45fc-4ca4-953e-a0e3ec6894be,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-08c81811-8e5c-4cb9-afa9-870b12a3c2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-eb64a479-36eb-4e14-bd4f-243e81d67e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-c3c8155b-63a0-48f2-95a7-053ab07c65fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-c921629c-4b66-47c7-8e20-2dd18a512f53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306996743-172.17.0.13-1595959773050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38313,DS-8a6690f4-af19-4090-882a-1456ddd07b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-891f81f8-8e8b-40f2-945b-eb818a82f16c,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-e36d5204-476f-46fd-a2cf-2a9300eee4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-9a7ac7a3-286e-49e5-a7b3-f2396238b190,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-94a6e698-c5ae-4922-b18b-8d755a6064b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-262b5cdc-5539-4a70-a440-8f0345928154,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-2dfdb00c-9bd8-4aac-9b6c-0325cf064310,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-d73f7c84-42df-4d5c-8be4-c05d94ee134f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306996743-172.17.0.13-1595959773050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38313,DS-8a6690f4-af19-4090-882a-1456ddd07b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-891f81f8-8e8b-40f2-945b-eb818a82f16c,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-e36d5204-476f-46fd-a2cf-2a9300eee4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-9a7ac7a3-286e-49e5-a7b3-f2396238b190,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-94a6e698-c5ae-4922-b18b-8d755a6064b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-262b5cdc-5539-4a70-a440-8f0345928154,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-2dfdb00c-9bd8-4aac-9b6c-0325cf064310,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-d73f7c84-42df-4d5c-8be4-c05d94ee134f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849751176-172.17.0.13-1595959844057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44599,DS-28c756b2-a5f7-46bb-a624-b359ccdf1686,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-d0b96e6a-3c2e-429d-896f-916aeefab169,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-f8704994-84c4-4722-b698-1e093a34f7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-5efd155f-6aa8-4fa0-a164-6aac01507c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-545a68ae-dae4-4792-a2b9-bf743b33eb40,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-064f42b0-be7a-403a-8b46-2e5c08d5e201,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-192a63cd-376c-464d-b1ef-d0a5f9486326,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-1ea8d118-5cc4-4519-b5a2-b1d3c89736c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849751176-172.17.0.13-1595959844057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44599,DS-28c756b2-a5f7-46bb-a624-b359ccdf1686,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-d0b96e6a-3c2e-429d-896f-916aeefab169,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-f8704994-84c4-4722-b698-1e093a34f7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-5efd155f-6aa8-4fa0-a164-6aac01507c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-545a68ae-dae4-4792-a2b9-bf743b33eb40,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-064f42b0-be7a-403a-8b46-2e5c08d5e201,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-192a63cd-376c-464d-b1ef-d0a5f9486326,DISK], DatanodeInfoWithStorage[127.0.0.1:41233,DS-1ea8d118-5cc4-4519-b5a2-b1d3c89736c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028699424-172.17.0.13-1595960031099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42204,DS-6a121c9d-d86c-4b7d-af06-cb1d35c0f660,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-68a2e9fc-2b4c-430a-9921-be07b8f95267,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-b50666d1-50f3-4ef0-99c2-6b6f2035b890,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-b2dd2e61-d7b6-4202-a012-7cabc032332b,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-1de4ee80-c362-48ba-979f-5616b49e20eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-cd1fef9a-45c2-4019-96ac-2e1d1c011f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-f5077a2d-4b22-447b-b372-f2f77e856037,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-2d2f3235-2163-4c45-96c4-9f543f5e8f87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028699424-172.17.0.13-1595960031099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42204,DS-6a121c9d-d86c-4b7d-af06-cb1d35c0f660,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-68a2e9fc-2b4c-430a-9921-be07b8f95267,DISK], DatanodeInfoWithStorage[127.0.0.1:41948,DS-b50666d1-50f3-4ef0-99c2-6b6f2035b890,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-b2dd2e61-d7b6-4202-a012-7cabc032332b,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-1de4ee80-c362-48ba-979f-5616b49e20eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-cd1fef9a-45c2-4019-96ac-2e1d1c011f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-f5077a2d-4b22-447b-b372-f2f77e856037,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-2d2f3235-2163-4c45-96c4-9f543f5e8f87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259867333-172.17.0.13-1595960157362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-03f7934a-d4be-4d14-a7b6-f1f43910fab7,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-cc6f25b5-8ebc-45fd-b506-c3c7a28cc619,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-34dc9dd8-1123-4212-8305-a7c3ae34baaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-d7a97dd9-0819-4b9e-bb06-fd977e3fbb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-ad0931a8-fa4e-4be2-987d-e06fa68fd5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-1d604367-1187-497f-8c52-eef42f23de3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-61271b5e-6d0b-403c-a3db-9fea761d1a33,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-d9b6eaeb-1dc6-43e0-a30b-56872e27cdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259867333-172.17.0.13-1595960157362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-03f7934a-d4be-4d14-a7b6-f1f43910fab7,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-cc6f25b5-8ebc-45fd-b506-c3c7a28cc619,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-34dc9dd8-1123-4212-8305-a7c3ae34baaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-d7a97dd9-0819-4b9e-bb06-fd977e3fbb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-ad0931a8-fa4e-4be2-987d-e06fa68fd5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-1d604367-1187-497f-8c52-eef42f23de3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-61271b5e-6d0b-403c-a3db-9fea761d1a33,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-d9b6eaeb-1dc6-43e0-a30b-56872e27cdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035644298-172.17.0.13-1595960254490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38401,DS-f5cbe891-bd53-45c3-b577-bba7769072d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-a546b0f8-7563-4ad3-ad7e-eb2028c0265b,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-3b648b48-82a8-4def-9bc9-35e4a8264e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-8f0bd9bf-a3c8-4da6-bcbb-7e713a440d82,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-1ca37d79-b9de-45c7-ab35-53372d35d0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-719b7224-aee2-4eb0-9684-3ea15967bf90,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-51ae280e-81f6-4b2f-92f5-e58744443a17,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-4ef9ef56-f28f-4592-becc-439e75913c87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035644298-172.17.0.13-1595960254490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38401,DS-f5cbe891-bd53-45c3-b577-bba7769072d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-a546b0f8-7563-4ad3-ad7e-eb2028c0265b,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-3b648b48-82a8-4def-9bc9-35e4a8264e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-8f0bd9bf-a3c8-4da6-bcbb-7e713a440d82,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-1ca37d79-b9de-45c7-ab35-53372d35d0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-719b7224-aee2-4eb0-9684-3ea15967bf90,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-51ae280e-81f6-4b2f-92f5-e58744443a17,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-4ef9ef56-f28f-4592-becc-439e75913c87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567884075-172.17.0.13-1595960388691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35553,DS-1ab2add4-4674-4027-b378-27e0aee6fdac,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-18c77a45-2206-4652-8588-fc20e2c3ff2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-d5b6b473-281d-4003-942c-955df8db2bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-ae0392a7-817b-4084-ab4b-ab808dc8f736,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-70788882-22cf-4fa8-bd5b-695d0b8d90ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-7f0fa2ba-8e22-4b77-a40d-ec9f6ce6ecd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-f3a30161-2efc-4e2a-b327-5963815d6a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-588b5c28-849c-44bc-90bd-3d9494b772a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567884075-172.17.0.13-1595960388691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35553,DS-1ab2add4-4674-4027-b378-27e0aee6fdac,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-18c77a45-2206-4652-8588-fc20e2c3ff2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-d5b6b473-281d-4003-942c-955df8db2bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-ae0392a7-817b-4084-ab4b-ab808dc8f736,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-70788882-22cf-4fa8-bd5b-695d0b8d90ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-7f0fa2ba-8e22-4b77-a40d-ec9f6ce6ecd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-f3a30161-2efc-4e2a-b327-5963815d6a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-588b5c28-849c-44bc-90bd-3d9494b772a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093590580-172.17.0.13-1595960555177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43869,DS-20578ba7-0962-4c97-9168-b8a74a97e7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-df7fb220-da18-4fd7-afa7-70fd5dc7ad99,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-bcaa7d6d-4b69-42ce-81d9-c96eb77802ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-6d124919-1977-4100-9935-ad8bca10ba58,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-97bfa076-7967-43aa-b7da-dcabfb266d43,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-aa06b69e-2a85-4f47-84f8-b66bfc22b2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-c1e0b6e3-b82f-4b8d-80c8-748779cc0a16,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-0377779c-de5d-4c94-9000-668b3cd4d960,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093590580-172.17.0.13-1595960555177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43869,DS-20578ba7-0962-4c97-9168-b8a74a97e7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-df7fb220-da18-4fd7-afa7-70fd5dc7ad99,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-bcaa7d6d-4b69-42ce-81d9-c96eb77802ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-6d124919-1977-4100-9935-ad8bca10ba58,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-97bfa076-7967-43aa-b7da-dcabfb266d43,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-aa06b69e-2a85-4f47-84f8-b66bfc22b2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-c1e0b6e3-b82f-4b8d-80c8-748779cc0a16,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-0377779c-de5d-4c94-9000-668b3cd4d960,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912238645-172.17.0.13-1595960683839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41161,DS-0d034b32-4873-497b-b355-28824f865005,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-b6a50e7d-5b59-40c4-a50a-c57ca82a7e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-fad39855-b924-48e9-889d-dd198602388a,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-ea8cb726-df88-4e69-b7a3-c7d722c0f005,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-9da9e700-e41f-4876-a2bb-c240ad695efe,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-6daf84c4-8819-46bf-a9d9-d5c75d9ac69c,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-878c9a50-f44c-4099-b114-1a2a00976571,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-588e2121-8e02-49f9-b96c-e4e5e3294082,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912238645-172.17.0.13-1595960683839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41161,DS-0d034b32-4873-497b-b355-28824f865005,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-b6a50e7d-5b59-40c4-a50a-c57ca82a7e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-fad39855-b924-48e9-889d-dd198602388a,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-ea8cb726-df88-4e69-b7a3-c7d722c0f005,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-9da9e700-e41f-4876-a2bb-c240ad695efe,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-6daf84c4-8819-46bf-a9d9-d5c75d9ac69c,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-878c9a50-f44c-4099-b114-1a2a00976571,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-588e2121-8e02-49f9-b96c-e4e5e3294082,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576789932-172.17.0.13-1595960718433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34718,DS-2ef3ce97-df5d-4db8-a6b1-7cc3471f0a94,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-45d85943-9823-4aeb-863d-76bf61612358,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-c3f8f615-bcfa-4235-a589-120a175c4fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-5b48001a-42cb-49ef-b708-79d62d9f792c,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-bbe224ac-bd08-41a9-9d58-7f512fa12c45,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-ccab1f66-57f7-4cb3-805a-88ade295baf7,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-7ed29e26-ccfc-464d-86b0-9d1e66000e06,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-6393624e-e749-4cd4-ac85-2c68965f9034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576789932-172.17.0.13-1595960718433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34718,DS-2ef3ce97-df5d-4db8-a6b1-7cc3471f0a94,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-45d85943-9823-4aeb-863d-76bf61612358,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-c3f8f615-bcfa-4235-a589-120a175c4fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-5b48001a-42cb-49ef-b708-79d62d9f792c,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-bbe224ac-bd08-41a9-9d58-7f512fa12c45,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-ccab1f66-57f7-4cb3-805a-88ade295baf7,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-7ed29e26-ccfc-464d-86b0-9d1e66000e06,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-6393624e-e749-4cd4-ac85-2c68965f9034,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155644838-172.17.0.13-1595960779584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46177,DS-d7c41b0d-8760-4e83-aed3-e39f4819e2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-bb55687c-faed-43b6-979a-5043c326dd10,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-5cd11a78-2dc5-4aa7-9585-2882e4bca60b,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-4fac738b-33c6-4ea6-ad8d-16b94f06f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-6bdfd3ab-073e-4855-b1fb-5d969336e1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-f9870406-99b8-472e-acf7-23db83621191,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-6dc8a65b-015f-4210-b792-e2080b594708,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-47fb54c2-98d5-471a-b2e1-1fe20fd5a33f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155644838-172.17.0.13-1595960779584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46177,DS-d7c41b0d-8760-4e83-aed3-e39f4819e2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-bb55687c-faed-43b6-979a-5043c326dd10,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-5cd11a78-2dc5-4aa7-9585-2882e4bca60b,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-4fac738b-33c6-4ea6-ad8d-16b94f06f29e,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-6bdfd3ab-073e-4855-b1fb-5d969336e1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-f9870406-99b8-472e-acf7-23db83621191,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-6dc8a65b-015f-4210-b792-e2080b594708,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-47fb54c2-98d5-471a-b2e1-1fe20fd5a33f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348114466-172.17.0.13-1595960813274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44544,DS-6dc8f3a8-829d-497e-b05c-ccd56d8380e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-490dccfb-eed4-4314-a5b1-37f7d9243973,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-d97a7628-b928-49bc-b466-890c53528003,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-4b6d61e6-bd91-42f4-8fe8-481086454651,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-261da389-28a5-4d7b-a40f-d85bc0bcec80,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-17272c84-2d07-4d81-97f7-a772b655b788,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-893ccec3-cdfd-4ce6-8ab8-96d9869e52e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-7b489d82-55bb-457c-a98c-e90bdc447d30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-348114466-172.17.0.13-1595960813274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44544,DS-6dc8f3a8-829d-497e-b05c-ccd56d8380e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-490dccfb-eed4-4314-a5b1-37f7d9243973,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-d97a7628-b928-49bc-b466-890c53528003,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-4b6d61e6-bd91-42f4-8fe8-481086454651,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-261da389-28a5-4d7b-a40f-d85bc0bcec80,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-17272c84-2d07-4d81-97f7-a772b655b788,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-893ccec3-cdfd-4ce6-8ab8-96d9869e52e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-7b489d82-55bb-457c-a98c-e90bdc447d30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702028011-172.17.0.13-1595961084308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39222,DS-2a7d810c-80ff-4165-8e7f-4c822bd30312,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-d713bfcc-0be6-4f3e-aa6f-8005d5364fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-54444511-9ae6-4570-9c4c-f145f974ec03,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-71c4d0db-8ea3-4c42-92f6-7ebeb7e855fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-463cb9be-e9d5-4548-9eaa-be83f026b273,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-9102184f-f8df-484d-90b3-a7392749a2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-d72f19fa-0af4-4d82-bc07-dccf56833851,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-5f6bf136-87c2-4026-99da-8e4b8a600612,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702028011-172.17.0.13-1595961084308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39222,DS-2a7d810c-80ff-4165-8e7f-4c822bd30312,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-d713bfcc-0be6-4f3e-aa6f-8005d5364fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-54444511-9ae6-4570-9c4c-f145f974ec03,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-71c4d0db-8ea3-4c42-92f6-7ebeb7e855fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-463cb9be-e9d5-4548-9eaa-be83f026b273,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-9102184f-f8df-484d-90b3-a7392749a2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-d72f19fa-0af4-4d82-bc07-dccf56833851,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-5f6bf136-87c2-4026-99da-8e4b8a600612,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117172206-172.17.0.13-1595961121940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33015,DS-fd984176-1e40-466c-ac43-a173869c899e,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-46939f51-c5ba-4d63-8a18-9141b2221e86,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-f376c900-32cb-4ced-b5f8-7fe2d7c7402a,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-767a2df5-6716-4a0f-8c4c-a8ba25e05b79,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-8f9bec4f-b643-44af-b528-5c96c8e67ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-ed17ffdf-07c2-48d8-99b0-2e180cb7e254,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-5a890763-2474-4cd4-a3cf-1207145afe76,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-0e858fae-208b-4d16-b9d4-d48b63870a11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117172206-172.17.0.13-1595961121940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33015,DS-fd984176-1e40-466c-ac43-a173869c899e,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-46939f51-c5ba-4d63-8a18-9141b2221e86,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-f376c900-32cb-4ced-b5f8-7fe2d7c7402a,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-767a2df5-6716-4a0f-8c4c-a8ba25e05b79,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-8f9bec4f-b643-44af-b528-5c96c8e67ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-ed17ffdf-07c2-48d8-99b0-2e180cb7e254,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-5a890763-2474-4cd4-a3cf-1207145afe76,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-0e858fae-208b-4d16-b9d4-d48b63870a11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974440038-172.17.0.13-1595961158883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34565,DS-1943bcf0-2742-46f8-83b3-69855b6eadc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-ffcb1418-4044-409d-911f-e84ba16eb1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-0f9c43da-6326-4b66-a69a-42f9d6dd4d97,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-fe4f8099-984b-4e87-b366-de6b86485929,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-cec24d8e-1646-4553-a0fc-3ec46c70ad14,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-b99d1d8d-23d3-402f-bc07-71288b089566,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-17e75055-14fc-4253-ac98-4d750b38a4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-ac65e8b9-41fd-4242-829a-99c7dabc4dda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974440038-172.17.0.13-1595961158883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34565,DS-1943bcf0-2742-46f8-83b3-69855b6eadc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-ffcb1418-4044-409d-911f-e84ba16eb1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-0f9c43da-6326-4b66-a69a-42f9d6dd4d97,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-fe4f8099-984b-4e87-b366-de6b86485929,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-cec24d8e-1646-4553-a0fc-3ec46c70ad14,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-b99d1d8d-23d3-402f-bc07-71288b089566,DISK], DatanodeInfoWithStorage[127.0.0.1:40460,DS-17e75055-14fc-4253-ac98-4d750b38a4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-ac65e8b9-41fd-4242-829a-99c7dabc4dda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378848718-172.17.0.13-1595961191907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38311,DS-53d1a44e-2c84-4ba2-9278-7201229bddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-ddc2e557-7958-44d0-8c02-a4283bce029a,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-d8b2726d-6dff-4839-9434-1b679855a7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-e62be18e-12fc-4471-9750-d3eb310d5e47,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-c369d480-c7a8-458e-a7f9-fb2d93db9895,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-58710f9e-59e1-45ea-b22b-c35033f49dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-647b5735-eb60-459a-b102-8d5cefc639b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-df94d5b0-e1e2-40d1-886d-92df764d08fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378848718-172.17.0.13-1595961191907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38311,DS-53d1a44e-2c84-4ba2-9278-7201229bddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-ddc2e557-7958-44d0-8c02-a4283bce029a,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-d8b2726d-6dff-4839-9434-1b679855a7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-e62be18e-12fc-4471-9750-d3eb310d5e47,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-c369d480-c7a8-458e-a7f9-fb2d93db9895,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-58710f9e-59e1-45ea-b22b-c35033f49dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-647b5735-eb60-459a-b102-8d5cefc639b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-df94d5b0-e1e2-40d1-886d-92df764d08fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110017960-172.17.0.13-1595961345956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33409,DS-b47fa089-249d-49c4-a81e-041913acb948,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-efc862f6-1717-4780-a5b1-9657728ccc34,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-78e79f9d-b35e-428f-8367-6f3e61b0b5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-d5682612-24fb-4209-9927-6c8a9883ac3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-595fefa6-1de2-4f21-a020-537aaf6444f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-7e592c07-c5e3-47a2-90a3-6d15ca46457f,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-6c6f8d51-4970-4ca1-89dd-cf7d7d966f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-6c3f3206-3df9-47f0-b1e2-8f98862b3515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110017960-172.17.0.13-1595961345956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33409,DS-b47fa089-249d-49c4-a81e-041913acb948,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-efc862f6-1717-4780-a5b1-9657728ccc34,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-78e79f9d-b35e-428f-8367-6f3e61b0b5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-d5682612-24fb-4209-9927-6c8a9883ac3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-595fefa6-1de2-4f21-a020-537aaf6444f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-7e592c07-c5e3-47a2-90a3-6d15ca46457f,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-6c6f8d51-4970-4ca1-89dd-cf7d7d966f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-6c3f3206-3df9-47f0-b1e2-8f98862b3515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754767940-172.17.0.13-1595961379822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45929,DS-58a6aff3-784c-4d25-b0a9-220cd7768122,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-aac03fd1-9198-47b8-88c1-0f8817417182,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-df0484ba-9f04-4916-8d39-023fcadc3f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-1d0bd241-6d8b-4189-b1ef-57ec5bf28c66,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-ed509eec-b795-411e-be3b-333ff8058d61,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-52d3a800-1e3d-4a6e-98eb-4db9232eb82f,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-44713f2f-a730-4189-83cd-69693bef543f,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-211bd949-b07d-4383-88d2-324c01326157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754767940-172.17.0.13-1595961379822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45929,DS-58a6aff3-784c-4d25-b0a9-220cd7768122,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-aac03fd1-9198-47b8-88c1-0f8817417182,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-df0484ba-9f04-4916-8d39-023fcadc3f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-1d0bd241-6d8b-4189-b1ef-57ec5bf28c66,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-ed509eec-b795-411e-be3b-333ff8058d61,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-52d3a800-1e3d-4a6e-98eb-4db9232eb82f,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-44713f2f-a730-4189-83cd-69693bef543f,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-211bd949-b07d-4383-88d2-324c01326157,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651274074-172.17.0.13-1595961416555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46729,DS-2b400fe6-42fa-4fda-bfbf-1a5b5ff0dfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-56d82d55-c4fa-4330-9542-a11d1f28c048,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-0660d855-8c78-45a3-a702-c1a47fbf501b,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-9c27efca-544d-4edd-9892-e39e569b0603,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-a2c6eeac-a8c3-467e-a936-4d02d712695b,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-d418299a-bea8-4234-a2cf-7b432b4359d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-104bf365-2a4a-41e0-a7e5-0d31b12baece,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-fac3fdb6-cad9-4fcf-97cf-12a6882b9986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651274074-172.17.0.13-1595961416555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46729,DS-2b400fe6-42fa-4fda-bfbf-1a5b5ff0dfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-56d82d55-c4fa-4330-9542-a11d1f28c048,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-0660d855-8c78-45a3-a702-c1a47fbf501b,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-9c27efca-544d-4edd-9892-e39e569b0603,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-a2c6eeac-a8c3-467e-a936-4d02d712695b,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-d418299a-bea8-4234-a2cf-7b432b4359d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-104bf365-2a4a-41e0-a7e5-0d31b12baece,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-fac3fdb6-cad9-4fcf-97cf-12a6882b9986,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457999070-172.17.0.13-1595961455937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42867,DS-c3d3df87-3ab6-4b42-b728-44e2d8953cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-c153f58d-ac75-415a-b5f9-241bde4187c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-cf6350e1-cb26-46ac-9859-332fecdc13f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-97a5179e-4d96-4b96-b8cf-23c0b7c02ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-4f688859-758c-4837-bc16-44ce91938423,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-2454e4ac-58dd-4c99-bd43-7a35f5a95cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-14e3e538-558d-432e-bcd6-0cd0793b421e,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-c78d5ab7-7bf1-4f92-bc99-0620ef2003eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457999070-172.17.0.13-1595961455937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42867,DS-c3d3df87-3ab6-4b42-b728-44e2d8953cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-c153f58d-ac75-415a-b5f9-241bde4187c9,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-cf6350e1-cb26-46ac-9859-332fecdc13f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-97a5179e-4d96-4b96-b8cf-23c0b7c02ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-4f688859-758c-4837-bc16-44ce91938423,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-2454e4ac-58dd-4c99-bd43-7a35f5a95cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-14e3e538-558d-432e-bcd6-0cd0793b421e,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-c78d5ab7-7bf1-4f92-bc99-0620ef2003eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578266865-172.17.0.13-1595961525760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36889,DS-ba3515e8-c5fc-4d75-b00f-67ce7d407f88,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-5d175840-f62b-498f-b179-6bc99cecc260,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-a0709dec-3cbc-4f72-8a32-c7440146d5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-4bf3759a-602f-40a8-97da-50c9faca9ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-d1772d44-4b44-4ba0-a731-7270fbb8245e,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-f5a429c2-2a03-40ff-acb8-f9258372142f,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-2d7cd625-63d6-4a6c-88f9-29c2e3ffe2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-9ae4f05f-60da-4dde-8936-2d60929f3201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578266865-172.17.0.13-1595961525760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36889,DS-ba3515e8-c5fc-4d75-b00f-67ce7d407f88,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-5d175840-f62b-498f-b179-6bc99cecc260,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-a0709dec-3cbc-4f72-8a32-c7440146d5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-4bf3759a-602f-40a8-97da-50c9faca9ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-d1772d44-4b44-4ba0-a731-7270fbb8245e,DISK], DatanodeInfoWithStorage[127.0.0.1:42083,DS-f5a429c2-2a03-40ff-acb8-f9258372142f,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-2d7cd625-63d6-4a6c-88f9-29c2e3ffe2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-9ae4f05f-60da-4dde-8936-2d60929f3201,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286311435-172.17.0.13-1595961709632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45936,DS-67fd5317-7138-42a8-b82a-713b5d969f38,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-aa884bd8-3331-4d66-afb9-ac7c99ee071a,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-14a008ce-ef90-41fa-9474-06aa57205a56,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-ec4ee442-8b3a-4652-bff0-f5e182e7a389,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-70266b72-dd87-4c0f-93ed-775302105565,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-1a3ad50e-2d26-490d-98b5-43f6eb511d51,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-de75633e-0003-4bbb-956f-dee23ef894fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-afe58aac-8f67-4e7e-a8ef-5c10a211dc2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1286311435-172.17.0.13-1595961709632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45936,DS-67fd5317-7138-42a8-b82a-713b5d969f38,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-aa884bd8-3331-4d66-afb9-ac7c99ee071a,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-14a008ce-ef90-41fa-9474-06aa57205a56,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-ec4ee442-8b3a-4652-bff0-f5e182e7a389,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-70266b72-dd87-4c0f-93ed-775302105565,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-1a3ad50e-2d26-490d-98b5-43f6eb511d51,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-de75633e-0003-4bbb-956f-dee23ef894fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-afe58aac-8f67-4e7e-a8ef-5c10a211dc2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119861015-172.17.0.13-1595961860107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35213,DS-93c0922b-8c72-479b-9649-a03a77cbede9,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-11b4ceb1-1876-4a45-b7d6-2f37be5844e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-6d2fc95b-9fe3-4abf-ab5d-110863621d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-349fee57-ede4-48ea-96a0-b65525ea16c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-d824ae5f-39f6-4431-af0f-8b83ad8f396a,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-4f991a41-9909-46f6-bec1-811c8a67b3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-7c12ff1d-356c-4ea6-a661-3c8462e51d13,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-e6157451-8264-4046-a739-1988bce2184a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119861015-172.17.0.13-1595961860107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35213,DS-93c0922b-8c72-479b-9649-a03a77cbede9,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-11b4ceb1-1876-4a45-b7d6-2f37be5844e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-6d2fc95b-9fe3-4abf-ab5d-110863621d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-349fee57-ede4-48ea-96a0-b65525ea16c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-d824ae5f-39f6-4431-af0f-8b83ad8f396a,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-4f991a41-9909-46f6-bec1-811c8a67b3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-7c12ff1d-356c-4ea6-a661-3c8462e51d13,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-e6157451-8264-4046-a739-1988bce2184a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.volumes.replica-add.threadpool.size
component: hdfs:DataNode
v1: 40
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678556730-172.17.0.13-1595962160836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39687,DS-4e0e3630-a333-4b20-856d-03d0152ce7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-8381914b-9319-4938-ae54-0e8dd3ee99bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-0106c528-4bcc-41b9-a5e6-c93f2854229b,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-c6c2b034-b6d6-4591-87ea-4972abcbe0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-57502346-3599-49a2-b7f5-15c44fa78297,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-786bc4c9-bdf4-43a2-a409-913cfaa4239c,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-b3bf15c9-0df1-4e8f-9062-99cbf5c12f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-e5fdbdbc-84df-4444-bb3d-a6c662b19d40,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678556730-172.17.0.13-1595962160836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39687,DS-4e0e3630-a333-4b20-856d-03d0152ce7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44749,DS-8381914b-9319-4938-ae54-0e8dd3ee99bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-0106c528-4bcc-41b9-a5e6-c93f2854229b,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-c6c2b034-b6d6-4591-87ea-4972abcbe0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-57502346-3599-49a2-b7f5-15c44fa78297,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-786bc4c9-bdf4-43a2-a409-913cfaa4239c,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-b3bf15c9-0df1-4e8f-9062-99cbf5c12f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44345,DS-e5fdbdbc-84df-4444-bb3d-a6c662b19d40,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 26 out of 50
result: false positive !!!
Total execution time in seconds : 5302
