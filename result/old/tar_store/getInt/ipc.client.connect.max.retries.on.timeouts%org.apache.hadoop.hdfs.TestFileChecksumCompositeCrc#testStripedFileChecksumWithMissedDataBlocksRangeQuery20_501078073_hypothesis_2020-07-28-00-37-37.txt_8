reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457565286-172.17.0.20-1595896716631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44613,DS-7257a7c8-d101-446e-a833-64649ea34884,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-444705ce-f720-4eba-8c8f-37bdeb6c3394,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-93cfb47e-e2f2-4914-90c6-659f66b3f8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-5a590d21-3dcd-4d8b-b8a3-eaa04f35050b,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-7ddba9dc-3288-4660-b220-626379c1f510,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-13cd6f69-0f79-490e-bafe-4b5b15e46094,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-78b3dc3a-18d7-42a4-b8f8-3830a1624ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-cbc5da22-d578-463e-8920-80327c22a88d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457565286-172.17.0.20-1595896716631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44613,DS-7257a7c8-d101-446e-a833-64649ea34884,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-444705ce-f720-4eba-8c8f-37bdeb6c3394,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-93cfb47e-e2f2-4914-90c6-659f66b3f8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-5a590d21-3dcd-4d8b-b8a3-eaa04f35050b,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-7ddba9dc-3288-4660-b220-626379c1f510,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-13cd6f69-0f79-490e-bafe-4b5b15e46094,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-78b3dc3a-18d7-42a4-b8f8-3830a1624ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-cbc5da22-d578-463e-8920-80327c22a88d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80710254-172.17.0.20-1595896814360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37747,DS-28402a92-48c2-417d-aa03-632915ada1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-d732cec8-b8c0-4926-a14e-99b16f138c62,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-29cfbf1b-19ec-484a-b993-8d4befa9d7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-bdd1eedd-a4c1-4941-bfe6-80fcb5ad068b,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-c200ae35-c529-4577-8dc6-862ff2acd736,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-07c0f2f0-8157-4afa-b920-5ec1e27ef3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-0a59c48c-468e-44bf-89fe-424ee227b36a,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-84ad0ad2-89ad-4c15-a666-071727ce97ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-80710254-172.17.0.20-1595896814360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37747,DS-28402a92-48c2-417d-aa03-632915ada1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-d732cec8-b8c0-4926-a14e-99b16f138c62,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-29cfbf1b-19ec-484a-b993-8d4befa9d7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-bdd1eedd-a4c1-4941-bfe6-80fcb5ad068b,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-c200ae35-c529-4577-8dc6-862ff2acd736,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-07c0f2f0-8157-4afa-b920-5ec1e27ef3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-0a59c48c-468e-44bf-89fe-424ee227b36a,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-84ad0ad2-89ad-4c15-a666-071727ce97ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517937498-172.17.0.20-1595897263345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40463,DS-b48408da-0520-43fc-8433-c28cc4a2c8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-cdbe579b-c5ef-4717-a91f-e684b64cf7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-83f2c857-7535-49f4-8be1-85d66b0b4403,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-e0ed7938-df82-4dd6-a509-b0d7c7c011b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-ce35d3bf-884d-4c9a-a94a-6ec4504c6467,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-71bda701-9c8e-465b-a5f5-5681df3373c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-e8756f98-91e4-4e07-ae71-f8047f1f3086,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-f4eb349b-2a6a-41f9-b545-64c28d85f0ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-517937498-172.17.0.20-1595897263345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40463,DS-b48408da-0520-43fc-8433-c28cc4a2c8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-cdbe579b-c5ef-4717-a91f-e684b64cf7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-83f2c857-7535-49f4-8be1-85d66b0b4403,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-e0ed7938-df82-4dd6-a509-b0d7c7c011b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-ce35d3bf-884d-4c9a-a94a-6ec4504c6467,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-71bda701-9c8e-465b-a5f5-5681df3373c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-e8756f98-91e4-4e07-ae71-f8047f1f3086,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-f4eb349b-2a6a-41f9-b545-64c28d85f0ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303534444-172.17.0.20-1595897698940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42441,DS-4459e8fb-5100-48d4-acbe-20d8d951211d,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-e19fc60a-e729-4138-8e50-f67e04e63f70,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-652dc92e-e178-457f-a404-2d2dc5909c28,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-d9b168a1-2415-429a-9202-3f2d89f5567f,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-2510b936-f2ce-4124-9c0b-2cefaf27125a,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-1a85def3-0817-40fb-9681-64f196758fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-25d11b5f-d553-4c70-9d25-a70c538fb7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-7331c80c-ffb4-4705-8eb9-eb2917e633ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303534444-172.17.0.20-1595897698940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42441,DS-4459e8fb-5100-48d4-acbe-20d8d951211d,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-e19fc60a-e729-4138-8e50-f67e04e63f70,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-652dc92e-e178-457f-a404-2d2dc5909c28,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-d9b168a1-2415-429a-9202-3f2d89f5567f,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-2510b936-f2ce-4124-9c0b-2cefaf27125a,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-1a85def3-0817-40fb-9681-64f196758fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-25d11b5f-d553-4c70-9d25-a70c538fb7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-7331c80c-ffb4-4705-8eb9-eb2917e633ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-521499476-172.17.0.20-1595897828754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38505,DS-4bd479c9-36f1-4164-bc78-5311bfb8c2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-bc571026-e2f8-4c4b-98df-e8a5060835ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-eb8b0259-47c7-4f43-b0f8-4d7fbda189a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-c21f4da1-0713-46d6-b18e-e7ff0016190c,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-22f2acb3-1510-43ea-8ed3-b6e2d5c28544,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-b2cf8b19-ccfd-4ae3-a2b5-8ac1775582de,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-3b24a82d-dcbf-4a37-ac48-82b953bea59f,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-23f42a22-3ca5-4cf3-b9db-3ff95899cbad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-521499476-172.17.0.20-1595897828754:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38505,DS-4bd479c9-36f1-4164-bc78-5311bfb8c2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-bc571026-e2f8-4c4b-98df-e8a5060835ee,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-eb8b0259-47c7-4f43-b0f8-4d7fbda189a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-c21f4da1-0713-46d6-b18e-e7ff0016190c,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-22f2acb3-1510-43ea-8ed3-b6e2d5c28544,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-b2cf8b19-ccfd-4ae3-a2b5-8ac1775582de,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-3b24a82d-dcbf-4a37-ac48-82b953bea59f,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-23f42a22-3ca5-4cf3-b9db-3ff95899cbad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-78644607-172.17.0.20-1595897930950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45514,DS-fd29b8c1-3be0-4048-8b54-7346c12ef409,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-4322af5b-c669-4730-8823-dfda048d5c67,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-b98dc6f8-73b6-434d-9a06-4c3a5d3a1ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-f906d4fc-c83c-4be3-ac46-600940b18768,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-65d64c2b-1da8-49f9-8326-fd1afce22b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-3a45b741-b108-408c-a2f1-9216cd497116,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-5d303cd0-3cbe-4c94-b93d-d3be4bbe8bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-feddea00-6b75-4b6d-acb7-2d349498fbce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-78644607-172.17.0.20-1595897930950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45514,DS-fd29b8c1-3be0-4048-8b54-7346c12ef409,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-4322af5b-c669-4730-8823-dfda048d5c67,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-b98dc6f8-73b6-434d-9a06-4c3a5d3a1ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-f906d4fc-c83c-4be3-ac46-600940b18768,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-65d64c2b-1da8-49f9-8326-fd1afce22b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-3a45b741-b108-408c-a2f1-9216cd497116,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-5d303cd0-3cbe-4c94-b93d-d3be4bbe8bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-feddea00-6b75-4b6d-acb7-2d349498fbce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024164604-172.17.0.20-1595897967600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46664,DS-85c0eddf-fde4-4844-873e-06ee3039c061,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-c3f4392c-69be-40cc-8bdd-72beec91ba2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-3c031316-d40e-4c83-b5cb-9990bd2d3a92,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-48fa3b39-4333-4298-9553-4f82306fa415,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-28f1f23b-9b18-46d8-a830-20d975b627d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-64857f33-608d-4b1b-84bf-10829a7c8077,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-5a74ce26-a0c3-4941-9f8b-b891abcd71d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-e77c1a57-d597-4327-beef-9f0b19bb28a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024164604-172.17.0.20-1595897967600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46664,DS-85c0eddf-fde4-4844-873e-06ee3039c061,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-c3f4392c-69be-40cc-8bdd-72beec91ba2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-3c031316-d40e-4c83-b5cb-9990bd2d3a92,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-48fa3b39-4333-4298-9553-4f82306fa415,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-28f1f23b-9b18-46d8-a830-20d975b627d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-64857f33-608d-4b1b-84bf-10829a7c8077,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-5a74ce26-a0c3-4941-9f8b-b891abcd71d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-e77c1a57-d597-4327-beef-9f0b19bb28a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530216316-172.17.0.20-1595898565437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35876,DS-6c2cbc27-a3b1-422c-9e43-54eb3fc88578,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-8e3e87af-1265-473d-94de-e00abc94a2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-1837eaad-622b-4737-b023-24d32e29057d,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-5bfe76ca-dcc3-4d19-870f-e868c056ec5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-021eb9df-ece1-47f2-bb57-dd34dca72f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-143b2724-bc09-4c0a-a918-74231f8bf328,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-b76ac70a-8176-4dcf-b710-f1d71c6695a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-76f1c472-ab7b-43af-85ae-d5cccc621540,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530216316-172.17.0.20-1595898565437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35876,DS-6c2cbc27-a3b1-422c-9e43-54eb3fc88578,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-8e3e87af-1265-473d-94de-e00abc94a2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-1837eaad-622b-4737-b023-24d32e29057d,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-5bfe76ca-dcc3-4d19-870f-e868c056ec5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-021eb9df-ece1-47f2-bb57-dd34dca72f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-143b2724-bc09-4c0a-a918-74231f8bf328,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-b76ac70a-8176-4dcf-b710-f1d71c6695a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-76f1c472-ab7b-43af-85ae-d5cccc621540,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1165302452-172.17.0.20-1595899174412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43783,DS-29c909aa-c4d7-4eb7-8c12-e619480f45c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-ce096d29-92a8-4cc5-a4a9-338f451cf265,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-ff3ff388-f948-4084-89d5-ba4b3aae6913,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-08556748-11ab-489f-ad7f-ce0997495e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-a9a4fe0c-442d-4637-b5f8-c0731ae1e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-ad3298ad-d072-4ec4-ad5d-e7512e7276b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-f40743f2-cf9e-4311-9b94-a36782c4aea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-b5287f97-d3a3-4bb0-80e5-d3499f9511fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1165302452-172.17.0.20-1595899174412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43783,DS-29c909aa-c4d7-4eb7-8c12-e619480f45c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-ce096d29-92a8-4cc5-a4a9-338f451cf265,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-ff3ff388-f948-4084-89d5-ba4b3aae6913,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-08556748-11ab-489f-ad7f-ce0997495e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-a9a4fe0c-442d-4637-b5f8-c0731ae1e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-ad3298ad-d072-4ec4-ad5d-e7512e7276b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-f40743f2-cf9e-4311-9b94-a36782c4aea3,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-b5287f97-d3a3-4bb0-80e5-d3499f9511fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615790878-172.17.0.20-1595899215850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42160,DS-49ee5321-91c8-4a18-b46a-697942acb1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-9ad66b50-76ca-4117-8e71-3e3bec8bcd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-69e8e347-b553-47ed-a33f-b19421511933,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-d546b167-24fd-4ef9-acc9-ef9efebea1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-163592df-e671-4a23-b97d-a07c4e88a850,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-2e362505-b197-4f3c-b24f-171d858d38ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-81946df8-30ba-49eb-ac63-f37093d84c70,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-db528d1c-4f7b-4033-9ae6-28d8fe86531c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615790878-172.17.0.20-1595899215850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42160,DS-49ee5321-91c8-4a18-b46a-697942acb1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-9ad66b50-76ca-4117-8e71-3e3bec8bcd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-69e8e347-b553-47ed-a33f-b19421511933,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-d546b167-24fd-4ef9-acc9-ef9efebea1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-163592df-e671-4a23-b97d-a07c4e88a850,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-2e362505-b197-4f3c-b24f-171d858d38ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-81946df8-30ba-49eb-ac63-f37093d84c70,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-db528d1c-4f7b-4033-9ae6-28d8fe86531c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244338097-172.17.0.20-1595899500560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41902,DS-52750b33-68f6-4f70-a979-7ff7959a059d,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-b88a6a63-3b49-4649-b51d-30b1d5437d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-c0cf30ad-0032-4f7c-801c-87aa339e3663,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-5df3a755-abaf-4eb6-95ea-23a803c7ccf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-5460bf31-05ab-444d-bfdb-537c079f1b41,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-064fdd3e-d52b-46be-8609-895d3a6a4813,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-ae23f5c4-4fb7-49f2-9bb1-f5e7f7634a58,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-ec91b722-6b49-4ed0-9d65-ec0def681ad9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244338097-172.17.0.20-1595899500560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41902,DS-52750b33-68f6-4f70-a979-7ff7959a059d,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-b88a6a63-3b49-4649-b51d-30b1d5437d5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-c0cf30ad-0032-4f7c-801c-87aa339e3663,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-5df3a755-abaf-4eb6-95ea-23a803c7ccf7,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-5460bf31-05ab-444d-bfdb-537c079f1b41,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-064fdd3e-d52b-46be-8609-895d3a6a4813,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-ae23f5c4-4fb7-49f2-9bb1-f5e7f7634a58,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-ec91b722-6b49-4ed0-9d65-ec0def681ad9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-73941101-172.17.0.20-1595900361742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34928,DS-30659eca-ee33-4636-9449-9e772f192c54,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-00957b91-3f75-44e9-9386-de8019afcfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-b83883ea-8338-4137-a9f4-762e5906a3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-007d1287-c094-4345-82f4-d38afbb2038f,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-450b1ae4-4254-46c8-a079-ecc688782746,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-a1149055-ca9c-46bf-b2b2-af6d41dd625a,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-c4689a80-069b-42ad-a4c2-45b7e8c02081,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-1112828a-a20e-4483-ba4e-f4ca2f78e3b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-73941101-172.17.0.20-1595900361742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34928,DS-30659eca-ee33-4636-9449-9e772f192c54,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-00957b91-3f75-44e9-9386-de8019afcfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-b83883ea-8338-4137-a9f4-762e5906a3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-007d1287-c094-4345-82f4-d38afbb2038f,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-450b1ae4-4254-46c8-a079-ecc688782746,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-a1149055-ca9c-46bf-b2b2-af6d41dd625a,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-c4689a80-069b-42ad-a4c2-45b7e8c02081,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-1112828a-a20e-4483-ba4e-f4ca2f78e3b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096215962-172.17.0.20-1595900701907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37556,DS-f6752797-5c8d-4c62-b8a8-00b0fa32cdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-381f46f4-2ed7-49d7-bd60-59a938e2ccaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-ddbada8c-5b3e-4515-bd68-a255f7af265a,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-ea600014-6529-4970-a915-353928554d96,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-007b847b-e142-445d-aaf3-75d6f3cdf67b,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-e0572439-3f3d-459f-94a0-3fea24daa29f,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-42febd7a-d9ae-4ac0-a992-d067d3ac9a61,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-e3dbefaf-74d2-4fab-af42-9f6e42baeb7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2096215962-172.17.0.20-1595900701907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37556,DS-f6752797-5c8d-4c62-b8a8-00b0fa32cdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-381f46f4-2ed7-49d7-bd60-59a938e2ccaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-ddbada8c-5b3e-4515-bd68-a255f7af265a,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-ea600014-6529-4970-a915-353928554d96,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-007b847b-e142-445d-aaf3-75d6f3cdf67b,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-e0572439-3f3d-459f-94a0-3fea24daa29f,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-42febd7a-d9ae-4ac0-a992-d067d3ac9a61,DISK], DatanodeInfoWithStorage[127.0.0.1:45503,DS-e3dbefaf-74d2-4fab-af42-9f6e42baeb7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408470891-172.17.0.20-1595900773762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39537,DS-b0c62641-f28e-4b1e-9320-f131e8ac3c66,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-fd231996-7e2a-4094-b299-7565c25866b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-908aad34-f919-4fc8-99ef-64cd407e440c,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-583f898c-1f51-4b8b-9bb6-b289e3851bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-7798aea0-8f2d-42bd-affb-aa81ced70bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-036af375-b8cb-44f7-8d98-3a96ceb39a39,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-b4aeb549-934f-416b-96bf-a7ffb7d58d41,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-c25642f7-95c7-4165-aae9-6576320727db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1408470891-172.17.0.20-1595900773762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39537,DS-b0c62641-f28e-4b1e-9320-f131e8ac3c66,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-fd231996-7e2a-4094-b299-7565c25866b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-908aad34-f919-4fc8-99ef-64cd407e440c,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-583f898c-1f51-4b8b-9bb6-b289e3851bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-7798aea0-8f2d-42bd-affb-aa81ced70bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-036af375-b8cb-44f7-8d98-3a96ceb39a39,DISK], DatanodeInfoWithStorage[127.0.0.1:40657,DS-b4aeb549-934f-416b-96bf-a7ffb7d58d41,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-c25642f7-95c7-4165-aae9-6576320727db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504596951-172.17.0.20-1595901126517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40049,DS-c403d891-bb57-4016-8b00-1d0117136fca,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-a18a6980-de00-404f-aea9-fffe964af9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-349b132e-c8ca-4391-bec4-82852f3158fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-7cafc6c5-56f3-4717-9564-9b5d2b850686,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-d1ca670f-bdc8-42ab-a765-006a1a59158b,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-5c1eafb5-ccef-4311-aa4b-43c89464f20a,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-6116bb9a-33dd-4cd6-aa17-b24f089e3e86,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-927b5ff4-bc78-4e24-a189-743b9f9e868f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504596951-172.17.0.20-1595901126517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40049,DS-c403d891-bb57-4016-8b00-1d0117136fca,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-a18a6980-de00-404f-aea9-fffe964af9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-349b132e-c8ca-4391-bec4-82852f3158fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-7cafc6c5-56f3-4717-9564-9b5d2b850686,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-d1ca670f-bdc8-42ab-a765-006a1a59158b,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-5c1eafb5-ccef-4311-aa4b-43c89464f20a,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-6116bb9a-33dd-4cd6-aa17-b24f089e3e86,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-927b5ff4-bc78-4e24-a189-743b9f9e868f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387290071-172.17.0.20-1595901542814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39800,DS-c7d07b86-9e26-4c3b-8fe4-006f3a4c0f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-213e901a-e27d-420c-852d-732a337759c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-7226118c-c3ae-4737-9954-847a38049321,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-9416c60a-73c4-4117-b772-14c5a9701a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-4d161408-85f2-4679-970e-7e3f93cd0118,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-7925d44d-7f10-4070-812e-4f06382ace22,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-bc5d6b98-94d5-47af-833f-b01291b17b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-1d9cdf34-5bc3-4e30-aa6a-474d6a6da474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387290071-172.17.0.20-1595901542814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39800,DS-c7d07b86-9e26-4c3b-8fe4-006f3a4c0f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-213e901a-e27d-420c-852d-732a337759c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-7226118c-c3ae-4737-9954-847a38049321,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-9416c60a-73c4-4117-b772-14c5a9701a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-4d161408-85f2-4679-970e-7e3f93cd0118,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-7925d44d-7f10-4070-812e-4f06382ace22,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-bc5d6b98-94d5-47af-833f-b01291b17b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-1d9cdf34-5bc3-4e30-aa6a-474d6a6da474,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1630200742-172.17.0.20-1595901574786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35865,DS-d34a455f-c8f1-447c-829b-40df16c3e402,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-c6573f54-037e-4285-8137-42102a7be2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-66991af6-d6ac-4038-902a-5d68bf013556,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-71010093-1d15-487d-a1d9-856454a2577a,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-fc36ca3d-7558-46e7-b57e-87e1e3ace5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-17a2fc93-b311-4108-8eec-103ecec5418d,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-d1337ccb-6ae5-4bd3-90a7-eb4604c5f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-1827204c-e500-4f39-b20f-8ee96ed06519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1630200742-172.17.0.20-1595901574786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35865,DS-d34a455f-c8f1-447c-829b-40df16c3e402,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-c6573f54-037e-4285-8137-42102a7be2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-66991af6-d6ac-4038-902a-5d68bf013556,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-71010093-1d15-487d-a1d9-856454a2577a,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-fc36ca3d-7558-46e7-b57e-87e1e3ace5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-17a2fc93-b311-4108-8eec-103ecec5418d,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-d1337ccb-6ae5-4bd3-90a7-eb4604c5f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-1827204c-e500-4f39-b20f-8ee96ed06519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759547171-172.17.0.20-1595901611333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33975,DS-01dadc18-d283-4b14-8ae2-14c43cf4c07a,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-945fff06-6e6a-4c9b-86ff-e7103142913c,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-e9b48554-2e5d-41c0-a9a3-eb5a69942d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-d745cdb3-ad9d-43af-ac39-e2a4a82b2cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-fba4d849-5c9c-424f-bcaa-d719af7d3eef,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-a82d71a4-1cd5-49ba-81a2-968c5d003046,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-e341e20e-56c6-400d-9c05-0a2a4ebf928d,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-35d0ad31-0c09-4871-b4e5-aa53902aedd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759547171-172.17.0.20-1595901611333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33975,DS-01dadc18-d283-4b14-8ae2-14c43cf4c07a,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-945fff06-6e6a-4c9b-86ff-e7103142913c,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-e9b48554-2e5d-41c0-a9a3-eb5a69942d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-d745cdb3-ad9d-43af-ac39-e2a4a82b2cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-fba4d849-5c9c-424f-bcaa-d719af7d3eef,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-a82d71a4-1cd5-49ba-81a2-968c5d003046,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-e341e20e-56c6-400d-9c05-0a2a4ebf928d,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-35d0ad31-0c09-4871-b4e5-aa53902aedd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5228
