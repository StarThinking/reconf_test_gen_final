reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999476842-172.17.0.8-1595904445191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41709,DS-b170e150-def8-4e72-826a-aedac1568ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-b2f8ca3e-f0cf-45bd-85d8-8e0b72fa45dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-fde5b1bc-b761-4ba9-8191-73d955bb72c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-2bd46893-e836-4764-b9b1-2b1f669819f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-5fb300fe-adc4-47ed-8878-02a2aa5ec312,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-71aa50f7-fc6b-413e-9b05-ed1e597ebb35,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-be5c72cf-b78f-4093-a90c-29745cf9ebce,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-832f0e5a-1b77-4fff-9df1-72eb91447456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999476842-172.17.0.8-1595904445191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41709,DS-b170e150-def8-4e72-826a-aedac1568ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-b2f8ca3e-f0cf-45bd-85d8-8e0b72fa45dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-fde5b1bc-b761-4ba9-8191-73d955bb72c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-2bd46893-e836-4764-b9b1-2b1f669819f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-5fb300fe-adc4-47ed-8878-02a2aa5ec312,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-71aa50f7-fc6b-413e-9b05-ed1e597ebb35,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-be5c72cf-b78f-4093-a90c-29745cf9ebce,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-832f0e5a-1b77-4fff-9df1-72eb91447456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58704041-172.17.0.8-1595904819489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-cb743b3c-5339-4498-8236-54943f81b987,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-2a148998-a319-4a06-b41f-dc12f86e3e67,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-858b785b-a034-4da3-a9d4-7df8d9eb47ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-d3bb4e7b-8a8f-4157-bbba-6630dc2a9e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-6ae81d1e-53c8-41ce-bdeb-bbfc37bdd3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-928d5406-eb5b-46cd-a50b-267b1c01863c,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-d2ec6135-ebcf-4654-83dd-447d0553f3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-b5608087-97fa-4f31-bd15-ff4a88709505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58704041-172.17.0.8-1595904819489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-cb743b3c-5339-4498-8236-54943f81b987,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-2a148998-a319-4a06-b41f-dc12f86e3e67,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-858b785b-a034-4da3-a9d4-7df8d9eb47ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-d3bb4e7b-8a8f-4157-bbba-6630dc2a9e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-6ae81d1e-53c8-41ce-bdeb-bbfc37bdd3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-928d5406-eb5b-46cd-a50b-267b1c01863c,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-d2ec6135-ebcf-4654-83dd-447d0553f3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-b5608087-97fa-4f31-bd15-ff4a88709505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488509897-172.17.0.8-1595904888822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33359,DS-78dc4845-bafa-4107-aca3-560c79c2bf38,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-f717749c-9280-418e-b50b-e353ff21b726,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-79ab40a9-3026-4647-ab31-2cb92b21770d,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-6de0b6ef-98ae-4001-8224-4ffcbf0731db,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-7f08e91e-2e35-43db-8e9f-591d1e03e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-bea512f8-9167-4c64-bfa1-66569b2178ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-ac16590e-0041-4eab-bc9f-696e589f063f,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-2cb8f210-2515-4543-a2bd-1315b6cdb54c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488509897-172.17.0.8-1595904888822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33359,DS-78dc4845-bafa-4107-aca3-560c79c2bf38,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-f717749c-9280-418e-b50b-e353ff21b726,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-79ab40a9-3026-4647-ab31-2cb92b21770d,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-6de0b6ef-98ae-4001-8224-4ffcbf0731db,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-7f08e91e-2e35-43db-8e9f-591d1e03e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-bea512f8-9167-4c64-bfa1-66569b2178ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-ac16590e-0041-4eab-bc9f-696e589f063f,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-2cb8f210-2515-4543-a2bd-1315b6cdb54c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637200479-172.17.0.8-1595905254834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45412,DS-b3551693-3b83-44ad-8923-32b3692e6624,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-b2bf0c8b-489c-4528-9815-864fe1e77ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-cdc2c433-6f89-40d7-80db-a83310e57798,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-07fd1311-3450-4bb7-931d-eeab4cb2da6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-fcf4deb0-ccb4-4330-b095-4599f82c1c83,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-658cb8d6-bda9-43d2-aed6-14b4a2464bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-1b19ca57-0a2f-452e-aacc-def8fafe8bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-6172ed91-112b-41d4-b009-35b7c7eeedef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637200479-172.17.0.8-1595905254834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45412,DS-b3551693-3b83-44ad-8923-32b3692e6624,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-b2bf0c8b-489c-4528-9815-864fe1e77ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-cdc2c433-6f89-40d7-80db-a83310e57798,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-07fd1311-3450-4bb7-931d-eeab4cb2da6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-fcf4deb0-ccb4-4330-b095-4599f82c1c83,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-658cb8d6-bda9-43d2-aed6-14b4a2464bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-1b19ca57-0a2f-452e-aacc-def8fafe8bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-6172ed91-112b-41d4-b009-35b7c7eeedef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561806725-172.17.0.8-1595906220870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33124,DS-adfb1166-396a-4875-ac80-a5bbd2aea251,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-8f339f38-43bc-43f5-b6eb-bc1bb071a079,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-befe259a-bfd0-426c-8066-c2d5ee3c251c,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-82af8a6c-07ed-416a-9f9b-584fbb958931,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-b99b478b-86b5-476d-a84b-05299ede7ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-39058e84-19b5-4ca0-b24e-e399c2aa55fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-2e05353a-7330-4fb0-86a0-0ceec523ee33,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-87f05ace-7bc7-47ba-a729-35042f169c1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1561806725-172.17.0.8-1595906220870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33124,DS-adfb1166-396a-4875-ac80-a5bbd2aea251,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-8f339f38-43bc-43f5-b6eb-bc1bb071a079,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-befe259a-bfd0-426c-8066-c2d5ee3c251c,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-82af8a6c-07ed-416a-9f9b-584fbb958931,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-b99b478b-86b5-476d-a84b-05299ede7ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-39058e84-19b5-4ca0-b24e-e399c2aa55fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-2e05353a-7330-4fb0-86a0-0ceec523ee33,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-87f05ace-7bc7-47ba-a729-35042f169c1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376071657-172.17.0.8-1595906412910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43962,DS-315b980a-a68c-48d9-b03e-91758a76a57e,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-f27daab3-767d-4f14-9da4-4cabe6224c34,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-075c3fad-2ffb-435c-b69c-fc2b118d460f,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-f994cbab-6613-4c49-80e7-fe718df3ef63,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-8bc47808-e6ef-4ec5-9b02-3c79db080319,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-fcac28ff-9571-4d9d-8827-9e0369b318c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-8f9bda9f-af5c-424c-bae8-ecb84aec37ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-2e996907-a52e-4048-b442-4afa1ac8c2c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376071657-172.17.0.8-1595906412910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43962,DS-315b980a-a68c-48d9-b03e-91758a76a57e,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-f27daab3-767d-4f14-9da4-4cabe6224c34,DISK], DatanodeInfoWithStorage[127.0.0.1:42888,DS-075c3fad-2ffb-435c-b69c-fc2b118d460f,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-f994cbab-6613-4c49-80e7-fe718df3ef63,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-8bc47808-e6ef-4ec5-9b02-3c79db080319,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-fcac28ff-9571-4d9d-8827-9e0369b318c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-8f9bda9f-af5c-424c-bae8-ecb84aec37ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-2e996907-a52e-4048-b442-4afa1ac8c2c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535185277-172.17.0.8-1595906445355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38216,DS-b3f0f1e6-327d-4d5a-bc66-fa1419027cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-edffeefb-4693-47e1-8201-b89175880842,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-7a9cf99f-4e46-4fc1-8621-0b4a43f48a46,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-f015889e-483f-4873-a345-909703a34eab,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-9c854c79-8196-4ad5-ae26-0d96784c0ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-6fdc1b91-d423-4c84-8fad-751b763793f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-24de0dbd-0690-4f20-8936-f31932a08a79,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-e8ccade2-cdeb-4931-b018-739a15038acc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535185277-172.17.0.8-1595906445355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38216,DS-b3f0f1e6-327d-4d5a-bc66-fa1419027cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-edffeefb-4693-47e1-8201-b89175880842,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-7a9cf99f-4e46-4fc1-8621-0b4a43f48a46,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-f015889e-483f-4873-a345-909703a34eab,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-9c854c79-8196-4ad5-ae26-0d96784c0ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-6fdc1b91-d423-4c84-8fad-751b763793f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-24de0dbd-0690-4f20-8936-f31932a08a79,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-e8ccade2-cdeb-4931-b018-739a15038acc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410932585-172.17.0.8-1595906677700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34635,DS-73fbb995-9a1b-4837-857c-b8c8f8c142b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-61043982-6dfc-4cad-9c28-10e859dd42fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-1aa12cfc-76ac-459b-ae00-75235d5c9225,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-190ea0ce-3ed5-488f-9495-3c2440f2e72d,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-2986f197-16fd-4e24-ae03-8b8c067381d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-6e455240-18e0-4f24-8e73-6026c865bad1,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-ee917acb-3a20-4739-b790-d838470d223b,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-3a2c7bf5-0f71-45fc-86ac-fd502c06ca0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410932585-172.17.0.8-1595906677700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34635,DS-73fbb995-9a1b-4837-857c-b8c8f8c142b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34876,DS-61043982-6dfc-4cad-9c28-10e859dd42fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-1aa12cfc-76ac-459b-ae00-75235d5c9225,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-190ea0ce-3ed5-488f-9495-3c2440f2e72d,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-2986f197-16fd-4e24-ae03-8b8c067381d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42889,DS-6e455240-18e0-4f24-8e73-6026c865bad1,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-ee917acb-3a20-4739-b790-d838470d223b,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-3a2c7bf5-0f71-45fc-86ac-fd502c06ca0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489275840-172.17.0.8-1595907771514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39189,DS-d2bd7de2-5716-4613-9360-866208e9dd64,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-bc5e1fa5-a95f-4605-bc3e-8bc948ab5228,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-b3fc0d3d-cf3b-46f1-8762-61d95c6ab125,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-8d24d0e9-3cdd-4fb3-a215-5c55545260b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-57bbaa8a-f1af-4de3-af29-9443d0115b50,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-19f09444-e21c-4201-b913-37b7484bb155,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-2c60ed1e-b116-4f35-886d-6d1e5a13d7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-ab36acb1-9885-4cb9-a701-32563cfa03be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489275840-172.17.0.8-1595907771514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39189,DS-d2bd7de2-5716-4613-9360-866208e9dd64,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-bc5e1fa5-a95f-4605-bc3e-8bc948ab5228,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-b3fc0d3d-cf3b-46f1-8762-61d95c6ab125,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-8d24d0e9-3cdd-4fb3-a215-5c55545260b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-57bbaa8a-f1af-4de3-af29-9443d0115b50,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-19f09444-e21c-4201-b913-37b7484bb155,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-2c60ed1e-b116-4f35-886d-6d1e5a13d7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-ab36acb1-9885-4cb9-a701-32563cfa03be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121281734-172.17.0.8-1595907948094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37750,DS-9e746fcb-eb06-42fd-aab1-198180016b95,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-04ac433f-180e-42c1-a138-25aa50eca6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-d41c0a30-50de-42b6-a832-218336ffb3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-a770c500-091c-4336-b08d-5af969105136,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b0071b0f-8730-492a-bb5a-6b52ab560bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-e4519c89-b0db-49a4-a8fb-c32b0ab8754a,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-92510a74-ffa1-4a29-90f8-3865a006d0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-583b2006-7841-487e-ac11-77c2f4d027c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121281734-172.17.0.8-1595907948094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37750,DS-9e746fcb-eb06-42fd-aab1-198180016b95,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-04ac433f-180e-42c1-a138-25aa50eca6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-d41c0a30-50de-42b6-a832-218336ffb3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-a770c500-091c-4336-b08d-5af969105136,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-b0071b0f-8730-492a-bb5a-6b52ab560bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-e4519c89-b0db-49a4-a8fb-c32b0ab8754a,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-92510a74-ffa1-4a29-90f8-3865a006d0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-583b2006-7841-487e-ac11-77c2f4d027c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251115471-172.17.0.8-1595908417182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37115,DS-74069bad-0fa3-43cf-87a8-7238ed0c8a75,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-30c67a85-b66a-402b-86e3-e88fb18ed091,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-c48c3a5c-ad89-4ef4-af8f-98f7cdcdbba4,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-b5f64b69-4ebe-47e4-9512-e5da276d7a53,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-7b110c7e-6fae-41ae-bcd8-677c0d32aaac,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-39766e1c-871b-4f70-81f8-d9b44c7c9b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-1b81e269-eb17-41f4-bb1d-3a96d0b59656,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-65f35a44-e7f4-4752-bc5a-08a829a97000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1251115471-172.17.0.8-1595908417182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37115,DS-74069bad-0fa3-43cf-87a8-7238ed0c8a75,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-30c67a85-b66a-402b-86e3-e88fb18ed091,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-c48c3a5c-ad89-4ef4-af8f-98f7cdcdbba4,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-b5f64b69-4ebe-47e4-9512-e5da276d7a53,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-7b110c7e-6fae-41ae-bcd8-677c0d32aaac,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-39766e1c-871b-4f70-81f8-d9b44c7c9b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-1b81e269-eb17-41f4-bb1d-3a96d0b59656,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-65f35a44-e7f4-4752-bc5a-08a829a97000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 1048576
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608731505-172.17.0.8-1595908565243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35892,DS-60db5c73-56d6-43a1-998a-8ba915c6e175,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-67422ea7-6bb4-4b8b-a24d-21c1d0df8f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-198ce513-76eb-4e3d-808d-5daa1c77870d,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-7d347bb5-5cec-4592-8698-0efb611c54d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-b816d4e9-f409-480f-951a-42a0f881278c,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-3fe2da32-9dbf-461d-a6df-f394adf776b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-716e7cec-0659-479a-adcb-11105615e030,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-0d71a24b-6f6d-45cb-8060-c52b55f021c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608731505-172.17.0.8-1595908565243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35892,DS-60db5c73-56d6-43a1-998a-8ba915c6e175,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-67422ea7-6bb4-4b8b-a24d-21c1d0df8f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-198ce513-76eb-4e3d-808d-5daa1c77870d,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-7d347bb5-5cec-4592-8698-0efb611c54d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-b816d4e9-f409-480f-951a-42a0f881278c,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-3fe2da32-9dbf-461d-a6df-f394adf776b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-716e7cec-0659-479a-adcb-11105615e030,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-0d71a24b-6f6d-45cb-8060-c52b55f021c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5392
