reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-588254235-172.17.0.7-1595924536880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42696,DS-a271cd5e-a496-48c3-a567-172b54522388,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-bfa1e849-0046-4781-aa11-5b8be3c87d85,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-93aefe0c-e13a-44ad-9d0b-a4a57744f3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-26074b4b-4e06-4336-a864-f544944b4949,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-24be8119-961a-40ea-95af-e2ea82be8a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-8a897327-b107-40b0-b2a4-54a85cf10366,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-c36bf732-4ac1-4454-835b-7cadae35857d,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-b45d7cb4-da0f-41f6-95bc-2cb961630cae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-588254235-172.17.0.7-1595924536880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42696,DS-a271cd5e-a496-48c3-a567-172b54522388,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-bfa1e849-0046-4781-aa11-5b8be3c87d85,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-93aefe0c-e13a-44ad-9d0b-a4a57744f3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-26074b4b-4e06-4336-a864-f544944b4949,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-24be8119-961a-40ea-95af-e2ea82be8a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-8a897327-b107-40b0-b2a4-54a85cf10366,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-c36bf732-4ac1-4454-835b-7cadae35857d,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-b45d7cb4-da0f-41f6-95bc-2cb961630cae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839099694-172.17.0.7-1595924769735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35581,DS-9581dbfe-94ff-46e6-a9a2-67dde2ec97f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-4c860d0e-8012-4f43-9210-eb9f2c0368c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-5680a869-0aaf-42bf-a805-4b94b74e1571,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-c6599278-ab7d-4f66-91de-263555b002ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-19b01d11-c259-4286-86ff-066438dc0c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-dbad709d-a86b-46a2-8a0c-6a4c1dd2a6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-7250e0b3-6d81-4230-8984-a9a8cbf9252f,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-56ab4d4c-51cc-4665-abfb-c6ecf8f82669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839099694-172.17.0.7-1595924769735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35581,DS-9581dbfe-94ff-46e6-a9a2-67dde2ec97f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-4c860d0e-8012-4f43-9210-eb9f2c0368c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-5680a869-0aaf-42bf-a805-4b94b74e1571,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-c6599278-ab7d-4f66-91de-263555b002ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-19b01d11-c259-4286-86ff-066438dc0c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-dbad709d-a86b-46a2-8a0c-6a4c1dd2a6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-7250e0b3-6d81-4230-8984-a9a8cbf9252f,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-56ab4d4c-51cc-4665-abfb-c6ecf8f82669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899367079-172.17.0.7-1595924811460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45665,DS-56326dfa-746e-401f-b10f-242720cf9af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-0207edf6-3c73-4dbf-9f73-45bdecf3a57e,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-77e15561-d7cd-4921-8769-dfc90807b5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-6b70623a-e6a3-4297-9fe7-140659e61642,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-c8f4bff1-9257-4748-8668-5eb09c4b2e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-94009e95-5eb3-48ac-a7b1-2e18991a898e,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-25616dc7-6252-4d29-8da0-423a002c27cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-d1f7fd46-620a-4dff-9535-1e89471d246c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1899367079-172.17.0.7-1595924811460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45665,DS-56326dfa-746e-401f-b10f-242720cf9af0,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-0207edf6-3c73-4dbf-9f73-45bdecf3a57e,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-77e15561-d7cd-4921-8769-dfc90807b5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-6b70623a-e6a3-4297-9fe7-140659e61642,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-c8f4bff1-9257-4748-8668-5eb09c4b2e77,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-94009e95-5eb3-48ac-a7b1-2e18991a898e,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-25616dc7-6252-4d29-8da0-423a002c27cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-d1f7fd46-620a-4dff-9535-1e89471d246c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133661470-172.17.0.7-1595924846268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35548,DS-cf5982b3-12d1-46e1-8e1c-3dc9e6257e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-9900e401-74a6-4d82-912b-339831e30a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-11ded095-366d-4984-874d-9c838399aee4,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-0919df0b-fe82-477d-bc35-924f4ea65476,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-fafbb843-c8b6-4d9b-b3d9-e00066648104,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-43478e99-64fb-4668-ac41-7263c1a06777,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-e876e5c5-ce19-4293-82c8-d8265e72ea1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-646e09ab-d0c3-4cae-8550-746749b80871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133661470-172.17.0.7-1595924846268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35548,DS-cf5982b3-12d1-46e1-8e1c-3dc9e6257e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-9900e401-74a6-4d82-912b-339831e30a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-11ded095-366d-4984-874d-9c838399aee4,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-0919df0b-fe82-477d-bc35-924f4ea65476,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-fafbb843-c8b6-4d9b-b3d9-e00066648104,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-43478e99-64fb-4668-ac41-7263c1a06777,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-e876e5c5-ce19-4293-82c8-d8265e72ea1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-646e09ab-d0c3-4cae-8550-746749b80871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370815037-172.17.0.7-1595924960172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41801,DS-4208e095-7fc0-488f-bc31-ec344548325c,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-93ee1915-5e97-4221-872e-a6a23b5a77d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-10b8400f-accf-49e3-bc37-38d4850a20ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-06f226cb-fd5b-49eb-81d2-400b608feac6,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-2b67afdc-c587-4929-a365-6a697f555dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-9881072e-8764-4380-8aff-9c87a181e73f,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-75eabe10-c056-4331-8a84-031caaf3f426,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-d30f5039-01f6-4193-b023-07f9b333e165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370815037-172.17.0.7-1595924960172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41801,DS-4208e095-7fc0-488f-bc31-ec344548325c,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-93ee1915-5e97-4221-872e-a6a23b5a77d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-10b8400f-accf-49e3-bc37-38d4850a20ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-06f226cb-fd5b-49eb-81d2-400b608feac6,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-2b67afdc-c587-4929-a365-6a697f555dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-9881072e-8764-4380-8aff-9c87a181e73f,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-75eabe10-c056-4331-8a84-031caaf3f426,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-d30f5039-01f6-4193-b023-07f9b333e165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918034422-172.17.0.7-1595925389680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46582,DS-cfa35f22-4087-478d-9df4-6d70d4fae295,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-83ccc16e-0634-4173-aa56-337ad889564d,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-04eef879-f3b4-4959-96ef-f68d3439c4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-f92ee775-a49d-40e6-a397-f088eb5d68e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-342e0a2d-c053-4325-ab13-771224a77533,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-7554acf6-a121-4561-a74f-013a56ad4268,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-d9ddae1e-4537-49e0-b73c-a10e1c9b886c,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-7a25e211-d637-4d12-b211-361d55bea26e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918034422-172.17.0.7-1595925389680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46582,DS-cfa35f22-4087-478d-9df4-6d70d4fae295,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-83ccc16e-0634-4173-aa56-337ad889564d,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-04eef879-f3b4-4959-96ef-f68d3439c4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-f92ee775-a49d-40e6-a397-f088eb5d68e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-342e0a2d-c053-4325-ab13-771224a77533,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-7554acf6-a121-4561-a74f-013a56ad4268,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-d9ddae1e-4537-49e0-b73c-a10e1c9b886c,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-7a25e211-d637-4d12-b211-361d55bea26e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452373026-172.17.0.7-1595925649552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44486,DS-ac8653b5-ec5f-4fca-ab9f-31bb5b4dae56,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-975d9038-52aa-4ddb-981d-a14d7e579892,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-5e510dff-7971-4736-9d77-9397eb023ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-1fec5a80-ecba-42f5-8ec0-cde56b564de8,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-bd179af5-40fb-4d5d-af82-768e15ec3b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-5f303858-00ec-4622-bd61-ec0527f1dac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-9eca9612-59c4-4c81-bce2-e30af4afbd80,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-d62ef63f-34df-4be0-bc2f-dcaa1b119146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452373026-172.17.0.7-1595925649552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44486,DS-ac8653b5-ec5f-4fca-ab9f-31bb5b4dae56,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-975d9038-52aa-4ddb-981d-a14d7e579892,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-5e510dff-7971-4736-9d77-9397eb023ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-1fec5a80-ecba-42f5-8ec0-cde56b564de8,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-bd179af5-40fb-4d5d-af82-768e15ec3b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-5f303858-00ec-4622-bd61-ec0527f1dac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-9eca9612-59c4-4c81-bce2-e30af4afbd80,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-d62ef63f-34df-4be0-bc2f-dcaa1b119146,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143930472-172.17.0.7-1595926041567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45024,DS-db64852d-2893-49ea-9161-02bc1c8f090d,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-8b3da0b8-1f07-43a1-9d81-8be9829d8a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-62d89362-e2f0-4edc-a6eb-14ffc36cd3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-c27fc106-a1bb-4866-beb2-73f2d0fca496,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-10bc61fd-b2fc-4e57-9b11-fe906608d912,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-00dfb8d4-606d-42ae-84d9-f629fa3e525b,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-4910a15a-581f-4e30-b99e-bcfbfb59544d,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-d96a9bc5-532e-4bb1-a506-9cafd1d9de88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143930472-172.17.0.7-1595926041567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45024,DS-db64852d-2893-49ea-9161-02bc1c8f090d,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-8b3da0b8-1f07-43a1-9d81-8be9829d8a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-62d89362-e2f0-4edc-a6eb-14ffc36cd3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-c27fc106-a1bb-4866-beb2-73f2d0fca496,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-10bc61fd-b2fc-4e57-9b11-fe906608d912,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-00dfb8d4-606d-42ae-84d9-f629fa3e525b,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-4910a15a-581f-4e30-b99e-bcfbfb59544d,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-d96a9bc5-532e-4bb1-a506-9cafd1d9de88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882962349-172.17.0.7-1595926115071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35943,DS-31372650-a5aa-4995-8b47-6d270676aea2,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-81aaafd6-e76e-443d-a26e-44396f652fff,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-3b721e40-9e9f-41a9-b47e-d4bda83d1650,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-d7784733-a2cb-4738-b70d-aef325371599,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-839af5f1-46be-4f12-9872-a2c9644842d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-edb545e3-e66f-47fc-8ae1-0d0c7f74696b,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-f2d5e512-8176-497e-b708-de9b61fccc12,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-ce572ef3-e8ff-4682-9fba-2913ca839f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882962349-172.17.0.7-1595926115071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35943,DS-31372650-a5aa-4995-8b47-6d270676aea2,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-81aaafd6-e76e-443d-a26e-44396f652fff,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-3b721e40-9e9f-41a9-b47e-d4bda83d1650,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-d7784733-a2cb-4738-b70d-aef325371599,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-839af5f1-46be-4f12-9872-a2c9644842d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-edb545e3-e66f-47fc-8ae1-0d0c7f74696b,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-f2d5e512-8176-497e-b708-de9b61fccc12,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-ce572ef3-e8ff-4682-9fba-2913ca839f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306065047-172.17.0.7-1595926294118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35298,DS-5d5bceec-997e-45ca-909a-3ca03435e3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-ed8ba3c0-ab45-4040-9ab6-c7a9de76120c,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-ce6f2f01-a4bb-49c4-8147-2088f6dd0c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-c0195686-88a4-4c03-90e5-196e3c7b018c,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-dcb79afd-d03c-4f82-a6f6-f184926ce01b,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-068e5831-a55c-49a3-af61-e10e42a1ea6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-27f5f90d-b100-407a-9901-266a776ff4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-09992385-3b0c-4a45-8897-3bd0f81f33ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306065047-172.17.0.7-1595926294118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35298,DS-5d5bceec-997e-45ca-909a-3ca03435e3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-ed8ba3c0-ab45-4040-9ab6-c7a9de76120c,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-ce6f2f01-a4bb-49c4-8147-2088f6dd0c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-c0195686-88a4-4c03-90e5-196e3c7b018c,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-dcb79afd-d03c-4f82-a6f6-f184926ce01b,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-068e5831-a55c-49a3-af61-e10e42a1ea6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-27f5f90d-b100-407a-9901-266a776ff4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-09992385-3b0c-4a45-8897-3bd0f81f33ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995345366-172.17.0.7-1595926747895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43677,DS-253f26df-a7b0-4dc2-97b1-f19a685192a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-111f603a-f8f9-4b28-8724-f06163485b44,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-c7685d50-08ab-47e9-969d-e97565a1b24c,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-7defe92b-58f1-49c6-b620-0195570da1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-686e228c-65c7-477d-a610-14da354d7d08,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-1ad739b6-df69-4e59-9d03-703bb0789716,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-cc10a4c4-0215-4765-8d5d-65d21b123074,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-8bdef4be-8847-4146-b3c1-e06a3904632c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995345366-172.17.0.7-1595926747895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43677,DS-253f26df-a7b0-4dc2-97b1-f19a685192a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-111f603a-f8f9-4b28-8724-f06163485b44,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-c7685d50-08ab-47e9-969d-e97565a1b24c,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-7defe92b-58f1-49c6-b620-0195570da1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-686e228c-65c7-477d-a610-14da354d7d08,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-1ad739b6-df69-4e59-9d03-703bb0789716,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-cc10a4c4-0215-4765-8d5d-65d21b123074,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-8bdef4be-8847-4146-b3c1-e06a3904632c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341306321-172.17.0.7-1595926808459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33924,DS-edc05d63-8791-4e08-b230-038d7b735590,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-55c9a2a6-8f0d-4a29-a95f-d29c58a3e8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-73bf2622-ec36-4d34-829b-84c480797b61,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-9a320c95-e93c-43f9-91d9-97f90109b934,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-7401ae30-e859-4c77-9790-a927c64f4363,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-c641d0a3-92d6-414b-a50d-2b14a5a8ee62,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-d2a8a1f4-9ccb-40eb-87c0-f6aa36710636,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-9c539042-3b11-4296-a5ac-74f6b1b2280f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341306321-172.17.0.7-1595926808459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33924,DS-edc05d63-8791-4e08-b230-038d7b735590,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-55c9a2a6-8f0d-4a29-a95f-d29c58a3e8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-73bf2622-ec36-4d34-829b-84c480797b61,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-9a320c95-e93c-43f9-91d9-97f90109b934,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-7401ae30-e859-4c77-9790-a927c64f4363,DISK], DatanodeInfoWithStorage[127.0.0.1:41361,DS-c641d0a3-92d6-414b-a50d-2b14a5a8ee62,DISK], DatanodeInfoWithStorage[127.0.0.1:42174,DS-d2a8a1f4-9ccb-40eb-87c0-f6aa36710636,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-9c539042-3b11-4296-a5ac-74f6b1b2280f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697131180-172.17.0.7-1595926887305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38944,DS-4cfdc774-2dc6-4647-a220-ec7bd10de3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-a72539e8-bb74-4f62-b05f-107475ee867b,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-a312700e-cca3-4731-8ff6-c83b88922548,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-2ecef7ca-89fe-4e88-a242-64269fab73ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-9525fed9-5c0c-4c7e-b407-3cc7b18bb1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-60603ad5-76b3-44f1-8c91-965af017e9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-daffd45d-0eac-45d5-a7b5-441369323fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-745591cc-f635-4b22-a4a7-933ea2fb2ee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697131180-172.17.0.7-1595926887305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38944,DS-4cfdc774-2dc6-4647-a220-ec7bd10de3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-a72539e8-bb74-4f62-b05f-107475ee867b,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-a312700e-cca3-4731-8ff6-c83b88922548,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-2ecef7ca-89fe-4e88-a242-64269fab73ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-9525fed9-5c0c-4c7e-b407-3cc7b18bb1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-60603ad5-76b3-44f1-8c91-965af017e9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-daffd45d-0eac-45d5-a7b5-441369323fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-745591cc-f635-4b22-a4a7-933ea2fb2ee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55519853-172.17.0.7-1595926989027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43065,DS-dea82f59-3105-4149-8598-9c94d8f5d558,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-313a1dfe-ac47-4fd3-984c-ba83dcb56fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-16d086cd-2f2b-4ef2-b291-c7d8401545d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-6f04bf96-079c-4ac0-9929-e4acdf00edf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-d04d3a55-2b60-495c-ad0f-3f2a08f84818,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-0a1004c9-5dc5-4c1c-b92f-0711fe26411b,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-0e04f996-5c9f-4bd7-aaf8-f49d3ad0e61a,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-82e45392-7c0c-414a-86bf-19bd893739ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-55519853-172.17.0.7-1595926989027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43065,DS-dea82f59-3105-4149-8598-9c94d8f5d558,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-313a1dfe-ac47-4fd3-984c-ba83dcb56fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-16d086cd-2f2b-4ef2-b291-c7d8401545d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-6f04bf96-079c-4ac0-9929-e4acdf00edf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-d04d3a55-2b60-495c-ad0f-3f2a08f84818,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-0a1004c9-5dc5-4c1c-b92f-0711fe26411b,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-0e04f996-5c9f-4bd7-aaf8-f49d3ad0e61a,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-82e45392-7c0c-414a-86bf-19bd893739ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278321703-172.17.0.7-1595927355569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32986,DS-a3f67daa-c236-4f2b-9b46-0e5b0f467d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-f256c638-cb3b-4447-b945-70f5fb242c66,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-40817390-a36a-4d02-bdaa-135a673b648a,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-916af2e4-5e71-4bad-9208-6a93892e5d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-4c66321f-24f0-45e9-b44d-f79219217ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-636bcd1c-22ad-42ab-a00e-809da4b1c6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-2fe24496-295f-453c-95a1-62396e1ed002,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-6cc50694-fb4c-4770-9f40-4346e61ce105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278321703-172.17.0.7-1595927355569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32986,DS-a3f67daa-c236-4f2b-9b46-0e5b0f467d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-f256c638-cb3b-4447-b945-70f5fb242c66,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-40817390-a36a-4d02-bdaa-135a673b648a,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-916af2e4-5e71-4bad-9208-6a93892e5d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-4c66321f-24f0-45e9-b44d-f79219217ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-636bcd1c-22ad-42ab-a00e-809da4b1c6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-2fe24496-295f-453c-95a1-62396e1ed002,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-6cc50694-fb4c-4770-9f40-4346e61ce105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866588712-172.17.0.7-1595927422274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-ee4a5fe9-6c26-400d-a710-64340d76e547,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-fda4ca45-449e-4127-89f8-4dfb8a3a6c98,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-3df3dbc2-eb68-4d4d-a452-c38cf80944ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-af730d14-e3aa-40b6-bcb8-16c696b22d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-446f134a-521b-490a-9e62-14fa5debca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-801f10f0-2d89-4433-964b-9ffc9645293e,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-91bfe4e8-bdc3-44c7-8a5e-4e54e5cf9bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-2817df12-4df0-4bbd-ab05-41216234b43e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866588712-172.17.0.7-1595927422274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-ee4a5fe9-6c26-400d-a710-64340d76e547,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-fda4ca45-449e-4127-89f8-4dfb8a3a6c98,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-3df3dbc2-eb68-4d4d-a452-c38cf80944ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-af730d14-e3aa-40b6-bcb8-16c696b22d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-446f134a-521b-490a-9e62-14fa5debca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-801f10f0-2d89-4433-964b-9ffc9645293e,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-91bfe4e8-bdc3-44c7-8a5e-4e54e5cf9bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-2817df12-4df0-4bbd-ab05-41216234b43e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545528428-172.17.0.7-1595927723196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37293,DS-9ad58c48-38d5-450f-8c71-119917a3c09e,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-10b84c92-d653-4ad2-b9d6-5f89fff1f064,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-386acb33-faf8-4e89-93a7-f551645ffb36,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-e2ae1165-7e05-4681-9048-b63f57dab6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-d613f524-b409-4cca-b715-dd6640f08d73,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-2757eebf-b545-44b1-9c64-92170e915cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-c0ee30b9-a0fd-4a4a-af11-5beb5494e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-bfd584a0-f98f-4ddd-94f8-89a5582e790c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545528428-172.17.0.7-1595927723196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37293,DS-9ad58c48-38d5-450f-8c71-119917a3c09e,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-10b84c92-d653-4ad2-b9d6-5f89fff1f064,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-386acb33-faf8-4e89-93a7-f551645ffb36,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-e2ae1165-7e05-4681-9048-b63f57dab6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-d613f524-b409-4cca-b715-dd6640f08d73,DISK], DatanodeInfoWithStorage[127.0.0.1:33218,DS-2757eebf-b545-44b1-9c64-92170e915cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-c0ee30b9-a0fd-4a4a-af11-5beb5494e71c,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-bfd584a0-f98f-4ddd-94f8-89a5582e790c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698430764-172.17.0.7-1595928140780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42647,DS-6ae13b22-a566-404c-8462-278a6d799801,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-914545b2-cd46-441f-ab28-cfea2d833893,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-85ff7835-ad74-4298-a71f-7ce7fb9c8a78,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-fca789e8-0f5f-4541-8c3d-5a8c793b5ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-b66e8589-33b2-45f5-8945-cc15c40b38b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-acf9c9a7-1e21-448d-86f7-f63d1b5f06cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-2887aa99-2229-424d-a816-d190c59ab475,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-b34d23ec-4c45-4b71-93ec-c3dd6a81fa19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698430764-172.17.0.7-1595928140780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42647,DS-6ae13b22-a566-404c-8462-278a6d799801,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-914545b2-cd46-441f-ab28-cfea2d833893,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-85ff7835-ad74-4298-a71f-7ce7fb9c8a78,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-fca789e8-0f5f-4541-8c3d-5a8c793b5ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-b66e8589-33b2-45f5-8945-cc15c40b38b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-acf9c9a7-1e21-448d-86f7-f63d1b5f06cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-2887aa99-2229-424d-a816-d190c59ab475,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-b34d23ec-4c45-4b71-93ec-c3dd6a81fa19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308202037-172.17.0.7-1595928297316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43933,DS-88af2f76-2a6a-430e-9336-aefdb111099e,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-ce2ae211-910e-47ca-aa77-c26e347fd636,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-7eff2db3-2265-4c31-bbb4-8c8a1fd5f80a,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-e7d20048-f3f8-42ca-85a7-c2a73cc6fd74,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-33418f8e-d96b-407c-8fb3-23f8a3e1ad00,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-46d86960-295a-44bb-bb55-1b97c6fe4b02,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-8f8596c1-185d-481b-ba2b-7ca2252f03b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-283f80c8-95b0-411a-8f20-94e31a078166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308202037-172.17.0.7-1595928297316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43933,DS-88af2f76-2a6a-430e-9336-aefdb111099e,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-ce2ae211-910e-47ca-aa77-c26e347fd636,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-7eff2db3-2265-4c31-bbb4-8c8a1fd5f80a,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-e7d20048-f3f8-42ca-85a7-c2a73cc6fd74,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-33418f8e-d96b-407c-8fb3-23f8a3e1ad00,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-46d86960-295a-44bb-bb55-1b97c6fe4b02,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-8f8596c1-185d-481b-ba2b-7ca2252f03b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-283f80c8-95b0-411a-8f20-94e31a078166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612016437-172.17.0.7-1595928611068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-a27e477b-109a-441b-9bfc-252f58b224de,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-88e50a84-e463-46a8-8205-0845c495b1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-09e625d6-df14-4ae8-b401-a62c3e165e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-07c97463-dc9c-4390-ab6a-dab30c9dd9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-b2059615-39b6-4df3-8061-ba8746bf980f,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-56295156-5fb5-476a-b93b-f93356602b34,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-d6b001f0-5fa3-42a8-9063-0c9e6f473a08,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-cb6a8289-e70f-47e5-9249-e3a05b6741d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612016437-172.17.0.7-1595928611068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-a27e477b-109a-441b-9bfc-252f58b224de,DISK], DatanodeInfoWithStorage[127.0.0.1:37611,DS-88e50a84-e463-46a8-8205-0845c495b1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-09e625d6-df14-4ae8-b401-a62c3e165e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-07c97463-dc9c-4390-ab6a-dab30c9dd9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-b2059615-39b6-4df3-8061-ba8746bf980f,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-56295156-5fb5-476a-b93b-f93356602b34,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-d6b001f0-5fa3-42a8-9063-0c9e6f473a08,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-cb6a8289-e70f-47e5-9249-e3a05b6741d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430842048-172.17.0.7-1595929199771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46068,DS-b70967a7-9d4c-4f44-886a-a4b843ae67f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-300e1a91-e5c1-4095-bd2c-1a4f423c5031,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-6e94b563-f15a-4828-8ad0-23d6eb176380,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-b22194ff-ea78-4459-8d6b-6a08d377987b,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-8905fb1b-bc60-4437-97bf-e09a76badfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-29321439-a9d8-468f-a754-f88e972a3caa,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-531e6dcf-392f-431d-a48d-657ca241223b,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-6318af60-971c-4fb9-bee3-3ee602518c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430842048-172.17.0.7-1595929199771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46068,DS-b70967a7-9d4c-4f44-886a-a4b843ae67f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-300e1a91-e5c1-4095-bd2c-1a4f423c5031,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-6e94b563-f15a-4828-8ad0-23d6eb176380,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-b22194ff-ea78-4459-8d6b-6a08d377987b,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-8905fb1b-bc60-4437-97bf-e09a76badfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-29321439-a9d8-468f-a754-f88e972a3caa,DISK], DatanodeInfoWithStorage[127.0.0.1:39127,DS-531e6dcf-392f-431d-a48d-657ca241223b,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-6318af60-971c-4fb9-bee3-3ee602518c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305288133-172.17.0.7-1595929236663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44450,DS-9d1ebfe2-c7d3-42a4-b104-36ee11810c33,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-c03a5825-3df1-48f9-b06d-1b1eba39aff1,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-db918aec-084e-47fc-892e-248815009e44,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-369b9db2-8912-49d7-b079-5ec95068004e,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-ec9cd092-1620-41d9-a824-d6e66d457d79,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-4a0c068f-50a1-415d-b89b-f1164db2ff43,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-78e59151-b0cc-478b-8082-6b5805ef2e92,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-9b3b19cb-4320-47b7-bdba-9d11c5cc85f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305288133-172.17.0.7-1595929236663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44450,DS-9d1ebfe2-c7d3-42a4-b104-36ee11810c33,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-c03a5825-3df1-48f9-b06d-1b1eba39aff1,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-db918aec-084e-47fc-892e-248815009e44,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-369b9db2-8912-49d7-b079-5ec95068004e,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-ec9cd092-1620-41d9-a824-d6e66d457d79,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-4a0c068f-50a1-415d-b89b-f1164db2ff43,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-78e59151-b0cc-478b-8082-6b5805ef2e92,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-9b3b19cb-4320-47b7-bdba-9d11c5cc85f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.quota.init-threads
component: hdfs:NameNode
v1: 4
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173049636-172.17.0.7-1595929534762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35871,DS-c7ffaf72-9cf0-402c-a08f-f944ec2970e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-dca8cd4b-5a0f-4c66-af5d-2bb3c44e97a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-d13d70cd-6b7e-4ded-9e04-3bbd98b0adac,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-a1be38d4-6ec7-42bd-adf9-e8d1b7ae29b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-aa652432-a170-4de8-8b22-e1c93f32ea2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-be56bf69-91f9-4d9c-95e7-5c4a5682c8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-53e739bc-f163-489a-80ef-87a5ac8cd496,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-859f969a-58f3-41ee-a91b-ed02161f217f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1173049636-172.17.0.7-1595929534762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35871,DS-c7ffaf72-9cf0-402c-a08f-f944ec2970e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-dca8cd4b-5a0f-4c66-af5d-2bb3c44e97a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-d13d70cd-6b7e-4ded-9e04-3bbd98b0adac,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-a1be38d4-6ec7-42bd-adf9-e8d1b7ae29b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-aa652432-a170-4de8-8b22-e1c93f32ea2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-be56bf69-91f9-4d9c-95e7-5c4a5682c8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-53e739bc-f163-489a-80ef-87a5ac8cd496,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-859f969a-58f3-41ee-a91b-ed02161f217f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5496
