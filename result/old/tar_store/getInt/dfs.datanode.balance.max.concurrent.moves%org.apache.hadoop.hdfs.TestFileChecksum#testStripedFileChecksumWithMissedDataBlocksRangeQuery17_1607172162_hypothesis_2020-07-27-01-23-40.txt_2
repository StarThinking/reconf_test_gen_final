reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656040285-172.17.0.10-1595813765091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-c53f7d07-9c47-457d-a085-82fd44fd8058,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-92d89407-dcf3-4f3b-a65b-56055e9da815,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-89fa748c-5ceb-4e78-a603-937e1fd5b65a,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-8a0449ff-ebc2-4c7d-8d6c-f47e9bf169c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-af9ba750-0c88-4014-9fc1-a499d5b88f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-96fee880-2071-4e80-8b88-b83b6db5d29a,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-7fc925fe-f33e-4db4-a153-680425c5a758,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-8ec06c79-7958-4175-b987-0bc20d76bbce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1656040285-172.17.0.10-1595813765091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46253,DS-c53f7d07-9c47-457d-a085-82fd44fd8058,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-92d89407-dcf3-4f3b-a65b-56055e9da815,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-89fa748c-5ceb-4e78-a603-937e1fd5b65a,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-8a0449ff-ebc2-4c7d-8d6c-f47e9bf169c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-af9ba750-0c88-4014-9fc1-a499d5b88f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-96fee880-2071-4e80-8b88-b83b6db5d29a,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-7fc925fe-f33e-4db4-a153-680425c5a758,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-8ec06c79-7958-4175-b987-0bc20d76bbce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328719134-172.17.0.10-1595813876361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40205,DS-07728605-df2a-40cf-9739-f54273129201,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-503dd146-e21c-4507-98e1-3aa2c41b1479,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-c789f4a4-9cb1-4d79-af47-ff94e66ceda3,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-110274ee-03c5-4d4c-84c6-1211e4f43377,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-5d4ba7fe-6ea7-488a-aea5-88798433c28f,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-4a49c7a4-56d3-4168-b22d-98c2b63bcdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-68ef7d08-4600-4d5c-9088-a33067a9ee4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-f1be1a8d-935c-4a03-8f14-78ddfab6206a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328719134-172.17.0.10-1595813876361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40205,DS-07728605-df2a-40cf-9739-f54273129201,DISK], DatanodeInfoWithStorage[127.0.0.1:42814,DS-503dd146-e21c-4507-98e1-3aa2c41b1479,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-c789f4a4-9cb1-4d79-af47-ff94e66ceda3,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-110274ee-03c5-4d4c-84c6-1211e4f43377,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-5d4ba7fe-6ea7-488a-aea5-88798433c28f,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-4a49c7a4-56d3-4168-b22d-98c2b63bcdf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-68ef7d08-4600-4d5c-9088-a33067a9ee4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-f1be1a8d-935c-4a03-8f14-78ddfab6206a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275659342-172.17.0.10-1595814578199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45578,DS-b5a3b016-cc72-4deb-b5c6-a0f702c7b3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-aa6c4b3b-ff14-4647-93d1-587ab4e98d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-2d891bad-8b23-44bb-84b4-4744a434576c,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-525493dd-46ae-4f6f-a3a3-ce46b282cb55,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-ff5ad09a-6d2a-42c9-ab9c-ea1f19a4825c,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-cf069877-09c1-4e9d-8802-b2d5bc9e415d,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-73eeeead-148d-4750-8651-23ffad7b864b,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-2eae5841-3741-4bbc-a701-3afe99f50410,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275659342-172.17.0.10-1595814578199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45578,DS-b5a3b016-cc72-4deb-b5c6-a0f702c7b3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-aa6c4b3b-ff14-4647-93d1-587ab4e98d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-2d891bad-8b23-44bb-84b4-4744a434576c,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-525493dd-46ae-4f6f-a3a3-ce46b282cb55,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-ff5ad09a-6d2a-42c9-ab9c-ea1f19a4825c,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-cf069877-09c1-4e9d-8802-b2d5bc9e415d,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-73eeeead-148d-4750-8651-23ffad7b864b,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-2eae5841-3741-4bbc-a701-3afe99f50410,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954133242-172.17.0.10-1595814982114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42553,DS-943d896f-d70c-490c-b5f0-54ff4914887f,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-d3aa3311-2342-450b-bce8-63d45e1aa857,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-bf076b26-e8f4-4198-b2f6-87d757f84ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-fa8e65c4-de52-42cb-86ff-06c7e773857d,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-8bda115f-7858-4b0b-b1d2-8270bb55748f,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-72cc4024-4916-441d-bf49-3a4cdb24926d,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-9f1803b0-cd4e-4819-975b-fda3fa2af2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-2442dc1a-9bd8-4292-bb8f-b01c1cae3820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954133242-172.17.0.10-1595814982114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42553,DS-943d896f-d70c-490c-b5f0-54ff4914887f,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-d3aa3311-2342-450b-bce8-63d45e1aa857,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-bf076b26-e8f4-4198-b2f6-87d757f84ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-fa8e65c4-de52-42cb-86ff-06c7e773857d,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-8bda115f-7858-4b0b-b1d2-8270bb55748f,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-72cc4024-4916-441d-bf49-3a4cdb24926d,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-9f1803b0-cd4e-4819-975b-fda3fa2af2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-2442dc1a-9bd8-4292-bb8f-b01c1cae3820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083461065-172.17.0.10-1595816432599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-9745dbe5-ea50-4e30-9743-eb57d3e21adc,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-56cb95c1-da7a-4c61-80d4-db1bdf885a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-242c69c1-34f8-4b08-90c8-98fe5499d8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-ac2a80ff-4de9-4266-aa72-494b9e52103e,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-62860b0a-213c-40ba-a56a-fb7e2630e462,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-6a5828fa-a4af-45af-96c3-d79c5ae732fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-dcd48eb8-e173-45c8-9afa-57f344c26d90,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-6a2dd966-8fc2-4a22-a2bf-e2d7437dc9c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1083461065-172.17.0.10-1595816432599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39596,DS-9745dbe5-ea50-4e30-9743-eb57d3e21adc,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-56cb95c1-da7a-4c61-80d4-db1bdf885a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-242c69c1-34f8-4b08-90c8-98fe5499d8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-ac2a80ff-4de9-4266-aa72-494b9e52103e,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-62860b0a-213c-40ba-a56a-fb7e2630e462,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-6a5828fa-a4af-45af-96c3-d79c5ae732fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-dcd48eb8-e173-45c8-9afa-57f344c26d90,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-6a2dd966-8fc2-4a22-a2bf-e2d7437dc9c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081886064-172.17.0.10-1595816699325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35132,DS-55b81cb3-b92d-4195-9f2f-594d66d709d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-1c8b9538-c466-4da7-9816-03723a3eb279,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-aaf42ef0-ada7-4a73-9406-f3770ea51b23,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-5a694330-aa80-455c-a2e6-ecec3914b624,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-31ed9093-9a10-4744-8133-50973e393c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-75d71951-9bc9-423d-a005-7be1bcc1d638,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-5b8b2ae3-6454-4550-bfeb-bfaae0835444,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-75520e99-ba38-4438-b1ab-143a7c34d46b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081886064-172.17.0.10-1595816699325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35132,DS-55b81cb3-b92d-4195-9f2f-594d66d709d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-1c8b9538-c466-4da7-9816-03723a3eb279,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-aaf42ef0-ada7-4a73-9406-f3770ea51b23,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-5a694330-aa80-455c-a2e6-ecec3914b624,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-31ed9093-9a10-4744-8133-50973e393c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-75d71951-9bc9-423d-a005-7be1bcc1d638,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-5b8b2ae3-6454-4550-bfeb-bfaae0835444,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-75520e99-ba38-4438-b1ab-143a7c34d46b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411011216-172.17.0.10-1595817073001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34127,DS-9244af91-01d3-4868-81e8-84825da80089,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-380aaa85-8f40-47ce-87fd-574821c1dba3,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-5a7358dd-c561-449b-b9a9-0f2c0fa4ea8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-f84e4118-02f8-4654-b9bd-971673c98730,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-d8bccbaf-fc9c-4612-9d22-de3d13d3bf93,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-1c3ec8e0-3180-434a-b712-77042eee8331,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-42db8ffa-fa5a-4cc9-b5d0-bc655b50cc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-96f89d4b-9b75-44f8-b057-534bbca102dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411011216-172.17.0.10-1595817073001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34127,DS-9244af91-01d3-4868-81e8-84825da80089,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-380aaa85-8f40-47ce-87fd-574821c1dba3,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-5a7358dd-c561-449b-b9a9-0f2c0fa4ea8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-f84e4118-02f8-4654-b9bd-971673c98730,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-d8bccbaf-fc9c-4612-9d22-de3d13d3bf93,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-1c3ec8e0-3180-434a-b712-77042eee8331,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-42db8ffa-fa5a-4cc9-b5d0-bc655b50cc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-96f89d4b-9b75-44f8-b057-534bbca102dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855971918-172.17.0.10-1595817446731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36903,DS-5731b5e8-d9e6-4bdd-a20e-81b5ba952b99,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-b00c66a0-0811-450e-9a6e-4abba07e8b04,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-4f9b07a9-18ee-4db9-879a-311b719d9146,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-0a818f6d-6c42-44b4-b458-a6251868d541,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-ce875e16-7fc5-4a2d-9584-dd1024ff445b,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-c4bb9a9d-d10a-4b00-af59-9edc9f93e576,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-3c9fd118-5d6b-45ac-950a-3abc9821ff9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-3cc4c340-7f5d-4300-b079-15c048b123a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855971918-172.17.0.10-1595817446731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36903,DS-5731b5e8-d9e6-4bdd-a20e-81b5ba952b99,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-b00c66a0-0811-450e-9a6e-4abba07e8b04,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-4f9b07a9-18ee-4db9-879a-311b719d9146,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-0a818f6d-6c42-44b4-b458-a6251868d541,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-ce875e16-7fc5-4a2d-9584-dd1024ff445b,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-c4bb9a9d-d10a-4b00-af59-9edc9f93e576,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-3c9fd118-5d6b-45ac-950a-3abc9821ff9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-3cc4c340-7f5d-4300-b079-15c048b123a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-280249196-172.17.0.10-1595817575276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36725,DS-1231b8be-d661-4982-ae4a-5ead6da72f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-d13350c2-1f68-417c-8818-b1d872c0bc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-1ad19988-05b9-4c12-95b1-dcedb34c6ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-0a748d2b-ff45-4515-a8e0-fc593f624339,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-c6a8701b-6c57-4761-9018-07fb9b74e754,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-0cdb85ba-315f-4bfb-87dc-f6945a5e25e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-368b4ea7-47d5-403d-b083-40a8c6efdfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-a91bb80e-5f6f-481c-b51a-320c064d8fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-280249196-172.17.0.10-1595817575276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36725,DS-1231b8be-d661-4982-ae4a-5ead6da72f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-d13350c2-1f68-417c-8818-b1d872c0bc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-1ad19988-05b9-4c12-95b1-dcedb34c6ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-0a748d2b-ff45-4515-a8e0-fc593f624339,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-c6a8701b-6c57-4761-9018-07fb9b74e754,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-0cdb85ba-315f-4bfb-87dc-f6945a5e25e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-368b4ea7-47d5-403d-b083-40a8c6efdfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-a91bb80e-5f6f-481c-b51a-320c064d8fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686810672-172.17.0.10-1595818215647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42934,DS-ed191668-c4b4-4e4d-8b7c-033703b7bb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-38f9af31-22db-4cce-a88a-93bacc764753,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-eea5ae92-e33c-4b25-8702-575c3ea3814d,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-06ddc5df-7372-41fc-b935-1941a14ae7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-3323c32d-2bda-44e2-9a77-9fb077de4606,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-bbf6ae72-fd91-485c-9fc4-c4a8e2334a78,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-cc585436-f3b1-42c3-8c92-7de992f4a368,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-047f403e-0c20-4947-8976-159f47b8d108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-686810672-172.17.0.10-1595818215647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42934,DS-ed191668-c4b4-4e4d-8b7c-033703b7bb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-38f9af31-22db-4cce-a88a-93bacc764753,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-eea5ae92-e33c-4b25-8702-575c3ea3814d,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-06ddc5df-7372-41fc-b935-1941a14ae7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-3323c32d-2bda-44e2-9a77-9fb077de4606,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-bbf6ae72-fd91-485c-9fc4-c4a8e2334a78,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-cc585436-f3b1-42c3-8c92-7de992f4a368,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-047f403e-0c20-4947-8976-159f47b8d108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 5244
