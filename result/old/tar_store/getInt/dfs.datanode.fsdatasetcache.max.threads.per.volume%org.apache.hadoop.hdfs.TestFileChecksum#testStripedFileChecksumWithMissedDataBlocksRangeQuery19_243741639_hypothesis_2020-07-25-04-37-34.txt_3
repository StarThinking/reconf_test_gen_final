reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-417493153-172.17.0.7-1595652131009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41901,DS-4365d4d2-1040-4992-b841-9e3fee574872,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-d0e1323d-8e6d-425e-a4b6-7ce373f159aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-cf87580b-a756-4762-b3ac-72410524804f,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-9af14e14-4a43-4082-8817-45a65da92e30,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-12593936-d986-4e32-9aea-b08d4dfe502d,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-00a533fe-3ab2-441f-b83e-df3315e3f920,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-1ef5860d-76e1-4bdb-8d2d-45a8bf57abbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-9cc165e0-9b96-4bd8-9b01-30cdc4db904e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-417493153-172.17.0.7-1595652131009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41901,DS-4365d4d2-1040-4992-b841-9e3fee574872,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-d0e1323d-8e6d-425e-a4b6-7ce373f159aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-cf87580b-a756-4762-b3ac-72410524804f,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-9af14e14-4a43-4082-8817-45a65da92e30,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-12593936-d986-4e32-9aea-b08d4dfe502d,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-00a533fe-3ab2-441f-b83e-df3315e3f920,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-1ef5860d-76e1-4bdb-8d2d-45a8bf57abbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-9cc165e0-9b96-4bd8-9b01-30cdc4db904e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261221086-172.17.0.7-1595652489727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33882,DS-0fb6eb1c-1c03-4ba5-80d5-06fd318371e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-1119b997-f217-4b88-b26a-3952e6ec2f14,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-1815f9da-b271-4093-8277-efc95e4274b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-8941e47a-be22-494b-a609-320f9a409a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-59cc932d-dde3-4b69-a9d7-a322ef860099,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-8010b24e-54a4-4ce8-b448-c4d8a0a80a78,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-82e5c579-95cb-4adb-9350-8d09af965889,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-c3f78c70-deac-4503-8f68-672e3338e073,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261221086-172.17.0.7-1595652489727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33882,DS-0fb6eb1c-1c03-4ba5-80d5-06fd318371e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-1119b997-f217-4b88-b26a-3952e6ec2f14,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-1815f9da-b271-4093-8277-efc95e4274b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-8941e47a-be22-494b-a609-320f9a409a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-59cc932d-dde3-4b69-a9d7-a322ef860099,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-8010b24e-54a4-4ce8-b448-c4d8a0a80a78,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-82e5c579-95cb-4adb-9350-8d09af965889,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-c3f78c70-deac-4503-8f68-672e3338e073,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1122717756-172.17.0.7-1595652599348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34040,DS-66a0a10e-2bfa-4031-89b9-0b4ca795cf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-a8669661-9694-4293-ab50-f65ddcccf088,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-cf31fb8b-ca36-45bd-9e9b-ba7d2844375c,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-b76b8262-bbd1-4cf3-ab26-f7568bb77253,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-505c1544-5411-48a7-bac4-62328c3c91ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-92dc88bd-7b13-4eb7-a94b-581e5ee4eaff,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-5be7c607-8faa-4a13-9ff4-b39351304cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-80db6112-a180-4937-ac27-2c6dca890b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1122717756-172.17.0.7-1595652599348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34040,DS-66a0a10e-2bfa-4031-89b9-0b4ca795cf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-a8669661-9694-4293-ab50-f65ddcccf088,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-cf31fb8b-ca36-45bd-9e9b-ba7d2844375c,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-b76b8262-bbd1-4cf3-ab26-f7568bb77253,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-505c1544-5411-48a7-bac4-62328c3c91ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-92dc88bd-7b13-4eb7-a94b-581e5ee4eaff,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-5be7c607-8faa-4a13-9ff4-b39351304cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-80db6112-a180-4937-ac27-2c6dca890b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300801856-172.17.0.7-1595652714733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-a812d239-1b65-4a12-9306-93330c70c8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-c5c16156-447f-4de7-9f6e-753218c2ccc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-c03450c8-605d-40c9-9b8c-c55c173e26ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-61d58b84-a248-4a21-a826-182895f92636,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-f4a17919-2c50-4156-9ff2-0919b418806b,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-befb14ff-ae93-4ef8-bf99-114df1ab10bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-db1ce53a-e013-4bf4-b95b-4d361f51a0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-2fd06da7-36c2-49e7-9690-8496eed7eaa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300801856-172.17.0.7-1595652714733:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-a812d239-1b65-4a12-9306-93330c70c8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-c5c16156-447f-4de7-9f6e-753218c2ccc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-c03450c8-605d-40c9-9b8c-c55c173e26ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-61d58b84-a248-4a21-a826-182895f92636,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-f4a17919-2c50-4156-9ff2-0919b418806b,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-befb14ff-ae93-4ef8-bf99-114df1ab10bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-db1ce53a-e013-4bf4-b95b-4d361f51a0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-2fd06da7-36c2-49e7-9690-8496eed7eaa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1683501451-172.17.0.7-1595653406482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44159,DS-c4940512-8d94-40b1-9b1c-0e617e8907fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-0487c0a4-9c9c-43fb-b714-8c6685ddec93,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-3957e5d8-80a1-4e02-acd7-b2d79c949f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-51a17752-79ba-4286-874a-99e35d7bf614,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-23273b82-314f-4c9f-84e6-4fb5e8d01048,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-f4c0bf43-f1b1-4fa0-a72e-795b65680aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-11322f20-be04-4bc3-b90d-d2b63b6dd13b,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-503bfcfb-0215-4d0c-947f-4a9359ce40a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1683501451-172.17.0.7-1595653406482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44159,DS-c4940512-8d94-40b1-9b1c-0e617e8907fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-0487c0a4-9c9c-43fb-b714-8c6685ddec93,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-3957e5d8-80a1-4e02-acd7-b2d79c949f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-51a17752-79ba-4286-874a-99e35d7bf614,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-23273b82-314f-4c9f-84e6-4fb5e8d01048,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-f4c0bf43-f1b1-4fa0-a72e-795b65680aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-11322f20-be04-4bc3-b90d-d2b63b6dd13b,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-503bfcfb-0215-4d0c-947f-4a9359ce40a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127449844-172.17.0.7-1595653723170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41036,DS-b6cc7c08-3642-43b0-add8-2dc81a261d22,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-29c260ef-be2c-4195-bd0b-b17fc34a0eea,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-d591af68-95d3-4fc8-815a-30bc8e91b888,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-466bffe0-a68f-49c7-bea8-3cb88c2e8dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-352b89a3-00c8-4e34-b967-076279ea7e93,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-67569046-b62a-495f-85a9-4ad250de8f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-867bb4ac-de84-42be-8c46-4bfbd2290019,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-169ed85b-9c7d-4781-bae2-26416ab8418b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127449844-172.17.0.7-1595653723170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41036,DS-b6cc7c08-3642-43b0-add8-2dc81a261d22,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-29c260ef-be2c-4195-bd0b-b17fc34a0eea,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-d591af68-95d3-4fc8-815a-30bc8e91b888,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-466bffe0-a68f-49c7-bea8-3cb88c2e8dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-352b89a3-00c8-4e34-b967-076279ea7e93,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-67569046-b62a-495f-85a9-4ad250de8f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-867bb4ac-de84-42be-8c46-4bfbd2290019,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-169ed85b-9c7d-4781-bae2-26416ab8418b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1580962865-172.17.0.7-1595653755889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44676,DS-2f096550-907a-4079-91b6-13dfd328998b,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-5317c111-c524-43d0-bc78-81fa15bfc0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-e42de15c-67dc-46cf-ab6d-d44ec72a65fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-af186cac-a959-4317-9fad-c380ff48993d,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-a490b03d-d2da-4670-88c7-e80d319b305e,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-3103bd7a-5c85-4d6f-91e8-15501c3cb776,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-ec30900b-20b9-4d7e-b106-361c4df73217,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-bf2f8293-0f74-493f-8740-3b29a4415afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1580962865-172.17.0.7-1595653755889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44676,DS-2f096550-907a-4079-91b6-13dfd328998b,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-5317c111-c524-43d0-bc78-81fa15bfc0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-e42de15c-67dc-46cf-ab6d-d44ec72a65fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-af186cac-a959-4317-9fad-c380ff48993d,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-a490b03d-d2da-4670-88c7-e80d319b305e,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-3103bd7a-5c85-4d6f-91e8-15501c3cb776,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-ec30900b-20b9-4d7e-b106-361c4df73217,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-bf2f8293-0f74-493f-8740-3b29a4415afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594353241-172.17.0.7-1595653836665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33961,DS-3a5a8225-67c2-422f-910c-703bd61e2444,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-1b50b428-332c-4c27-9e1e-ddd15ba22161,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-fe3caf66-7c61-4031-a946-b3e3cb561514,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-ba4e4fe5-192c-4a6d-911d-6a06ce602332,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-3ff77a6b-5b74-4eec-8884-bf9f6d9e0c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-2c7d3847-31e2-4302-8206-499bb8bb4d30,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-1b29851c-ab42-4e67-bed0-0d0d72ea8323,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-1d00b255-861f-49de-bfa5-308f9136fb93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594353241-172.17.0.7-1595653836665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33961,DS-3a5a8225-67c2-422f-910c-703bd61e2444,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-1b50b428-332c-4c27-9e1e-ddd15ba22161,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-fe3caf66-7c61-4031-a946-b3e3cb561514,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-ba4e4fe5-192c-4a6d-911d-6a06ce602332,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-3ff77a6b-5b74-4eec-8884-bf9f6d9e0c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-2c7d3847-31e2-4302-8206-499bb8bb4d30,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-1b29851c-ab42-4e67-bed0-0d0d72ea8323,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-1d00b255-861f-49de-bfa5-308f9136fb93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-414737497-172.17.0.7-1595654390484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38860,DS-bd7ce3dd-bf1b-4e78-bf3d-d05e6fe41974,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-8f35f793-2f54-4434-9c7b-08ae52e661e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-ad2f0599-c506-4f78-9527-d09235074b47,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-ff196b59-b355-4523-8010-0ab8f9ee5a46,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-d03a0d21-2a28-4564-aec8-e7a745793600,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-bb4274f9-0fe4-4439-b7e5-b441b5846dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-5e791a6e-49d5-4835-a0a5-663322fcc44d,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-c8ee0f18-b4ec-4520-95b9-21a29a0878ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-414737497-172.17.0.7-1595654390484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38860,DS-bd7ce3dd-bf1b-4e78-bf3d-d05e6fe41974,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-8f35f793-2f54-4434-9c7b-08ae52e661e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-ad2f0599-c506-4f78-9527-d09235074b47,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-ff196b59-b355-4523-8010-0ab8f9ee5a46,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-d03a0d21-2a28-4564-aec8-e7a745793600,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-bb4274f9-0fe4-4439-b7e5-b441b5846dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-5e791a6e-49d5-4835-a0a5-663322fcc44d,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-c8ee0f18-b4ec-4520-95b9-21a29a0878ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682393159-172.17.0.7-1595654456360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34169,DS-6525d9de-5d27-44bc-a25b-2a175aa71d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-4f2c4e93-0495-4651-81da-d3708ae0113e,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-de004676-8f62-4317-a7b5-3f22cabb931f,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-d374c29a-6d11-47e4-bb7d-a7d16b17365c,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-341ea27c-d21e-446c-b6c1-ac90c32c291c,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-a50310f5-9ede-4523-a191-53f5f72dda3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-09da91c5-979f-4990-8275-cb6fa8d7e85d,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-810cb212-c0dc-472a-8753-66ea337564ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682393159-172.17.0.7-1595654456360:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34169,DS-6525d9de-5d27-44bc-a25b-2a175aa71d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-4f2c4e93-0495-4651-81da-d3708ae0113e,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-de004676-8f62-4317-a7b5-3f22cabb931f,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-d374c29a-6d11-47e4-bb7d-a7d16b17365c,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-341ea27c-d21e-446c-b6c1-ac90c32c291c,DISK], DatanodeInfoWithStorage[127.0.0.1:44025,DS-a50310f5-9ede-4523-a191-53f5f72dda3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-09da91c5-979f-4990-8275-cb6fa8d7e85d,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-810cb212-c0dc-472a-8753-66ea337564ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-206329136-172.17.0.7-1595654696952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33495,DS-1349268d-9c29-4c39-9ea8-f67c93b3f56b,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-90a781cf-cd3d-4be4-ba92-9422e47b83a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-2c164708-d921-4f79-8d95-3e2d0eef2f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-ff3ebee4-3f67-442b-b050-2cf8fe5eb637,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-da2c94a2-3bad-4bc3-a595-4b1e5de30698,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-266cecf7-cbd6-4977-b849-4abcec397a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-dc4e43b9-26df-42ee-965c-5ee7afcae26e,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-1a69b5c3-4135-430d-8b49-dc2cf2adf9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-206329136-172.17.0.7-1595654696952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33495,DS-1349268d-9c29-4c39-9ea8-f67c93b3f56b,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-90a781cf-cd3d-4be4-ba92-9422e47b83a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-2c164708-d921-4f79-8d95-3e2d0eef2f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-ff3ebee4-3f67-442b-b050-2cf8fe5eb637,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-da2c94a2-3bad-4bc3-a595-4b1e5de30698,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-266cecf7-cbd6-4977-b849-4abcec397a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-dc4e43b9-26df-42ee-965c-5ee7afcae26e,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-1a69b5c3-4135-430d-8b49-dc2cf2adf9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136293295-172.17.0.7-1595654871976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43492,DS-13933d31-96f9-4560-910f-96038b9090a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-c05a3625-37b6-4ca0-8e00-86c71a651cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-9cbe47a0-1ade-48bb-87b8-3186f718cf36,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-6d2c9551-c295-43cf-a6f3-f878adc6c838,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-c197cafb-382f-451b-a4eb-f7a888a2491b,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-8c72413c-e466-467f-86eb-6c183e709c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-01a970af-408b-47b7-8acb-0272d9514c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-c7cf2ea7-f967-4486-acf3-d79b6cdf9789,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136293295-172.17.0.7-1595654871976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43492,DS-13933d31-96f9-4560-910f-96038b9090a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-c05a3625-37b6-4ca0-8e00-86c71a651cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-9cbe47a0-1ade-48bb-87b8-3186f718cf36,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-6d2c9551-c295-43cf-a6f3-f878adc6c838,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-c197cafb-382f-451b-a4eb-f7a888a2491b,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-8c72413c-e466-467f-86eb-6c183e709c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-01a970af-408b-47b7-8acb-0272d9514c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-c7cf2ea7-f967-4486-acf3-d79b6cdf9789,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411931118-172.17.0.7-1595655137454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45501,DS-6aa01c4a-c51e-4ee4-ab05-4acf1fcfbdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-eb2a9cc0-7294-4473-88dc-61fd690ac7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-ca765434-4349-49fd-a8e6-168f2e6a3a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-ab6e972f-867c-4b12-a0e6-e7083c4d62ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-64d1fe25-0447-4120-bdff-c06e02cb2477,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-9a0dcb6c-29c7-4257-a5af-85178d3b5f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-8d3b864c-8b0c-49f0-852e-69f8918f7fef,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-374692bd-bb96-4584-9896-a1e84cbd736d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-411931118-172.17.0.7-1595655137454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45501,DS-6aa01c4a-c51e-4ee4-ab05-4acf1fcfbdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-eb2a9cc0-7294-4473-88dc-61fd690ac7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-ca765434-4349-49fd-a8e6-168f2e6a3a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-ab6e972f-867c-4b12-a0e6-e7083c4d62ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-64d1fe25-0447-4120-bdff-c06e02cb2477,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-9a0dcb6c-29c7-4257-a5af-85178d3b5f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-8d3b864c-8b0c-49f0-852e-69f8918f7fef,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-374692bd-bb96-4584-9896-a1e84cbd736d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194583544-172.17.0.7-1595655216066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41681,DS-21aa13b1-b9bf-45cf-8952-454ec3259d11,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-3a7939cb-70e2-45a4-963c-71106bdb022f,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-14e76c41-f862-4ab7-934d-a2188f916c89,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-f7911a24-244e-4ff3-930f-505c1da3bba7,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-fa0b2273-4b8f-46fd-8504-0af3cc496573,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-a7d20cae-beee-4279-b3b8-1b22a993491b,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-3c39c64d-b849-4975-b1b3-290ac766bdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-36546867-0a8a-454e-b272-da7adbf13185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194583544-172.17.0.7-1595655216066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41681,DS-21aa13b1-b9bf-45cf-8952-454ec3259d11,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-3a7939cb-70e2-45a4-963c-71106bdb022f,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-14e76c41-f862-4ab7-934d-a2188f916c89,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-f7911a24-244e-4ff3-930f-505c1da3bba7,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-fa0b2273-4b8f-46fd-8504-0af3cc496573,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-a7d20cae-beee-4279-b3b8-1b22a993491b,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-3c39c64d-b849-4975-b1b3-290ac766bdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-36546867-0a8a-454e-b272-da7adbf13185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341384911-172.17.0.7-1595655252784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34803,DS-7cf60c5e-6fde-4eef-9790-d44a84c2a115,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-eeb15c8b-0369-41e9-b834-ecfe01dbd0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-f6fe9810-050c-4010-b2d8-5703dc61de49,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-aa3c7f4e-e52c-4e4f-8642-817c633f9932,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-95f5ec32-60a5-413c-b4af-beaa2e48b494,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-3d832396-af3f-4fd6-bea3-bd8ad648924c,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-7095c5c0-b481-41b6-94f8-f274d2968d54,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-2cd979e3-709e-4236-a2a8-b68ee5824d6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-341384911-172.17.0.7-1595655252784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34803,DS-7cf60c5e-6fde-4eef-9790-d44a84c2a115,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-eeb15c8b-0369-41e9-b834-ecfe01dbd0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-f6fe9810-050c-4010-b2d8-5703dc61de49,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-aa3c7f4e-e52c-4e4f-8642-817c633f9932,DISK], DatanodeInfoWithStorage[127.0.0.1:38212,DS-95f5ec32-60a5-413c-b4af-beaa2e48b494,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-3d832396-af3f-4fd6-bea3-bd8ad648924c,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-7095c5c0-b481-41b6-94f8-f274d2968d54,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-2cd979e3-709e-4236-a2a8-b68ee5824d6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593605111-172.17.0.7-1595655284088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36160,DS-eef0de3a-f80a-4705-b879-88ca41a3f208,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-844ca277-d139-476d-8340-0e8f23fbfd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-68105e7d-cc95-4bb2-a898-f58e964c493e,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-725b1cb9-2437-4b78-8b9e-88d3d53c8023,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-5481c7c2-f347-4bf3-ba26-8c5d26a6d8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-b8242d7a-3793-448a-850c-946c181b0197,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-d2bc793f-a5a3-41fa-aef6-2284572ac5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-7f626817-6a1c-4ddd-8da9-7929c6f2b135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593605111-172.17.0.7-1595655284088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36160,DS-eef0de3a-f80a-4705-b879-88ca41a3f208,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-844ca277-d139-476d-8340-0e8f23fbfd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-68105e7d-cc95-4bb2-a898-f58e964c493e,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-725b1cb9-2437-4b78-8b9e-88d3d53c8023,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-5481c7c2-f347-4bf3-ba26-8c5d26a6d8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-b8242d7a-3793-448a-850c-946c181b0197,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-d2bc793f-a5a3-41fa-aef6-2284572ac5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-7f626817-6a1c-4ddd-8da9-7929c6f2b135,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-840988938-172.17.0.7-1595655709205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38909,DS-02426b51-6404-4bf9-abaf-f18bb907c900,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-6d59c4b3-4154-4079-a815-233cfe9afd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-239332fb-4130-4f72-9c7d-8e5d2e9eaf08,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-8d7283d9-aa39-48d0-b92d-6bbc04f04e06,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-5eddf0ca-2f3d-4c35-8b46-a49fa0592198,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-cf7960ea-6281-4ecf-a5bb-fd4f0e0c928b,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-02d6f288-01db-4242-86e5-0457c8de1bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-f685fa14-9b2b-404d-8e01-7c7fd01a5240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-840988938-172.17.0.7-1595655709205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38909,DS-02426b51-6404-4bf9-abaf-f18bb907c900,DISK], DatanodeInfoWithStorage[127.0.0.1:36818,DS-6d59c4b3-4154-4079-a815-233cfe9afd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-239332fb-4130-4f72-9c7d-8e5d2e9eaf08,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-8d7283d9-aa39-48d0-b92d-6bbc04f04e06,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-5eddf0ca-2f3d-4c35-8b46-a49fa0592198,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-cf7960ea-6281-4ecf-a5bb-fd4f0e0c928b,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-02d6f288-01db-4242-86e5-0457c8de1bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-f685fa14-9b2b-404d-8e01-7c7fd01a5240,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499994214-172.17.0.7-1595656496709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37212,DS-e2be3294-c5fe-446a-b3a3-065f6349a11d,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-c760fb6e-2dad-4f61-8e2f-3530f4f53854,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-61003c34-1555-4ffa-93a9-48578df6a544,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-98e138a6-c0fb-4404-936b-605d486352e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-8918dcf7-1c8c-4482-8d75-cedcf8ca250f,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-ce066b6a-f738-4db6-ab98-f5aedf50152e,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-8f6bb672-b282-4eb0-b697-625a22c35b49,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-d68bb765-bb83-48fc-992e-4012e368468b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499994214-172.17.0.7-1595656496709:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37212,DS-e2be3294-c5fe-446a-b3a3-065f6349a11d,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-c760fb6e-2dad-4f61-8e2f-3530f4f53854,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-61003c34-1555-4ffa-93a9-48578df6a544,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-98e138a6-c0fb-4404-936b-605d486352e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-8918dcf7-1c8c-4482-8d75-cedcf8ca250f,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-ce066b6a-f738-4db6-ab98-f5aedf50152e,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-8f6bb672-b282-4eb0-b697-625a22c35b49,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-d68bb765-bb83-48fc-992e-4012e368468b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365681397-172.17.0.7-1595656682091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35069,DS-ebaf2287-5997-4687-8e01-35bb7e0ae9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-f13534c1-1562-40fe-85c0-425014a2e131,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-4ddd212a-9e1c-4fba-88fb-16cf9d5f98ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-5b7bd43a-eee0-4fa2-b95a-fc976c459d45,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-401ee706-bc9e-4aac-8b04-4e809430e7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-014e86bf-8fb1-49d7-86ba-6547d72fbced,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-58bea955-4fb0-4f31-9a8e-3b17ab943d17,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-f841f957-06ef-4ab4-9ad8-f4c9af858d5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365681397-172.17.0.7-1595656682091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35069,DS-ebaf2287-5997-4687-8e01-35bb7e0ae9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-f13534c1-1562-40fe-85c0-425014a2e131,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-4ddd212a-9e1c-4fba-88fb-16cf9d5f98ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-5b7bd43a-eee0-4fa2-b95a-fc976c459d45,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-401ee706-bc9e-4aac-8b04-4e809430e7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-014e86bf-8fb1-49d7-86ba-6547d72fbced,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-58bea955-4fb0-4f31-9a8e-3b17ab943d17,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-f841f957-06ef-4ab4-9ad8-f4c9af858d5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fsdatasetcache.max.threads.per.volume
component: hdfs:DataNode
v1: 4
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968341901-172.17.0.7-1595657032769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46370,DS-65e8aaeb-18f6-4b04-a7a1-a9ecf87f8373,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-683452bb-344f-41a5-a383-12033e5e8e09,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-16aa6713-a8f3-4a26-b641-c2899f5546c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-4808a453-f71f-4898-adf3-830d1c3f1c76,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-ff38c7dd-18f9-4e96-9ff1-c44ee792b752,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-fd01f3ef-83b4-4c56-9413-6cb8aa5d80d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-95c980d9-fa44-4190-8c33-8d82fd0cd5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-3a98bd41-00d5-4e3b-92eb-d2f4d5962367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968341901-172.17.0.7-1595657032769:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46370,DS-65e8aaeb-18f6-4b04-a7a1-a9ecf87f8373,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-683452bb-344f-41a5-a383-12033e5e8e09,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-16aa6713-a8f3-4a26-b641-c2899f5546c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-4808a453-f71f-4898-adf3-830d1c3f1c76,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-ff38c7dd-18f9-4e96-9ff1-c44ee792b752,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-fd01f3ef-83b4-4c56-9413-6cb8aa5d80d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-95c980d9-fa44-4190-8c33-8d82fd0cd5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-3a98bd41-00d5-4e3b-92eb-d2f4d5962367,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5300
