reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1592989987-172.17.0.16-1595658195157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44972,DS-add983f2-0116-4974-93b3-f08d92977f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-1f4de779-0d09-48e4-bade-8cb86f980e95,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-4730ad9c-ac62-4116-bc63-dbc45c6f340c,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-f54ba490-8668-4afa-9463-a6dc7b2e4bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-30403186-63ae-4bf2-b0e9-11d8e17e995d,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-7877f3e7-bb4f-426b-82ab-efc329f015ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-65ddd82c-158c-4b4d-83a0-696bf45d4f57,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-85551b3f-bda1-4193-93ec-7e4d82e865ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1592989987-172.17.0.16-1595658195157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44972,DS-add983f2-0116-4974-93b3-f08d92977f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-1f4de779-0d09-48e4-bade-8cb86f980e95,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-4730ad9c-ac62-4116-bc63-dbc45c6f340c,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-f54ba490-8668-4afa-9463-a6dc7b2e4bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-30403186-63ae-4bf2-b0e9-11d8e17e995d,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-7877f3e7-bb4f-426b-82ab-efc329f015ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-65ddd82c-158c-4b4d-83a0-696bf45d4f57,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-85551b3f-bda1-4193-93ec-7e4d82e865ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179351855-172.17.0.16-1595658492425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33227,DS-28055159-def0-4f0b-92a9-141da90b3de2,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-afdc2cde-1ae3-402a-bf38-d49cb0cd984e,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-2448feb6-e1c3-47c4-a335-a9c5966203b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-2f878d61-8d74-4b74-ad6b-e27dba190d77,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-4474b3ef-79d4-4209-9340-9e2b9f731df5,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-35d9adc6-106f-4d15-9961-db7664a23bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-4b874ed8-a3dc-4700-8a2b-84fc962a6551,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-0eb48dab-8f31-415f-8f82-c2bf5ca0ed46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179351855-172.17.0.16-1595658492425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33227,DS-28055159-def0-4f0b-92a9-141da90b3de2,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-afdc2cde-1ae3-402a-bf38-d49cb0cd984e,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-2448feb6-e1c3-47c4-a335-a9c5966203b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-2f878d61-8d74-4b74-ad6b-e27dba190d77,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-4474b3ef-79d4-4209-9340-9e2b9f731df5,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-35d9adc6-106f-4d15-9961-db7664a23bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-4b874ed8-a3dc-4700-8a2b-84fc962a6551,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-0eb48dab-8f31-415f-8f82-c2bf5ca0ed46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231914103-172.17.0.16-1595658753298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-9cae474b-520a-44bd-978c-b85cc34406e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-4ab18a0b-e154-4a86-ab40-36d203309413,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-588a507e-9714-4b1a-b03c-d8c8f31a4879,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-044c3c58-ecf9-4953-8b2d-92f228f0febc,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-8bdae70d-50ff-4dde-9c44-0aade95b34c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-adba6fa2-9d13-4046-ab36-5024bd994157,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-5b21797c-d5d1-4668-bcbf-60abb314341a,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-2a3e96c4-8fe6-42d5-9bd4-7c2b67b64509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231914103-172.17.0.16-1595658753298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37254,DS-9cae474b-520a-44bd-978c-b85cc34406e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-4ab18a0b-e154-4a86-ab40-36d203309413,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-588a507e-9714-4b1a-b03c-d8c8f31a4879,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-044c3c58-ecf9-4953-8b2d-92f228f0febc,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-8bdae70d-50ff-4dde-9c44-0aade95b34c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-adba6fa2-9d13-4046-ab36-5024bd994157,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-5b21797c-d5d1-4668-bcbf-60abb314341a,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-2a3e96c4-8fe6-42d5-9bd4-7c2b67b64509,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921479734-172.17.0.16-1595658994013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39550,DS-64888e18-2fea-4105-9ef7-a23f3e076235,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-41bdce2a-63a7-41e3-815d-427694e9ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-74b96c8e-883a-4173-a7c0-64d9e76d6d61,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-728320f5-d21c-401b-bfef-c02819861ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-a18805cc-ae56-4e1c-8a31-29548dcc3906,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-9271eb95-75df-486b-8ade-b70ac9ae25e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-ba93c3c2-58a3-4c19-87e6-c0d30a9cea28,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-676be205-f323-4cc5-8ac3-d655b380755a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1921479734-172.17.0.16-1595658994013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39550,DS-64888e18-2fea-4105-9ef7-a23f3e076235,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-41bdce2a-63a7-41e3-815d-427694e9ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-74b96c8e-883a-4173-a7c0-64d9e76d6d61,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-728320f5-d21c-401b-bfef-c02819861ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-a18805cc-ae56-4e1c-8a31-29548dcc3906,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-9271eb95-75df-486b-8ade-b70ac9ae25e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-ba93c3c2-58a3-4c19-87e6-c0d30a9cea28,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-676be205-f323-4cc5-8ac3-d655b380755a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197401898-172.17.0.16-1595659159141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38214,DS-3b2ddf75-a434-48ea-874b-aa0bb1873b04,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-e95613d1-7c4a-4f49-be5d-a6c0af45bfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-cafaae56-9b07-4f38-a8af-bf005dfce234,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-fc29f963-a951-4c13-bb33-be0be4d1aff0,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-b0c08478-d522-4962-9a49-b9a67ea804ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-b9005963-abbe-4221-91a2-f3e10dbe7c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-e92b1647-2472-49e7-87a4-4c750c097117,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-e2a9a2b6-0ef7-4533-b6a9-cbb4cd7d522a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197401898-172.17.0.16-1595659159141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38214,DS-3b2ddf75-a434-48ea-874b-aa0bb1873b04,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-e95613d1-7c4a-4f49-be5d-a6c0af45bfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-cafaae56-9b07-4f38-a8af-bf005dfce234,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-fc29f963-a951-4c13-bb33-be0be4d1aff0,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-b0c08478-d522-4962-9a49-b9a67ea804ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-b9005963-abbe-4221-91a2-f3e10dbe7c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-e92b1647-2472-49e7-87a4-4c750c097117,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-e2a9a2b6-0ef7-4533-b6a9-cbb4cd7d522a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369754813-172.17.0.16-1595659634590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46172,DS-510678a8-babb-4f82-bdbe-1957a1895c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-50cc2e3f-8633-4f4c-b634-acfa0e2abf51,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-8e3a7024-06a7-4fe0-9be5-8fb75580b584,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-e0a33827-d2fa-4b33-a645-9788caaf8446,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-3a3581a7-e4bb-4bb3-8d24-ce774b89be47,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-acf33b3f-eafe-40fb-9d74-e14528829837,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-541fe208-2982-4f93-907a-3af6a4132009,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-10d7eece-75a4-4d1f-9a1e-5d2073a99100,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369754813-172.17.0.16-1595659634590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46172,DS-510678a8-babb-4f82-bdbe-1957a1895c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-50cc2e3f-8633-4f4c-b634-acfa0e2abf51,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-8e3a7024-06a7-4fe0-9be5-8fb75580b584,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-e0a33827-d2fa-4b33-a645-9788caaf8446,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-3a3581a7-e4bb-4bb3-8d24-ce774b89be47,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-acf33b3f-eafe-40fb-9d74-e14528829837,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-541fe208-2982-4f93-907a-3af6a4132009,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-10d7eece-75a4-4d1f-9a1e-5d2073a99100,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802753897-172.17.0.16-1595659875473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38060,DS-31cbc977-b408-4395-a236-c69d0abc4fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-0e50e8b0-57db-4026-92e8-8dffac14c057,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-ac1c44f9-274d-48c3-80ca-ef4f15d6fab5,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-c0b5928f-0f4b-4847-8acc-b7953721d16a,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-20b42f21-dfcd-440f-ad72-9201b9b932d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-e4304c21-e8e0-4bc2-bd4e-edbd9ecbd35d,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-cb0c030b-bf44-4f27-936f-a73f3cc1a0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-c1274cd9-865a-4f10-b00d-a3cb4e23ffdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802753897-172.17.0.16-1595659875473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38060,DS-31cbc977-b408-4395-a236-c69d0abc4fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-0e50e8b0-57db-4026-92e8-8dffac14c057,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-ac1c44f9-274d-48c3-80ca-ef4f15d6fab5,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-c0b5928f-0f4b-4847-8acc-b7953721d16a,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-20b42f21-dfcd-440f-ad72-9201b9b932d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-e4304c21-e8e0-4bc2-bd4e-edbd9ecbd35d,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-cb0c030b-bf44-4f27-936f-a73f3cc1a0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-c1274cd9-865a-4f10-b00d-a3cb4e23ffdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603571366-172.17.0.16-1595659910572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33388,DS-c31876f0-09fb-4873-a071-ebbef93440dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-25ad37d2-4eae-4f0c-a57f-6149fd352ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-e8997f02-3916-412f-b0f8-20a2b3aa4816,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-4bd9c343-29bb-44fa-8b19-947fd20004cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-fcf33708-75f2-4751-b051-363256d58b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-34c42510-bb83-478b-803b-a6d58948e3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-071bb3f9-b5d0-4b17-82f7-3ff930aaa831,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-b3b7cc2e-4fd4-4fe3-86db-e3a04fc84cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603571366-172.17.0.16-1595659910572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33388,DS-c31876f0-09fb-4873-a071-ebbef93440dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-25ad37d2-4eae-4f0c-a57f-6149fd352ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-e8997f02-3916-412f-b0f8-20a2b3aa4816,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-4bd9c343-29bb-44fa-8b19-947fd20004cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-fcf33708-75f2-4751-b051-363256d58b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-34c42510-bb83-478b-803b-a6d58948e3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-071bb3f9-b5d0-4b17-82f7-3ff930aaa831,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-b3b7cc2e-4fd4-4fe3-86db-e3a04fc84cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092573339-172.17.0.16-1595661550464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46553,DS-5c5fd815-03d2-4427-88d3-fbcfb1c04e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-2d4101f2-11b3-479e-a981-61dac40e663a,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-df89bb1e-a82b-460a-b604-cbcc9ea00022,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-5d823399-815e-40e1-b19e-f84a08e48c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-36a675b4-d145-4784-a03f-31f6f9163f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-57dcd3be-a8bb-43c5-bbb7-0a6e4e486f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-2aeb19af-81c7-4bde-ae7f-b51128bebfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-19a9ec0e-2461-4150-99b9-084d3822fa7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092573339-172.17.0.16-1595661550464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46553,DS-5c5fd815-03d2-4427-88d3-fbcfb1c04e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-2d4101f2-11b3-479e-a981-61dac40e663a,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-df89bb1e-a82b-460a-b604-cbcc9ea00022,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-5d823399-815e-40e1-b19e-f84a08e48c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-36a675b4-d145-4784-a03f-31f6f9163f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-57dcd3be-a8bb-43c5-bbb7-0a6e4e486f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-2aeb19af-81c7-4bde-ae7f-b51128bebfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-19a9ec0e-2461-4150-99b9-084d3822fa7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474228942-172.17.0.16-1595661803849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-7b3a24a0-55b7-4cd0-ba67-2a6b2fc6ccc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-8fc4b2aa-769f-46b6-83b6-d0b288b0244d,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-95930e98-01ba-4eed-8270-a15397e1af26,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-700c8140-dd77-4ec7-b3fb-97bd3d171b03,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-b2d73188-041f-4a60-9a02-5742b220724f,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-d210afde-f8cb-446a-8859-589aac7eaa10,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-511005e9-248c-442b-acf7-a65bb86744d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-7cbf3d15-5b29-4f5c-81ff-7d735550594f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474228942-172.17.0.16-1595661803849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36660,DS-7b3a24a0-55b7-4cd0-ba67-2a6b2fc6ccc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-8fc4b2aa-769f-46b6-83b6-d0b288b0244d,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-95930e98-01ba-4eed-8270-a15397e1af26,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-700c8140-dd77-4ec7-b3fb-97bd3d171b03,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-b2d73188-041f-4a60-9a02-5742b220724f,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-d210afde-f8cb-446a-8859-589aac7eaa10,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-511005e9-248c-442b-acf7-a65bb86744d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-7cbf3d15-5b29-4f5c-81ff-7d735550594f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179158086-172.17.0.16-1595662175370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35562,DS-e9c077b0-e257-40e9-b173-e847b76b64ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-0982dfcd-c0db-4134-884f-7df751a87e08,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-84c8402c-5a0e-4465-976e-3dbbf8ca235d,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-76d37347-4d48-4d81-a96e-331715f883ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-ef6d2e75-f926-4234-8cb8-f8ea857e0a10,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-8093c427-23e1-43be-9f98-12fc1727bb85,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-18ca1cc0-7131-4e52-8b05-08a1f915bc51,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-f7682839-f1fe-4f48-a287-886389022350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-179158086-172.17.0.16-1595662175370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35562,DS-e9c077b0-e257-40e9-b173-e847b76b64ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-0982dfcd-c0db-4134-884f-7df751a87e08,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-84c8402c-5a0e-4465-976e-3dbbf8ca235d,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-76d37347-4d48-4d81-a96e-331715f883ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-ef6d2e75-f926-4234-8cb8-f8ea857e0a10,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-8093c427-23e1-43be-9f98-12fc1727bb85,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-18ca1cc0-7131-4e52-8b05-08a1f915bc51,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-f7682839-f1fe-4f48-a287-886389022350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5205
