reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2128016820-172.17.0.16-1595815701401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38645,DS-a134a7b2-85d3-41b2-a7bd-d4a7982d1579,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-ada6abbc-c6c6-4bf3-bdc5-551d0d27020c,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-0bda971c-9d86-446a-b0f8-aa427f5dca56,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-5d327748-e8ed-4e85-aa3e-3ac7de356dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-66fcb3cf-70f8-4e56-af5f-a8a469414907,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-204cb74a-94c9-44e2-878d-dc701da2bdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-03237806-5165-4d36-8540-832c00c9cb69,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-dc94ed5c-0c36-4de9-8a6d-bef7b92ea21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2128016820-172.17.0.16-1595815701401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38645,DS-a134a7b2-85d3-41b2-a7bd-d4a7982d1579,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-ada6abbc-c6c6-4bf3-bdc5-551d0d27020c,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-0bda971c-9d86-446a-b0f8-aa427f5dca56,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-5d327748-e8ed-4e85-aa3e-3ac7de356dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-66fcb3cf-70f8-4e56-af5f-a8a469414907,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-204cb74a-94c9-44e2-878d-dc701da2bdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-03237806-5165-4d36-8540-832c00c9cb69,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-dc94ed5c-0c36-4de9-8a6d-bef7b92ea21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439069879-172.17.0.16-1595815732412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45849,DS-b5d5c7a8-6c6e-4ff5-8467-64d111added0,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-2027b7eb-d585-414b-81e4-764f4fafd65a,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-0712406b-4a4b-4418-9e58-0d6495ae397d,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-faf53a8e-7919-4b7e-933d-78a2308520c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-85d3690f-b42a-4201-a063-2df045011a17,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-2fb3fa94-0dd9-4842-b606-9226ab00db94,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-4a72fb45-54c7-4015-97d5-2d5a1f08d412,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-539dc0da-f28e-479d-a02f-9f59f7790bc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439069879-172.17.0.16-1595815732412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45849,DS-b5d5c7a8-6c6e-4ff5-8467-64d111added0,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-2027b7eb-d585-414b-81e4-764f4fafd65a,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-0712406b-4a4b-4418-9e58-0d6495ae397d,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-faf53a8e-7919-4b7e-933d-78a2308520c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-85d3690f-b42a-4201-a063-2df045011a17,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-2fb3fa94-0dd9-4842-b606-9226ab00db94,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-4a72fb45-54c7-4015-97d5-2d5a1f08d412,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-539dc0da-f28e-479d-a02f-9f59f7790bc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569343994-172.17.0.16-1595816219788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41912,DS-fa5568f3-96a2-4b23-b2e0-3e0eefc952d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-4012e72a-1e08-4ee9-a4a5-7a6e54b6ff7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-c5356617-26c9-4375-a94e-9ea04e940b67,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-626bd302-2b9b-4ed5-8ba9-3d7bd9c7d6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-0e7ff21b-35cc-4766-b06e-d640025a0abf,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-c364798b-cfda-4fff-a42c-48b9638606cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-a362bc83-b630-4bd2-9f9e-844d9e0e1db6,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-2d9a46f0-d8e4-4ca2-bc33-6dfc472e59ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569343994-172.17.0.16-1595816219788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41912,DS-fa5568f3-96a2-4b23-b2e0-3e0eefc952d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-4012e72a-1e08-4ee9-a4a5-7a6e54b6ff7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-c5356617-26c9-4375-a94e-9ea04e940b67,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-626bd302-2b9b-4ed5-8ba9-3d7bd9c7d6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-0e7ff21b-35cc-4766-b06e-d640025a0abf,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-c364798b-cfda-4fff-a42c-48b9638606cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-a362bc83-b630-4bd2-9f9e-844d9e0e1db6,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-2d9a46f0-d8e4-4ca2-bc33-6dfc472e59ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173708970-172.17.0.16-1595816344498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44100,DS-ae8a2221-0b8b-45ee-840a-6ae3ff95975e,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-281267f0-b39b-482f-a15e-1ec1f0ae939e,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-56526383-161c-4450-bc4f-260fd7ff91e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-6a7e42e0-a52e-4d66-ba23-c6e6cefca156,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-dc12e9b7-7238-4455-b0e0-5a49fd42c826,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-787d5035-5417-4249-8fc9-4fe0e6aad694,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-46719170-f566-4e33-abd1-2f7530e873f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-47fc159e-0e3a-40c7-878c-a2344ebfdf8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173708970-172.17.0.16-1595816344498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44100,DS-ae8a2221-0b8b-45ee-840a-6ae3ff95975e,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-281267f0-b39b-482f-a15e-1ec1f0ae939e,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-56526383-161c-4450-bc4f-260fd7ff91e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-6a7e42e0-a52e-4d66-ba23-c6e6cefca156,DISK], DatanodeInfoWithStorage[127.0.0.1:33898,DS-dc12e9b7-7238-4455-b0e0-5a49fd42c826,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-787d5035-5417-4249-8fc9-4fe0e6aad694,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-46719170-f566-4e33-abd1-2f7530e873f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-47fc159e-0e3a-40c7-878c-a2344ebfdf8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921848028-172.17.0.16-1595817192348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35300,DS-2956ba03-0180-46cc-95ae-2c546e2bbea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-2385ddc6-7cfb-453f-8a1b-0578ba5d31bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-b856a674-2a0f-4a3f-8d24-e752834fed2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-d34a6605-6b82-4593-ace6-6997e638e350,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-bd811820-c69a-4dc1-8375-1fadce87d919,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-b59af780-25dc-4c6a-b74c-3dce5da78939,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-2a3bccd9-3f6f-4a7b-b0a8-cacdf45b648c,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-f7ae1828-f038-40a0-aa90-b209e93574fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921848028-172.17.0.16-1595817192348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35300,DS-2956ba03-0180-46cc-95ae-2c546e2bbea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-2385ddc6-7cfb-453f-8a1b-0578ba5d31bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43004,DS-b856a674-2a0f-4a3f-8d24-e752834fed2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-d34a6605-6b82-4593-ace6-6997e638e350,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-bd811820-c69a-4dc1-8375-1fadce87d919,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-b59af780-25dc-4c6a-b74c-3dce5da78939,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-2a3bccd9-3f6f-4a7b-b0a8-cacdf45b648c,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-f7ae1828-f038-40a0-aa90-b209e93574fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112741770-172.17.0.16-1595817435551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41170,DS-de7323c0-6d81-4f05-8758-dffe50ed37f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-722cfa97-2e8f-498f-94e0-db441a7058e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-659cdac9-c7ad-4646-a65f-f3a5a517120c,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-834db8d3-4c18-44bd-9d6c-762f596dff7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-7f796ef0-aa6b-4b4e-9442-9ea00a543751,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-1ca6f66a-fda3-4a43-99da-d2b02809f71f,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-bda0e218-a3c3-42c8-b62d-eedd1aeb874e,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-8e8038a6-80ae-499f-8570-aa6bef18b7d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112741770-172.17.0.16-1595817435551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41170,DS-de7323c0-6d81-4f05-8758-dffe50ed37f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-722cfa97-2e8f-498f-94e0-db441a7058e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-659cdac9-c7ad-4646-a65f-f3a5a517120c,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-834db8d3-4c18-44bd-9d6c-762f596dff7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-7f796ef0-aa6b-4b4e-9442-9ea00a543751,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-1ca6f66a-fda3-4a43-99da-d2b02809f71f,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-bda0e218-a3c3-42c8-b62d-eedd1aeb874e,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-8e8038a6-80ae-499f-8570-aa6bef18b7d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148860019-172.17.0.16-1595817537955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39319,DS-990bcba2-80e9-4f6b-954a-41f47d0f28d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-39891f28-7844-45bc-b638-022e32bdc0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-001bd9ec-607c-4e63-9b18-a92fe08e4e96,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-26748afa-f6ba-495a-8f17-0fd8cdc6e488,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-7baf59b8-db45-4bdd-88ac-3579a42bbf35,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-d7e1a539-0bc2-4356-9ef9-541c7d4173a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-1c33ed9a-129c-486e-8ed3-9c194d252553,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-fd34cddd-c296-40ff-acaf-60b6456144f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148860019-172.17.0.16-1595817537955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39319,DS-990bcba2-80e9-4f6b-954a-41f47d0f28d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-39891f28-7844-45bc-b638-022e32bdc0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-001bd9ec-607c-4e63-9b18-a92fe08e4e96,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-26748afa-f6ba-495a-8f17-0fd8cdc6e488,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-7baf59b8-db45-4bdd-88ac-3579a42bbf35,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-d7e1a539-0bc2-4356-9ef9-541c7d4173a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-1c33ed9a-129c-486e-8ed3-9c194d252553,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-fd34cddd-c296-40ff-acaf-60b6456144f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219712359-172.17.0.16-1595818082979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37256,DS-be394457-6fb2-4979-b673-8865a13bdd30,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-d860647a-6eab-4f3d-8daa-9a2da7beed4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-99386b0f-ae9c-4e7c-9fb8-e5b201351807,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-90636f28-ad6e-4ec6-a648-d86411554f79,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-50db7adc-fdda-45a5-9ce4-3c0bbca30000,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-6e4f2624-54b3-4ff9-b1c9-a8cf97e05fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-9024721c-230b-4475-8c50-eded6e2aa632,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-02bf1da4-92bc-4ef3-b5bd-f81b9a5762cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219712359-172.17.0.16-1595818082979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37256,DS-be394457-6fb2-4979-b673-8865a13bdd30,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-d860647a-6eab-4f3d-8daa-9a2da7beed4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37577,DS-99386b0f-ae9c-4e7c-9fb8-e5b201351807,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-90636f28-ad6e-4ec6-a648-d86411554f79,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-50db7adc-fdda-45a5-9ce4-3c0bbca30000,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-6e4f2624-54b3-4ff9-b1c9-a8cf97e05fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-9024721c-230b-4475-8c50-eded6e2aa632,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-02bf1da4-92bc-4ef3-b5bd-f81b9a5762cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442027579-172.17.0.16-1595818307591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34283,DS-f2ba68cd-8598-4c7d-ac94-c77786cd7659,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-73408d97-96da-404e-8ed4-9137c49735bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-1b02e655-49d6-40e5-a973-b4af845abb84,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-f5f6f984-f971-4fe8-82d4-3479acab79d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-2f341fa6-d6e4-4165-ad5d-e7fb15e0dfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-51c435eb-2d34-461c-a653-4428b64caa35,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-78df158f-7089-48d2-8281-1d0725ade03f,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-b0449ccd-d54d-41a0-964a-89bd35508348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442027579-172.17.0.16-1595818307591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34283,DS-f2ba68cd-8598-4c7d-ac94-c77786cd7659,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-73408d97-96da-404e-8ed4-9137c49735bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-1b02e655-49d6-40e5-a973-b4af845abb84,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-f5f6f984-f971-4fe8-82d4-3479acab79d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-2f341fa6-d6e4-4165-ad5d-e7fb15e0dfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-51c435eb-2d34-461c-a653-4428b64caa35,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-78df158f-7089-48d2-8281-1d0725ade03f,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-b0449ccd-d54d-41a0-964a-89bd35508348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145334922-172.17.0.16-1595818592701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34197,DS-f5eb7d04-08e8-4138-a3ae-0dfbf6453585,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-523836c8-316c-4c77-b91e-cacdb149d0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-08d2539d-8c10-4168-8b46-81c3787457fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-5894539f-89d3-4f8a-bcae-aadc6cf90bda,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-8a47e88c-7bb7-46b6-aefb-5b2a615bc5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-95d0f79d-c155-427b-a391-751b5cf83c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-a21c8e6b-f633-46de-a1cc-2db2f6988dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-879cbacb-f2c5-4569-bcfe-1150337b5821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145334922-172.17.0.16-1595818592701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34197,DS-f5eb7d04-08e8-4138-a3ae-0dfbf6453585,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-523836c8-316c-4c77-b91e-cacdb149d0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-08d2539d-8c10-4168-8b46-81c3787457fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-5894539f-89d3-4f8a-bcae-aadc6cf90bda,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-8a47e88c-7bb7-46b6-aefb-5b2a615bc5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-95d0f79d-c155-427b-a391-751b5cf83c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-a21c8e6b-f633-46de-a1cc-2db2f6988dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-879cbacb-f2c5-4569-bcfe-1150337b5821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800281906-172.17.0.16-1595818665404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39528,DS-4c9d7653-3ae4-40e9-99ce-3aaa99fcd28b,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-bbaaad6f-4126-4d56-bbbf-d74191f74368,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-3d3bd752-d078-448e-857e-65ed84465566,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-b694559e-b74c-44db-b241-09daa3e8dba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-817b31f4-20fb-4e51-9f97-dab6404f90a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-36faba22-0891-4196-8af9-253c2e0941fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-202655f6-04b9-4f33-800f-2295ea6c65a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-2bc56aec-fcd1-4b5b-8319-4882efb653cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800281906-172.17.0.16-1595818665404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39528,DS-4c9d7653-3ae4-40e9-99ce-3aaa99fcd28b,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-bbaaad6f-4126-4d56-bbbf-d74191f74368,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-3d3bd752-d078-448e-857e-65ed84465566,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-b694559e-b74c-44db-b241-09daa3e8dba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-817b31f4-20fb-4e51-9f97-dab6404f90a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-36faba22-0891-4196-8af9-253c2e0941fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-202655f6-04b9-4f33-800f-2295ea6c65a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-2bc56aec-fcd1-4b5b-8319-4882efb653cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1029218761-172.17.0.16-1595818764169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43171,DS-df9ceb60-e20c-4ed4-bd82-b34e539aafe5,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-6e4e3d10-0c4e-49c8-af23-1cfb4a1919b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-3ca58e49-f48f-4308-8886-51fb3c8e23a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-ddb40b55-8884-4e42-8d93-fe26374d3a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-a4293b0a-6b5c-42e5-974e-b739a0eabc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-3e8cf1f2-0db4-43e6-8ec0-619bd99b25f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-e287f6b5-fbe8-45d8-aa4c-33a739c31984,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-cdf96336-035d-44ac-9c1e-436a1c3f9c16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1029218761-172.17.0.16-1595818764169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43171,DS-df9ceb60-e20c-4ed4-bd82-b34e539aafe5,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-6e4e3d10-0c4e-49c8-af23-1cfb4a1919b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-3ca58e49-f48f-4308-8886-51fb3c8e23a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-ddb40b55-8884-4e42-8d93-fe26374d3a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-a4293b0a-6b5c-42e5-974e-b739a0eabc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-3e8cf1f2-0db4-43e6-8ec0-619bd99b25f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-e287f6b5-fbe8-45d8-aa4c-33a739c31984,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-cdf96336-035d-44ac-9c1e-436a1c3f9c16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203523721-172.17.0.16-1595819396984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36833,DS-7d971737-f844-4d36-b3a9-36e86464bfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-124bfa34-2884-4a36-83e8-2095389a195d,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-00454cf4-4a64-44f5-9fcc-5321e8bde74c,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-94d0d0dd-dc37-4973-8701-3239eb6bcd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-853f5ec6-266e-4fc4-a5ea-5e7e24ea02e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-6b7a1ed8-f747-411f-a87f-b3fe18cfc32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-d4fff847-deac-44d0-a45b-0ea8c863f568,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-03fb23ad-ca97-488d-8d41-22649356f820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-203523721-172.17.0.16-1595819396984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36833,DS-7d971737-f844-4d36-b3a9-36e86464bfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-124bfa34-2884-4a36-83e8-2095389a195d,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-00454cf4-4a64-44f5-9fcc-5321e8bde74c,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-94d0d0dd-dc37-4973-8701-3239eb6bcd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-853f5ec6-266e-4fc4-a5ea-5e7e24ea02e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-6b7a1ed8-f747-411f-a87f-b3fe18cfc32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-d4fff847-deac-44d0-a45b-0ea8c863f568,DISK], DatanodeInfoWithStorage[127.0.0.1:46431,DS-03fb23ad-ca97-488d-8d41-22649356f820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.failover.sleep.max.millis
component: hdfs:NameNode
v1: 1500
v2: 15000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227530531-172.17.0.16-1595819588152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42744,DS-16a8c92f-c3f4-4c4b-9f97-9da2eec13d69,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-f5cfefe9-b934-4cfd-b5c9-94fc814e3f70,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-6f735ebb-3761-40e2-9062-a60c7dcf9afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-8ba22821-84f7-46f9-ad8e-d461ff002511,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-2a07aea0-2079-4b43-ab6e-8ea656cfa2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-8464077a-b22c-4be7-a424-895ceb62cc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-512781cb-b1b1-4901-8237-fdb759c84261,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-e4bf5e7c-5fc0-4dcc-9410-12cbd1d28853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227530531-172.17.0.16-1595819588152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42744,DS-16a8c92f-c3f4-4c4b-9f97-9da2eec13d69,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-f5cfefe9-b934-4cfd-b5c9-94fc814e3f70,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-6f735ebb-3761-40e2-9062-a60c7dcf9afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-8ba22821-84f7-46f9-ad8e-d461ff002511,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-2a07aea0-2079-4b43-ab6e-8ea656cfa2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-8464077a-b22c-4be7-a424-895ceb62cc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-512781cb-b1b1-4901-8237-fdb759c84261,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-e4bf5e7c-5fc0-4dcc-9410-12cbd1d28853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 4995
