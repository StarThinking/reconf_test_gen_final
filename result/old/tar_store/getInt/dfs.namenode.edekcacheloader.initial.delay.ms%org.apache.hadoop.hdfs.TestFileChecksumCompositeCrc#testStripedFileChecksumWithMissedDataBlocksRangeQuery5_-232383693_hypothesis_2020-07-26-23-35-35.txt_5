reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114346954-172.17.0.9-1595806774062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45308,DS-25069d17-0e12-4633-afaf-1705e11fc520,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-5437f63f-02f9-4e5d-97db-3286390e7087,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-b3cb92aa-7166-4e25-87ca-4f781a0dbd00,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-7acf4d1b-d189-4b9e-9ebb-26a1783eacee,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-782a7606-a7e9-468e-b8d1-d55b0ebceaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-977acaa5-ece1-413e-91d8-0bf463c11f58,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-0911bc15-974c-441f-b742-57f100e62934,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-acd7f767-22c7-4556-865d-a827edf5db4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114346954-172.17.0.9-1595806774062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45308,DS-25069d17-0e12-4633-afaf-1705e11fc520,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-5437f63f-02f9-4e5d-97db-3286390e7087,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-b3cb92aa-7166-4e25-87ca-4f781a0dbd00,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-7acf4d1b-d189-4b9e-9ebb-26a1783eacee,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-782a7606-a7e9-468e-b8d1-d55b0ebceaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-977acaa5-ece1-413e-91d8-0bf463c11f58,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-0911bc15-974c-441f-b742-57f100e62934,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-acd7f767-22c7-4556-865d-a827edf5db4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116159942-172.17.0.9-1595806862696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32887,DS-0e586b27-f24a-497a-bba3-630d5aece982,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-b2c7c89c-ddc2-4dee-99ee-0f98a53cd1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-96f7daed-9198-402f-a676-e252cd7c8e69,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-5b48a109-fd4b-46a7-87d1-858273370143,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-dc70579b-4eb7-4159-9471-5f6416f220fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-43fcd247-9b7f-4ea9-8894-286a0fcca3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-fb657c43-0fa9-43a5-8422-d05dfe8e507a,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-36d307a2-c175-41e4-b402-1e552adb648d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116159942-172.17.0.9-1595806862696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32887,DS-0e586b27-f24a-497a-bba3-630d5aece982,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-b2c7c89c-ddc2-4dee-99ee-0f98a53cd1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-96f7daed-9198-402f-a676-e252cd7c8e69,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-5b48a109-fd4b-46a7-87d1-858273370143,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-dc70579b-4eb7-4159-9471-5f6416f220fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-43fcd247-9b7f-4ea9-8894-286a0fcca3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-fb657c43-0fa9-43a5-8422-d05dfe8e507a,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-36d307a2-c175-41e4-b402-1e552adb648d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719057538-172.17.0.9-1595807470356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42818,DS-b547f881-cc1c-4aea-879d-14d93d36fe4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-ba22cdc7-d940-4a03-9eb3-e8eb61b90a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-cdca378f-ea5f-41e1-adc8-5c194c7b16d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-58f733c7-6005-4431-9f8c-55e5de385aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-0547b75f-3683-4358-a558-7caf03551e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-95dbf5ec-afaf-46da-8d0f-89d3d43a7f91,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-024b8e17-a205-43c5-9a59-e4408b92e153,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-e57fc858-c6b3-4c19-854b-dde31832b914,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719057538-172.17.0.9-1595807470356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42818,DS-b547f881-cc1c-4aea-879d-14d93d36fe4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-ba22cdc7-d940-4a03-9eb3-e8eb61b90a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-cdca378f-ea5f-41e1-adc8-5c194c7b16d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-58f733c7-6005-4431-9f8c-55e5de385aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-0547b75f-3683-4358-a558-7caf03551e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-95dbf5ec-afaf-46da-8d0f-89d3d43a7f91,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-024b8e17-a205-43c5-9a59-e4408b92e153,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-e57fc858-c6b3-4c19-854b-dde31832b914,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150861136-172.17.0.9-1595808004354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34796,DS-68c2f7c3-9b42-4d8f-b5b5-ea021587662c,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-033074d9-31a8-46b9-a185-a78deee25d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-fa8307f3-4653-4b7b-b89c-8bdcbc48024f,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-8426e51f-b945-42fe-aa07-ce4dc9e3cfed,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-eb9c58de-ffd4-4d18-a1bb-7d780d493a90,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-8956bd82-a48a-451b-9368-7ba108b22565,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-63827d7f-40de-4066-9072-76b5d0673dee,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-0b110a3d-f287-40b9-91aa-dbe18e80ffb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150861136-172.17.0.9-1595808004354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34796,DS-68c2f7c3-9b42-4d8f-b5b5-ea021587662c,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-033074d9-31a8-46b9-a185-a78deee25d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-fa8307f3-4653-4b7b-b89c-8bdcbc48024f,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-8426e51f-b945-42fe-aa07-ce4dc9e3cfed,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-eb9c58de-ffd4-4d18-a1bb-7d780d493a90,DISK], DatanodeInfoWithStorage[127.0.0.1:33810,DS-8956bd82-a48a-451b-9368-7ba108b22565,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-63827d7f-40de-4066-9072-76b5d0673dee,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-0b110a3d-f287-40b9-91aa-dbe18e80ffb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495844143-172.17.0.9-1595808403515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37667,DS-b5ab142c-7329-40f9-ae4e-30e9ed34c022,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-9c6aa158-cec0-47ff-aeaf-58d2de03b837,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-bebc78c2-381e-48cf-85a1-ac55f645bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-ca64123a-6d37-4499-83f5-7c946829d602,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-6262b463-4503-4906-8216-4cbbf16d5072,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-ad3985b1-2f0c-4fc7-a867-308474e67fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-aee97ced-1c6d-4387-8fe8-7bd34cd95c41,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-ad5ea86a-d918-49a5-a629-0141a7d1102f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1495844143-172.17.0.9-1595808403515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37667,DS-b5ab142c-7329-40f9-ae4e-30e9ed34c022,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-9c6aa158-cec0-47ff-aeaf-58d2de03b837,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-bebc78c2-381e-48cf-85a1-ac55f645bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-ca64123a-6d37-4499-83f5-7c946829d602,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-6262b463-4503-4906-8216-4cbbf16d5072,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-ad3985b1-2f0c-4fc7-a867-308474e67fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-aee97ced-1c6d-4387-8fe8-7bd34cd95c41,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-ad5ea86a-d918-49a5-a629-0141a7d1102f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138804637-172.17.0.9-1595808455094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38017,DS-a7855b24-38a4-4aaa-906f-5a6e950809b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-a13d88f0-4f87-49b0-8668-fe9e40593840,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-0f744246-fcee-483c-8043-7bf8e2c27902,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-4f0f527c-c8bc-4bcc-8954-be89cd9571db,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-425185dc-7503-479e-8f30-1b96d2eddc75,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-3ce03ea1-3269-4af0-b6fe-e757a6e1bbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-f00a6800-3be7-4d7e-b2ff-a5cd0467684a,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-1e587094-1211-4d85-89a2-c477e3f3a3f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138804637-172.17.0.9-1595808455094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38017,DS-a7855b24-38a4-4aaa-906f-5a6e950809b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-a13d88f0-4f87-49b0-8668-fe9e40593840,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-0f744246-fcee-483c-8043-7bf8e2c27902,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-4f0f527c-c8bc-4bcc-8954-be89cd9571db,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-425185dc-7503-479e-8f30-1b96d2eddc75,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-3ce03ea1-3269-4af0-b6fe-e757a6e1bbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45444,DS-f00a6800-3be7-4d7e-b2ff-a5cd0467684a,DISK], DatanodeInfoWithStorage[127.0.0.1:43434,DS-1e587094-1211-4d85-89a2-c477e3f3a3f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310263415-172.17.0.9-1595808763586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37459,DS-ca90ff75-4ddd-43fd-b41b-a3919dd6290e,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-e1eb70cf-a1e3-46e8-a3e6-911bde168b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-e948536b-4a0f-43a6-a969-117aed56b640,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-d52efd43-6e68-4aa7-bfca-d690aee978b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-e4677c1e-a922-4324-8a12-4450a963756c,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-607c39c8-fa12-4011-9e90-dcb99907ba99,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-a1843219-9a03-4b29-9b37-13146ed633f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-e4830407-73ef-46d1-9d56-9e37fbc8f895,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310263415-172.17.0.9-1595808763586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37459,DS-ca90ff75-4ddd-43fd-b41b-a3919dd6290e,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-e1eb70cf-a1e3-46e8-a3e6-911bde168b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-e948536b-4a0f-43a6-a969-117aed56b640,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-d52efd43-6e68-4aa7-bfca-d690aee978b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-e4677c1e-a922-4324-8a12-4450a963756c,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-607c39c8-fa12-4011-9e90-dcb99907ba99,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-a1843219-9a03-4b29-9b37-13146ed633f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-e4830407-73ef-46d1-9d56-9e37fbc8f895,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077769858-172.17.0.9-1595808937830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43613,DS-a42f8317-8bfc-4ece-b748-a4ca7e727a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-40876ea7-1f0c-444f-b26a-4bd9b4bf5481,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-8545ad8e-cc4d-4e36-8341-23a9bbc1931c,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-ff28edd3-d8c4-416d-9f18-02af8d065bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-21e54d0c-b288-4d9e-aaff-e17cbabcb92d,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-fe2c7bb3-1784-4850-9fc8-452810c5e086,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-92e5ece4-c40f-4d4a-a277-c0d03a69b5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-8a1b52a5-a72f-4a50-9b17-36989bab3985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077769858-172.17.0.9-1595808937830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43613,DS-a42f8317-8bfc-4ece-b748-a4ca7e727a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-40876ea7-1f0c-444f-b26a-4bd9b4bf5481,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-8545ad8e-cc4d-4e36-8341-23a9bbc1931c,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-ff28edd3-d8c4-416d-9f18-02af8d065bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-21e54d0c-b288-4d9e-aaff-e17cbabcb92d,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-fe2c7bb3-1784-4850-9fc8-452810c5e086,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-92e5ece4-c40f-4d4a-a277-c0d03a69b5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-8a1b52a5-a72f-4a50-9b17-36989bab3985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737997067-172.17.0.9-1595809391388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42547,DS-ae548327-da3e-4f5f-846e-2ea1d47e4b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-5780a558-c459-4726-9341-b50599a27c81,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-9ed3f9a0-973d-4f87-ba39-a92df6f488a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-e8124439-be3d-447f-b433-45c87ef7725f,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-52adb55e-ff87-4782-89da-93bc4185d37d,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-27da8eff-5325-4609-942a-a10645b5098a,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-fc7ea2d2-f725-4e3f-83b3-f0881ef9a82a,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-de5a4d2d-2ad8-409f-a98a-4fc11c25d5bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737997067-172.17.0.9-1595809391388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42547,DS-ae548327-da3e-4f5f-846e-2ea1d47e4b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-5780a558-c459-4726-9341-b50599a27c81,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-9ed3f9a0-973d-4f87-ba39-a92df6f488a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-e8124439-be3d-447f-b433-45c87ef7725f,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-52adb55e-ff87-4782-89da-93bc4185d37d,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-27da8eff-5325-4609-942a-a10645b5098a,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-fc7ea2d2-f725-4e3f-83b3-f0881ef9a82a,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-de5a4d2d-2ad8-409f-a98a-4fc11c25d5bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066663562-172.17.0.9-1595809434895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40155,DS-7195845c-db97-4b0b-b945-01a5b668f78c,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-0d84d474-174d-4d54-8b0f-4926be435bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-a3eea3a4-681f-4fc2-8bd2-64814e32bf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-532bf309-bdb3-4aa6-aaed-fb13af43ad53,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-2b725dcb-fd61-4e11-8344-5534eaaade81,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-74c9c09a-b00b-490a-86f6-4bbfa9bda440,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-306d0a65-0c6b-4ca6-a624-2da31b918dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-4f977962-2319-4592-91dd-9d01f81cea7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066663562-172.17.0.9-1595809434895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40155,DS-7195845c-db97-4b0b-b945-01a5b668f78c,DISK], DatanodeInfoWithStorage[127.0.0.1:33151,DS-0d84d474-174d-4d54-8b0f-4926be435bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-a3eea3a4-681f-4fc2-8bd2-64814e32bf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-532bf309-bdb3-4aa6-aaed-fb13af43ad53,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-2b725dcb-fd61-4e11-8344-5534eaaade81,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-74c9c09a-b00b-490a-86f6-4bbfa9bda440,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-306d0a65-0c6b-4ca6-a624-2da31b918dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-4f977962-2319-4592-91dd-9d01f81cea7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541679960-172.17.0.9-1595809657321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41954,DS-d12505fb-6e69-4533-9b59-e47f5a4457e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-7c0f5d74-58ad-4612-8728-1cd21150a41c,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-5362b46b-02e0-45f1-ab37-e0dd4a94eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-f6962ef6-26bd-4f46-a09c-a3be9f67473c,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-7f77c84c-0fe4-4dbc-9854-46c2a74b15a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-78b0ff22-1c6d-4d5c-bbb0-840afe8b4cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-8f942c0e-4a41-408d-920c-7a196643abc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-5b27c9ae-d19a-4167-b35e-fe92d34aa36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541679960-172.17.0.9-1595809657321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41954,DS-d12505fb-6e69-4533-9b59-e47f5a4457e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-7c0f5d74-58ad-4612-8728-1cd21150a41c,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-5362b46b-02e0-45f1-ab37-e0dd4a94eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-f6962ef6-26bd-4f46-a09c-a3be9f67473c,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-7f77c84c-0fe4-4dbc-9854-46c2a74b15a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-78b0ff22-1c6d-4d5c-bbb0-840afe8b4cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-8f942c0e-4a41-408d-920c-7a196643abc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-5b27c9ae-d19a-4167-b35e-fe92d34aa36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589801489-172.17.0.9-1595809712042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42815,DS-a114f405-fe2e-4b0a-a7c9-8f73f9cc6e45,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-f0c018ef-75c6-4dd4-8c91-41dc4f47d518,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-eb37c1f1-7fbf-4fdb-a25d-e602e332dd49,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-804b363d-97de-4d83-9eb3-ae25c5e3f9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-1e6a511e-b265-46e3-bb52-4d9fd6192214,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-fb283463-4904-4b33-98f6-87701719e154,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-5b770817-9b20-4486-bba0-26cbf64e8c93,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-4e5ab403-c08d-4980-a30e-ebac78112ddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1589801489-172.17.0.9-1595809712042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42815,DS-a114f405-fe2e-4b0a-a7c9-8f73f9cc6e45,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-f0c018ef-75c6-4dd4-8c91-41dc4f47d518,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-eb37c1f1-7fbf-4fdb-a25d-e602e332dd49,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-804b363d-97de-4d83-9eb3-ae25c5e3f9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-1e6a511e-b265-46e3-bb52-4d9fd6192214,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-fb283463-4904-4b33-98f6-87701719e154,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-5b770817-9b20-4486-bba0-26cbf64e8c93,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-4e5ab403-c08d-4980-a30e-ebac78112ddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161338565-172.17.0.9-1595809969457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-3bdadc29-0b56-476c-9d24-b07ad6af09f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-7883638e-7614-456a-9b8b-15e6ef7428b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-140fcd1e-17d2-49eb-b1df-166feab43b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-7ce6215f-90d6-4c6f-ba55-b760de7dcbde,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-d96b6c16-2f20-42ac-a23c-148ce1630af3,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-f3a87765-8eb9-4ff2-99bf-38fc2846afa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-0ab9cc6e-ef76-4dc2-8e0d-bdb27250f4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-4f034051-f870-4ed9-815f-af40696d1eca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161338565-172.17.0.9-1595809969457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-3bdadc29-0b56-476c-9d24-b07ad6af09f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-7883638e-7614-456a-9b8b-15e6ef7428b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-140fcd1e-17d2-49eb-b1df-166feab43b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-7ce6215f-90d6-4c6f-ba55-b760de7dcbde,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-d96b6c16-2f20-42ac-a23c-148ce1630af3,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-f3a87765-8eb9-4ff2-99bf-38fc2846afa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-0ab9cc6e-ef76-4dc2-8e0d-bdb27250f4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-4f034051-f870-4ed9-815f-af40696d1eca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718877705-172.17.0.9-1595810531086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46359,DS-679da816-220c-4628-a3cc-9a017c21aa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-94a3d98d-e250-4929-807a-6ea13619a933,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-eea69bbf-d1f7-41a9-91e9-b06bd003dbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-a103d579-0abb-4f6a-a2aa-37ad93a12bce,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-715cc790-d1fe-4ee7-aa5c-ece725db92a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-1b5cd43a-febd-4dd9-9166-4b2b61e32ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-d0aee7ea-2058-4a41-8173-f25aacf7e9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-d92a9ec1-5fe1-4c8c-94f0-5bfdc28b3396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718877705-172.17.0.9-1595810531086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46359,DS-679da816-220c-4628-a3cc-9a017c21aa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-94a3d98d-e250-4929-807a-6ea13619a933,DISK], DatanodeInfoWithStorage[127.0.0.1:32906,DS-eea69bbf-d1f7-41a9-91e9-b06bd003dbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-a103d579-0abb-4f6a-a2aa-37ad93a12bce,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-715cc790-d1fe-4ee7-aa5c-ece725db92a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-1b5cd43a-febd-4dd9-9166-4b2b61e32ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-d0aee7ea-2058-4a41-8173-f25aacf7e9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-d92a9ec1-5fe1-4c8c-94f0-5bfdc28b3396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399487988-172.17.0.9-1595810860524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44599,DS-9af63de5-c6c1-40b6-968e-5dce96d03f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-4edc19a3-486a-4a91-ae85-8ed74e912acb,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-632d3cb1-316e-4375-8d85-722d4efd4e55,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-8d52a018-14b5-42b6-9d51-f47ed01db395,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-e1b5bd1d-4405-44d4-a0ab-efb1eb3767c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-dcfd49b8-d660-4ab6-b381-fa64e322603c,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-fa6b7719-13f0-40f6-b825-d5634a810df3,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-380bde45-aeb4-4414-97ff-6d3916fce18a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399487988-172.17.0.9-1595810860524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44599,DS-9af63de5-c6c1-40b6-968e-5dce96d03f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-4edc19a3-486a-4a91-ae85-8ed74e912acb,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-632d3cb1-316e-4375-8d85-722d4efd4e55,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-8d52a018-14b5-42b6-9d51-f47ed01db395,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-e1b5bd1d-4405-44d4-a0ab-efb1eb3767c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-dcfd49b8-d660-4ab6-b381-fa64e322603c,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-fa6b7719-13f0-40f6-b825-d5634a810df3,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-380bde45-aeb4-4414-97ff-6d3916fce18a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546678725-172.17.0.9-1595810943235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43127,DS-3750c7ee-d808-433a-a843-d61877ae6b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-bd59b17f-6b3b-47a9-a97f-ed57c70325cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-31af9484-17de-4d58-8195-1145e22cbcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-ff945c35-548a-41a0-81fa-56188907300e,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-37411be4-c530-4460-922b-841163b876d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-df7390fe-455f-4eb4-9039-b46f6fc9ab4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-c1ffa188-8905-4752-9078-21dc624ee2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-5e9835c1-7db3-49df-a235-5b7520e1e742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546678725-172.17.0.9-1595810943235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43127,DS-3750c7ee-d808-433a-a843-d61877ae6b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43612,DS-bd59b17f-6b3b-47a9-a97f-ed57c70325cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-31af9484-17de-4d58-8195-1145e22cbcbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-ff945c35-548a-41a0-81fa-56188907300e,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-37411be4-c530-4460-922b-841163b876d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-df7390fe-455f-4eb4-9039-b46f6fc9ab4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-c1ffa188-8905-4752-9078-21dc624ee2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-5e9835c1-7db3-49df-a235-5b7520e1e742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870826546-172.17.0.9-1595811319431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33089,DS-69b5c14f-8d36-447f-8edf-b23b3f7a5b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-ec9d50c2-d86e-419c-a0e7-84d416d6d614,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-916863cd-8e0c-4f05-a9b1-9a68f46e0492,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-b34b2b4a-682d-4b86-af97-1dfa7898c930,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-51828546-eecf-4dab-ab12-0cdae8c3a948,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-c3028df2-596c-4433-a680-bd5c233a62e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-14c7ecb5-fb73-44d4-b04c-9831bfc7bf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-4f3b9aa2-8da5-4ee5-ad4d-6f0a53b6dc6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870826546-172.17.0.9-1595811319431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33089,DS-69b5c14f-8d36-447f-8edf-b23b3f7a5b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-ec9d50c2-d86e-419c-a0e7-84d416d6d614,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-916863cd-8e0c-4f05-a9b1-9a68f46e0492,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-b34b2b4a-682d-4b86-af97-1dfa7898c930,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-51828546-eecf-4dab-ab12-0cdae8c3a948,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-c3028df2-596c-4433-a680-bd5c233a62e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-14c7ecb5-fb73-44d4-b04c-9831bfc7bf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-4f3b9aa2-8da5-4ee5-ad4d-6f0a53b6dc6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555703435-172.17.0.9-1595811454071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39939,DS-4dcbaaab-498e-4ba3-a7b4-52f92a2ed071,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-0b440064-58bd-40cf-88c0-fc87b50c3ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-7090f611-1e45-4ae9-b534-ca2f979c5f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-851ccabe-5a8c-4623-b8d8-623d0dca026e,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-fd694332-1fb1-4c1e-a65a-1c4242e9c739,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-a6cf9656-36ab-4f76-b5b5-e64b23d76133,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-a430a861-6a3c-4551-b08b-90cbde8ffc60,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-d13d6199-d60a-4e03-b0d1-d8aa7bbe2694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1555703435-172.17.0.9-1595811454071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39939,DS-4dcbaaab-498e-4ba3-a7b4-52f92a2ed071,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-0b440064-58bd-40cf-88c0-fc87b50c3ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-7090f611-1e45-4ae9-b534-ca2f979c5f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-851ccabe-5a8c-4623-b8d8-623d0dca026e,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-fd694332-1fb1-4c1e-a65a-1c4242e9c739,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-a6cf9656-36ab-4f76-b5b5-e64b23d76133,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-a430a861-6a3c-4551-b08b-90cbde8ffc60,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-d13d6199-d60a-4e03-b0d1-d8aa7bbe2694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957132074-172.17.0.9-1595812069622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44734,DS-042edbd5-913f-4826-aa02-47d8d0c39e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-571147d8-22b0-46f1-9c05-79c98428ea97,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-053d35d4-263d-4004-add5-28018b623e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-5b7d520c-6c1e-4f85-aa2d-54b1292ad96b,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-607e0a33-4c08-4af0-b9f3-539da9483873,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-34fb44a0-abe2-4c60-836a-80748324ca9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-61208642-784a-4c7c-986d-0690f2c806ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-84c4321a-adba-4253-85da-0793e8839daa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957132074-172.17.0.9-1595812069622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44734,DS-042edbd5-913f-4826-aa02-47d8d0c39e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-571147d8-22b0-46f1-9c05-79c98428ea97,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-053d35d4-263d-4004-add5-28018b623e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-5b7d520c-6c1e-4f85-aa2d-54b1292ad96b,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-607e0a33-4c08-4af0-b9f3-539da9483873,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-34fb44a0-abe2-4c60-836a-80748324ca9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-61208642-784a-4c7c-986d-0690f2c806ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-84c4321a-adba-4253-85da-0793e8839daa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688390204-172.17.0.9-1595812417310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43749,DS-ba60616f-a522-4f98-baf1-c6f00adb4570,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-bf269934-6ac9-460c-9c47-88c848ff1158,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-bae95dde-1364-4d16-b169-c0341b265cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-8abd8978-3402-44a0-95ee-71d44f780288,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-c81a2385-6678-4c21-bc6f-93488a0111da,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-ca37f412-2c6c-46f1-bcba-8c056d4a66fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-1c967b07-fc88-4aaa-aa56-ce4fe1a953eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-5625559f-7622-434f-ab68-bc075897c85a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688390204-172.17.0.9-1595812417310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43749,DS-ba60616f-a522-4f98-baf1-c6f00adb4570,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-bf269934-6ac9-460c-9c47-88c848ff1158,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-bae95dde-1364-4d16-b169-c0341b265cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-8abd8978-3402-44a0-95ee-71d44f780288,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-c81a2385-6678-4c21-bc6f-93488a0111da,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-ca37f412-2c6c-46f1-bcba-8c056d4a66fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-1c967b07-fc88-4aaa-aa56-ce4fe1a953eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-5625559f-7622-434f-ab68-bc075897c85a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267385417-172.17.0.9-1595812889973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36871,DS-f2a24238-d566-46b1-8297-bbea08f00c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-406db22b-0e07-4ea5-95ee-e736f8cc6dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-39dca16f-97e5-4c76-9546-d9c0bef39c59,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-131485e8-ddd8-4fd0-881f-485e350a83e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-739d0f3f-f85f-4167-bb6f-56f4a520a179,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-f62e4fdd-68b3-4dc4-8566-0b542a0e9431,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-5c678c99-7768-46a3-b1fa-d308f90255a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-11bad44a-9d98-42b3-bcc2-4171c8cd0052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267385417-172.17.0.9-1595812889973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36871,DS-f2a24238-d566-46b1-8297-bbea08f00c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-406db22b-0e07-4ea5-95ee-e736f8cc6dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-39dca16f-97e5-4c76-9546-d9c0bef39c59,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-131485e8-ddd8-4fd0-881f-485e350a83e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-739d0f3f-f85f-4167-bb6f-56f4a520a179,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-f62e4fdd-68b3-4dc4-8566-0b542a0e9431,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-5c678c99-7768-46a3-b1fa-d308f90255a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-11bad44a-9d98-42b3-bcc2-4171c8cd0052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6581
