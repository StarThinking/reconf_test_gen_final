reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933327118-172.17.0.3-1595957368410:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46351,DS-b44843b3-da0b-45d6-aacb-e3f052098aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-f0953888-1b6b-45bc-bee2-97debf3e00a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-f5c6f96d-1eec-4fb4-99a9-84c82a4b6108,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-4e288d16-6596-4b32-9160-22243c6adc49,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-47dec870-325d-49f2-8572-d0d9ec30eeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-9b5b7d2c-7a2d-416d-b24f-48bd1b879ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-e0104a46-b9f6-4d68-b88a-0f11458ea825,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-97c90f55-2c3a-4c39-a4fb-2458b9433496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933327118-172.17.0.3-1595957368410:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46351,DS-b44843b3-da0b-45d6-aacb-e3f052098aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-f0953888-1b6b-45bc-bee2-97debf3e00a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-f5c6f96d-1eec-4fb4-99a9-84c82a4b6108,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-4e288d16-6596-4b32-9160-22243c6adc49,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-47dec870-325d-49f2-8572-d0d9ec30eeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-9b5b7d2c-7a2d-416d-b24f-48bd1b879ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-e0104a46-b9f6-4d68-b88a-0f11458ea825,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-97c90f55-2c3a-4c39-a4fb-2458b9433496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664839861-172.17.0.3-1595957401357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46822,DS-6705ec42-2bd5-4c95-b3bd-b4dc59114af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-2bb1dd51-4b73-4445-a8ab-24768a9e86a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-1590ee50-33d4-49cf-8279-0e5ea52ca442,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-78771282-aa62-469c-9c49-5f37979083db,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-0774febe-7991-41d6-9be3-dae4eb012f04,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-bf1025c1-0d59-43fa-ae3f-fabee4c73209,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-0a902a22-f667-44ad-8eca-902c7c193fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-d4102319-aa81-4815-b7d2-5f3905674595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664839861-172.17.0.3-1595957401357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46822,DS-6705ec42-2bd5-4c95-b3bd-b4dc59114af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-2bb1dd51-4b73-4445-a8ab-24768a9e86a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-1590ee50-33d4-49cf-8279-0e5ea52ca442,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-78771282-aa62-469c-9c49-5f37979083db,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-0774febe-7991-41d6-9be3-dae4eb012f04,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-bf1025c1-0d59-43fa-ae3f-fabee4c73209,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-0a902a22-f667-44ad-8eca-902c7c193fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-d4102319-aa81-4815-b7d2-5f3905674595,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021236646-172.17.0.3-1595957959220:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41207,DS-a8636c6f-f8e5-4c41-9c8a-08efce469959,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-4668d151-ee25-4468-aa4b-b7e0aa8ac89a,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-0a1265c4-5af0-4dce-9add-c8dca9ce429a,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-93727c1c-7a2f-4374-9e15-6bf5755818db,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-3740ce40-8ae9-468c-a28f-ea3883e0c1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-560f80f2-7332-4124-badb-acae47669955,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-cfec1a9b-dd99-4ba2-a3de-3566d1dd43a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-f86d63dd-5c2b-49c7-96ae-2f6cf8b7d031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021236646-172.17.0.3-1595957959220:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41207,DS-a8636c6f-f8e5-4c41-9c8a-08efce469959,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-4668d151-ee25-4468-aa4b-b7e0aa8ac89a,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-0a1265c4-5af0-4dce-9add-c8dca9ce429a,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-93727c1c-7a2f-4374-9e15-6bf5755818db,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-3740ce40-8ae9-468c-a28f-ea3883e0c1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-560f80f2-7332-4124-badb-acae47669955,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-cfec1a9b-dd99-4ba2-a3de-3566d1dd43a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-f86d63dd-5c2b-49c7-96ae-2f6cf8b7d031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569970087-172.17.0.3-1595958184982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38375,DS-d82459b5-ff3f-4876-9557-cbbe4de3cc70,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-c961cfe8-6886-4218-8406-fb884ee769dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-f7e0e2f7-ec73-44ae-9687-912a04490b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-0c24607c-dc90-43ea-a6cb-eb991d69a2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-4b0fae20-b9d8-4089-ac86-100cc1a7edcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-4a0bf2ec-6404-469e-a357-7d43a7c684e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-3081753f-c1cf-4d2f-8ab5-966639f0ea57,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-a972b848-7689-4845-bbfd-7eaac9765f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569970087-172.17.0.3-1595958184982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38375,DS-d82459b5-ff3f-4876-9557-cbbe4de3cc70,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-c961cfe8-6886-4218-8406-fb884ee769dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-f7e0e2f7-ec73-44ae-9687-912a04490b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-0c24607c-dc90-43ea-a6cb-eb991d69a2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-4b0fae20-b9d8-4089-ac86-100cc1a7edcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-4a0bf2ec-6404-469e-a357-7d43a7c684e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-3081753f-c1cf-4d2f-8ab5-966639f0ea57,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-a972b848-7689-4845-bbfd-7eaac9765f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867726069-172.17.0.3-1595959159226:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44038,DS-2e9b1402-6f71-49c9-8614-55104d235c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-513161fa-8967-4268-b038-2447fd5124a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-eae483f7-24ac-4d64-b4cb-250096bdf3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-d546c3fc-d42c-42e8-9a99-c92b08722065,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-c2b52a28-bb8d-42c2-bda2-279a73c12fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-76807d46-1111-4c67-9a4f-5bd5d23914bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-2193a8a2-7b6b-459d-a245-3c61881d3639,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-d6ef4124-2248-4937-aaa7-5e4480863b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867726069-172.17.0.3-1595959159226:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44038,DS-2e9b1402-6f71-49c9-8614-55104d235c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-513161fa-8967-4268-b038-2447fd5124a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-eae483f7-24ac-4d64-b4cb-250096bdf3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-d546c3fc-d42c-42e8-9a99-c92b08722065,DISK], DatanodeInfoWithStorage[127.0.0.1:40173,DS-c2b52a28-bb8d-42c2-bda2-279a73c12fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-76807d46-1111-4c67-9a4f-5bd5d23914bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-2193a8a2-7b6b-459d-a245-3c61881d3639,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-d6ef4124-2248-4937-aaa7-5e4480863b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137329422-172.17.0.3-1595959947444:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45375,DS-07106da3-a6bf-4a0e-8ec2-5b0a0317ace9,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-541d3d67-4b0d-4fb1-a816-44cdddaedfab,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-edc7445f-64d4-43c2-a1af-73943543a5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-6a4a181e-c524-4170-b081-42cbd486c155,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-62564ead-3d4d-40a9-83cd-e298ef01eba0,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-acf976a7-619a-400b-8131-4e83b72003fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-c992c71e-9c2c-460d-8395-c630ba58e7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-c2595a4e-2d04-4082-b02e-75c1a6b1fed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137329422-172.17.0.3-1595959947444:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45375,DS-07106da3-a6bf-4a0e-8ec2-5b0a0317ace9,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-541d3d67-4b0d-4fb1-a816-44cdddaedfab,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-edc7445f-64d4-43c2-a1af-73943543a5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-6a4a181e-c524-4170-b081-42cbd486c155,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-62564ead-3d4d-40a9-83cd-e298ef01eba0,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-acf976a7-619a-400b-8131-4e83b72003fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-c992c71e-9c2c-460d-8395-c630ba58e7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-c2595a4e-2d04-4082-b02e-75c1a6b1fed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-26324277-172.17.0.3-1595960225558:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40160,DS-5b6904bd-33e3-4db5-954c-c23ec8b320fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-ec01da61-3165-4649-bcb3-f48cc021099d,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-88ce4ebd-d8cd-4b97-820b-2b0a469ac011,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-cce328fe-947e-43e8-bdc2-93f3086b55eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-e59e3f32-2d30-4882-8a6f-550dd17b0c21,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-59aa6d50-eb95-482a-be1b-d21d85359f18,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-02157a7c-8789-4409-8ce1-5ebd4e3d1e47,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-4ddc8924-f269-43a2-aa7a-e65fb5f8dfd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-26324277-172.17.0.3-1595960225558:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40160,DS-5b6904bd-33e3-4db5-954c-c23ec8b320fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-ec01da61-3165-4649-bcb3-f48cc021099d,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-88ce4ebd-d8cd-4b97-820b-2b0a469ac011,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-cce328fe-947e-43e8-bdc2-93f3086b55eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-e59e3f32-2d30-4882-8a6f-550dd17b0c21,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-59aa6d50-eb95-482a-be1b-d21d85359f18,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-02157a7c-8789-4409-8ce1-5ebd4e3d1e47,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-4ddc8924-f269-43a2-aa7a-e65fb5f8dfd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580520200-172.17.0.3-1595960253489:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45005,DS-c9fd990a-d462-432a-8048-30c6f02e1388,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-52880b6d-3422-497f-a77b-fa494140d903,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-6c7e55af-6f17-4b4f-bd2a-d41be4452c88,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-ceb026f2-d312-45f5-89dc-1719722ca4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-e57f5e4a-35fb-4a18-b99a-dc584bd53f99,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-3651c2b1-0cc1-466b-a2b7-4d88de0c5137,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-6c09946f-572e-445b-937e-1d41a5ee2a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-c9bbc2a3-1366-4b1d-be4a-829e15457369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580520200-172.17.0.3-1595960253489:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45005,DS-c9fd990a-d462-432a-8048-30c6f02e1388,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-52880b6d-3422-497f-a77b-fa494140d903,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-6c7e55af-6f17-4b4f-bd2a-d41be4452c88,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-ceb026f2-d312-45f5-89dc-1719722ca4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45363,DS-e57f5e4a-35fb-4a18-b99a-dc584bd53f99,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-3651c2b1-0cc1-466b-a2b7-4d88de0c5137,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-6c09946f-572e-445b-937e-1d41a5ee2a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-c9bbc2a3-1366-4b1d-be4a-829e15457369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388813138-172.17.0.3-1595960575624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42600,DS-9b36a905-cfea-4fad-8f10-1065f6eb3e53,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-d23dd664-ec91-4c46-83b3-30a9418eec9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-c8f041ec-fbb3-48a0-8413-05340af1747d,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-1675b9ac-7b3b-477d-ac61-20f1075e4253,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-e53c4549-2742-480f-ae23-381b254205e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-dc00a421-f342-4510-8a79-212f6006abf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-d48315aa-6ed4-4a9f-8c25-9eb434397e02,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-444e345a-17fa-4c53-968d-d7f4bc75f6e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388813138-172.17.0.3-1595960575624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42600,DS-9b36a905-cfea-4fad-8f10-1065f6eb3e53,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-d23dd664-ec91-4c46-83b3-30a9418eec9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-c8f041ec-fbb3-48a0-8413-05340af1747d,DISK], DatanodeInfoWithStorage[127.0.0.1:35935,DS-1675b9ac-7b3b-477d-ac61-20f1075e4253,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-e53c4549-2742-480f-ae23-381b254205e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-dc00a421-f342-4510-8a79-212f6006abf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-d48315aa-6ed4-4a9f-8c25-9eb434397e02,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-444e345a-17fa-4c53-968d-d7f4bc75f6e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198109514-172.17.0.3-1595962085841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46770,DS-0a2a792e-c949-4c2d-817d-cf85156d735d,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-3915dfe9-bd1a-42ab-9cc0-79eb33694938,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-c993fb1e-9c3c-4235-a676-0f1a505dab37,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-d450ccd3-5edd-4f93-aaec-510bd849e914,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-fb63dacb-f429-47c7-99fc-4848a05a2067,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-ae6c19ee-f45a-40c1-badc-a22b2889b3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-9979a828-fc6d-47b7-85c2-896311ae0c18,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-a8785cb3-5786-41d8-aa92-6d23e517f327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198109514-172.17.0.3-1595962085841:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46770,DS-0a2a792e-c949-4c2d-817d-cf85156d735d,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-3915dfe9-bd1a-42ab-9cc0-79eb33694938,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-c993fb1e-9c3c-4235-a676-0f1a505dab37,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-d450ccd3-5edd-4f93-aaec-510bd849e914,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-fb63dacb-f429-47c7-99fc-4848a05a2067,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-ae6c19ee-f45a-40c1-badc-a22b2889b3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-9979a828-fc6d-47b7-85c2-896311ae0c18,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-a8785cb3-5786-41d8-aa92-6d23e517f327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 4988
