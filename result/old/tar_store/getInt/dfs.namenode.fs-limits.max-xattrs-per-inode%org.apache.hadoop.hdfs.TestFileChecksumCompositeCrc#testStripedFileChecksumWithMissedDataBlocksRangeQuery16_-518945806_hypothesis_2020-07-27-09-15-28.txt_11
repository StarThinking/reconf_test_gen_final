reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1342594050-172.17.0.20-1595841646299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-bfcf381a-5cb7-4509-bda8-593c323ba18d,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-2560d7cb-1b80-4d08-a938-b2164ffc6156,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-aebb3344-f358-4312-8fbb-3c919e265a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-abf118a4-9d7e-45b2-adc5-27864987cde4,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-8bb5f133-215d-4c22-b122-4922e81e05f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-bcdfa0f0-feeb-4eef-93cf-81c1b30aa2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-962b2833-d686-44fa-a415-38851afa1bde,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-172bba03-3e08-45b5-b519-ee310031dda9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1342594050-172.17.0.20-1595841646299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40936,DS-bfcf381a-5cb7-4509-bda8-593c323ba18d,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-2560d7cb-1b80-4d08-a938-b2164ffc6156,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-aebb3344-f358-4312-8fbb-3c919e265a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-abf118a4-9d7e-45b2-adc5-27864987cde4,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-8bb5f133-215d-4c22-b122-4922e81e05f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-bcdfa0f0-feeb-4eef-93cf-81c1b30aa2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-962b2833-d686-44fa-a415-38851afa1bde,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-172bba03-3e08-45b5-b519-ee310031dda9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303383056-172.17.0.20-1595841729025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40389,DS-b481e04b-2416-4175-8072-3153bc5e9b39,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-268a4ab5-2d23-4871-bb16-415069779c49,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-a617927d-741a-4b16-8a6c-6e0eb51ca878,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-ea57258b-50fd-4840-8a3b-44c3ade1029c,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-954caf30-4c35-4685-8cf3-59c75ec63842,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-f47ce57c-a9cc-4b83-9bc6-781fd6e67371,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-9b753864-bdc9-4e95-b935-aef31011b1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-f793ca28-f499-4766-b8b9-af18793ab0e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303383056-172.17.0.20-1595841729025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40389,DS-b481e04b-2416-4175-8072-3153bc5e9b39,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-268a4ab5-2d23-4871-bb16-415069779c49,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-a617927d-741a-4b16-8a6c-6e0eb51ca878,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-ea57258b-50fd-4840-8a3b-44c3ade1029c,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-954caf30-4c35-4685-8cf3-59c75ec63842,DISK], DatanodeInfoWithStorage[127.0.0.1:38227,DS-f47ce57c-a9cc-4b83-9bc6-781fd6e67371,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-9b753864-bdc9-4e95-b935-aef31011b1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-f793ca28-f499-4766-b8b9-af18793ab0e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078019509-172.17.0.20-1595841757677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39297,DS-59c47e1e-4640-4010-b712-95433da17ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-d0a72a7a-a83b-47a3-b451-73847b1b067a,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-8ab8aea5-1152-4153-9a78-5fd52bd10c77,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-28031592-163f-415c-87d1-f44d68c45ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-e358eeff-0d4b-42eb-8651-0e79f1ecc19e,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-7759d679-e90d-4cfd-87be-648a64b09830,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-cf923ac1-5a38-4c79-afaf-acbe3fa5529d,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-c8130368-5607-424a-a3f7-4af77c73a844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078019509-172.17.0.20-1595841757677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39297,DS-59c47e1e-4640-4010-b712-95433da17ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-d0a72a7a-a83b-47a3-b451-73847b1b067a,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-8ab8aea5-1152-4153-9a78-5fd52bd10c77,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-28031592-163f-415c-87d1-f44d68c45ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-e358eeff-0d4b-42eb-8651-0e79f1ecc19e,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-7759d679-e90d-4cfd-87be-648a64b09830,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-cf923ac1-5a38-4c79-afaf-acbe3fa5529d,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-c8130368-5607-424a-a3f7-4af77c73a844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-250361793-172.17.0.20-1595842550942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43392,DS-316e026b-66c6-4d87-84e0-8644d5c4f112,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-dfb86fe3-84a2-40b2-aad0-22fa6ea72562,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-40f419e1-1f48-4975-aecc-773425ac92aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-d4607adc-4b8b-490c-9e40-c8334a2ec473,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-d3c96cfc-acca-4120-8f87-cb1670c33970,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-a3638d78-732c-485c-a319-08a9fab3b167,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-4245a518-e4de-4abb-8133-36f40d1ba8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-413b103f-acf9-4afe-bea3-3e96d3ce8d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-250361793-172.17.0.20-1595842550942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43392,DS-316e026b-66c6-4d87-84e0-8644d5c4f112,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-dfb86fe3-84a2-40b2-aad0-22fa6ea72562,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-40f419e1-1f48-4975-aecc-773425ac92aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-d4607adc-4b8b-490c-9e40-c8334a2ec473,DISK], DatanodeInfoWithStorage[127.0.0.1:40059,DS-d3c96cfc-acca-4120-8f87-cb1670c33970,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-a3638d78-732c-485c-a319-08a9fab3b167,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-4245a518-e4de-4abb-8133-36f40d1ba8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-413b103f-acf9-4afe-bea3-3e96d3ce8d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1949465623-172.17.0.20-1595843267413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42700,DS-b80498ca-6d19-45b4-a466-f931298813c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-1b3969b2-af5b-4be9-b8c3-8407bd80ac3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-b3995648-d329-4561-8973-61a64956d7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-9ae6b95e-3ae2-49fa-a57c-1bd49f17ce3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-4dc690fe-76bc-423c-9b90-1cdedfe053d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-41a26243-bfaa-4672-a0db-8ed4e3b71b79,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-2cd4334f-7b7f-4541-9095-1f4bf0c21cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-e2f5961f-9e53-435f-ba3c-7630154f2fdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1949465623-172.17.0.20-1595843267413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42700,DS-b80498ca-6d19-45b4-a466-f931298813c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-1b3969b2-af5b-4be9-b8c3-8407bd80ac3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-b3995648-d329-4561-8973-61a64956d7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-9ae6b95e-3ae2-49fa-a57c-1bd49f17ce3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-4dc690fe-76bc-423c-9b90-1cdedfe053d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-41a26243-bfaa-4672-a0db-8ed4e3b71b79,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-2cd4334f-7b7f-4541-9095-1f4bf0c21cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-e2f5961f-9e53-435f-ba3c-7630154f2fdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456637309-172.17.0.20-1595843503265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37246,DS-a6cc63e4-89d9-496f-8d25-fb96d9b15e32,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-674f947f-3588-410a-b88f-dc71c02b9938,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-e1fab425-89f2-4611-9a83-b3fcb9b5cbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-0ce2745d-d52e-49be-98b4-58b48b283852,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-b3dac675-5de2-46c6-a233-5fbd52a3e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-56874a5f-b165-4d83-8946-0b0405f5cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-cfc10db8-e4af-4a6a-a2e0-2f48dc098569,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-1f722b72-2a07-4742-9245-139cd2feb960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456637309-172.17.0.20-1595843503265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37246,DS-a6cc63e4-89d9-496f-8d25-fb96d9b15e32,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-674f947f-3588-410a-b88f-dc71c02b9938,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-e1fab425-89f2-4611-9a83-b3fcb9b5cbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-0ce2745d-d52e-49be-98b4-58b48b283852,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-b3dac675-5de2-46c6-a233-5fbd52a3e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-56874a5f-b165-4d83-8946-0b0405f5cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-cfc10db8-e4af-4a6a-a2e0-2f48dc098569,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-1f722b72-2a07-4742-9245-139cd2feb960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1481692281-172.17.0.20-1595843975315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38563,DS-812c27bf-198b-482d-9f21-ad77b7c71b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-70fbe96c-4933-47d0-be0d-24f0f0f71e05,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-8b2539a0-bbe9-4a06-b741-cc9c716e54b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-2bbe5217-4e1e-47e6-93cf-ca924e9aff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-a4c450e8-35c4-4ec2-aa50-a47ff8cb41f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-af905f2e-2ac8-4205-993b-5f8dcc9c8fff,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-bca85160-36af-44cb-b8a9-45841f22bd54,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-d09696c2-c67d-4b37-b2c0-b9809af8c8df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1481692281-172.17.0.20-1595843975315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38563,DS-812c27bf-198b-482d-9f21-ad77b7c71b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-70fbe96c-4933-47d0-be0d-24f0f0f71e05,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-8b2539a0-bbe9-4a06-b741-cc9c716e54b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-2bbe5217-4e1e-47e6-93cf-ca924e9aff4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-a4c450e8-35c4-4ec2-aa50-a47ff8cb41f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-af905f2e-2ac8-4205-993b-5f8dcc9c8fff,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-bca85160-36af-44cb-b8a9-45841f22bd54,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-d09696c2-c67d-4b37-b2c0-b9809af8c8df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374870718-172.17.0.20-1595844490788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38348,DS-1d068689-ec5a-4fa9-807b-ad7494ff0583,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-4ad47211-3d13-4a4c-9885-cd75b546adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-69505eaf-90b7-433a-b443-fc326519f619,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-9f77e7a3-c2dc-4866-8999-6a183dde99a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-7c7d931e-1664-441b-9a81-5a3fe2c60e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-55c2a7ca-1494-41ad-a89d-92ed5558697f,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-5091a41b-23e6-4404-b14b-471a1ce6387b,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-fc4495d4-b04a-48c4-9da9-ea7c783ed460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374870718-172.17.0.20-1595844490788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38348,DS-1d068689-ec5a-4fa9-807b-ad7494ff0583,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-4ad47211-3d13-4a4c-9885-cd75b546adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-69505eaf-90b7-433a-b443-fc326519f619,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-9f77e7a3-c2dc-4866-8999-6a183dde99a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-7c7d931e-1664-441b-9a81-5a3fe2c60e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-55c2a7ca-1494-41ad-a89d-92ed5558697f,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-5091a41b-23e6-4404-b14b-471a1ce6387b,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-fc4495d4-b04a-48c4-9da9-ea7c783ed460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 32
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885665817-172.17.0.20-1595845805846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40907,DS-c66a64b8-b4ba-4a9b-9d4c-2a11b2b68ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-4e592047-978f-4b1a-831a-56e24a26120c,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-a9d6ea2a-b404-44e9-9378-2021b3d7ccf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-ac12d5e0-3961-4a74-985e-bb454d30115c,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-608a1ea6-32a2-4032-960a-fad5f5931b56,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-aed1ea28-61c3-4492-8b52-ebccd6079fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-69c4780e-bc5f-46ed-8327-9a4f26808af0,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-b34a2620-a52c-485c-b2c0-79b823dc7af3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885665817-172.17.0.20-1595845805846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40907,DS-c66a64b8-b4ba-4a9b-9d4c-2a11b2b68ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-4e592047-978f-4b1a-831a-56e24a26120c,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-a9d6ea2a-b404-44e9-9378-2021b3d7ccf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-ac12d5e0-3961-4a74-985e-bb454d30115c,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-608a1ea6-32a2-4032-960a-fad5f5931b56,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-aed1ea28-61c3-4492-8b52-ebccd6079fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-69c4780e-bc5f-46ed-8327-9a4f26808af0,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-b34a2620-a52c-485c-b2c0-79b823dc7af3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 5162
