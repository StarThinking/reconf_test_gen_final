reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175733500-172.17.0.13-1595850384583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33469,DS-5280a0c6-00a1-4eed-8138-f0ce6c42ea83,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-304029e8-fd2c-43b9-9af9-6579f7884d55,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-ee49a00a-7a94-4c14-b2f3-21759f04a5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-ec0a1c04-d4ac-42a4-88e9-1950059ecd26,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-50bc365e-a5b0-4e4f-b32f-cdeb4a48da08,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-29fe1ef7-fbf2-4941-84f5-6806fbcb3e77,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-1dc8dd52-f33c-4f6f-a251-4a0545c04f67,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-fd281c58-93f9-4fc3-a9f2-b652c75faaf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1175733500-172.17.0.13-1595850384583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33469,DS-5280a0c6-00a1-4eed-8138-f0ce6c42ea83,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-304029e8-fd2c-43b9-9af9-6579f7884d55,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-ee49a00a-7a94-4c14-b2f3-21759f04a5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43858,DS-ec0a1c04-d4ac-42a4-88e9-1950059ecd26,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-50bc365e-a5b0-4e4f-b32f-cdeb4a48da08,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-29fe1ef7-fbf2-4941-84f5-6806fbcb3e77,DISK], DatanodeInfoWithStorage[127.0.0.1:38794,DS-1dc8dd52-f33c-4f6f-a251-4a0545c04f67,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-fd281c58-93f9-4fc3-a9f2-b652c75faaf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578724103-172.17.0.13-1595850523689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37417,DS-3f81a115-ea06-4f40-8e2b-a879cff2c41a,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-2458e54d-1b73-4fda-a2ba-a98462e7630c,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-a6f78845-4f85-4add-ab59-a5946262651d,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-1529825b-27f3-46e8-bf26-c0f3392dc55b,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-d0e14fa6-ecc5-42a2-9c10-20893600be9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-cd4bc824-80d6-4b92-999a-1fb50656a7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-9810a4f1-9474-4858-ae5e-07e1a419be35,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-7455a5ab-86e3-4382-bd06-ffcdcd62f79f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578724103-172.17.0.13-1595850523689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37417,DS-3f81a115-ea06-4f40-8e2b-a879cff2c41a,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-2458e54d-1b73-4fda-a2ba-a98462e7630c,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-a6f78845-4f85-4add-ab59-a5946262651d,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-1529825b-27f3-46e8-bf26-c0f3392dc55b,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-d0e14fa6-ecc5-42a2-9c10-20893600be9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-cd4bc824-80d6-4b92-999a-1fb50656a7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-9810a4f1-9474-4858-ae5e-07e1a419be35,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-7455a5ab-86e3-4382-bd06-ffcdcd62f79f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86260891-172.17.0.13-1595850555695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37817,DS-6e4146f8-0f6f-419f-ab14-406af0c22900,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-d370ce07-a333-4641-9ece-4694b2b9ee8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-45c186e6-83ce-4e34-ab52-bf5db4ea1177,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-befc9431-8ee9-4ec0-802a-7a06b743ccb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-c1ac1576-bd9b-49cf-8c53-c230c3b8a44c,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-38c294e6-faa9-4dd9-bc22-25c688888e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-dd8a62da-6537-487b-9545-fae7d6b3c5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-8faebdc5-e60b-4f55-a8fb-187d129df699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86260891-172.17.0.13-1595850555695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37817,DS-6e4146f8-0f6f-419f-ab14-406af0c22900,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-d370ce07-a333-4641-9ece-4694b2b9ee8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-45c186e6-83ce-4e34-ab52-bf5db4ea1177,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-befc9431-8ee9-4ec0-802a-7a06b743ccb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-c1ac1576-bd9b-49cf-8c53-c230c3b8a44c,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-38c294e6-faa9-4dd9-bc22-25c688888e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-dd8a62da-6537-487b-9545-fae7d6b3c5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-8faebdc5-e60b-4f55-a8fb-187d129df699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342579857-172.17.0.13-1595850598646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-089c3d7a-b9e1-4003-8d0f-5331669671f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-6af787b0-c5a0-4f90-b54c-da27e58ca7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-b97c2598-49d7-45cd-926d-de950acc14ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-0fc51187-aa85-44f5-adc2-5af66864bcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-33a495a1-23d5-4d4c-91e8-9081a67b67e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-3e3a7583-fa92-44c8-9fee-8e60cae5014a,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-0f2f9740-b882-43a5-b4de-69f4809137e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-35f030d9-ef9c-47c5-be83-376f811d7c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342579857-172.17.0.13-1595850598646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40657,DS-089c3d7a-b9e1-4003-8d0f-5331669671f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-6af787b0-c5a0-4f90-b54c-da27e58ca7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-b97c2598-49d7-45cd-926d-de950acc14ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-0fc51187-aa85-44f5-adc2-5af66864bcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-33a495a1-23d5-4d4c-91e8-9081a67b67e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-3e3a7583-fa92-44c8-9fee-8e60cae5014a,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-0f2f9740-b882-43a5-b4de-69f4809137e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-35f030d9-ef9c-47c5-be83-376f811d7c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233809974-172.17.0.13-1595851097762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34467,DS-7717972d-4af7-452f-a79c-b7f0ce533fac,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-96c7b556-460d-4a8e-9cbd-d4ea96bf80bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-27e0b75a-2bd1-4c45-ab35-7145a8ab88c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-de1785a8-593b-42c5-af0e-33432fd25a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-8c57c71b-9c7d-4591-942c-52c765d2e3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-7a0e5141-ddb0-490f-9c3d-ab38d01c3346,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-2deec7eb-cb62-4c00-9684-bda2a2eff866,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-91d4c143-5b91-4405-8c6f-3c3b64e96d83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1233809974-172.17.0.13-1595851097762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34467,DS-7717972d-4af7-452f-a79c-b7f0ce533fac,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-96c7b556-460d-4a8e-9cbd-d4ea96bf80bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-27e0b75a-2bd1-4c45-ab35-7145a8ab88c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-de1785a8-593b-42c5-af0e-33432fd25a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-8c57c71b-9c7d-4591-942c-52c765d2e3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-7a0e5141-ddb0-490f-9c3d-ab38d01c3346,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-2deec7eb-cb62-4c00-9684-bda2a2eff866,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-91d4c143-5b91-4405-8c6f-3c3b64e96d83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950776923-172.17.0.13-1595851509112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33216,DS-be77e4dd-12f8-4074-be5e-c018c9a4e93e,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-233bca58-4828-4448-8648-c467e66205c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-38f9fe3e-481d-4242-9cee-caf556730c48,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-5a0ada0c-31ab-4a16-b91f-aad1b9a88a60,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-63b892ff-ca6a-4380-a2b9-684fb3180427,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-2773401f-231e-4fd0-9314-4385d57d86ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-bde0a48d-53a4-455c-af8d-4154f831bdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-d3c9f17e-3a42-4c40-94fa-3104bdbce47b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950776923-172.17.0.13-1595851509112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33216,DS-be77e4dd-12f8-4074-be5e-c018c9a4e93e,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-233bca58-4828-4448-8648-c467e66205c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-38f9fe3e-481d-4242-9cee-caf556730c48,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-5a0ada0c-31ab-4a16-b91f-aad1b9a88a60,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-63b892ff-ca6a-4380-a2b9-684fb3180427,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-2773401f-231e-4fd0-9314-4385d57d86ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-bde0a48d-53a4-455c-af8d-4154f831bdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-d3c9f17e-3a42-4c40-94fa-3104bdbce47b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836670798-172.17.0.13-1595851545218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42678,DS-388b443b-61eb-48f6-a013-8e7dd859610b,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-c8042b22-a717-4215-8f82-ba3aad5bb00c,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-4308db58-bb2d-4f09-986e-703901763578,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-dde30e5a-c098-42eb-8064-5f87fb9eb96b,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-bf787c44-70c0-4735-ba70-b72ccce1649a,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-3593d19d-519b-4f8a-847b-48b8296709ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-1fe99fd1-5396-4e45-8897-9a5cf4ca3d34,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-706ccb60-7868-4aa3-92dc-678d2875f108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836670798-172.17.0.13-1595851545218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42678,DS-388b443b-61eb-48f6-a013-8e7dd859610b,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-c8042b22-a717-4215-8f82-ba3aad5bb00c,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-4308db58-bb2d-4f09-986e-703901763578,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-dde30e5a-c098-42eb-8064-5f87fb9eb96b,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-bf787c44-70c0-4735-ba70-b72ccce1649a,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-3593d19d-519b-4f8a-847b-48b8296709ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-1fe99fd1-5396-4e45-8897-9a5cf4ca3d34,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-706ccb60-7868-4aa3-92dc-678d2875f108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777323963-172.17.0.13-1595851861672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34098,DS-3884cd64-38bb-4362-8a68-88a990181a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-afc4abda-a85e-4484-9965-445ffbb5a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-c636640c-9ad1-46a5-9b60-4ff55c081e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-da36ecc0-97c7-4f60-b2e3-d48ad63de492,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-1220865c-ac4b-4ab6-8857-b411601f6e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-d7fc8f43-c8e6-490d-9a2f-1a8db995cdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-fa912d42-3a39-4faf-b4f8-e8c5994fddee,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-538a4259-f281-479a-baf1-2965c41a1af4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-777323963-172.17.0.13-1595851861672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34098,DS-3884cd64-38bb-4362-8a68-88a990181a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-afc4abda-a85e-4484-9965-445ffbb5a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-c636640c-9ad1-46a5-9b60-4ff55c081e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-da36ecc0-97c7-4f60-b2e3-d48ad63de492,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-1220865c-ac4b-4ab6-8857-b411601f6e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-d7fc8f43-c8e6-490d-9a2f-1a8db995cdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-fa912d42-3a39-4faf-b4f8-e8c5994fddee,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-538a4259-f281-479a-baf1-2965c41a1af4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856187090-172.17.0.13-1595851983181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40084,DS-6cb69166-deac-4c3b-a161-5b302c4d9710,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-be5a0ba6-6816-4d17-8f8a-9a582008251a,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-db064257-3b6b-4bb0-97c0-106461328065,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-2c533c5b-7e8d-46cc-b0cc-a7b97f4e17bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-d1580eb0-b696-4044-89a7-5f9bf304f708,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-cf561636-0470-4982-8455-caa945ed8b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-e3eeada2-0681-45a9-8435-1a2f81d9e95f,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-8b3df79f-7bc8-49c7-828c-8c09e8066aca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-856187090-172.17.0.13-1595851983181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40084,DS-6cb69166-deac-4c3b-a161-5b302c4d9710,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-be5a0ba6-6816-4d17-8f8a-9a582008251a,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-db064257-3b6b-4bb0-97c0-106461328065,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-2c533c5b-7e8d-46cc-b0cc-a7b97f4e17bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-d1580eb0-b696-4044-89a7-5f9bf304f708,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-cf561636-0470-4982-8455-caa945ed8b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-e3eeada2-0681-45a9-8435-1a2f81d9e95f,DISK], DatanodeInfoWithStorage[127.0.0.1:35474,DS-8b3df79f-7bc8-49c7-828c-8c09e8066aca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510186757-172.17.0.13-1595852063920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-2f7c216d-61a0-40d2-bf52-0969a7fd2ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-35fc3b07-0d5c-4c7b-aed7-3ecb85fd5ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-61f3b6b1-df4a-4b3b-a10c-d3aa0f744c01,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-e7f1e617-0a73-484e-8d71-e95c499f599c,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-b8947bd3-a1dc-4bd4-b15f-7e43fa8bce08,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-fe578360-6774-4843-a8cf-9c3b342499ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-28bd1879-d4aa-4f15-a280-ad27b118bc60,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-91538d44-a904-4fc6-b58b-39d2ef7db5ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510186757-172.17.0.13-1595852063920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-2f7c216d-61a0-40d2-bf52-0969a7fd2ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-35fc3b07-0d5c-4c7b-aed7-3ecb85fd5ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-61f3b6b1-df4a-4b3b-a10c-d3aa0f744c01,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-e7f1e617-0a73-484e-8d71-e95c499f599c,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-b8947bd3-a1dc-4bd4-b15f-7e43fa8bce08,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-fe578360-6774-4843-a8cf-9c3b342499ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-28bd1879-d4aa-4f15-a280-ad27b118bc60,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-91538d44-a904-4fc6-b58b-39d2ef7db5ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033237077-172.17.0.13-1595852296950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40553,DS-aab1ace5-4160-4b7b-9922-7e74bd6f99e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-c56a6d0a-06c0-4d1a-8d01-ea6357bb17e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-855cab7f-6464-4e63-aba5-0f39ee0908c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-802a7f01-2e6e-457c-92c2-5010eb46d1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-3d003e6e-e7ef-4bc8-ab96-46e033a99ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-1d3da61b-06ac-4262-8f58-39f73ebce57e,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-1f93d42d-7d48-40b9-8c66-d830bfbe35c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-44f5f2dd-846f-45a5-a206-5b3f6a6a25b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033237077-172.17.0.13-1595852296950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40553,DS-aab1ace5-4160-4b7b-9922-7e74bd6f99e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-c56a6d0a-06c0-4d1a-8d01-ea6357bb17e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-855cab7f-6464-4e63-aba5-0f39ee0908c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39563,DS-802a7f01-2e6e-457c-92c2-5010eb46d1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-3d003e6e-e7ef-4bc8-ab96-46e033a99ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-1d3da61b-06ac-4262-8f58-39f73ebce57e,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-1f93d42d-7d48-40b9-8c66-d830bfbe35c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-44f5f2dd-846f-45a5-a206-5b3f6a6a25b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10660457-172.17.0.13-1595852375912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36314,DS-9ef4f1c2-3d86-487a-bb99-5201795e5db0,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-d2e919f3-6b13-42e8-a398-75faa198e0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-a6f06bbd-0e15-4b3f-aebd-e7d6b24e23a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-2563c06b-05bb-4712-92a0-df6159545556,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-764c2dda-1713-4059-88a9-8d4f1dc9f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-aa12ca4b-6343-4b7b-b659-f36f5b32b9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-18ee0f68-5efb-4006-b4c0-7cb8eacdf390,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-eac50d78-f0ce-4d04-bd42-023ef11abc27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10660457-172.17.0.13-1595852375912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36314,DS-9ef4f1c2-3d86-487a-bb99-5201795e5db0,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-d2e919f3-6b13-42e8-a398-75faa198e0d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-a6f06bbd-0e15-4b3f-aebd-e7d6b24e23a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-2563c06b-05bb-4712-92a0-df6159545556,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-764c2dda-1713-4059-88a9-8d4f1dc9f4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-aa12ca4b-6343-4b7b-b659-f36f5b32b9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-18ee0f68-5efb-4006-b4c0-7cb8eacdf390,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-eac50d78-f0ce-4d04-bd42-023ef11abc27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677565498-172.17.0.13-1595852411389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43964,DS-74aeee87-ce38-4404-9c24-5fdaffe9442e,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-ee70d70a-b06c-4fe8-be25-f84e6d261eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-54abc7ec-663b-4082-b741-99d808d9a8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-cfbac757-5b73-4bc5-a8e8-560d26f00994,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-991e9e4a-bc74-4be8-b98e-a52096c758de,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-c33b256f-b174-4ace-aa7a-03c404814297,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-7fe80543-0c8b-42a9-9002-b2a028380484,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-0d4b3fab-396c-4fb7-86c8-9ee7434582c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677565498-172.17.0.13-1595852411389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43964,DS-74aeee87-ce38-4404-9c24-5fdaffe9442e,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-ee70d70a-b06c-4fe8-be25-f84e6d261eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-54abc7ec-663b-4082-b741-99d808d9a8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-cfbac757-5b73-4bc5-a8e8-560d26f00994,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-991e9e4a-bc74-4be8-b98e-a52096c758de,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-c33b256f-b174-4ace-aa7a-03c404814297,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-7fe80543-0c8b-42a9-9002-b2a028380484,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-0d4b3fab-396c-4fb7-86c8-9ee7434582c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169701858-172.17.0.13-1595852584722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34054,DS-8c62e057-6594-43f6-b224-a5012c0509f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-f68a1770-3860-4ba5-a067-90df9db7be87,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-d8d5fad3-c100-4efe-a631-f83fe1065188,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-38278d15-58df-48f5-a809-ae499bf37c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-c8fb4c49-ed01-45c0-bc8c-5d42d9a11a34,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-d0df930a-f504-4ae3-b5ab-67f3a6745a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-45722a19-8382-43cb-be79-06581f1994e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-69e1d070-28ab-4423-8ca5-ace0a7e479cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169701858-172.17.0.13-1595852584722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34054,DS-8c62e057-6594-43f6-b224-a5012c0509f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-f68a1770-3860-4ba5-a067-90df9db7be87,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-d8d5fad3-c100-4efe-a631-f83fe1065188,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-38278d15-58df-48f5-a809-ae499bf37c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-c8fb4c49-ed01-45c0-bc8c-5d42d9a11a34,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-d0df930a-f504-4ae3-b5ab-67f3a6745a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-45722a19-8382-43cb-be79-06581f1994e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-69e1d070-28ab-4423-8ca5-ace0a7e479cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175252994-172.17.0.13-1595852913881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41252,DS-99912232-ddd1-4902-9ba9-4717d6bf62b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-10250b7d-85e0-470a-a136-48f12af90d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-a5a2fe47-cef3-45bc-996a-cac859e045c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-fc327271-2480-4a75-9ea7-6ac41299febb,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-b295bda4-fd45-49c5-84a1-0e2e78d3cdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-9bb5cfde-fa73-47d8-a82d-601b8aa76c00,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-8a71e324-b878-44da-a05a-c4b303ae29f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-5ff0f1f4-2168-4038-9b04-56fe5df52399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175252994-172.17.0.13-1595852913881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41252,DS-99912232-ddd1-4902-9ba9-4717d6bf62b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-10250b7d-85e0-470a-a136-48f12af90d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-a5a2fe47-cef3-45bc-996a-cac859e045c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-fc327271-2480-4a75-9ea7-6ac41299febb,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-b295bda4-fd45-49c5-84a1-0e2e78d3cdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-9bb5cfde-fa73-47d8-a82d-601b8aa76c00,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-8a71e324-b878-44da-a05a-c4b303ae29f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-5ff0f1f4-2168-4038-9b04-56fe5df52399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246423892-172.17.0.13-1595853160634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-8282e138-b0ef-43f2-92cf-3cbf0724d062,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-2400def4-8d86-4a3c-98d4-a8a63a036e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-b0a56ed6-cac9-41a1-b234-361be71f54fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-5de47d45-638f-4f1d-a2fd-ae4125547538,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-77d14a46-f285-4ed5-9cea-ff1fc47e6e86,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-2a455c2a-2841-4d06-945e-f2c8f1e23f02,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-fe10c761-2586-4b8e-8156-8ed7a65c6a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-2beebab7-1b19-4895-8f57-f06bb3ea8b16,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246423892-172.17.0.13-1595853160634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-8282e138-b0ef-43f2-92cf-3cbf0724d062,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-2400def4-8d86-4a3c-98d4-a8a63a036e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-b0a56ed6-cac9-41a1-b234-361be71f54fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-5de47d45-638f-4f1d-a2fd-ae4125547538,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-77d14a46-f285-4ed5-9cea-ff1fc47e6e86,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-2a455c2a-2841-4d06-945e-f2c8f1e23f02,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-fe10c761-2586-4b8e-8156-8ed7a65c6a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-2beebab7-1b19-4895-8f57-f06bb3ea8b16,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936842328-172.17.0.13-1595853617261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37135,DS-5c051160-b2b1-4578-9ce8-3e0bc8c5c7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-8ebcc1d0-6895-4ed2-b8d7-cf776e26877a,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-28280b82-565d-497e-8668-8d26b7031379,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-178f1fc2-4ff4-43ba-80cb-a0cfaa6bdf82,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-83c2567f-772a-4377-907e-b4648e67062c,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-92d78d07-3816-4ca0-9c2f-d17036c9d6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-535c4db6-f9f1-4408-8bc1-6178633093b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-51389f11-8970-4e96-a95c-1b60953a4d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936842328-172.17.0.13-1595853617261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37135,DS-5c051160-b2b1-4578-9ce8-3e0bc8c5c7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-8ebcc1d0-6895-4ed2-b8d7-cf776e26877a,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-28280b82-565d-497e-8668-8d26b7031379,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-178f1fc2-4ff4-43ba-80cb-a0cfaa6bdf82,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-83c2567f-772a-4377-907e-b4648e67062c,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-92d78d07-3816-4ca0-9c2f-d17036c9d6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-535c4db6-f9f1-4408-8bc1-6178633093b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-51389f11-8970-4e96-a95c-1b60953a4d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148811881-172.17.0.13-1595853668527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33191,DS-d64b6e21-d94a-4e39-849e-8ed075cf7f87,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-04ddb931-cf8b-4c11-abe3-de43ad884c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-b635ff6c-047a-4d3f-a672-6397f6eaab0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-edac3fd8-e02d-49af-8744-56ad85fa031b,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-bde62682-fc4d-45c9-8231-11b7957ea019,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-da3e77cf-d04f-43a8-b1ab-316c9030a0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-efbc6464-25db-48c8-bc5d-d012844b3337,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-d86f6329-a91b-4173-a372-29b7a7b5fa90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148811881-172.17.0.13-1595853668527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33191,DS-d64b6e21-d94a-4e39-849e-8ed075cf7f87,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-04ddb931-cf8b-4c11-abe3-de43ad884c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-b635ff6c-047a-4d3f-a672-6397f6eaab0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-edac3fd8-e02d-49af-8744-56ad85fa031b,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-bde62682-fc4d-45c9-8231-11b7957ea019,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-da3e77cf-d04f-43a8-b1ab-316c9030a0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-efbc6464-25db-48c8-bc5d-d012844b3337,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-d86f6329-a91b-4173-a372-29b7a7b5fa90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645788136-172.17.0.13-1595854098141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46269,DS-94e9cb54-2e20-4996-a146-a62603335a44,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-ea13ea75-d531-4a0c-a3d5-c438c1f7c7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-8f60b654-4cf1-4964-bf74-fc5c1cadf509,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-5dfcdbdc-c634-49af-b5fe-5355cb9977d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-293511c2-be97-4a31-88bf-ddc91cf90f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-1ae938c3-1b8f-45fd-b46d-56ecfd6aad04,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-9fdfabd5-de30-4504-ba5d-51f0227c1ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-2586a3f1-07e5-40b6-b21b-bbe12f76bd0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645788136-172.17.0.13-1595854098141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46269,DS-94e9cb54-2e20-4996-a146-a62603335a44,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-ea13ea75-d531-4a0c-a3d5-c438c1f7c7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-8f60b654-4cf1-4964-bf74-fc5c1cadf509,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-5dfcdbdc-c634-49af-b5fe-5355cb9977d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-293511c2-be97-4a31-88bf-ddc91cf90f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-1ae938c3-1b8f-45fd-b46d-56ecfd6aad04,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-9fdfabd5-de30-4504-ba5d-51f0227c1ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-2586a3f1-07e5-40b6-b21b-bbe12f76bd0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959359301-172.17.0.13-1595854533836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33790,DS-f24051f4-b77f-48bc-86c5-3adc8fa1ab70,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-3514659a-69f9-4c32-be90-7588ba820ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-eb0db88e-d086-41a6-914d-0d3d2042e4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-636fab95-3627-48b8-9460-80df72b6e8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-db5c4d44-038e-4a5d-b94a-cd5d1dbad5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-ed01eeb1-9609-47c1-8916-c2880d45f005,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-3185aa29-397b-4685-b277-c63144ac39d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-d285b5e9-1bd9-4aa4-ab91-8fdaf21b1d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959359301-172.17.0.13-1595854533836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33790,DS-f24051f4-b77f-48bc-86c5-3adc8fa1ab70,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-3514659a-69f9-4c32-be90-7588ba820ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-eb0db88e-d086-41a6-914d-0d3d2042e4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-636fab95-3627-48b8-9460-80df72b6e8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-db5c4d44-038e-4a5d-b94a-cd5d1dbad5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-ed01eeb1-9609-47c1-8916-c2880d45f005,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-3185aa29-397b-4685-b277-c63144ac39d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-d285b5e9-1bd9-4aa4-ab91-8fdaf21b1d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993401877-172.17.0.13-1595854580712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44417,DS-3a896608-d4d6-45a9-a5ba-7a092fae29d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-6cd9ad28-bdbb-4ee6-b2c4-1708f4965829,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-606938a3-1c1e-4c5b-8c0d-6e4d4fba66b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-e55c1d8a-7eb9-41d5-9f7b-395c4ccb30a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-200788d5-54b4-4f2e-bd4c-7f723ffce635,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-bd106fab-3919-48e6-bc31-8acd8f0b17cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-d3336c32-5e61-4b37-877a-ce85fbfc3f78,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-693bb617-8db6-412b-a306-23b7c046e835,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993401877-172.17.0.13-1595854580712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44417,DS-3a896608-d4d6-45a9-a5ba-7a092fae29d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-6cd9ad28-bdbb-4ee6-b2c4-1708f4965829,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-606938a3-1c1e-4c5b-8c0d-6e4d4fba66b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-e55c1d8a-7eb9-41d5-9f7b-395c4ccb30a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-200788d5-54b4-4f2e-bd4c-7f723ffce635,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-bd106fab-3919-48e6-bc31-8acd8f0b17cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-d3336c32-5e61-4b37-877a-ce85fbfc3f78,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-693bb617-8db6-412b-a306-23b7c046e835,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155487025-172.17.0.13-1595855101871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45556,DS-8457802c-029b-40ae-91e8-d0ea8a22b176,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-4a523691-8bf9-41c4-a8e7-b3b3044bf899,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-358c2af0-89f2-4182-9ec1-22254da0c691,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-4c668323-890e-44ec-bcab-bc14d36ab358,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-b666e2a0-d996-4fe6-bff2-cb548cc48d77,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-06c743e3-d357-4df2-bb85-563fff2990eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-fd15d5c2-7bac-4e1b-9eb6-1c6d91ae8306,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-34bbd0c5-7c1c-4fc5-98c7-57ea821fbe1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155487025-172.17.0.13-1595855101871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45556,DS-8457802c-029b-40ae-91e8-d0ea8a22b176,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-4a523691-8bf9-41c4-a8e7-b3b3044bf899,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-358c2af0-89f2-4182-9ec1-22254da0c691,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-4c668323-890e-44ec-bcab-bc14d36ab358,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-b666e2a0-d996-4fe6-bff2-cb548cc48d77,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-06c743e3-d357-4df2-bb85-563fff2990eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-fd15d5c2-7bac-4e1b-9eb6-1c6d91ae8306,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-34bbd0c5-7c1c-4fc5-98c7-57ea821fbe1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72170338-172.17.0.13-1595855150707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41497,DS-771179f4-6209-43e5-8490-03cadacdaabf,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-578337ee-4b0c-4858-9a0b-f6ca6c21bffb,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-23282195-11a7-45ad-aab1-7f1484288c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-ec4c182f-dd36-4332-bb65-ecc25b670365,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-03006127-f8d7-4fe4-b86d-77e12b164cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-c6151960-022b-44f8-be00-7be0f1915eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-4c51c44c-0864-425d-8dac-60701aec2f40,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-ad0a7438-0f01-4015-9618-17b05bc6ce74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72170338-172.17.0.13-1595855150707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41497,DS-771179f4-6209-43e5-8490-03cadacdaabf,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-578337ee-4b0c-4858-9a0b-f6ca6c21bffb,DISK], DatanodeInfoWithStorage[127.0.0.1:46120,DS-23282195-11a7-45ad-aab1-7f1484288c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-ec4c182f-dd36-4332-bb65-ecc25b670365,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-03006127-f8d7-4fe4-b86d-77e12b164cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-c6151960-022b-44f8-be00-7be0f1915eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-4c51c44c-0864-425d-8dac-60701aec2f40,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-ad0a7438-0f01-4015-9618-17b05bc6ce74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579391602-172.17.0.13-1595855237868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46475,DS-a2506a58-d91c-447d-ba86-6151b1cc076d,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-90e296c9-05f8-4625-b5af-ca1b7d9b95ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-56184a8b-6fb7-4c20-875b-0ec5bacf0a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-1033f8f9-b835-410e-82a1-dc891fd25511,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-434e49bb-fa87-4255-bc45-18ac3e6167f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-4180da37-b779-49d9-b464-8c82147eff42,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-186f47f8-5722-4e3a-999c-899566dfa76f,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-7646ffa7-bd4d-4127-ad02-65563248e2f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579391602-172.17.0.13-1595855237868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46475,DS-a2506a58-d91c-447d-ba86-6151b1cc076d,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-90e296c9-05f8-4625-b5af-ca1b7d9b95ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-56184a8b-6fb7-4c20-875b-0ec5bacf0a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-1033f8f9-b835-410e-82a1-dc891fd25511,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-434e49bb-fa87-4255-bc45-18ac3e6167f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-4180da37-b779-49d9-b464-8c82147eff42,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-186f47f8-5722-4e3a-999c-899566dfa76f,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-7646ffa7-bd4d-4127-ad02-65563248e2f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193379437-172.17.0.13-1595855293458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38786,DS-34954584-aa28-4cfe-95f3-fb6859668c30,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-0c2031f5-1231-4c07-92dc-ee0b6e6f914e,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-2a6ee0e2-9788-412c-ba05-e067365487cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-c575d06d-56d5-4f60-9323-c62d4af830ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-8ed21597-c215-47d5-94f7-1302a81d7137,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-b0cbf287-700a-4c78-baf2-b10394eadd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-5157fe6f-2fdb-41e2-a281-6c883dc31848,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-29db062a-ff44-4e80-9e79-1c84e9e79e45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193379437-172.17.0.13-1595855293458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38786,DS-34954584-aa28-4cfe-95f3-fb6859668c30,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-0c2031f5-1231-4c07-92dc-ee0b6e6f914e,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-2a6ee0e2-9788-412c-ba05-e067365487cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-c575d06d-56d5-4f60-9323-c62d4af830ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-8ed21597-c215-47d5-94f7-1302a81d7137,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-b0cbf287-700a-4c78-baf2-b10394eadd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-5157fe6f-2fdb-41e2-a281-6c883dc31848,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-29db062a-ff44-4e80-9e79-1c84e9e79e45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002873299-172.17.0.13-1595855623511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-2f81a4f6-331a-4520-bd82-f2323fe0bd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-753b8c26-ba0b-44cc-b463-356ebd4e4afa,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-d9120037-349d-4928-a645-c671d8c617b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-d8650605-72a7-48e7-87c9-f0fe4280c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-97f50ecf-53f5-4561-ab61-7b38e272fcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-c5ac05c3-c954-4561-a801-a9ff33987421,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-6ac51421-06c1-470a-8087-1116086c0352,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-b31f35ab-fdab-44a0-a62f-aabedb8451d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002873299-172.17.0.13-1595855623511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-2f81a4f6-331a-4520-bd82-f2323fe0bd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-753b8c26-ba0b-44cc-b463-356ebd4e4afa,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-d9120037-349d-4928-a645-c671d8c617b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-d8650605-72a7-48e7-87c9-f0fe4280c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-97f50ecf-53f5-4561-ab61-7b38e272fcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-c5ac05c3-c954-4561-a801-a9ff33987421,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-6ac51421-06c1-470a-8087-1116086c0352,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-b31f35ab-fdab-44a0-a62f-aabedb8451d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380262996-172.17.0.13-1595855762550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36725,DS-3b6efd0d-9cb8-41c4-8669-4386b85c16aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-bbdfe857-b351-4ed1-88c2-e1635a917550,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-481eb44c-e2ff-4ca1-bb5e-ffd71677e610,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-3ac5b327-814f-4638-8bd0-0041fa964b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-47838a1e-ced1-4324-8208-4af8b22a987c,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-087179c7-c9e4-4771-bb25-7cc9659260e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-4ad9ae29-3117-4b8c-939d-af77902e80c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-f9cc4d37-391d-4694-91e1-c336c6622163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-380262996-172.17.0.13-1595855762550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36725,DS-3b6efd0d-9cb8-41c4-8669-4386b85c16aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-bbdfe857-b351-4ed1-88c2-e1635a917550,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-481eb44c-e2ff-4ca1-bb5e-ffd71677e610,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-3ac5b327-814f-4638-8bd0-0041fa964b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-47838a1e-ced1-4324-8208-4af8b22a987c,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-087179c7-c9e4-4771-bb25-7cc9659260e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-4ad9ae29-3117-4b8c-939d-af77902e80c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-f9cc4d37-391d-4694-91e1-c336c6622163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956525669-172.17.0.13-1595856022205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-3f360644-31cc-4cd7-840e-6c471a686cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-69878264-1876-41ef-beb1-ca3bf2b4e6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-3f578bcf-756f-4fa7-9828-fe13e8aaf575,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-f7a4c499-1cad-4498-b71f-4dda0f7a0578,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-9b5699d1-a9f0-48cb-bdfb-964946cb4637,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-6508efe2-5965-4018-997d-04117c72c6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-630d096f-a13f-4563-9a92-9f66b98222c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-bea83c2e-ad6f-4f9d-be6e-f50fef9b2f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956525669-172.17.0.13-1595856022205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33436,DS-3f360644-31cc-4cd7-840e-6c471a686cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-69878264-1876-41ef-beb1-ca3bf2b4e6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-3f578bcf-756f-4fa7-9828-fe13e8aaf575,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-f7a4c499-1cad-4498-b71f-4dda0f7a0578,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-9b5699d1-a9f0-48cb-bdfb-964946cb4637,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-6508efe2-5965-4018-997d-04117c72c6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-630d096f-a13f-4563-9a92-9f66b98222c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-bea83c2e-ad6f-4f9d-be6e-f50fef9b2f5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915915125-172.17.0.13-1595856064705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38829,DS-934f5db5-cb5c-4400-9d2d-5ab00a80f513,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-03955a69-8533-4109-95c3-2ad58d2ec787,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-e625f987-4e39-4d99-a21e-22e23440e1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-a408e12d-c7e1-4efb-b605-938f2a491ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-4bcbf22b-2874-421e-a58e-50793ca48f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-1955fd16-6953-45dc-b3e9-77478dd6ab33,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-d1d850a1-049c-40cf-b0e2-56e026807112,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-0c93902d-821f-481c-bed4-13ad43ef2548,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915915125-172.17.0.13-1595856064705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38829,DS-934f5db5-cb5c-4400-9d2d-5ab00a80f513,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-03955a69-8533-4109-95c3-2ad58d2ec787,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-e625f987-4e39-4d99-a21e-22e23440e1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-a408e12d-c7e1-4efb-b605-938f2a491ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-4bcbf22b-2874-421e-a58e-50793ca48f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-1955fd16-6953-45dc-b3e9-77478dd6ab33,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-d1d850a1-049c-40cf-b0e2-56e026807112,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-0c93902d-821f-481c-bed4-13ad43ef2548,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102309882-172.17.0.13-1595856146268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43780,DS-0dea6455-5bdb-4d1e-9037-e878db3fcf47,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-691849e2-e3a3-4c70-91c7-ded18d18eaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-abe8021e-703e-43f6-9627-161b312c2e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-6b45c358-7571-4700-ac11-e47295858095,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-35b5a7ab-1f27-46f5-934b-911c7742e724,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-69705cb2-ba0b-4c28-9b60-8c572e120ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-0644775f-caac-49a4-b257-93aa02ed7b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-d0e690b4-e763-43c3-97f7-cfb9d4169684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102309882-172.17.0.13-1595856146268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43780,DS-0dea6455-5bdb-4d1e-9037-e878db3fcf47,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-691849e2-e3a3-4c70-91c7-ded18d18eaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-abe8021e-703e-43f6-9627-161b312c2e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-6b45c358-7571-4700-ac11-e47295858095,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-35b5a7ab-1f27-46f5-934b-911c7742e724,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-69705cb2-ba0b-4c28-9b60-8c572e120ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-0644775f-caac-49a4-b257-93aa02ed7b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-d0e690b4-e763-43c3-97f7-cfb9d4169684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653412954-172.17.0.13-1595856297217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37570,DS-60c14185-d319-4274-b915-4f8dcbffa4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-7de718cb-643a-40b7-8283-bfd75f752bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-4e932011-2f7b-45c0-82de-e9301f6dd8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-f32f3553-c414-4d83-9f50-421f8fe51d89,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-d81023c6-5a2f-402f-8d0a-b0ee195bab51,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-45a11cd4-5757-4cea-a89a-744c59fcba4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-7576ebf0-d1cc-4cbd-9f98-498c8fa195a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-5a2d0b86-b75e-4d32-803e-75d7af52298b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653412954-172.17.0.13-1595856297217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37570,DS-60c14185-d319-4274-b915-4f8dcbffa4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-7de718cb-643a-40b7-8283-bfd75f752bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-4e932011-2f7b-45c0-82de-e9301f6dd8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-f32f3553-c414-4d83-9f50-421f8fe51d89,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-d81023c6-5a2f-402f-8d0a-b0ee195bab51,DISK], DatanodeInfoWithStorage[127.0.0.1:46117,DS-45a11cd4-5757-4cea-a89a-744c59fcba4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-7576ebf0-d1cc-4cbd-9f98-498c8fa195a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-5a2d0b86-b75e-4d32-803e-75d7af52298b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981936756-172.17.0.13-1595856391447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46638,DS-96459510-024b-4ebe-b36c-c0adad1fad64,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-6e30dae0-2490-48fb-8ae1-dc3d91f20c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-0776a39b-74b7-4a93-b3b7-e2cd3147534b,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-3062aac1-7af1-4d6c-905e-36219009fe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-4c98f383-cd95-4859-a83e-e0abc51142b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-bd13a9a3-ec0e-4b19-8b03-0957d01399b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-de720152-527c-4782-b9e1-27cf618d3332,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-44139680-5f98-4364-ab9d-8c6d717bd8e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981936756-172.17.0.13-1595856391447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46638,DS-96459510-024b-4ebe-b36c-c0adad1fad64,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-6e30dae0-2490-48fb-8ae1-dc3d91f20c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-0776a39b-74b7-4a93-b3b7-e2cd3147534b,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-3062aac1-7af1-4d6c-905e-36219009fe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-4c98f383-cd95-4859-a83e-e0abc51142b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-bd13a9a3-ec0e-4b19-8b03-0957d01399b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-de720152-527c-4782-b9e1-27cf618d3332,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-44139680-5f98-4364-ab9d-8c6d717bd8e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202454583-172.17.0.13-1595856435030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35033,DS-43bdf100-e9d5-4171-bcb3-2335ea6889f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-5787e170-7058-4cf8-a45d-1dcba8920a09,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-27da386b-d8fd-49d1-9c49-0b9143d7a74b,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-1dd8da36-fb43-49a6-855e-dbb3d584347d,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-05349971-fe35-4fbb-b50c-e6374620e352,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-0e37ffe9-6c9e-4753-9fb7-f0fa9b0c386e,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-feaa9b9f-564f-46ed-876c-93eeb1cb2297,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-11b084b3-f0b6-4e12-a1f2-413e2f6e98ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202454583-172.17.0.13-1595856435030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35033,DS-43bdf100-e9d5-4171-bcb3-2335ea6889f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-5787e170-7058-4cf8-a45d-1dcba8920a09,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-27da386b-d8fd-49d1-9c49-0b9143d7a74b,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-1dd8da36-fb43-49a6-855e-dbb3d584347d,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-05349971-fe35-4fbb-b50c-e6374620e352,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-0e37ffe9-6c9e-4753-9fb7-f0fa9b0c386e,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-feaa9b9f-564f-46ed-876c-93eeb1cb2297,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-11b084b3-f0b6-4e12-a1f2-413e2f6e98ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661665398-172.17.0.13-1595856784795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46870,DS-643699be-e05d-4a23-8f81-9f90dc1fb7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-44aa11bc-bf78-414b-a62c-5c7d2b9a171b,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-285c9276-926d-4c56-ad89-fcdd37a523c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-f9d49e58-c2ff-47bc-bc32-120c77474e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-66488780-3f45-42e4-863b-412bdd371453,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-553934e4-bf7b-4054-9d66-6a06d81b2c55,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-c55b4d54-3856-451d-98db-0949194adc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-bb96aaf6-b184-47be-91fa-8f68e97f7b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-661665398-172.17.0.13-1595856784795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46870,DS-643699be-e05d-4a23-8f81-9f90dc1fb7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-44aa11bc-bf78-414b-a62c-5c7d2b9a171b,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-285c9276-926d-4c56-ad89-fcdd37a523c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-f9d49e58-c2ff-47bc-bc32-120c77474e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-66488780-3f45-42e4-863b-412bdd371453,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-553934e4-bf7b-4054-9d66-6a06d81b2c55,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-c55b4d54-3856-451d-98db-0949194adc6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-bb96aaf6-b184-47be-91fa-8f68e97f7b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 6909
