reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623157226-172.17.0.21-1596019747272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44443,DS-f48c9e52-2daf-432b-9fae-1434546f0f56,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-1954e9a5-6e68-433a-a9eb-060e9799c51f,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-e054d27c-b04a-4f61-8065-73b402f351e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-894ad322-9883-4372-a126-28819da7d0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-70ab0bcd-980a-4644-8064-1befc6f85c37,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-b346e48a-a5b4-46a0-882a-bb637d90af08,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-af142d58-3f06-484f-9517-2b977f663369,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-8edfce55-914d-4db2-9285-a65a7911187a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623157226-172.17.0.21-1596019747272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44443,DS-f48c9e52-2daf-432b-9fae-1434546f0f56,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-1954e9a5-6e68-433a-a9eb-060e9799c51f,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-e054d27c-b04a-4f61-8065-73b402f351e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-894ad322-9883-4372-a126-28819da7d0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-70ab0bcd-980a-4644-8064-1befc6f85c37,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-b346e48a-a5b4-46a0-882a-bb637d90af08,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-af142d58-3f06-484f-9517-2b977f663369,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-8edfce55-914d-4db2-9285-a65a7911187a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275871882-172.17.0.21-1596019853395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38428,DS-a4c3cade-4b76-4fc7-91e3-68581ebf0a75,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-2b3c1078-0942-40c5-b2c1-2929d86aaf17,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-adf4947b-c216-451e-9085-3ecdbd14ff1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-50c3b806-962d-4a60-a3f0-79e9af0e1452,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-8feddf6b-216f-40da-a4fc-48f4f1f9efa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-6395ec2f-88e7-4933-b919-b8f13e109c87,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-73c722d6-79da-4aa7-9738-52f35804f0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-b830839a-7d7d-4d9f-b903-9daeda675388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275871882-172.17.0.21-1596019853395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38428,DS-a4c3cade-4b76-4fc7-91e3-68581ebf0a75,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-2b3c1078-0942-40c5-b2c1-2929d86aaf17,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-adf4947b-c216-451e-9085-3ecdbd14ff1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-50c3b806-962d-4a60-a3f0-79e9af0e1452,DISK], DatanodeInfoWithStorage[127.0.0.1:36642,DS-8feddf6b-216f-40da-a4fc-48f4f1f9efa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-6395ec2f-88e7-4933-b919-b8f13e109c87,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-73c722d6-79da-4aa7-9738-52f35804f0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-b830839a-7d7d-4d9f-b903-9daeda675388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664876121-172.17.0.21-1596020019726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35395,DS-452037b4-cf3c-46b3-a258-c798caa05a22,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-910104bf-64ce-403a-ad10-dfcdb9b713c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-a1403690-94d5-442f-8a06-1a3d8355efc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-34111d23-925d-4cf8-ac62-681ae19108b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-001bf28a-8c4a-4e13-9d79-cba3acba64ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-32cff39f-2f5e-44cc-ae52-6a12c365cda5,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-b8632713-773a-4ba6-bd67-07b5c879c5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-3d00387a-30c4-41ca-aa9b-15ce0c4a91f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664876121-172.17.0.21-1596020019726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35395,DS-452037b4-cf3c-46b3-a258-c798caa05a22,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-910104bf-64ce-403a-ad10-dfcdb9b713c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-a1403690-94d5-442f-8a06-1a3d8355efc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-34111d23-925d-4cf8-ac62-681ae19108b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-001bf28a-8c4a-4e13-9d79-cba3acba64ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-32cff39f-2f5e-44cc-ae52-6a12c365cda5,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-b8632713-773a-4ba6-bd67-07b5c879c5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-3d00387a-30c4-41ca-aa9b-15ce0c4a91f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719816553-172.17.0.21-1596020156453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46055,DS-a9f1fdf5-7893-4b21-979f-ba5f8c486a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-e52411fb-5c7e-48de-ae31-d4ae7495f189,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-4d3ab008-d2b5-47ce-9417-7423b198ed51,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-a7992a29-7b1c-41a0-888c-0229bbb21fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-48498937-6f15-45cf-b40d-30e54ef9fd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-2187fbd5-93d6-4e9d-a29a-7397c94d8cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-e23c2979-aa85-4024-a04f-ad9a45a91125,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-108812e0-8e83-4e4e-8dfc-78c0ddda4af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-719816553-172.17.0.21-1596020156453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46055,DS-a9f1fdf5-7893-4b21-979f-ba5f8c486a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-e52411fb-5c7e-48de-ae31-d4ae7495f189,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-4d3ab008-d2b5-47ce-9417-7423b198ed51,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-a7992a29-7b1c-41a0-888c-0229bbb21fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-48498937-6f15-45cf-b40d-30e54ef9fd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-2187fbd5-93d6-4e9d-a29a-7397c94d8cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-e23c2979-aa85-4024-a04f-ad9a45a91125,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-108812e0-8e83-4e4e-8dfc-78c0ddda4af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645712583-172.17.0.21-1596020564368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-75877c8c-af59-438d-a238-a5a1fe19a0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-ff560de4-4b83-4099-aaee-c786f29a765d,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-1fa17930-2bb4-4a77-8e5e-8ca26c1b96fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-92fefe54-4c74-4313-a2d3-36bb1bb39327,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-3c33d5d6-e7e7-4907-adf1-621635fa560d,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-a11e93ef-a8ef-4604-8786-17424e757de9,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-1b0165a1-4371-4ecc-a1ba-72dde12dcf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-6e811fad-54c6-4276-a179-583647fdee5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645712583-172.17.0.21-1596020564368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-75877c8c-af59-438d-a238-a5a1fe19a0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-ff560de4-4b83-4099-aaee-c786f29a765d,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-1fa17930-2bb4-4a77-8e5e-8ca26c1b96fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-92fefe54-4c74-4313-a2d3-36bb1bb39327,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-3c33d5d6-e7e7-4907-adf1-621635fa560d,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-a11e93ef-a8ef-4604-8786-17424e757de9,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-1b0165a1-4371-4ecc-a1ba-72dde12dcf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-6e811fad-54c6-4276-a179-583647fdee5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447793673-172.17.0.21-1596021656598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33528,DS-339aac25-f1ef-43d7-8e01-227dd287f617,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-2e83dbfd-2916-429e-ad39-9ce2e82f68ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-5729c421-d41b-484f-a7a4-27d26ce2d00f,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-54e129b0-f459-413d-aa66-969d6a8373c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-c8fd0d21-37e2-476d-81e2-8c32c357beae,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-0bc5572b-8037-4d0a-8a2f-0685d8174dde,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-b9905b05-01f4-48af-845a-cdaae8d90ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-74ec3034-5bae-4dc0-b746-e263f8b0c843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-447793673-172.17.0.21-1596021656598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33528,DS-339aac25-f1ef-43d7-8e01-227dd287f617,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-2e83dbfd-2916-429e-ad39-9ce2e82f68ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-5729c421-d41b-484f-a7a4-27d26ce2d00f,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-54e129b0-f459-413d-aa66-969d6a8373c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-c8fd0d21-37e2-476d-81e2-8c32c357beae,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-0bc5572b-8037-4d0a-8a2f-0685d8174dde,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-b9905b05-01f4-48af-845a-cdaae8d90ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-74ec3034-5bae-4dc0-b746-e263f8b0c843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060868075-172.17.0.21-1596021739615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-6d38c6ad-aabe-490f-a9b0-ce37300970bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-d018d927-e77e-4e26-aa8c-9d60032d3e76,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-2a8d6e12-1c6e-4ed0-a20a-10e36937b0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-04fb5979-ebe2-47f7-a737-fb475510d26e,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-4018d63b-a354-4d1a-8464-7d05cbea529f,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-d443f951-23bb-49ef-8d82-36cac742515c,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-df85da26-23fb-4940-b3da-5d9fd0e95b20,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-e79e0f61-b910-41b4-bab8-3470d06802bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060868075-172.17.0.21-1596021739615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-6d38c6ad-aabe-490f-a9b0-ce37300970bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-d018d927-e77e-4e26-aa8c-9d60032d3e76,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-2a8d6e12-1c6e-4ed0-a20a-10e36937b0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-04fb5979-ebe2-47f7-a737-fb475510d26e,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-4018d63b-a354-4d1a-8464-7d05cbea529f,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-d443f951-23bb-49ef-8d82-36cac742515c,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-df85da26-23fb-4940-b3da-5d9fd0e95b20,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-e79e0f61-b910-41b4-bab8-3470d06802bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916790106-172.17.0.21-1596021946658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33686,DS-6f4f2cf5-e464-4129-b85d-e9fb96754f38,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-aab27feb-439a-42ac-86df-71bf54867824,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-fd37d022-204b-44d5-9ddd-e0e5805178a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-fd481b44-3ad2-424e-a197-8ba24ee36000,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-d99bea9f-7669-46b0-bb68-e917e036850e,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-1c9f6367-880d-42db-a7b4-780626f591ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-f2ed351e-cf4c-4112-8d7c-5fbfe3ae85e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-71e7ea1e-7d89-4ae6-a541-35056aa4aceb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916790106-172.17.0.21-1596021946658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33686,DS-6f4f2cf5-e464-4129-b85d-e9fb96754f38,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-aab27feb-439a-42ac-86df-71bf54867824,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-fd37d022-204b-44d5-9ddd-e0e5805178a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-fd481b44-3ad2-424e-a197-8ba24ee36000,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-d99bea9f-7669-46b0-bb68-e917e036850e,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-1c9f6367-880d-42db-a7b4-780626f591ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-f2ed351e-cf4c-4112-8d7c-5fbfe3ae85e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-71e7ea1e-7d89-4ae6-a541-35056aa4aceb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1420709532-172.17.0.21-1596022424018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37449,DS-c476832a-8e68-4c87-82b5-8b32d3f3d0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-29046835-8d45-4e71-a3ac-e77c3b24ea18,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-1f4391a9-e01f-4688-83f3-015f64b97967,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-0234aac3-ddee-4630-bac9-aecf409ed467,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-e4ba8644-6f09-4096-8806-fbd717643377,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-a5b4e38d-6376-419c-865e-0de71fbd8a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-fad050c6-4e10-49bf-a7c2-2bb1b370d6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-393d217a-4586-4300-b2c1-326353688fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1420709532-172.17.0.21-1596022424018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37449,DS-c476832a-8e68-4c87-82b5-8b32d3f3d0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-29046835-8d45-4e71-a3ac-e77c3b24ea18,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-1f4391a9-e01f-4688-83f3-015f64b97967,DISK], DatanodeInfoWithStorage[127.0.0.1:42402,DS-0234aac3-ddee-4630-bac9-aecf409ed467,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-e4ba8644-6f09-4096-8806-fbd717643377,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-a5b4e38d-6376-419c-865e-0de71fbd8a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-fad050c6-4e10-49bf-a7c2-2bb1b370d6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-393d217a-4586-4300-b2c1-326353688fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34727088-172.17.0.21-1596022567221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40126,DS-dca7ff12-0fe3-4a50-bd32-52067c7c4758,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-2265b48a-6476-41ce-8937-4f3731eb5685,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-e51acea7-ef1a-40b5-a44c-576acc77d4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-db44d484-99e6-4063-bb23-50486f934ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-01ab8c95-a228-4632-8496-ad8da8a2c8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-92a76cfc-ec7e-4c67-b2c0-e7fc080f1fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-9cc41bac-2318-471d-9257-71154462afd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-78dc45be-a2f9-4a13-98fd-e39e03cff284,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34727088-172.17.0.21-1596022567221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40126,DS-dca7ff12-0fe3-4a50-bd32-52067c7c4758,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-2265b48a-6476-41ce-8937-4f3731eb5685,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-e51acea7-ef1a-40b5-a44c-576acc77d4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-db44d484-99e6-4063-bb23-50486f934ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-01ab8c95-a228-4632-8496-ad8da8a2c8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-92a76cfc-ec7e-4c67-b2c0-e7fc080f1fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-9cc41bac-2318-471d-9257-71154462afd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-78dc45be-a2f9-4a13-98fd-e39e03cff284,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093216048-172.17.0.21-1596022604946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41681,DS-516977d3-68fe-424b-a7a2-74a7f74d5f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-f9897d38-2bf4-41fa-9297-c20dc464ac12,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-05662717-9c22-4411-bb70-7d82e006c495,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-53f9765d-9369-4de8-9bc1-ac73156554d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-6a77be47-f65a-45eb-bc34-89ef689f2749,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-15badf29-7530-4adf-a1bc-f499f12cbdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-5ae720ab-9970-440d-ac5f-9044ce0e6a67,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-ea25a570-bc0c-4eee-9538-9fcefc975fcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093216048-172.17.0.21-1596022604946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41681,DS-516977d3-68fe-424b-a7a2-74a7f74d5f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-f9897d38-2bf4-41fa-9297-c20dc464ac12,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-05662717-9c22-4411-bb70-7d82e006c495,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-53f9765d-9369-4de8-9bc1-ac73156554d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-6a77be47-f65a-45eb-bc34-89ef689f2749,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-15badf29-7530-4adf-a1bc-f499f12cbdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-5ae720ab-9970-440d-ac5f-9044ce0e6a67,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-ea25a570-bc0c-4eee-9538-9fcefc975fcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548596690-172.17.0.21-1596022808272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45615,DS-adc3e649-d643-4270-8778-ca2afd8453cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-63f6d483-4a7c-49bf-a18c-8cea962cdb74,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-b4a66406-3562-4198-a5a9-2b11faeee6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-ad8260ec-b495-4649-ada0-82d1ef9339c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-531a9657-6b82-4bc6-a068-8ba8a267761b,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-f9d5d941-831f-485a-b9d6-141f7b7acab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-a4808363-d4a0-4ef6-9d37-650440f58594,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-c7df29d3-2cb2-4118-b8fe-2f3b1ecb2eb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548596690-172.17.0.21-1596022808272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45615,DS-adc3e649-d643-4270-8778-ca2afd8453cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-63f6d483-4a7c-49bf-a18c-8cea962cdb74,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-b4a66406-3562-4198-a5a9-2b11faeee6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-ad8260ec-b495-4649-ada0-82d1ef9339c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-531a9657-6b82-4bc6-a068-8ba8a267761b,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-f9d5d941-831f-485a-b9d6-141f7b7acab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-a4808363-d4a0-4ef6-9d37-650440f58594,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-c7df29d3-2cb2-4118-b8fe-2f3b1ecb2eb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330678640-172.17.0.21-1596023044334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41868,DS-da860cdf-a167-44ae-b904-9d7c6b6a5176,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-2df066d2-eae5-4e2b-85bb-de60c7039d87,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-915298a5-adc8-4bc1-97d9-c663977e5e65,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-b9fd1ac7-de54-42e8-9975-0fdf1d95aad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-01c1c1bc-87f5-4ca4-b61c-fe8a1cdaff36,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-5c608e46-a178-40fd-b7b2-dc56779225b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-413fa119-a136-44d6-abbe-9a736b3d78fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-49ee5802-2205-446f-beeb-b47c77484cef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330678640-172.17.0.21-1596023044334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41868,DS-da860cdf-a167-44ae-b904-9d7c6b6a5176,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-2df066d2-eae5-4e2b-85bb-de60c7039d87,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-915298a5-adc8-4bc1-97d9-c663977e5e65,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-b9fd1ac7-de54-42e8-9975-0fdf1d95aad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-01c1c1bc-87f5-4ca4-b61c-fe8a1cdaff36,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-5c608e46-a178-40fd-b7b2-dc56779225b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-413fa119-a136-44d6-abbe-9a736b3d78fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-49ee5802-2205-446f-beeb-b47c77484cef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803730907-172.17.0.21-1596024389776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44517,DS-5139ae43-03e1-41c6-adb7-4d838ae4dd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-dab1c8a1-2f00-4212-96cc-cc09ebad46f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-c0e01150-d736-405e-9fe1-c7503d230dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-c48a3cbc-1dbf-4229-a32e-2c1add07a239,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-e4c75b73-80cc-4e25-8adf-a211e7651fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-2a133e7e-610d-48f4-b445-9ac112209423,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-ed58011f-ddf5-4545-90d2-4386b0df95da,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-c26d8e15-4157-45b4-8e86-81300069bfd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803730907-172.17.0.21-1596024389776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44517,DS-5139ae43-03e1-41c6-adb7-4d838ae4dd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-dab1c8a1-2f00-4212-96cc-cc09ebad46f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-c0e01150-d736-405e-9fe1-c7503d230dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44664,DS-c48a3cbc-1dbf-4229-a32e-2c1add07a239,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-e4c75b73-80cc-4e25-8adf-a211e7651fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-2a133e7e-610d-48f4-b445-9ac112209423,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-ed58011f-ddf5-4545-90d2-4386b0df95da,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-c26d8e15-4157-45b4-8e86-81300069bfd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676372754-172.17.0.21-1596024539767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35359,DS-d0d14e24-6bbb-43d2-8792-91ab4a7c7249,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-8b6522b6-8fb0-43d2-a91e-d2f6ece067dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-b67dd2b4-f4bc-455b-8900-721610f03770,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-8a3d2e33-6913-4925-9d82-e7065e262ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-281abe9a-0b41-456b-80ac-10130b97e6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-9334c9b3-d04e-483c-b525-225e4270cdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-02f30305-19fb-43b2-8832-1266cc6cef50,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-5e4433f6-b0ad-4b5d-b6f1-5a01f6731fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676372754-172.17.0.21-1596024539767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35359,DS-d0d14e24-6bbb-43d2-8792-91ab4a7c7249,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-8b6522b6-8fb0-43d2-a91e-d2f6ece067dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-b67dd2b4-f4bc-455b-8900-721610f03770,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-8a3d2e33-6913-4925-9d82-e7065e262ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-281abe9a-0b41-456b-80ac-10130b97e6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-9334c9b3-d04e-483c-b525-225e4270cdd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-02f30305-19fb-43b2-8832-1266cc6cef50,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-5e4433f6-b0ad-4b5d-b6f1-5a01f6731fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868872687-172.17.0.21-1596024577156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40890,DS-5d37de75-b774-491b-aabc-cbe772e4e18f,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-a6ed7ee5-22f3-43e6-b3c2-79f90fda4cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-2e97662d-3399-4ff5-b463-5ad28cb317fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-4caa8bb3-e548-4dde-8f47-60f33af1afb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-8d05c33a-43be-4535-9090-3298459c6a58,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-ee6ddb2c-a003-405c-a7ed-f9215985316a,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-92e7713b-d859-4dfd-a149-3111e273aad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-2866f600-4d9c-4796-aa4f-006bba1062a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868872687-172.17.0.21-1596024577156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40890,DS-5d37de75-b774-491b-aabc-cbe772e4e18f,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-a6ed7ee5-22f3-43e6-b3c2-79f90fda4cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-2e97662d-3399-4ff5-b463-5ad28cb317fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-4caa8bb3-e548-4dde-8f47-60f33af1afb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-8d05c33a-43be-4535-9090-3298459c6a58,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-ee6ddb2c-a003-405c-a7ed-f9215985316a,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-92e7713b-d859-4dfd-a149-3111e273aad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-2866f600-4d9c-4796-aa4f-006bba1062a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049053308-172.17.0.21-1596024683924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34865,DS-0e073929-0c50-48e3-adc7-cf5e9979ce86,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-f282c55c-6988-4379-a62b-43b0f2943ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-0d00fad8-3b25-4d63-aac4-1ddf3265384c,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-04cb1e48-fb89-4643-8dcb-13056b676bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-2ce11bcc-44a1-4299-8906-bf47ea9dc203,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-08668083-1479-4442-9906-bd66cf194cea,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-b82823d4-2c63-4d80-ab9b-e7f9b441730b,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-db9fbeb7-d5a9-47ef-85fd-0d90332b21e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049053308-172.17.0.21-1596024683924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34865,DS-0e073929-0c50-48e3-adc7-cf5e9979ce86,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-f282c55c-6988-4379-a62b-43b0f2943ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-0d00fad8-3b25-4d63-aac4-1ddf3265384c,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-04cb1e48-fb89-4643-8dcb-13056b676bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-2ce11bcc-44a1-4299-8906-bf47ea9dc203,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-08668083-1479-4442-9906-bd66cf194cea,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-b82823d4-2c63-4d80-ab9b-e7f9b441730b,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-db9fbeb7-d5a9-47ef-85fd-0d90332b21e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.min
component: hdfs:NameNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494774757-172.17.0.21-1596025095515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38184,DS-0608828c-1ca7-46ac-b7b0-3b25634d9ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-0fa6dffc-e34f-417c-8e64-04cdbd1c3148,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-ce88bc22-a601-4b2c-9f98-51bdb8612e90,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-e92ae01d-746d-429c-8a5f-f474c6b65b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-2b917b57-f4db-4379-af1f-e35527a6cbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-274ff8cb-a02e-4f91-acc1-325450033c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-b2e4c77d-fa98-4dbd-b4c1-8a7305a8a70d,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-d2e71991-497b-427c-852e-1ca365c503ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-494774757-172.17.0.21-1596025095515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38184,DS-0608828c-1ca7-46ac-b7b0-3b25634d9ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-0fa6dffc-e34f-417c-8e64-04cdbd1c3148,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-ce88bc22-a601-4b2c-9f98-51bdb8612e90,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-e92ae01d-746d-429c-8a5f-f474c6b65b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-2b917b57-f4db-4379-af1f-e35527a6cbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-274ff8cb-a02e-4f91-acc1-325450033c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-b2e4c77d-fa98-4dbd-b4c1-8a7305a8a70d,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-d2e71991-497b-427c-852e-1ca365c503ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5651
