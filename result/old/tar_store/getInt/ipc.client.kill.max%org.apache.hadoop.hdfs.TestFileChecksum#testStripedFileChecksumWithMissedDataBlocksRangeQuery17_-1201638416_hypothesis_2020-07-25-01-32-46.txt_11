reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773495570-172.17.0.13-1595641283549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-83358390-5978-4e46-8891-cd3373178df9,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-8333f609-00c0-4fdf-8614-d7a20eaad155,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-6b7fa248-aac9-472e-a919-11228a2f44f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-55157344-f558-4144-b7d3-d4dd9e8aeb05,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-a9820f52-f718-424a-abff-b677c70fcbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-73829297-fe05-49d8-ad5e-aa688cdf2fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-4f0a14ba-8353-45e2-b5cd-f877286c9973,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-8e74e215-98f0-4ea4-8205-b249b7c53e18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773495570-172.17.0.13-1595641283549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34426,DS-83358390-5978-4e46-8891-cd3373178df9,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-8333f609-00c0-4fdf-8614-d7a20eaad155,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-6b7fa248-aac9-472e-a919-11228a2f44f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43885,DS-55157344-f558-4144-b7d3-d4dd9e8aeb05,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-a9820f52-f718-424a-abff-b677c70fcbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-73829297-fe05-49d8-ad5e-aa688cdf2fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-4f0a14ba-8353-45e2-b5cd-f877286c9973,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-8e74e215-98f0-4ea4-8205-b249b7c53e18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292342822-172.17.0.13-1595641421114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37134,DS-9f310a7c-73b3-440b-baba-7d22aa7dbf21,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-4dfd4312-1713-432f-adda-886036cc7a62,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-5677f944-566e-41dd-a67a-faf0ea5c2125,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-7d5d4424-1209-4520-b239-184c105bac20,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-63948a73-4057-4b66-9a0c-4fbb21b6d3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-8af71b73-cbb5-4b0c-83b3-3a3f4008d8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-2dd0b8fa-5d80-4f00-8a3f-0b2144084096,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-b7361d52-c53e-4175-816e-d2b383eb9dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292342822-172.17.0.13-1595641421114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37134,DS-9f310a7c-73b3-440b-baba-7d22aa7dbf21,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-4dfd4312-1713-432f-adda-886036cc7a62,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-5677f944-566e-41dd-a67a-faf0ea5c2125,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-7d5d4424-1209-4520-b239-184c105bac20,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-63948a73-4057-4b66-9a0c-4fbb21b6d3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-8af71b73-cbb5-4b0c-83b3-3a3f4008d8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-2dd0b8fa-5d80-4f00-8a3f-0b2144084096,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-b7361d52-c53e-4175-816e-d2b383eb9dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-62879829-172.17.0.13-1595642149599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38032,DS-af08a68f-33f7-40f2-a9b8-736d383e14b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-3b0e2998-7362-4b70-a5c0-c49ceaf802d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-ef55d6bc-b097-42a8-83b2-aa71ddf2dd18,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-81c04220-63c8-4101-ac7e-89ecfcb6acb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-f3bc8fec-515e-4e75-9c72-269b6388cb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-2d45a9d7-5868-402d-a9b3-a39dc64c2ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-b87121b2-c448-46aa-ab5e-0c7fe283b595,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-f3735e0d-bf8c-4ea5-9392-17a83f048606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-62879829-172.17.0.13-1595642149599:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38032,DS-af08a68f-33f7-40f2-a9b8-736d383e14b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-3b0e2998-7362-4b70-a5c0-c49ceaf802d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-ef55d6bc-b097-42a8-83b2-aa71ddf2dd18,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-81c04220-63c8-4101-ac7e-89ecfcb6acb1,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-f3bc8fec-515e-4e75-9c72-269b6388cb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-2d45a9d7-5868-402d-a9b3-a39dc64c2ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-b87121b2-c448-46aa-ab5e-0c7fe283b595,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-f3735e0d-bf8c-4ea5-9392-17a83f048606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1751745779-172.17.0.13-1595642249116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40225,DS-e4606623-8c7c-47e8-8991-11a41e8b765a,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-b7010053-9ad8-43b8-b7de-a55e348cf2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-29aee544-e600-4764-afa0-f061ae604495,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-34528e49-b4ea-4975-8125-ada70869a68c,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-cd3b0ab2-8acc-4465-84b6-23820a42a3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-2a06e577-41e7-4ca7-8044-23a0c51dde2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-35c4fcb8-9e9e-4c09-b82a-22ce943a41d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-44bdac5b-9169-420f-91c2-8e8d768c88d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1751745779-172.17.0.13-1595642249116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40225,DS-e4606623-8c7c-47e8-8991-11a41e8b765a,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-b7010053-9ad8-43b8-b7de-a55e348cf2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-29aee544-e600-4764-afa0-f061ae604495,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-34528e49-b4ea-4975-8125-ada70869a68c,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-cd3b0ab2-8acc-4465-84b6-23820a42a3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-2a06e577-41e7-4ca7-8044-23a0c51dde2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-35c4fcb8-9e9e-4c09-b82a-22ce943a41d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-44bdac5b-9169-420f-91c2-8e8d768c88d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132154066-172.17.0.13-1595642319533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43247,DS-d66cf158-892a-4fdb-8bff-bf79b9b990ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-480984f6-08a0-4775-9969-635cf88814eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-83a08fb5-0ea3-49c4-9e56-25af67993687,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-af79b711-5f3e-49b8-89df-e66a15dc5f54,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-24d66c7a-3792-4151-a0d2-1e1142df8ade,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-37f9bd3e-9bb8-4717-9cad-24da5ce24ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-3682c6d3-ce75-43e1-93b8-8b21ce1849bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-d42146b2-e36a-4791-9480-4db0a0f01de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132154066-172.17.0.13-1595642319533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43247,DS-d66cf158-892a-4fdb-8bff-bf79b9b990ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-480984f6-08a0-4775-9969-635cf88814eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-83a08fb5-0ea3-49c4-9e56-25af67993687,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-af79b711-5f3e-49b8-89df-e66a15dc5f54,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-24d66c7a-3792-4151-a0d2-1e1142df8ade,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-37f9bd3e-9bb8-4717-9cad-24da5ce24ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-3682c6d3-ce75-43e1-93b8-8b21ce1849bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-d42146b2-e36a-4791-9480-4db0a0f01de0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375383386-172.17.0.13-1595643057672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42067,DS-a7a6f0f8-4603-4f10-94f2-c6e12d1c8b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-5cbc7c76-a429-43c6-9c10-1c0a000644d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-b4bfa943-98af-4f5e-83b0-88312b02788e,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-9bdbb668-c006-487e-bbe4-88ebf2082ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-20367844-18bd-4042-8b2c-5be631757653,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-e56355b4-e1f8-4b36-89de-fb17ea093e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-171e1612-35cf-479f-9bdf-c4e0262e70ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-b33200c0-39fa-49dc-9406-3de5431bb6c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375383386-172.17.0.13-1595643057672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42067,DS-a7a6f0f8-4603-4f10-94f2-c6e12d1c8b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-5cbc7c76-a429-43c6-9c10-1c0a000644d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-b4bfa943-98af-4f5e-83b0-88312b02788e,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-9bdbb668-c006-487e-bbe4-88ebf2082ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-20367844-18bd-4042-8b2c-5be631757653,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-e56355b4-e1f8-4b36-89de-fb17ea093e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-171e1612-35cf-479f-9bdf-c4e0262e70ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-b33200c0-39fa-49dc-9406-3de5431bb6c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1056864128-172.17.0.13-1595643295598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-f27e0591-cfed-459d-a1c6-83f0a5afff25,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-c8e35b7c-798b-4ae3-8480-fd33646bef4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-d23a70b6-ec6b-479e-9201-160ee043451b,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-09970a83-9cf5-44f2-bc94-c76b5467d205,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-76c36958-ff34-434e-8168-3d4ca99ebaec,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-3647de06-3311-4400-9ce0-b06ccd9d014b,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-17365e21-8098-40ac-a856-e95f7272b6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-cd625c95-b8a9-42cd-bbac-7ac026362da3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1056864128-172.17.0.13-1595643295598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-f27e0591-cfed-459d-a1c6-83f0a5afff25,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-c8e35b7c-798b-4ae3-8480-fd33646bef4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-d23a70b6-ec6b-479e-9201-160ee043451b,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-09970a83-9cf5-44f2-bc94-c76b5467d205,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-76c36958-ff34-434e-8168-3d4ca99ebaec,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-3647de06-3311-4400-9ce0-b06ccd9d014b,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-17365e21-8098-40ac-a856-e95f7272b6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-cd625c95-b8a9-42cd-bbac-7ac026362da3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261709709-172.17.0.13-1595643332863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34213,DS-a51ab3ed-c993-4717-849f-43312de9a402,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-e4af6046-a46e-44ad-8601-b331957f18dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-02fb4a38-3ad4-4fb9-920e-dc3eb5178463,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-e3b6fa2e-086e-4989-b5a9-21b805d323e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-53c164b3-c327-4b6c-a9af-2c532b27d3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-5f6989ff-765a-441f-af50-84462cd1f382,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-4448787b-6e87-403f-af65-08a7caf84c36,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-4bda2801-cd99-4285-8961-051e9245f292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261709709-172.17.0.13-1595643332863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34213,DS-a51ab3ed-c993-4717-849f-43312de9a402,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-e4af6046-a46e-44ad-8601-b331957f18dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-02fb4a38-3ad4-4fb9-920e-dc3eb5178463,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-e3b6fa2e-086e-4989-b5a9-21b805d323e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-53c164b3-c327-4b6c-a9af-2c532b27d3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-5f6989ff-765a-441f-af50-84462cd1f382,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-4448787b-6e87-403f-af65-08a7caf84c36,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-4bda2801-cd99-4285-8961-051e9245f292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228985732-172.17.0.13-1595643595107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32995,DS-bf0cf495-a7f0-4b8a-85ea-f23a156d2179,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-2d44fc34-f1d3-4f43-8d49-1f85de7a8e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-c1825db9-9c5e-4a0c-a66d-10f5c2a153be,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-baf8dfe3-d863-4941-a450-26288cfd9cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-f4baa8d8-1296-4403-9521-5c0fb25fe110,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-113eccf8-5920-4bd8-862d-8a1ba0242cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-69e39546-cfbf-4cb6-8e5c-6134eb199a42,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-fd4080bf-7daa-47b5-9f04-3661631a6db3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228985732-172.17.0.13-1595643595107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32995,DS-bf0cf495-a7f0-4b8a-85ea-f23a156d2179,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-2d44fc34-f1d3-4f43-8d49-1f85de7a8e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-c1825db9-9c5e-4a0c-a66d-10f5c2a153be,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-baf8dfe3-d863-4941-a450-26288cfd9cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-f4baa8d8-1296-4403-9521-5c0fb25fe110,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-113eccf8-5920-4bd8-862d-8a1ba0242cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-69e39546-cfbf-4cb6-8e5c-6134eb199a42,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-fd4080bf-7daa-47b5-9f04-3661631a6db3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003355987-172.17.0.13-1595643691670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34630,DS-52192a3d-6fff-4de0-8331-88e81dee500d,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-50b45e03-afb3-4cc6-8bda-c3e92c32f9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-a9f48452-be43-4f45-97a3-513ed2f87a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-81fdd0a7-64ef-4890-951f-987efa5be204,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-57de9d6a-a191-42ad-bdde-784be315fa12,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-c195d88e-35aa-4893-a941-2a88b9c04878,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-8821724f-eed7-4d68-8a92-a0bc69fdb53e,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-7ccaf141-65d8-422c-8274-15c758069d17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2003355987-172.17.0.13-1595643691670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34630,DS-52192a3d-6fff-4de0-8331-88e81dee500d,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-50b45e03-afb3-4cc6-8bda-c3e92c32f9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-a9f48452-be43-4f45-97a3-513ed2f87a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-81fdd0a7-64ef-4890-951f-987efa5be204,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-57de9d6a-a191-42ad-bdde-784be315fa12,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-c195d88e-35aa-4893-a941-2a88b9c04878,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-8821724f-eed7-4d68-8a92-a0bc69fdb53e,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-7ccaf141-65d8-422c-8274-15c758069d17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094800847-172.17.0.13-1595644045527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41787,DS-3f0e02da-6e27-4f53-9768-59199570b551,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-4f514230-9cc9-4560-b96e-d908c3c474f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-b3792def-28a9-4375-a28c-717c164e0f79,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-63772f40-541d-4d64-958d-545b2a3a6b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-0d352d36-4a68-4281-8d84-b9b049a61c76,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-cd6aba59-d555-461f-a774-8818d83142cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-8956d72e-dc14-4ced-a229-073f1a03bbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-f811d013-0cb4-437f-a7b4-e54424ac2880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094800847-172.17.0.13-1595644045527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41787,DS-3f0e02da-6e27-4f53-9768-59199570b551,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-4f514230-9cc9-4560-b96e-d908c3c474f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-b3792def-28a9-4375-a28c-717c164e0f79,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-63772f40-541d-4d64-958d-545b2a3a6b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-0d352d36-4a68-4281-8d84-b9b049a61c76,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-cd6aba59-d555-461f-a774-8818d83142cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-8956d72e-dc14-4ced-a229-073f1a03bbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-f811d013-0cb4-437f-a7b4-e54424ac2880,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234471043-172.17.0.13-1595644463218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45021,DS-dd6f88dd-d289-4d4e-b6ea-819c5d1cb297,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-9a60b8c0-55d6-45df-928d-56ea2b9d91c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-18b005dc-0913-4074-9db7-7dc8f5f9c096,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-fd0c597e-19b1-49ba-b9a7-1a8c86467b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-dbbdc212-a647-4443-8fdc-32158054cb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-96ade32e-e174-4d35-a335-863ccdf9a292,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-c9a7c271-fa5c-486c-a3c3-7af91a512b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-b653534f-13f4-4df0-bcd9-92213a12f82f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234471043-172.17.0.13-1595644463218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45021,DS-dd6f88dd-d289-4d4e-b6ea-819c5d1cb297,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-9a60b8c0-55d6-45df-928d-56ea2b9d91c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-18b005dc-0913-4074-9db7-7dc8f5f9c096,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-fd0c597e-19b1-49ba-b9a7-1a8c86467b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-dbbdc212-a647-4443-8fdc-32158054cb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-96ade32e-e174-4d35-a335-863ccdf9a292,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-c9a7c271-fa5c-486c-a3c3-7af91a512b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-b653534f-13f4-4df0-bcd9-92213a12f82f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091353577-172.17.0.13-1595644498580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41046,DS-cf4d9c25-c787-4cd0-939b-1a218d13b0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-da002d8e-8352-44d4-89bb-a3b12fe5ef0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-eb65a43a-1bf9-4221-aebe-b17d52e809da,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-032b3e41-f894-4606-9b7c-915ff0a899e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-5d5e9f85-8ffc-49b6-836b-609c5f7a1a04,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-ebf7e354-7af6-4697-90bc-0f3470dc121b,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-7874a182-3778-4125-a819-45426a4e8843,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-5f0be37d-b8a7-45f1-afd2-670cc9ee1d7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2091353577-172.17.0.13-1595644498580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41046,DS-cf4d9c25-c787-4cd0-939b-1a218d13b0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-da002d8e-8352-44d4-89bb-a3b12fe5ef0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-eb65a43a-1bf9-4221-aebe-b17d52e809da,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-032b3e41-f894-4606-9b7c-915ff0a899e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-5d5e9f85-8ffc-49b6-836b-609c5f7a1a04,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-ebf7e354-7af6-4697-90bc-0f3470dc121b,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-7874a182-3778-4125-a819-45426a4e8843,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-5f0be37d-b8a7-45f1-afd2-670cc9ee1d7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667251594-172.17.0.13-1595644675079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-18ab21f3-f782-4ed7-880d-41c2e17b0a40,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-eeab50fc-2084-4b05-a9be-99afd22cbac3,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-f2ed4a9a-cf93-4554-bbf5-5f18b7e9ab36,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-999700d1-dc28-461c-97ad-2f55f6da167c,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-7b6e38a6-e39b-4209-b137-44ff26479253,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-c65e8321-3d64-4fde-8353-90b6c271003c,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-86578427-63e7-4b2f-a8b2-10d2bd0517a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-f8fa35df-649d-4296-a1ae-e0485641bc7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667251594-172.17.0.13-1595644675079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33179,DS-18ab21f3-f782-4ed7-880d-41c2e17b0a40,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-eeab50fc-2084-4b05-a9be-99afd22cbac3,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-f2ed4a9a-cf93-4554-bbf5-5f18b7e9ab36,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-999700d1-dc28-461c-97ad-2f55f6da167c,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-7b6e38a6-e39b-4209-b137-44ff26479253,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-c65e8321-3d64-4fde-8353-90b6c271003c,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-86578427-63e7-4b2f-a8b2-10d2bd0517a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-f8fa35df-649d-4296-a1ae-e0485641bc7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:NameNode
v1: 20
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-633035120-172.17.0.13-1595644899189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45770,DS-7690948d-7dd2-4f22-862a-9c9d34961fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-d076989d-bac6-4dd4-a294-46d48eeb9044,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-e9c41a56-caf1-4cc8-8a77-93356e77350d,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-48ea0b07-e841-40bd-a0af-49e0eb16b738,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-4927d096-6570-4136-ba1c-4c6057f7f5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b508079b-8df9-4670-b3e7-18bb2523eeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-c3cf16f0-b0c8-4ee7-8acb-c97dd1a100cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-d08012fe-8970-48d6-922c-7b9b499074ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-633035120-172.17.0.13-1595644899189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45770,DS-7690948d-7dd2-4f22-862a-9c9d34961fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-d076989d-bac6-4dd4-a294-46d48eeb9044,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-e9c41a56-caf1-4cc8-8a77-93356e77350d,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-48ea0b07-e841-40bd-a0af-49e0eb16b738,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-4927d096-6570-4136-ba1c-4c6057f7f5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b508079b-8df9-4670-b3e7-18bb2523eeb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-c3cf16f0-b0c8-4ee7-8acb-c97dd1a100cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-d08012fe-8970-48d6-922c-7b9b499074ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5272
