reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767570677-172.17.0.15-1595641644583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32822,DS-ca4fde1f-6c79-423b-b5a1-805302ec9d39,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-771fe0de-0a24-4b19-96be-a9b024000280,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-ab8c9861-21e0-476b-bac0-8d23e4578a36,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-993c50b0-7a4f-4a7d-980e-d906a0f49be0,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-456095f4-0485-4fae-93b2-09d746965cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-0a1bba53-191c-472f-9a38-3f809e8cc855,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-450116e5-c0c9-448a-8b66-361bbcdd8971,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-f067cb75-3da8-4da9-9c63-bf67b122ccd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-767570677-172.17.0.15-1595641644583:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32822,DS-ca4fde1f-6c79-423b-b5a1-805302ec9d39,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-771fe0de-0a24-4b19-96be-a9b024000280,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-ab8c9861-21e0-476b-bac0-8d23e4578a36,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-993c50b0-7a4f-4a7d-980e-d906a0f49be0,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-456095f4-0485-4fae-93b2-09d746965cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-0a1bba53-191c-472f-9a38-3f809e8cc855,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-450116e5-c0c9-448a-8b66-361bbcdd8971,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-f067cb75-3da8-4da9-9c63-bf67b122ccd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507239011-172.17.0.15-1595641749069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45475,DS-fd7b2098-6a52-4cb4-8133-d0441299eb65,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-a274c899-6660-4e3c-8691-e3d3d0e01c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-70276813-e518-42eb-96c0-416b3fb05f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-d7decf25-2d7a-450f-b05e-47b4d047abc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-f672b211-50e2-48de-9289-ad855325c529,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-a0dc0bcc-0706-4dfc-b889-9f776f2082d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-98e45319-687c-4c30-9815-4946483dc072,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-d15704ae-913f-499b-9b58-82ddcb0ba6c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507239011-172.17.0.15-1595641749069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45475,DS-fd7b2098-6a52-4cb4-8133-d0441299eb65,DISK], DatanodeInfoWithStorage[127.0.0.1:34535,DS-a274c899-6660-4e3c-8691-e3d3d0e01c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-70276813-e518-42eb-96c0-416b3fb05f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-d7decf25-2d7a-450f-b05e-47b4d047abc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-f672b211-50e2-48de-9289-ad855325c529,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-a0dc0bcc-0706-4dfc-b889-9f776f2082d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-98e45319-687c-4c30-9815-4946483dc072,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-d15704ae-913f-499b-9b58-82ddcb0ba6c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745775705-172.17.0.15-1595642024745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45883,DS-4d6bac28-5f83-4dd3-9fc3-146e2219fd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-f4e37281-4796-4583-b37a-d0796c584701,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-63399ed2-18bc-4d0c-a07d-afd904890da9,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-b424c267-e429-42df-90c1-e9aa454842bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-16c1a798-6c88-4b9b-8868-fd6be2d33041,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-7b241a55-0fa3-4894-9060-dcfc34493c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-fa3f0fd2-b61e-4bc8-8c5d-e1a81f2e5650,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-bce770ef-2315-4cf2-9ed8-3d2e865401f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-745775705-172.17.0.15-1595642024745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45883,DS-4d6bac28-5f83-4dd3-9fc3-146e2219fd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-f4e37281-4796-4583-b37a-d0796c584701,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-63399ed2-18bc-4d0c-a07d-afd904890da9,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-b424c267-e429-42df-90c1-e9aa454842bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-16c1a798-6c88-4b9b-8868-fd6be2d33041,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-7b241a55-0fa3-4894-9060-dcfc34493c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-fa3f0fd2-b61e-4bc8-8c5d-e1a81f2e5650,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-bce770ef-2315-4cf2-9ed8-3d2e865401f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116237898-172.17.0.15-1595642162638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43297,DS-ce71d895-44f4-4442-bea1-6f93c58b9807,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-ebb136ee-a915-4ca5-8475-f29527b80d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-7740b785-8917-46cc-9840-0c2e7cfc1730,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-6771f045-c280-42ab-8cff-7201198992c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-9287a225-3eee-4705-a8d8-a8f90c8cb818,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-c34de941-f50b-4a9e-87c1-6f9f85dd89b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-c332636d-6fe8-4957-bc84-3b43b20a4565,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-64dad600-0bbb-4726-a1d3-88b776011226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116237898-172.17.0.15-1595642162638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43297,DS-ce71d895-44f4-4442-bea1-6f93c58b9807,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-ebb136ee-a915-4ca5-8475-f29527b80d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-7740b785-8917-46cc-9840-0c2e7cfc1730,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-6771f045-c280-42ab-8cff-7201198992c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-9287a225-3eee-4705-a8d8-a8f90c8cb818,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-c34de941-f50b-4a9e-87c1-6f9f85dd89b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-c332636d-6fe8-4957-bc84-3b43b20a4565,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-64dad600-0bbb-4726-a1d3-88b776011226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867130390-172.17.0.15-1595642644471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33852,DS-281a7d2f-044c-45a8-b258-b267c3d35296,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-d446d559-b42a-490c-9f3d-2a22c7efcd43,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-7c3d9482-79a1-451e-9995-448a141b83e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-02ccfb5b-8996-446a-8731-53d84d2cd48e,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-4b61137d-f66d-4c55-93a4-115f37e71f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-b05fdcc2-8189-4108-ab1a-9a6aecc07ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-0e4b4c57-ea55-418e-8450-37be9a93581a,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-cbf01e33-486d-4da2-9bff-1782c89604fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867130390-172.17.0.15-1595642644471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33852,DS-281a7d2f-044c-45a8-b258-b267c3d35296,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-d446d559-b42a-490c-9f3d-2a22c7efcd43,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-7c3d9482-79a1-451e-9995-448a141b83e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-02ccfb5b-8996-446a-8731-53d84d2cd48e,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-4b61137d-f66d-4c55-93a4-115f37e71f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-b05fdcc2-8189-4108-ab1a-9a6aecc07ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-0e4b4c57-ea55-418e-8450-37be9a93581a,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-cbf01e33-486d-4da2-9bff-1782c89604fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835868825-172.17.0.15-1595642716936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46024,DS-c0d85c11-cab6-458e-9d9a-d70903264871,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-10bbb2d1-067e-4494-80c1-4b8e1cec84da,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-57c60f18-791e-49d3-ae5a-d4d6f39a3197,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-f81a4457-5f34-4445-811a-f408502ddf86,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-56698e7b-7370-46c5-9ceb-670e7e815bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-ca09f5b3-fdc0-4811-9001-cd020eb792e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-1c3b231d-c532-4101-a489-1d8fbacc2bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-4a7602ce-3035-4393-a31e-fa78379412e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835868825-172.17.0.15-1595642716936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46024,DS-c0d85c11-cab6-458e-9d9a-d70903264871,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-10bbb2d1-067e-4494-80c1-4b8e1cec84da,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-57c60f18-791e-49d3-ae5a-d4d6f39a3197,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-f81a4457-5f34-4445-811a-f408502ddf86,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-56698e7b-7370-46c5-9ceb-670e7e815bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-ca09f5b3-fdc0-4811-9001-cd020eb792e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44785,DS-1c3b231d-c532-4101-a489-1d8fbacc2bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-4a7602ce-3035-4393-a31e-fa78379412e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999280677-172.17.0.15-1595642828333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39456,DS-3c5c98e9-3d15-4335-8cb2-d0b43df21a83,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-7c31625f-2c30-4099-aea3-bfc9d9a6ff02,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-95534bfb-4003-4e38-89ef-5cc57f4860c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-93bd11b8-6088-42a8-8fab-b43dca1d6d12,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-77088936-929a-4ebd-8515-c4498e71e937,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-9b318380-7640-4493-96a7-623ed54feb33,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-e63bcb09-a70c-4a55-93b6-8646e57219e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-7426f69b-a380-413f-9409-9362651c0bc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999280677-172.17.0.15-1595642828333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39456,DS-3c5c98e9-3d15-4335-8cb2-d0b43df21a83,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-7c31625f-2c30-4099-aea3-bfc9d9a6ff02,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-95534bfb-4003-4e38-89ef-5cc57f4860c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-93bd11b8-6088-42a8-8fab-b43dca1d6d12,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-77088936-929a-4ebd-8515-c4498e71e937,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-9b318380-7640-4493-96a7-623ed54feb33,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-e63bcb09-a70c-4a55-93b6-8646e57219e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-7426f69b-a380-413f-9409-9362651c0bc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524934242-172.17.0.15-1595642968284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36880,DS-50300d16-0747-4ea5-9a7d-325f5b2467c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-bc6a5b2c-7e22-4907-92ae-7c11589752ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-1ace2a82-c9e6-44a4-a8db-fe2b7bc14e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-35ea6e69-44c1-41cd-b9cf-e94a995b1a85,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-2f9a38ff-e5a6-49c3-869d-203fe3f027f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-56f6e704-58ca-411e-aec6-4a1603a6f355,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-e9b197c9-c62e-4522-9b12-3f1a6a44ad17,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-e3b0d3fc-46d3-4bd8-b31b-f25f620ecd50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524934242-172.17.0.15-1595642968284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36880,DS-50300d16-0747-4ea5-9a7d-325f5b2467c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-bc6a5b2c-7e22-4907-92ae-7c11589752ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-1ace2a82-c9e6-44a4-a8db-fe2b7bc14e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-35ea6e69-44c1-41cd-b9cf-e94a995b1a85,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-2f9a38ff-e5a6-49c3-869d-203fe3f027f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-56f6e704-58ca-411e-aec6-4a1603a6f355,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-e9b197c9-c62e-4522-9b12-3f1a6a44ad17,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-e3b0d3fc-46d3-4bd8-b31b-f25f620ecd50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-25065472-172.17.0.15-1595643082068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33129,DS-1437dbe5-cf2f-4761-8f65-a006cf32af25,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-6e411fff-df95-4fba-80be-b011569d98b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-d4515cfc-5e05-45f9-aa90-3c53e5595f11,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-d914b78d-94f4-4724-99c2-e85a3ce2fa73,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-48eaf1c9-8393-4162-83dc-3643083ade79,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-fa945af6-1ca7-4f86-97d2-01b9ba2ebedc,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-9d8f1389-5fff-4921-b49c-56ebf966c216,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-649f09f0-eb5c-4e83-9707-728ce07c5a97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-25065472-172.17.0.15-1595643082068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33129,DS-1437dbe5-cf2f-4761-8f65-a006cf32af25,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-6e411fff-df95-4fba-80be-b011569d98b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-d4515cfc-5e05-45f9-aa90-3c53e5595f11,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-d914b78d-94f4-4724-99c2-e85a3ce2fa73,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-48eaf1c9-8393-4162-83dc-3643083ade79,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-fa945af6-1ca7-4f86-97d2-01b9ba2ebedc,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-9d8f1389-5fff-4921-b49c-56ebf966c216,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-649f09f0-eb5c-4e83-9707-728ce07c5a97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-93238030-172.17.0.15-1595643117643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34015,DS-bbaf80c7-3a4a-46f4-9f6d-9b52ce2a59af,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-56a918e7-5c25-4b5f-8d22-88e8b517741d,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-82e35d21-1eb9-47a7-bd9f-24348db1a2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-56c08482-d0b0-4c8b-bbba-3c427cec2edf,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-722eae3a-7584-474b-b645-9ac76ce365f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-c6acad54-e38a-4f9b-8f59-8983df600b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-61b68f96-8621-48ec-85ef-29dc7f77e73a,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-4ede8748-b103-4044-a505-2548dcfd6a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-93238030-172.17.0.15-1595643117643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34015,DS-bbaf80c7-3a4a-46f4-9f6d-9b52ce2a59af,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-56a918e7-5c25-4b5f-8d22-88e8b517741d,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-82e35d21-1eb9-47a7-bd9f-24348db1a2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-56c08482-d0b0-4c8b-bbba-3c427cec2edf,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-722eae3a-7584-474b-b645-9ac76ce365f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-c6acad54-e38a-4f9b-8f59-8983df600b87,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-61b68f96-8621-48ec-85ef-29dc7f77e73a,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-4ede8748-b103-4044-a505-2548dcfd6a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1866872000-172.17.0.15-1595643198476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40580,DS-e3413f03-28ad-4e98-8fed-e329376064f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-86131813-83a3-4aeb-bca4-4b8556cc0fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-265c4e56-d104-476a-9c20-60fab2d115e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-8aa7ce10-f72e-48b0-9a82-12e249ef29c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-dace8965-06a0-4977-a81d-cf3418ac9a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-2e47204b-35a2-4e6c-b64d-d5329a5115c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-df847e2e-1f62-40b3-94ae-4050e6b6cb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-1e96acfa-c9a5-4720-ae08-3a4550163fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1866872000-172.17.0.15-1595643198476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40580,DS-e3413f03-28ad-4e98-8fed-e329376064f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-86131813-83a3-4aeb-bca4-4b8556cc0fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-265c4e56-d104-476a-9c20-60fab2d115e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-8aa7ce10-f72e-48b0-9a82-12e249ef29c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-dace8965-06a0-4977-a81d-cf3418ac9a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-2e47204b-35a2-4e6c-b64d-d5329a5115c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-df847e2e-1f62-40b3-94ae-4050e6b6cb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-1e96acfa-c9a5-4720-ae08-3a4550163fa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980264480-172.17.0.15-1595643346522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38070,DS-14d88b32-e5ed-40fe-a1b6-4d1dfc0e37d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-0a2b3ab7-b4a2-4ed6-bb3a-da97607caa64,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-fff9f602-6602-4f6a-997a-41d3e5f03d91,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-1f02cccd-c60e-4f67-8eca-eab44a8b5f98,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-b3cae20a-a955-4b9e-9434-98b2e56c303b,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-c69f6d86-de7f-46d0-bfa3-e1e385242fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-da2fe978-668c-4b45-84c8-89dd49eaa018,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-99a1638f-6365-4858-808b-51af6a86ee82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980264480-172.17.0.15-1595643346522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38070,DS-14d88b32-e5ed-40fe-a1b6-4d1dfc0e37d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-0a2b3ab7-b4a2-4ed6-bb3a-da97607caa64,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-fff9f602-6602-4f6a-997a-41d3e5f03d91,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-1f02cccd-c60e-4f67-8eca-eab44a8b5f98,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-b3cae20a-a955-4b9e-9434-98b2e56c303b,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-c69f6d86-de7f-46d0-bfa3-e1e385242fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-da2fe978-668c-4b45-84c8-89dd49eaa018,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-99a1638f-6365-4858-808b-51af6a86ee82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094583647-172.17.0.15-1595643724967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37031,DS-ed3adc57-1f49-4eff-b6e2-2ff365ca9a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-0b985618-74d2-4a49-adb4-6b2140091f41,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-75ab9a1c-f649-4e8c-a624-bb119289e207,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-0e90e79c-ce59-4f8c-b7d3-43967bd02426,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-95ed8811-5c09-48d7-b29d-f5631a907957,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-84c1e911-60fb-4c23-a1e2-58f8720042a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-8b422722-ca02-472e-973b-19346bb82e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-8f7ec960-5089-457a-ac56-32d8418df7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2094583647-172.17.0.15-1595643724967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37031,DS-ed3adc57-1f49-4eff-b6e2-2ff365ca9a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-0b985618-74d2-4a49-adb4-6b2140091f41,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-75ab9a1c-f649-4e8c-a624-bb119289e207,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-0e90e79c-ce59-4f8c-b7d3-43967bd02426,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-95ed8811-5c09-48d7-b29d-f5631a907957,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-84c1e911-60fb-4c23-a1e2-58f8720042a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-8b422722-ca02-472e-973b-19346bb82e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38774,DS-8f7ec960-5089-457a-ac56-32d8418df7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939465445-172.17.0.15-1595643833056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-9da2d2a4-28e5-4d4e-8e11-b5defb570b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-1f1f0913-a398-4e69-b71e-ec4d546e910a,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-c48c6c0e-665b-442c-8f81-a5aab96190e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-cdb7726b-761d-4b8f-b47d-09e8b7d3f0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-2f605621-cfa7-4fa3-a81f-18cb4e7ccf87,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-750c0f8b-5596-4f95-b7de-b853c4c14446,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-9d547d52-517c-4524-96c6-bd9574dd141c,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-2ac6a6de-425c-4f2e-88b1-59df41b252e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939465445-172.17.0.15-1595643833056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-9da2d2a4-28e5-4d4e-8e11-b5defb570b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-1f1f0913-a398-4e69-b71e-ec4d546e910a,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-c48c6c0e-665b-442c-8f81-a5aab96190e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-cdb7726b-761d-4b8f-b47d-09e8b7d3f0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-2f605621-cfa7-4fa3-a81f-18cb4e7ccf87,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-750c0f8b-5596-4f95-b7de-b853c4c14446,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-9d547d52-517c-4524-96c6-bd9574dd141c,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-2ac6a6de-425c-4f2e-88b1-59df41b252e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1715017795-172.17.0.15-1595644029242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36739,DS-5cea3f14-c40e-4a2a-8f4e-9d3e1b597d93,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-577f150c-d20e-4d56-a1f3-754ae37cdb58,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-0a2c77c5-dca8-4dbf-9c00-b866213c2e34,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-e2776701-087d-4ae8-b281-0f82aa5f6339,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-d186e7f6-099f-4de9-a46c-b3528c7470ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-d0016258-51bc-4cad-a818-16e7402e5d10,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-6ef3cbc4-c09c-4ebc-992c-c5b77460be05,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-71714fbe-8323-4a1c-a47a-018a1d670475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1715017795-172.17.0.15-1595644029242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36739,DS-5cea3f14-c40e-4a2a-8f4e-9d3e1b597d93,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-577f150c-d20e-4d56-a1f3-754ae37cdb58,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-0a2c77c5-dca8-4dbf-9c00-b866213c2e34,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-e2776701-087d-4ae8-b281-0f82aa5f6339,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-d186e7f6-099f-4de9-a46c-b3528c7470ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-d0016258-51bc-4cad-a818-16e7402e5d10,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-6ef3cbc4-c09c-4ebc-992c-c5b77460be05,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-71714fbe-8323-4a1c-a47a-018a1d670475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918166881-172.17.0.15-1595644708175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-0f703dc5-ebf3-42ad-8a76-5e63c854a51c,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-51acdaa9-be5d-4f4d-858a-773dcc2ecada,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-e3634ad5-6a5c-4efa-9780-979809e8e122,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-36777dcf-dcdb-43d8-b6cf-5c9af3dd8892,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-67af99e5-b5c1-4864-8992-b93fc09065be,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-3543e3fe-4c0b-4ee4-981e-37a4bdc76ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-fbbe0b92-8029-42ae-a6a7-bdbfa0a99ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-970d9f6a-19ab-4718-b90d-3ae9f1e8e746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918166881-172.17.0.15-1595644708175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-0f703dc5-ebf3-42ad-8a76-5e63c854a51c,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-51acdaa9-be5d-4f4d-858a-773dcc2ecada,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-e3634ad5-6a5c-4efa-9780-979809e8e122,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-36777dcf-dcdb-43d8-b6cf-5c9af3dd8892,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-67af99e5-b5c1-4864-8992-b93fc09065be,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-3543e3fe-4c0b-4ee4-981e-37a4bdc76ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-fbbe0b92-8029-42ae-a6a7-bdbfa0a99ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-970d9f6a-19ab-4718-b90d-3ae9f1e8e746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999301870-172.17.0.15-1595644844841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37092,DS-b1c1f19b-c5ad-45f8-8393-1d33e252b46a,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-817fefcb-235a-437d-a369-6d9bad0c9ade,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-9b7dfd36-f9b7-464a-a467-2460d6e5346b,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-670e0a6a-3209-47c2-9bfc-471dafeeeb52,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-93f3fb6e-1376-46a5-9414-d8ecd1855723,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-03c3e3c8-0b01-4edc-a6c0-ae3a17cc5060,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-5268d147-8d70-4f7e-a218-8cb1fdc8fd52,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-8ac3315c-1cf0-4db9-8e9e-15704a82fb6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999301870-172.17.0.15-1595644844841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37092,DS-b1c1f19b-c5ad-45f8-8393-1d33e252b46a,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-817fefcb-235a-437d-a369-6d9bad0c9ade,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-9b7dfd36-f9b7-464a-a467-2460d6e5346b,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-670e0a6a-3209-47c2-9bfc-471dafeeeb52,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-93f3fb6e-1376-46a5-9414-d8ecd1855723,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-03c3e3c8-0b01-4edc-a6c0-ae3a17cc5060,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-5268d147-8d70-4f7e-a218-8cb1fdc8fd52,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-8ac3315c-1cf0-4db9-8e9e-15704a82fb6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-868177410-172.17.0.15-1595645033919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40508,DS-931635ba-8c54-4b00-843d-dce15bd71148,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-38dbcb4d-fb6d-4ffb-8801-a168994244a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-7ac60e90-26ba-4e40-8a73-c97642b50be8,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-bbcc93c5-5478-4c95-bdc6-8b8e463907f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-15b9cf9e-51da-4795-b69f-64d60fd8d476,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-55f3a95d-8d8c-4624-8ef1-3ade946effb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-009fffaa-5a7b-4f68-b5e9-05a5fedaef4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-634e516e-fb25-4709-b38d-f55a62179930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-868177410-172.17.0.15-1595645033919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40508,DS-931635ba-8c54-4b00-843d-dce15bd71148,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-38dbcb4d-fb6d-4ffb-8801-a168994244a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-7ac60e90-26ba-4e40-8a73-c97642b50be8,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-bbcc93c5-5478-4c95-bdc6-8b8e463907f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-15b9cf9e-51da-4795-b69f-64d60fd8d476,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-55f3a95d-8d8c-4624-8ef1-3ade946effb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-009fffaa-5a7b-4f68-b5e9-05a5fedaef4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-634e516e-fb25-4709-b38d-f55a62179930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133443978-172.17.0.15-1595645094702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39303,DS-7f5a4e6b-25d0-4e65-b801-62dd072dcd74,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-35da4887-d516-403f-9e4b-4ad739caaf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-2b4ab13e-645c-4e38-a434-93960a0cfb79,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-f6897831-1a96-44cf-a692-292b248f159e,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-d6837578-7ee5-4775-9456-34d7bc510750,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-bcdb8650-590a-466c-8b9a-f92c7f8704dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-37cfe9e2-b4d6-4963-9934-324924c52385,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-cca06526-bac1-4cc4-b09e-e8c1600d8e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1133443978-172.17.0.15-1595645094702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39303,DS-7f5a4e6b-25d0-4e65-b801-62dd072dcd74,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-35da4887-d516-403f-9e4b-4ad739caaf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-2b4ab13e-645c-4e38-a434-93960a0cfb79,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-f6897831-1a96-44cf-a692-292b248f159e,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-d6837578-7ee5-4775-9456-34d7bc510750,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-bcdb8650-590a-466c-8b9a-f92c7f8704dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-37cfe9e2-b4d6-4963-9934-324924c52385,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-cca06526-bac1-4cc4-b09e-e8c1600d8e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770587970-172.17.0.15-1595645257603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45858,DS-9c16b5dd-37f0-4b7c-b708-ca5b000a2a16,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-3bc9821a-30e7-4366-ada6-da16dd802894,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-b033c8d8-0692-4ba1-b0e3-4909dc43e98b,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-a9d2e85d-92ef-4d53-b4b2-a2cf695be095,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-89017544-5579-4cf1-ba83-6c67175715f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-e8c65a96-e35f-494f-9cf4-8b3bf5f7ff67,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-52f9c084-3441-4e25-8a36-55a2ddb8297a,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-65fee009-308c-4e1b-a1f2-710f93c6e2a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770587970-172.17.0.15-1595645257603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45858,DS-9c16b5dd-37f0-4b7c-b708-ca5b000a2a16,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-3bc9821a-30e7-4366-ada6-da16dd802894,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-b033c8d8-0692-4ba1-b0e3-4909dc43e98b,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-a9d2e85d-92ef-4d53-b4b2-a2cf695be095,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-89017544-5579-4cf1-ba83-6c67175715f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-e8c65a96-e35f-494f-9cf4-8b3bf5f7ff67,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-52f9c084-3441-4e25-8a36-55a2ddb8297a,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-65fee009-308c-4e1b-a1f2-710f93c6e2a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934817697-172.17.0.15-1595645400044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37795,DS-09ef56e2-689e-482f-8a3d-255a52c81b03,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-549cfab5-32ac-4106-a3e1-1f77adf11ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-e3ad516b-74be-4297-bec5-e8a0991623d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-91cae3db-900c-4186-b1bc-520d95c3df7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-1577cfb9-594b-4ba2-bc14-c73493bfdf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-a599d03e-2263-46dc-9220-708d74d06b60,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-2e21dc70-95b2-41bd-881e-04a0e00fa849,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-717a724e-45a4-4344-a3c4-12e24b20fa51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934817697-172.17.0.15-1595645400044:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37795,DS-09ef56e2-689e-482f-8a3d-255a52c81b03,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-549cfab5-32ac-4106-a3e1-1f77adf11ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-e3ad516b-74be-4297-bec5-e8a0991623d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-91cae3db-900c-4186-b1bc-520d95c3df7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-1577cfb9-594b-4ba2-bc14-c73493bfdf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-a599d03e-2263-46dc-9220-708d74d06b60,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-2e21dc70-95b2-41bd-881e-04a0e00fa849,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-717a724e-45a4-4344-a3c4-12e24b20fa51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558460348-172.17.0.15-1595645629341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38220,DS-40f90fd2-bc3c-4989-abf3-5cfdc0cab5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-a05f5302-8d2e-4baa-bef2-ac9bd99ba15a,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-d75b9f24-5e85-4898-8fe7-0280e7cfce7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-aea57498-4e61-497e-90fd-015b1ed5667f,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-fa1f6959-f9c7-4b3e-ac37-ec2a32ecebd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-8aff817d-f8ec-4639-b170-9bbcd2eaa75d,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-0b6befef-5344-42da-ac0b-d152fc060750,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-37e7c7bb-c41d-4365-b5cd-7bb9c210328a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558460348-172.17.0.15-1595645629341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38220,DS-40f90fd2-bc3c-4989-abf3-5cfdc0cab5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-a05f5302-8d2e-4baa-bef2-ac9bd99ba15a,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-d75b9f24-5e85-4898-8fe7-0280e7cfce7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-aea57498-4e61-497e-90fd-015b1ed5667f,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-fa1f6959-f9c7-4b3e-ac37-ec2a32ecebd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-8aff817d-f8ec-4639-b170-9bbcd2eaa75d,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-0b6befef-5344-42da-ac0b-d152fc060750,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-37e7c7bb-c41d-4365-b5cd-7bb9c210328a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-21625092-172.17.0.15-1595645732122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33079,DS-004abe7c-a3fc-49d7-aafc-cc06db8cfdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-66a73ad6-c3f5-4c5a-83bb-086239d92a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-682f632b-90da-49de-ae36-579d16e2ca91,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-d44d3d6b-d913-4569-9dc9-698de818bfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-d85d1dd2-7d4e-4131-9cf7-6d90a73e9786,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-f0c0fccb-ddf4-4195-a67a-cb0bf3c2e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-11b41dc2-7f96-4ee1-af94-8a436c69c97c,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-10578433-9b4a-4b33-8392-30b2eafa83e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-21625092-172.17.0.15-1595645732122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33079,DS-004abe7c-a3fc-49d7-aafc-cc06db8cfdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-66a73ad6-c3f5-4c5a-83bb-086239d92a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-682f632b-90da-49de-ae36-579d16e2ca91,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-d44d3d6b-d913-4569-9dc9-698de818bfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-d85d1dd2-7d4e-4131-9cf7-6d90a73e9786,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-f0c0fccb-ddf4-4195-a67a-cb0bf3c2e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-11b41dc2-7f96-4ee1-af94-8a436c69c97c,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-10578433-9b4a-4b33-8392-30b2eafa83e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011098811-172.17.0.15-1595645760053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38964,DS-cede7b8d-61fd-42d2-b761-731b7be7db2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-a21a0e26-f84b-40aa-afc4-0dbfa6f838bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-b089a470-f38d-41ba-a871-b0e543f9e3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-737211dd-d590-4754-a88a-0f81946e4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-528e80ab-04b7-4b22-b148-e7e6e4df081b,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-90c6aa10-167f-46df-870c-a82629e30f87,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-8ca9b98a-2b18-4c62-8309-bc124c52387f,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-3982d12b-14d9-478c-8f1b-e8d01af7fce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011098811-172.17.0.15-1595645760053:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38964,DS-cede7b8d-61fd-42d2-b761-731b7be7db2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-a21a0e26-f84b-40aa-afc4-0dbfa6f838bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-b089a470-f38d-41ba-a871-b0e543f9e3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-737211dd-d590-4754-a88a-0f81946e4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-528e80ab-04b7-4b22-b148-e7e6e4df081b,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-90c6aa10-167f-46df-870c-a82629e30f87,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-8ca9b98a-2b18-4c62-8309-bc124c52387f,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-3982d12b-14d9-478c-8f1b-e8d01af7fce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427281897-172.17.0.15-1595646138369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38436,DS-40b255a2-d2de-41ff-bbe6-21773d37222c,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-9acc0baa-6c66-40c8-8f3f-be821a09f918,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-75809231-4b1f-4599-95f7-05a0c00bcc67,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-3ef63266-7cc2-41c1-a03d-8afe134570c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-0a286f8f-051f-45a2-a29d-32ed8c0fddfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-8a8b1e3e-4632-414e-826c-56d1f2497f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-52e442bd-dad3-4c44-aa5e-c820ebabf06f,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-71fac815-92ac-4164-8e90-3616f5fb3571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427281897-172.17.0.15-1595646138369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38436,DS-40b255a2-d2de-41ff-bbe6-21773d37222c,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-9acc0baa-6c66-40c8-8f3f-be821a09f918,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-75809231-4b1f-4599-95f7-05a0c00bcc67,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-3ef63266-7cc2-41c1-a03d-8afe134570c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-0a286f8f-051f-45a2-a29d-32ed8c0fddfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-8a8b1e3e-4632-414e-826c-56d1f2497f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-52e442bd-dad3-4c44-aa5e-c820ebabf06f,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-71fac815-92ac-4164-8e90-3616f5fb3571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515489551-172.17.0.15-1595646390346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34701,DS-902f64b6-6377-4885-860f-ecec9028319a,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-03b2762e-051a-4275-9d3a-9ac52c2f159b,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-5e3143a7-f3ba-4909-94d2-84bb2a66a037,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-bc67e929-f0e1-4898-b90a-93389d2d91e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-b1752d17-0ab3-427d-937e-d3cf3864aff9,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-62fdffc6-cc59-4779-b264-50e3e25f5ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-5fe813ca-2d68-40cb-858c-a0dada9fe9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-55278d4a-9b20-4902-9731-20897d0dca84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515489551-172.17.0.15-1595646390346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34701,DS-902f64b6-6377-4885-860f-ecec9028319a,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-03b2762e-051a-4275-9d3a-9ac52c2f159b,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-5e3143a7-f3ba-4909-94d2-84bb2a66a037,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-bc67e929-f0e1-4898-b90a-93389d2d91e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-b1752d17-0ab3-427d-937e-d3cf3864aff9,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-62fdffc6-cc59-4779-b264-50e3e25f5ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-5fe813ca-2d68-40cb-858c-a0dada9fe9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-55278d4a-9b20-4902-9731-20897d0dca84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5116
