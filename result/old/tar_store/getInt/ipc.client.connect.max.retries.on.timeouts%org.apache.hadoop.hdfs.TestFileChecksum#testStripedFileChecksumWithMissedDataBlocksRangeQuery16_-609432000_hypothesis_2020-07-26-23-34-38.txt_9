reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821172745-172.17.0.14-1595807125414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35104,DS-b8db3dd0-430f-48a4-8e00-27159be7ec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-2c595c3a-ac15-45bc-bca9-3ef8000319bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-2305392d-2078-48da-9e18-75d1372e6935,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-e0efef16-5663-43ff-9c24-de2ef3e1c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-a0ee7cdc-8b2d-4ba8-bcad-3142b94653e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-54ff924d-6ed9-4314-8459-c4f23bf2b5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-0c9f858d-e764-4670-85b3-a76bf7ec3ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-8e98ba48-4f14-4339-921d-59c9d7ca943e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821172745-172.17.0.14-1595807125414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35104,DS-b8db3dd0-430f-48a4-8e00-27159be7ec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-2c595c3a-ac15-45bc-bca9-3ef8000319bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-2305392d-2078-48da-9e18-75d1372e6935,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-e0efef16-5663-43ff-9c24-de2ef3e1c0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37561,DS-a0ee7cdc-8b2d-4ba8-bcad-3142b94653e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-54ff924d-6ed9-4314-8459-c4f23bf2b5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-0c9f858d-e764-4670-85b3-a76bf7ec3ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-8e98ba48-4f14-4339-921d-59c9d7ca943e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702443761-172.17.0.14-1595807290471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37492,DS-35e06def-6961-4f27-92b4-35ebb3f9f0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-30c003c0-9cab-4d12-84bd-41d2d076e4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-4d7d9512-4bae-4b32-a1d5-206de8c6e643,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-fbd93bb0-92d8-45bf-9a2c-88a3dc60222c,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-f0a1add8-c34d-4771-bd7a-128d9eeb0a34,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-1533b25c-5e04-44ce-8c34-e65117dfb18c,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-653b1e8a-6388-46c3-a207-56ccd2cd25bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-9cfc81fc-f478-4356-97f6-faa688c7f499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702443761-172.17.0.14-1595807290471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37492,DS-35e06def-6961-4f27-92b4-35ebb3f9f0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-30c003c0-9cab-4d12-84bd-41d2d076e4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-4d7d9512-4bae-4b32-a1d5-206de8c6e643,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-fbd93bb0-92d8-45bf-9a2c-88a3dc60222c,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-f0a1add8-c34d-4771-bd7a-128d9eeb0a34,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-1533b25c-5e04-44ce-8c34-e65117dfb18c,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-653b1e8a-6388-46c3-a207-56ccd2cd25bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-9cfc81fc-f478-4356-97f6-faa688c7f499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486934507-172.17.0.14-1595807582458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41841,DS-8407c1a9-e762-443c-a545-4fb392a1047b,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-117fe98b-328f-482b-9852-505597480c06,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-6f9e3c42-4337-4157-a3aa-e88e9e77c704,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-758085f0-e1ae-4a56-9cad-e03a448b86b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-b5223b60-8a67-487f-a01f-0ce23f860b97,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-4adb49cf-d04b-414a-b7a6-62a8454f28b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-f3852584-650d-42d2-9eb1-f8337358eca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-18c988bf-bf44-45b1-914a-bec6e2647da5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1486934507-172.17.0.14-1595807582458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41841,DS-8407c1a9-e762-443c-a545-4fb392a1047b,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-117fe98b-328f-482b-9852-505597480c06,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-6f9e3c42-4337-4157-a3aa-e88e9e77c704,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-758085f0-e1ae-4a56-9cad-e03a448b86b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-b5223b60-8a67-487f-a01f-0ce23f860b97,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-4adb49cf-d04b-414a-b7a6-62a8454f28b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-f3852584-650d-42d2-9eb1-f8337358eca0,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-18c988bf-bf44-45b1-914a-bec6e2647da5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133975483-172.17.0.14-1595807843114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40379,DS-2f1ed3d1-ed65-4461-a1f4-b549bebbed03,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-227c100c-ea00-4641-a286-73ae7a343029,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-078015c7-2812-4675-99d7-7c21bb37d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-9670841f-d6da-496f-98c3-7cf94cca289d,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-560d792b-af51-4b0e-ac1a-637fbfa35d59,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-fd7d0961-05c5-41c8-a642-a351ef676d72,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-afc586e7-57a2-416b-8ae1-7a36f228ab7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-9440d454-5578-4817-bd3d-022dc382f4d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2133975483-172.17.0.14-1595807843114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40379,DS-2f1ed3d1-ed65-4461-a1f4-b549bebbed03,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-227c100c-ea00-4641-a286-73ae7a343029,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-078015c7-2812-4675-99d7-7c21bb37d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-9670841f-d6da-496f-98c3-7cf94cca289d,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-560d792b-af51-4b0e-ac1a-637fbfa35d59,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-fd7d0961-05c5-41c8-a642-a351ef676d72,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-afc586e7-57a2-416b-8ae1-7a36f228ab7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-9440d454-5578-4817-bd3d-022dc382f4d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224470342-172.17.0.14-1595808279329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45934,DS-448cd338-7a06-42aa-af81-7dd9fcdc2986,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-080f5a0e-2ee3-4f69-92a9-962b9cd32226,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-bd5b24de-56e7-4544-b873-1c525a144ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-c2fee342-2ebe-4cb6-a983-c549e3bd79ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-1cf152ce-d7a4-42b0-a019-ad38cea05cca,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-6efe78e1-cae0-491b-96af-23a90c337bce,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-329c3c74-548a-45fd-bbf3-f4330aadcae6,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-067fac1f-9c7d-48b3-8310-5b2e0349d32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224470342-172.17.0.14-1595808279329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45934,DS-448cd338-7a06-42aa-af81-7dd9fcdc2986,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-080f5a0e-2ee3-4f69-92a9-962b9cd32226,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-bd5b24de-56e7-4544-b873-1c525a144ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-c2fee342-2ebe-4cb6-a983-c549e3bd79ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-1cf152ce-d7a4-42b0-a019-ad38cea05cca,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-6efe78e1-cae0-491b-96af-23a90c337bce,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-329c3c74-548a-45fd-bbf3-f4330aadcae6,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-067fac1f-9c7d-48b3-8310-5b2e0349d32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593961171-172.17.0.14-1595808592758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38681,DS-59f02304-1057-4c1f-9ee8-5005902f6e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-610ba371-c763-44ee-b8a4-af5b3336144d,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-97fab506-a825-41cc-90ba-cb5a54c398ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-21b85824-7bad-4d08-9c98-b44ef90bca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-2eeeadc4-b931-4b51-872f-5739a6a90f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-77e3a16d-ae77-408b-ad43-02187f5e64d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-c8185166-0f7e-441b-9bfe-b7a36b5ee010,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-e61ca489-787e-4e25-8071-a49ff5a1f40c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593961171-172.17.0.14-1595808592758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38681,DS-59f02304-1057-4c1f-9ee8-5005902f6e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-610ba371-c763-44ee-b8a4-af5b3336144d,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-97fab506-a825-41cc-90ba-cb5a54c398ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-21b85824-7bad-4d08-9c98-b44ef90bca5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-2eeeadc4-b931-4b51-872f-5739a6a90f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-77e3a16d-ae77-408b-ad43-02187f5e64d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-c8185166-0f7e-441b-9bfe-b7a36b5ee010,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-e61ca489-787e-4e25-8071-a49ff5a1f40c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706879722-172.17.0.14-1595808665703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35705,DS-baee120d-3e1d-4952-806d-35de0e2ab042,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-bc82227b-4150-489d-8fc9-001288fd0d76,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-26f7dce7-7c76-4122-ac5d-10880df52eab,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-d313ae17-8f75-42d3-90b0-b05cf8b7635c,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-ee51e184-bf70-4653-9222-0d7cd1941de6,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-2f7385c6-7551-4b1e-8dc6-60384f580049,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-5a5f14ed-6849-4cd8-a58f-b6904f944143,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-d64037a5-1944-4959-9d31-e7b70f15dc3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706879722-172.17.0.14-1595808665703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35705,DS-baee120d-3e1d-4952-806d-35de0e2ab042,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-bc82227b-4150-489d-8fc9-001288fd0d76,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-26f7dce7-7c76-4122-ac5d-10880df52eab,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-d313ae17-8f75-42d3-90b0-b05cf8b7635c,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-ee51e184-bf70-4653-9222-0d7cd1941de6,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-2f7385c6-7551-4b1e-8dc6-60384f580049,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-5a5f14ed-6849-4cd8-a58f-b6904f944143,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-d64037a5-1944-4959-9d31-e7b70f15dc3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955063452-172.17.0.14-1595808737133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44939,DS-12617fb8-32e9-4cbc-9daf-f02018623cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-b940a9d0-8807-4c24-9b50-a17b49f5304a,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-a7a19cab-2847-4a6b-91b7-892fd08ca30e,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-1b31ebf8-3a28-445c-87fc-7f1a2462b341,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-3bb5e91a-8564-4ffa-a48b-90a110e71b49,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-a02da0b4-adb1-4ee0-959b-693b29ca18dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-71e059ce-93f1-4d8b-9f1f-d7e9c8674b74,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-96709c8b-c478-47f3-9e28-aa44cbd47480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955063452-172.17.0.14-1595808737133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44939,DS-12617fb8-32e9-4cbc-9daf-f02018623cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-b940a9d0-8807-4c24-9b50-a17b49f5304a,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-a7a19cab-2847-4a6b-91b7-892fd08ca30e,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-1b31ebf8-3a28-445c-87fc-7f1a2462b341,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-3bb5e91a-8564-4ffa-a48b-90a110e71b49,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-a02da0b4-adb1-4ee0-959b-693b29ca18dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-71e059ce-93f1-4d8b-9f1f-d7e9c8674b74,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-96709c8b-c478-47f3-9e28-aa44cbd47480,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294882755-172.17.0.14-1595808985222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44033,DS-a874e2c3-bc46-4123-8409-a304cbf1d614,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-1906b746-5792-4e03-8bd2-390f662171bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-ba1adae4-8e37-40f4-ba35-62935cd57203,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-33b18f95-4b59-49bb-82e6-e5033aae1d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-eda1f62a-867b-482c-aab1-d0ecb1da4464,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-3f0584d8-c4d7-4299-b0f5-13be605ce1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-561cc7e1-05b8-4fba-b511-eb6855138053,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-0e1badf0-c924-4f60-bd8c-49c872855249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294882755-172.17.0.14-1595808985222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44033,DS-a874e2c3-bc46-4123-8409-a304cbf1d614,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-1906b746-5792-4e03-8bd2-390f662171bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-ba1adae4-8e37-40f4-ba35-62935cd57203,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-33b18f95-4b59-49bb-82e6-e5033aae1d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-eda1f62a-867b-482c-aab1-d0ecb1da4464,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-3f0584d8-c4d7-4299-b0f5-13be605ce1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40488,DS-561cc7e1-05b8-4fba-b511-eb6855138053,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-0e1badf0-c924-4f60-bd8c-49c872855249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954887584-172.17.0.14-1595809249262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34382,DS-48e46c2b-982b-4ca9-a170-96173eb63f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-26664e5c-e370-4a28-9bed-1644f14df776,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-ecb03feb-242d-4278-bd22-f1b7678900a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-7040419c-c3f4-4c73-9e62-35ba3da1e7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-034a7da6-0fb4-49c7-8e29-abde8a670ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-5e9b07c1-23f4-4b21-8048-b5394bb097bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-18a0d5a0-380c-444e-8203-5c3af6d23e88,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-f450cc7a-85b5-4097-87f3-05bc9be1f9b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954887584-172.17.0.14-1595809249262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34382,DS-48e46c2b-982b-4ca9-a170-96173eb63f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-26664e5c-e370-4a28-9bed-1644f14df776,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-ecb03feb-242d-4278-bd22-f1b7678900a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-7040419c-c3f4-4c73-9e62-35ba3da1e7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-034a7da6-0fb4-49c7-8e29-abde8a670ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-5e9b07c1-23f4-4b21-8048-b5394bb097bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-18a0d5a0-380c-444e-8203-5c3af6d23e88,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-f450cc7a-85b5-4097-87f3-05bc9be1f9b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1260556208-172.17.0.14-1595809288328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40783,DS-78561009-8772-494b-b034-f0363ce5a9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-c1feac91-90e9-45df-aa22-aaa4269b4cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-aa8f4b37-bf18-4082-9387-1aacbd5f961f,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-f84649e1-71a3-42ec-a6ff-a51ef127c1da,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-a83a5353-d584-4d63-b8e1-be67ccb2e45a,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-d377ee77-3e03-4385-93a6-13b0b5fc870a,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-a0b14a71-b09e-4633-aea6-4f988706b620,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-4f3d1da0-1fa0-41f2-b0f6-fc9f6e34feb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1260556208-172.17.0.14-1595809288328:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40783,DS-78561009-8772-494b-b034-f0363ce5a9ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-c1feac91-90e9-45df-aa22-aaa4269b4cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-aa8f4b37-bf18-4082-9387-1aacbd5f961f,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-f84649e1-71a3-42ec-a6ff-a51ef127c1da,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-a83a5353-d584-4d63-b8e1-be67ccb2e45a,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-d377ee77-3e03-4385-93a6-13b0b5fc870a,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-a0b14a71-b09e-4633-aea6-4f988706b620,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-4f3d1da0-1fa0-41f2-b0f6-fc9f6e34feb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580029285-172.17.0.14-1595809392225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38108,DS-0032f421-3810-4117-8e52-e7c420bc2e09,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-dc9e79e5-ff8b-4686-bb1a-692d329f960a,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-859c97dc-f50f-4c30-bf75-0e0ff386df92,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-688f0523-d876-41d9-9eac-8489578a234f,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-52103b8d-a44a-4dc4-b2bd-63267d785492,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-5a669e94-7d74-44c1-b536-12ff05e48a06,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-c9b6bef6-0501-4aab-87a4-bdac137c7839,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-4c14ee9a-268b-4b8f-829a-a6a9a42706f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580029285-172.17.0.14-1595809392225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38108,DS-0032f421-3810-4117-8e52-e7c420bc2e09,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-dc9e79e5-ff8b-4686-bb1a-692d329f960a,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-859c97dc-f50f-4c30-bf75-0e0ff386df92,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-688f0523-d876-41d9-9eac-8489578a234f,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-52103b8d-a44a-4dc4-b2bd-63267d785492,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-5a669e94-7d74-44c1-b536-12ff05e48a06,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-c9b6bef6-0501-4aab-87a4-bdac137c7839,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-4c14ee9a-268b-4b8f-829a-a6a9a42706f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867077122-172.17.0.14-1595809502643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36147,DS-1f3c2106-74b5-49b3-b587-bd1db3a380fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-80a931a8-cd7c-49fc-bcf6-24930d8ccc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-544d1c59-66b1-4647-8c14-d3cbd086a2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-8e884e39-bc39-4e6f-9bfe-b9cb19c0d68a,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-3d48434f-fc6c-4fec-ae57-029c30a93cda,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-dd3cd342-54d8-4531-89d6-abd634cc6bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-3d92d949-78d4-47f5-ab2d-35a02e59af4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-5467ee81-5a59-4fd9-815e-ee492bce4d9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867077122-172.17.0.14-1595809502643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36147,DS-1f3c2106-74b5-49b3-b587-bd1db3a380fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-80a931a8-cd7c-49fc-bcf6-24930d8ccc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-544d1c59-66b1-4647-8c14-d3cbd086a2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-8e884e39-bc39-4e6f-9bfe-b9cb19c0d68a,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-3d48434f-fc6c-4fec-ae57-029c30a93cda,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-dd3cd342-54d8-4531-89d6-abd634cc6bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34647,DS-3d92d949-78d4-47f5-ab2d-35a02e59af4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-5467ee81-5a59-4fd9-815e-ee492bce4d9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918255813-172.17.0.14-1595809848208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36008,DS-498074ff-af53-47f1-ba52-48265f53c67e,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-69cf53a6-db2c-45ec-90bf-c5784100463f,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-ca1c216d-456c-439d-82ce-069b5e564405,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-e139f41a-d3c4-41f8-ae94-19072dc9baa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-fcdffa08-f45d-48d7-83de-6ec4b9ea1cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-169241de-1ccc-482f-bbcc-18bbcc5b8471,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-14ad58ea-5e96-4b94-ab3c-4eb52644539d,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-9336d0a7-39fd-4ded-a935-c1df1ddfcd25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918255813-172.17.0.14-1595809848208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36008,DS-498074ff-af53-47f1-ba52-48265f53c67e,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-69cf53a6-db2c-45ec-90bf-c5784100463f,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-ca1c216d-456c-439d-82ce-069b5e564405,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-e139f41a-d3c4-41f8-ae94-19072dc9baa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-fcdffa08-f45d-48d7-83de-6ec4b9ea1cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-169241de-1ccc-482f-bbcc-18bbcc5b8471,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-14ad58ea-5e96-4b94-ab3c-4eb52644539d,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-9336d0a7-39fd-4ded-a935-c1df1ddfcd25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-180291995-172.17.0.14-1595810572414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36502,DS-e50e99b9-0a2c-41ff-8057-0b09b69b6415,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-39731d06-de90-437e-852c-13e948cd92f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-aab1095b-ee0b-42fa-b314-0994410483d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-96bf3e52-0541-4a66-a4a4-7fb8a2afb4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-d53bde79-35a4-48a0-8e6a-f23181d576ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-5e467cad-05fa-48c0-b838-0914adf26ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-d779db67-9e9c-4512-b6ae-76c78665092e,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-259645e5-f930-4ad9-8a9e-94a01c935be5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-180291995-172.17.0.14-1595810572414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36502,DS-e50e99b9-0a2c-41ff-8057-0b09b69b6415,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-39731d06-de90-437e-852c-13e948cd92f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-aab1095b-ee0b-42fa-b314-0994410483d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-96bf3e52-0541-4a66-a4a4-7fb8a2afb4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-d53bde79-35a4-48a0-8e6a-f23181d576ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-5e467cad-05fa-48c0-b838-0914adf26ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-d779db67-9e9c-4512-b6ae-76c78665092e,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-259645e5-f930-4ad9-8a9e-94a01c935be5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325002752-172.17.0.14-1595810716015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36984,DS-ba34b577-f8c2-47f9-bd13-f623cae6c9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-a9f6d94c-0125-4488-96be-b58cc1e067b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-170f5761-fe54-43c2-9f73-4b4466cd7125,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-6fcd65be-a5f2-400b-a71d-4d749d915c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-f87fa6e7-ff26-4fb7-8d54-6f12d4ae258f,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-31f3efc5-37fd-4d59-8be2-12893b8061c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-9d2b8431-5454-4d5c-9d6a-8860c616a72a,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-d7aa9df6-e18c-42e5-bd77-c2d443e89215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325002752-172.17.0.14-1595810716015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36984,DS-ba34b577-f8c2-47f9-bd13-f623cae6c9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-a9f6d94c-0125-4488-96be-b58cc1e067b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-170f5761-fe54-43c2-9f73-4b4466cd7125,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-6fcd65be-a5f2-400b-a71d-4d749d915c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-f87fa6e7-ff26-4fb7-8d54-6f12d4ae258f,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-31f3efc5-37fd-4d59-8be2-12893b8061c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-9d2b8431-5454-4d5c-9d6a-8860c616a72a,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-d7aa9df6-e18c-42e5-bd77-c2d443e89215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019781591-172.17.0.14-1595810902221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46400,DS-0cce886c-11b7-433f-a5ad-8ce8f1f46979,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-8b6f0811-3fbb-4e43-ba30-a1abe89d4070,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-5bb42092-047b-4e41-8332-b09321c288c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-3c574c9a-cf90-4aad-8882-68ee5c344563,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-bc01c058-03f2-46d1-b3d6-f254f148d0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-750d873e-0bad-45b7-b9dd-7fc73ce6883b,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-00c04bc9-72af-4060-b7bc-a9f89aea96f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-80292a88-c929-49f7-89ff-42903d207aed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019781591-172.17.0.14-1595810902221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46400,DS-0cce886c-11b7-433f-a5ad-8ce8f1f46979,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-8b6f0811-3fbb-4e43-ba30-a1abe89d4070,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-5bb42092-047b-4e41-8332-b09321c288c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-3c574c9a-cf90-4aad-8882-68ee5c344563,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-bc01c058-03f2-46d1-b3d6-f254f148d0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39997,DS-750d873e-0bad-45b7-b9dd-7fc73ce6883b,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-00c04bc9-72af-4060-b7bc-a9f89aea96f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-80292a88-c929-49f7-89ff-42903d207aed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672425796-172.17.0.14-1595810940414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33612,DS-1f8b55c5-cb3d-4db0-8100-bb51210d0762,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-a146bbce-e5bf-479d-8f27-53ce24803890,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-2072e83c-4088-4e31-9344-697b1788e014,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-e5095552-58e4-42fc-aebe-1e6a870c11d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-c9fb9409-0283-4c62-9a2c-92d0115e12a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-658ece9b-6f73-4252-b6fe-a7834ac7fcab,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-de245c5b-ecc6-4b1c-ac4a-0f20fd1013ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-df6abf3b-9e2c-4468-be10-508fda187fe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1672425796-172.17.0.14-1595810940414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33612,DS-1f8b55c5-cb3d-4db0-8100-bb51210d0762,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-a146bbce-e5bf-479d-8f27-53ce24803890,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-2072e83c-4088-4e31-9344-697b1788e014,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-e5095552-58e4-42fc-aebe-1e6a870c11d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-c9fb9409-0283-4c62-9a2c-92d0115e12a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-658ece9b-6f73-4252-b6fe-a7834ac7fcab,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-de245c5b-ecc6-4b1c-ac4a-0f20fd1013ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-df6abf3b-9e2c-4468-be10-508fda187fe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387813028-172.17.0.14-1595811229575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33787,DS-24e5bd31-6d9f-442a-ba60-42c19db96065,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-6b85c384-ae62-4928-8f35-a7da0238f212,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-f66b1fc8-c634-4463-a814-84fbcc345ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-42bf7754-53ab-4d14-8de4-8d603f12a8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-8db3cb4c-e3d6-4fc7-aceb-df6b85c670c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-cfa33e40-8685-4b71-ad70-1a8761eab282,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-f0dbc424-64ab-41eb-9505-5c543bde22cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-95e50d18-f525-41f1-a0a7-97490a0f7fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387813028-172.17.0.14-1595811229575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33787,DS-24e5bd31-6d9f-442a-ba60-42c19db96065,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-6b85c384-ae62-4928-8f35-a7da0238f212,DISK], DatanodeInfoWithStorage[127.0.0.1:39895,DS-f66b1fc8-c634-4463-a814-84fbcc345ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-42bf7754-53ab-4d14-8de4-8d603f12a8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-8db3cb4c-e3d6-4fc7-aceb-df6b85c670c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-cfa33e40-8685-4b71-ad70-1a8761eab282,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-f0dbc424-64ab-41eb-9505-5c543bde22cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-95e50d18-f525-41f1-a0a7-97490a0f7fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563630924-172.17.0.14-1595811753884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-534f14a8-bb45-43b8-86b4-d641bdadf43d,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-4dfa6686-36bb-4484-a4db-b7de933cf16f,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-213fc31b-e238-4b9c-9be6-085355965aca,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-30e3b853-ae27-4f24-9da1-ed9c6977b88b,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-b60cc6f8-280b-4731-b42c-eb99816155bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-0496a12d-8e04-4711-b9ee-42b0bd733df9,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-3d41fef6-6f49-43a0-b68e-28e4be755b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-27538505-1626-48c4-be82-57226101663b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-563630924-172.17.0.14-1595811753884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-534f14a8-bb45-43b8-86b4-d641bdadf43d,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-4dfa6686-36bb-4484-a4db-b7de933cf16f,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-213fc31b-e238-4b9c-9be6-085355965aca,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-30e3b853-ae27-4f24-9da1-ed9c6977b88b,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-b60cc6f8-280b-4731-b42c-eb99816155bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-0496a12d-8e04-4711-b9ee-42b0bd733df9,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-3d41fef6-6f49-43a0-b68e-28e4be755b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42813,DS-27538505-1626-48c4-be82-57226101663b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 10
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537836003-172.17.0.14-1595811788026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38526,DS-7d8a164b-8b67-409e-a261-5c9df2d62d03,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-d5ade22b-f23b-4b5f-b5f8-4c271870a0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-f1f86698-3c6f-42f9-bb83-55313ed481f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-9fedf461-7b4f-4eec-a6aa-1f133cffca2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-3155eae0-4f1a-4fdc-a4b5-542922bcdf68,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-0001089e-d1f5-42c5-a1b9-3021e98d4dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-9b408812-1e54-4f8a-9fe5-44d03e795c11,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-e5a386b5-17b8-4409-a1be-4b188c7fe57e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-537836003-172.17.0.14-1595811788026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38526,DS-7d8a164b-8b67-409e-a261-5c9df2d62d03,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-d5ade22b-f23b-4b5f-b5f8-4c271870a0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-f1f86698-3c6f-42f9-bb83-55313ed481f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-9fedf461-7b4f-4eec-a6aa-1f133cffca2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-3155eae0-4f1a-4fdc-a4b5-542922bcdf68,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-0001089e-d1f5-42c5-a1b9-3021e98d4dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-9b408812-1e54-4f8a-9fe5-44d03e795c11,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-e5a386b5-17b8-4409-a1be-4b188c7fe57e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5403
