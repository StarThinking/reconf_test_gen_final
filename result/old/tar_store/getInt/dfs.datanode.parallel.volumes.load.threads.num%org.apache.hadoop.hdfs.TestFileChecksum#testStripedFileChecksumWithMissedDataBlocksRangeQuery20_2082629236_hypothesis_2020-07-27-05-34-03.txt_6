reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1418627460-172.17.0.13-1595828501441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43653,DS-a8ef34e1-e78d-4452-9b94-c30ec520a1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-59bce075-a04a-42fb-a341-b4dce512d212,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-d7c27ce9-278b-4914-9970-922e085c8155,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-1d319ac5-0de6-4341-a9a3-3e5022ec5fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-25b6b3c8-c593-4ccd-bcfc-5d942af435ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-3c6703b8-111b-4f62-ae23-ff48b7f844cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-6bef60ca-f4aa-4b15-9a28-e0464172ab41,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-ae639159-115d-4712-8204-ace7fdd5677f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1418627460-172.17.0.13-1595828501441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43653,DS-a8ef34e1-e78d-4452-9b94-c30ec520a1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-59bce075-a04a-42fb-a341-b4dce512d212,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-d7c27ce9-278b-4914-9970-922e085c8155,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-1d319ac5-0de6-4341-a9a3-3e5022ec5fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-25b6b3c8-c593-4ccd-bcfc-5d942af435ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46540,DS-3c6703b8-111b-4f62-ae23-ff48b7f844cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-6bef60ca-f4aa-4b15-9a28-e0464172ab41,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-ae639159-115d-4712-8204-ace7fdd5677f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-44428298-172.17.0.13-1595828717135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37771,DS-a48a88a2-c058-4929-a440-f674c6815750,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-ac45080d-90ca-4572-b7ef-dcb7b7f9cff9,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-4c6de76e-dbef-4bc9-b342-47e85de85dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-5681b900-b624-4ab5-87dd-0e2c3ed566cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-4afa0361-f0fc-434b-b7f5-0008928665f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-b5a873b4-2c51-4a5c-bb66-cc6af0543867,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-69156469-e720-4c7d-adf5-73f3a47cc294,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-568b1223-c6b1-40b0-b296-42ff7c2be500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-44428298-172.17.0.13-1595828717135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37771,DS-a48a88a2-c058-4929-a440-f674c6815750,DISK], DatanodeInfoWithStorage[127.0.0.1:43981,DS-ac45080d-90ca-4572-b7ef-dcb7b7f9cff9,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-4c6de76e-dbef-4bc9-b342-47e85de85dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-5681b900-b624-4ab5-87dd-0e2c3ed566cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-4afa0361-f0fc-434b-b7f5-0008928665f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-b5a873b4-2c51-4a5c-bb66-cc6af0543867,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-69156469-e720-4c7d-adf5-73f3a47cc294,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-568b1223-c6b1-40b0-b296-42ff7c2be500,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529747420-172.17.0.13-1595829772446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38530,DS-8b7e189f-17c2-493b-b232-17afd7c38ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-49749f28-6db2-4008-a892-78ddba5de6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-7f43666a-4eef-4391-8d00-ebc2a744082d,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-edd1bd7c-9f18-4626-a604-c5c74fe3d90d,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-52bface4-587e-4e81-b9af-ef389857377a,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-b0555a48-6708-4f86-b8c3-3e4366dff1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-462d038c-be19-4e2f-a447-0dd456224bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-3507efd3-e461-4d49-b42d-16b4c5bb07bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1529747420-172.17.0.13-1595829772446:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38530,DS-8b7e189f-17c2-493b-b232-17afd7c38ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-49749f28-6db2-4008-a892-78ddba5de6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-7f43666a-4eef-4391-8d00-ebc2a744082d,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-edd1bd7c-9f18-4626-a604-c5c74fe3d90d,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-52bface4-587e-4e81-b9af-ef389857377a,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-b0555a48-6708-4f86-b8c3-3e4366dff1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-462d038c-be19-4e2f-a447-0dd456224bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-3507efd3-e461-4d49-b42d-16b4c5bb07bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919878431-172.17.0.13-1595829946713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40934,DS-6f2e2669-85dd-45fd-b742-f9d61becc2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-875e2734-9443-43d6-ab33-95c2f95e076b,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-c7d05c16-43af-442d-8b87-54f83812ff45,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-5de346c7-9c06-4f94-b0ee-1a5164dd00de,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-f3d9bc91-dad1-42c8-be4d-41449364ec9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-bb388982-a32d-4dc2-b501-86dbc37b0741,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-60da0a46-1692-44c1-95f4-0160dd1fbfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-e15d8d8f-7b8a-4b2c-94f1-12c8b34acfba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919878431-172.17.0.13-1595829946713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40934,DS-6f2e2669-85dd-45fd-b742-f9d61becc2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-875e2734-9443-43d6-ab33-95c2f95e076b,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-c7d05c16-43af-442d-8b87-54f83812ff45,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-5de346c7-9c06-4f94-b0ee-1a5164dd00de,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-f3d9bc91-dad1-42c8-be4d-41449364ec9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-bb388982-a32d-4dc2-b501-86dbc37b0741,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-60da0a46-1692-44c1-95f4-0160dd1fbfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-e15d8d8f-7b8a-4b2c-94f1-12c8b34acfba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1576861475-172.17.0.13-1595829985629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43831,DS-67fd48ba-b54e-4499-af50-eaaf7459b8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-bf678022-a833-4209-bfbc-0ee04cd0b753,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-d41d34fe-e824-47f8-bc67-5a6388e1479b,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-3186753c-d584-481f-b23e-53dfa76f18ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-cbf63f49-fcfc-44f1-b5da-4a1562ddd2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-a849e8fd-690e-412b-9337-76940ce9ea0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-4e9d709d-5d31-4ff9-8d72-0d36fb725e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-85fb10b0-8d8c-4187-a5e0-79bdb38ba222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1576861475-172.17.0.13-1595829985629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43831,DS-67fd48ba-b54e-4499-af50-eaaf7459b8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-bf678022-a833-4209-bfbc-0ee04cd0b753,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-d41d34fe-e824-47f8-bc67-5a6388e1479b,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-3186753c-d584-481f-b23e-53dfa76f18ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-cbf63f49-fcfc-44f1-b5da-4a1562ddd2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-a849e8fd-690e-412b-9337-76940ce9ea0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44204,DS-4e9d709d-5d31-4ff9-8d72-0d36fb725e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-85fb10b0-8d8c-4187-a5e0-79bdb38ba222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385463480-172.17.0.13-1595830129929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36521,DS-9533b581-7542-415a-b778-2a40669b19cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-1fe3ff47-56fb-4dfc-b716-0092b54229f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-117388f5-bc48-4c82-a67a-97234fc66eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-98c1afeb-1ea8-4dde-9fdb-a0c400c2ab31,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-024ed883-2d7f-47cd-8c25-bea388435995,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-ba4ac82e-f250-4233-b768-699540945ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-c25755b4-72fc-4d99-808f-09463a3fb4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-f0a36cb2-5e04-4a92-a3f7-684a56daab3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385463480-172.17.0.13-1595830129929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36521,DS-9533b581-7542-415a-b778-2a40669b19cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-1fe3ff47-56fb-4dfc-b716-0092b54229f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-117388f5-bc48-4c82-a67a-97234fc66eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-98c1afeb-1ea8-4dde-9fdb-a0c400c2ab31,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-024ed883-2d7f-47cd-8c25-bea388435995,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-ba4ac82e-f250-4233-b768-699540945ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-c25755b4-72fc-4d99-808f-09463a3fb4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-f0a36cb2-5e04-4a92-a3f7-684a56daab3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198706478-172.17.0.13-1595830656875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43965,DS-7b63464d-93b1-480f-9abb-8bfb67a36c36,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-f24aed9c-ec74-42d5-8595-30f618b088fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-354449a6-1294-4a21-bf44-18175c3893d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-9c3183ff-ba08-4a6c-8e3a-a7b2a4256356,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-d3c8b6ff-818d-4801-836d-bfeb3da37845,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-2566cce2-e6b5-4695-9590-2a9e16b9a689,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-574f1ae1-ecb1-43c2-ac7d-6385350edcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-1a17bd8c-3d8d-4f50-a694-f8e3031b5be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198706478-172.17.0.13-1595830656875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43965,DS-7b63464d-93b1-480f-9abb-8bfb67a36c36,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-f24aed9c-ec74-42d5-8595-30f618b088fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-354449a6-1294-4a21-bf44-18175c3893d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-9c3183ff-ba08-4a6c-8e3a-a7b2a4256356,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-d3c8b6ff-818d-4801-836d-bfeb3da37845,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-2566cce2-e6b5-4695-9590-2a9e16b9a689,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-574f1ae1-ecb1-43c2-ac7d-6385350edcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-1a17bd8c-3d8d-4f50-a694-f8e3031b5be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51667321-172.17.0.13-1595830801306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40487,DS-909ceb38-decf-4d8e-b681-33678e3efa42,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-bed458ff-ec95-41b9-9da0-238626038d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-d2b62257-22ac-4b24-9f11-46035c48ec61,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-f05e8c56-adc4-4198-8f6f-3822d63bccc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-a959c9b6-d64b-470e-bc64-7cfe927b6233,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-72dbbe96-380e-4d9d-aecd-41e807e5b4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-9eba4e85-f396-43e2-8ecb-dfa484aaa419,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-9aa1c2c3-89c1-44a3-9995-6d2763f47edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-51667321-172.17.0.13-1595830801306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40487,DS-909ceb38-decf-4d8e-b681-33678e3efa42,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-bed458ff-ec95-41b9-9da0-238626038d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-d2b62257-22ac-4b24-9f11-46035c48ec61,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-f05e8c56-adc4-4198-8f6f-3822d63bccc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-a959c9b6-d64b-470e-bc64-7cfe927b6233,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-72dbbe96-380e-4d9d-aecd-41e807e5b4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-9eba4e85-f396-43e2-8ecb-dfa484aaa419,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-9aa1c2c3-89c1-44a3-9995-6d2763f47edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245098389-172.17.0.13-1595830983788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42354,DS-8df03184-733c-465e-ba0e-7afb537136e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-f50476ef-ada1-47e8-b771-fc1a3cda9adc,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-c1495877-b5a7-4b4d-8578-ebc423542efa,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-8693f548-89e1-4c1f-8b50-1050ab4c451c,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-6bf45261-ec8b-4792-a981-47a0775b3dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-c517d933-9341-4e2b-91e0-c2b73d116b38,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-d7aae5b6-a4be-4d1b-9105-22fab189a882,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-532f3daa-c904-40ad-b12a-96b0f20dfe0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245098389-172.17.0.13-1595830983788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42354,DS-8df03184-733c-465e-ba0e-7afb537136e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-f50476ef-ada1-47e8-b771-fc1a3cda9adc,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-c1495877-b5a7-4b4d-8578-ebc423542efa,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-8693f548-89e1-4c1f-8b50-1050ab4c451c,DISK], DatanodeInfoWithStorage[127.0.0.1:38185,DS-6bf45261-ec8b-4792-a981-47a0775b3dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-c517d933-9341-4e2b-91e0-c2b73d116b38,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-d7aae5b6-a4be-4d1b-9105-22fab189a882,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-532f3daa-c904-40ad-b12a-96b0f20dfe0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271106947-172.17.0.13-1595831016080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39467,DS-80a03622-b5f3-4ee8-88d2-16a721e63ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-56ced455-a883-4071-b9e0-c5ce3db67b03,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-c3d7cd35-6e78-4bee-9709-2d4ae3bc4257,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-2caf9614-df0f-411f-9936-219eae449176,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-a835e282-cd52-4a3e-a003-52aff9a293d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-ed64622a-e136-4f3e-aa47-0624a09c6429,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-5a7ce725-2f1d-42e3-a199-6e1febbf80a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-c1a163ca-b811-407e-b325-b0ca5381bbfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1271106947-172.17.0.13-1595831016080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39467,DS-80a03622-b5f3-4ee8-88d2-16a721e63ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-56ced455-a883-4071-b9e0-c5ce3db67b03,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-c3d7cd35-6e78-4bee-9709-2d4ae3bc4257,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-2caf9614-df0f-411f-9936-219eae449176,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-a835e282-cd52-4a3e-a003-52aff9a293d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-ed64622a-e136-4f3e-aa47-0624a09c6429,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-5a7ce725-2f1d-42e3-a199-6e1febbf80a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-c1a163ca-b811-407e-b325-b0ca5381bbfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111674970-172.17.0.13-1595832185213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38955,DS-6327830e-83cb-4304-bdf8-403bd287747c,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-708d90b0-033a-47f4-9a12-bfbd6b84f988,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-b2e05ce4-d02c-42da-b7c8-5bdc7edaa36b,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-12055d0c-bc3c-44f1-b792-9e2db7450b93,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-c5a92743-5f90-4125-8ac8-5a3f40deac5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-54fb4358-bf75-4c87-ab0b-8dfefbc40661,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-cfc7485c-23a5-495c-ac16-e2e18c91c884,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-02e81d3c-19d9-490b-a6e3-dface43c692e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111674970-172.17.0.13-1595832185213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38955,DS-6327830e-83cb-4304-bdf8-403bd287747c,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-708d90b0-033a-47f4-9a12-bfbd6b84f988,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-b2e05ce4-d02c-42da-b7c8-5bdc7edaa36b,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-12055d0c-bc3c-44f1-b792-9e2db7450b93,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-c5a92743-5f90-4125-8ac8-5a3f40deac5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-54fb4358-bf75-4c87-ab0b-8dfefbc40661,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-cfc7485c-23a5-495c-ac16-e2e18c91c884,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-02e81d3c-19d9-490b-a6e3-dface43c692e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112271530-172.17.0.13-1595832253818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45376,DS-3611c0f9-faa6-4ef4-93c6-8d108a8f67ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-f0d4636c-b82c-4a3f-9ed9-095722018af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-e18b6536-52c0-4761-95f8-518d6d4326ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-46a2618f-092e-4cad-98ab-ddc9e71cb360,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-1535eef8-7d66-48b0-acf7-0bb6fd22cdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-f74187f5-2a43-411a-835b-36c61f5c4c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-71fa4387-0803-4bf7-a93c-b3fc534833b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-3e81ec04-e707-4539-ab3a-e037086687de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112271530-172.17.0.13-1595832253818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45376,DS-3611c0f9-faa6-4ef4-93c6-8d108a8f67ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33032,DS-f0d4636c-b82c-4a3f-9ed9-095722018af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-e18b6536-52c0-4761-95f8-518d6d4326ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-46a2618f-092e-4cad-98ab-ddc9e71cb360,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-1535eef8-7d66-48b0-acf7-0bb6fd22cdc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-f74187f5-2a43-411a-835b-36c61f5c4c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-71fa4387-0803-4bf7-a93c-b3fc534833b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-3e81ec04-e707-4539-ab3a-e037086687de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684066797-172.17.0.13-1595833029668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39804,DS-e97a1b58-7ec3-4355-942c-41a030a701d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-c51dc962-0b63-4452-9974-6ca848663802,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-9ac80922-b3a7-4530-ac4c-664d785a6618,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-2e7100d4-ebbf-451b-82f8-de801bdb2a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-3c8aad2e-d381-4d6a-b4c6-ba6fdd42b9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-a7320122-2262-467a-85f0-f41cb7d21bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-17c575ea-5ff9-43ce-9add-bbb023a15418,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-95641e7c-6a3f-46fa-a535-ee0880b561f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684066797-172.17.0.13-1595833029668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39804,DS-e97a1b58-7ec3-4355-942c-41a030a701d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-c51dc962-0b63-4452-9974-6ca848663802,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-9ac80922-b3a7-4530-ac4c-664d785a6618,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-2e7100d4-ebbf-451b-82f8-de801bdb2a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-3c8aad2e-d381-4d6a-b4c6-ba6fdd42b9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-a7320122-2262-467a-85f0-f41cb7d21bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-17c575ea-5ff9-43ce-9add-bbb023a15418,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-95641e7c-6a3f-46fa-a535-ee0880b561f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034065122-172.17.0.13-1595833068200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34572,DS-0b452ed2-0769-4996-8532-cc2728d76c47,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-c1453ab2-f8e7-4fbb-ad5a-c78d77549249,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-b77d537b-5019-4b4c-90bf-1cc684420cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-dbd0427b-cf39-418d-b1e5-0e2648ebcd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-8fb96a11-e143-4aa4-aa08-9ee63453655e,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-c0e1dafe-b89d-42c0-8c13-147894bb269b,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-06585d7b-2dc1-4303-a0cd-4e71c2f57191,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-1d8513ea-f1ed-428e-a1d1-9ac6403cf0fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034065122-172.17.0.13-1595833068200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34572,DS-0b452ed2-0769-4996-8532-cc2728d76c47,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-c1453ab2-f8e7-4fbb-ad5a-c78d77549249,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-b77d537b-5019-4b4c-90bf-1cc684420cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-dbd0427b-cf39-418d-b1e5-0e2648ebcd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-8fb96a11-e143-4aa4-aa08-9ee63453655e,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-c0e1dafe-b89d-42c0-8c13-147894bb269b,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-06585d7b-2dc1-4303-a0cd-4e71c2f57191,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-1d8513ea-f1ed-428e-a1d1-9ac6403cf0fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944491089-172.17.0.13-1595833171073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46605,DS-24ab1212-0d3b-47b8-8a21-5d01ff07b8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-d74407db-70aa-4d64-a684-270f68032d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-93d86d09-e47d-41ac-b564-098099bb7fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-eed26215-7ce2-48a4-b1e5-b08f7e7fc87a,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-349568cf-0f83-40e6-a82d-0d3638e7b9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-64031be4-3312-41ac-b2b1-4dda307808d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-37ed6b8e-aace-4213-a13f-5dd9ffa57f37,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-bdad51a3-1f80-4676-8cb3-ac004dd74c83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944491089-172.17.0.13-1595833171073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46605,DS-24ab1212-0d3b-47b8-8a21-5d01ff07b8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-d74407db-70aa-4d64-a684-270f68032d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-93d86d09-e47d-41ac-b564-098099bb7fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-eed26215-7ce2-48a4-b1e5-b08f7e7fc87a,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-349568cf-0f83-40e6-a82d-0d3638e7b9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-64031be4-3312-41ac-b2b1-4dda307808d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-37ed6b8e-aace-4213-a13f-5dd9ffa57f37,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-bdad51a3-1f80-4676-8cb3-ac004dd74c83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 2
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1179141713-172.17.0.13-1595833207233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37884,DS-b9eb56df-fb0c-41ea-9c1c-d60f7a266f97,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-c05c4437-329c-4b82-b089-65c04017b055,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-6e90c839-0891-4842-96ef-fc28f1ae2ced,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-e4b4018e-d840-4930-96c1-298faaa5ffe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-c53c1b1d-3198-4600-b44d-1e0580c8beb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-4bc622d1-a11d-46db-9e13-89f334d743b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-6de30820-64f2-42c4-b815-8bc4ab8f1d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-38af338d-5d3d-4674-9731-84cdb1ed06ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1179141713-172.17.0.13-1595833207233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37884,DS-b9eb56df-fb0c-41ea-9c1c-d60f7a266f97,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-c05c4437-329c-4b82-b089-65c04017b055,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-6e90c839-0891-4842-96ef-fc28f1ae2ced,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-e4b4018e-d840-4930-96c1-298faaa5ffe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-c53c1b1d-3198-4600-b44d-1e0580c8beb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-4bc622d1-a11d-46db-9e13-89f334d743b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-6de30820-64f2-42c4-b815-8bc4ab8f1d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-38af338d-5d3d-4674-9731-84cdb1ed06ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5180
