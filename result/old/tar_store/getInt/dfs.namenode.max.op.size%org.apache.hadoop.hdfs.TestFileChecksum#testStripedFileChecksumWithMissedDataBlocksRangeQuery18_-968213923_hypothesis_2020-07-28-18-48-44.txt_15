reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397944696-172.17.0.19-1595962172309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41464,DS-eaa75105-f5cb-437b-a36e-14149d6d911e,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-a1ecec36-250e-4d89-a728-dff65e5f2623,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-a063c63d-7207-4233-8bff-26fafe46cfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-02144b42-47bc-4f43-aa46-fa7d4beab4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-b8d1032a-b736-4c9e-b611-7a6975268be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-fbafe5b7-ab12-4226-9879-fcc76ae8395d,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-1d058cbe-75f2-4019-b6e0-738276fd6aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-d192472a-08eb-435a-8b5c-9fd35782dc73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-397944696-172.17.0.19-1595962172309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41464,DS-eaa75105-f5cb-437b-a36e-14149d6d911e,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-a1ecec36-250e-4d89-a728-dff65e5f2623,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-a063c63d-7207-4233-8bff-26fafe46cfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-02144b42-47bc-4f43-aa46-fa7d4beab4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-b8d1032a-b736-4c9e-b611-7a6975268be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-fbafe5b7-ab12-4226-9879-fcc76ae8395d,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-1d058cbe-75f2-4019-b6e0-738276fd6aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-d192472a-08eb-435a-8b5c-9fd35782dc73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-164961514-172.17.0.19-1595962644889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37715,DS-2b29fdcd-b484-4f69-9c27-f449495f1ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-b6650a05-b7cc-4c6f-a551-cc572b428c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-6a6bbae4-5d81-42cd-b3c0-b1cda5cc17a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-09a3f768-cf04-42b3-ab16-6eb4db9be17f,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-6092e561-9404-4985-a80c-a34d85438007,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-d863fcf1-493c-4941-aa15-30c3338e519a,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-17c134b1-39c8-400e-b521-f127f554ba88,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-3800b311-fead-4833-a757-d60ec55450f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-164961514-172.17.0.19-1595962644889:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37715,DS-2b29fdcd-b484-4f69-9c27-f449495f1ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-b6650a05-b7cc-4c6f-a551-cc572b428c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-6a6bbae4-5d81-42cd-b3c0-b1cda5cc17a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-09a3f768-cf04-42b3-ab16-6eb4db9be17f,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-6092e561-9404-4985-a80c-a34d85438007,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-d863fcf1-493c-4941-aa15-30c3338e519a,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-17c134b1-39c8-400e-b521-f127f554ba88,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-3800b311-fead-4833-a757-d60ec55450f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494485225-172.17.0.19-1595962712694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40478,DS-28aca739-32a6-4b16-ad8d-150e14ab393f,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-2dd36469-b7d4-4e09-a2b6-21ca050dfb01,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-727a8de9-f260-4e94-8226-7a4c6b4649bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-e8916143-ca7f-4da8-b679-e6fa190d1639,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-5ac65b05-f4bc-4284-b8d0-cfed18c7c33d,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-264c47b8-64b4-4d7a-b1e1-80c150647117,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-3042b609-df3b-493c-995c-31fdd24cad15,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-d2191e84-ed1a-460c-b016-cde7810bbd4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494485225-172.17.0.19-1595962712694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40478,DS-28aca739-32a6-4b16-ad8d-150e14ab393f,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-2dd36469-b7d4-4e09-a2b6-21ca050dfb01,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-727a8de9-f260-4e94-8226-7a4c6b4649bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-e8916143-ca7f-4da8-b679-e6fa190d1639,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-5ac65b05-f4bc-4284-b8d0-cfed18c7c33d,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-264c47b8-64b4-4d7a-b1e1-80c150647117,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-3042b609-df3b-493c-995c-31fdd24cad15,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-d2191e84-ed1a-460c-b016-cde7810bbd4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-437042987-172.17.0.19-1595962920247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43036,DS-e7f2da20-72a3-48e3-aa8e-93a1047a9160,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-6cd332b0-1133-48ae-bded-56fbc511eb36,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-1ccf8acd-d838-4a28-83ce-2ed52e1b2e96,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-85cae46f-2ad3-49c0-8102-710ecd0a126c,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-531cfb59-d1ac-49f3-a24d-2499e214a639,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-1fe1e3e1-2004-4c9e-b0e9-e8f0c365ab6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-c55cb007-e115-4b11-8746-e8bac1328d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-d2ac5d5a-3a13-4c52-9dc4-61837b29dac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-437042987-172.17.0.19-1595962920247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43036,DS-e7f2da20-72a3-48e3-aa8e-93a1047a9160,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-6cd332b0-1133-48ae-bded-56fbc511eb36,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-1ccf8acd-d838-4a28-83ce-2ed52e1b2e96,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-85cae46f-2ad3-49c0-8102-710ecd0a126c,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-531cfb59-d1ac-49f3-a24d-2499e214a639,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-1fe1e3e1-2004-4c9e-b0e9-e8f0c365ab6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-c55cb007-e115-4b11-8746-e8bac1328d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-d2ac5d5a-3a13-4c52-9dc4-61837b29dac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435279943-172.17.0.19-1595963252514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-abb228b7-f714-478c-8a7a-b572cfd2e1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-056711cb-19aa-41da-befb-e71443eb0faa,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-57ea176e-1935-4601-8e0b-cfae3cf43ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-edf2f845-6d4e-439d-82bf-af39857c5cba,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-1708336a-f63c-4126-a708-181abf5cb4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-f5fd6232-fa97-4ad9-bec4-1b45a18914b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-3192de3b-b9a8-43c5-9df6-bd85905bb467,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-e4313ac3-e587-49c7-8181-ca0d5c27030a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435279943-172.17.0.19-1595963252514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-abb228b7-f714-478c-8a7a-b572cfd2e1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-056711cb-19aa-41da-befb-e71443eb0faa,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-57ea176e-1935-4601-8e0b-cfae3cf43ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-edf2f845-6d4e-439d-82bf-af39857c5cba,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-1708336a-f63c-4126-a708-181abf5cb4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-f5fd6232-fa97-4ad9-bec4-1b45a18914b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-3192de3b-b9a8-43c5-9df6-bd85905bb467,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-e4313ac3-e587-49c7-8181-ca0d5c27030a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463715276-172.17.0.19-1595963575466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39082,DS-de27faf1-5bcf-4225-a680-088c1dd43792,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-95cb8a48-d01e-40cd-9abf-0dc4e02f513b,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-d9937a27-023a-4d5c-9484-0ac771468470,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-22a5739f-a334-4061-acbd-f5819b84d77a,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-6155ae69-a562-4687-8c67-256751787af9,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-f1f0c49c-029c-4c45-910e-10dfb1964d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-12c05b5c-af58-426b-bf3a-ff1569b3ad79,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-602d37bc-57bf-49e3-a15b-0c17ee0a961c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463715276-172.17.0.19-1595963575466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39082,DS-de27faf1-5bcf-4225-a680-088c1dd43792,DISK], DatanodeInfoWithStorage[127.0.0.1:46133,DS-95cb8a48-d01e-40cd-9abf-0dc4e02f513b,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-d9937a27-023a-4d5c-9484-0ac771468470,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-22a5739f-a334-4061-acbd-f5819b84d77a,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-6155ae69-a562-4687-8c67-256751787af9,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-f1f0c49c-029c-4c45-910e-10dfb1964d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-12c05b5c-af58-426b-bf3a-ff1569b3ad79,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-602d37bc-57bf-49e3-a15b-0c17ee0a961c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1052333501-172.17.0.19-1595963794431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35793,DS-8dd7e5e8-3be3-4866-87eb-aec55724babf,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-df545000-1ab4-4df2-8c52-5968d88b14bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-2d6918e7-71b1-4a7d-a836-8b5f6b129a53,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-9b5ffae0-f7f8-4338-9e7c-319430b8904f,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-41f41ab2-6e02-45dd-aa0c-12444fff8edb,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-9b0f5b17-896e-41ae-9009-20f3c3799636,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-5f845846-8e57-41ba-b819-518f39d453a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-b7c8933a-b0d5-41c2-9691-22205e663b89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1052333501-172.17.0.19-1595963794431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35793,DS-8dd7e5e8-3be3-4866-87eb-aec55724babf,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-df545000-1ab4-4df2-8c52-5968d88b14bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-2d6918e7-71b1-4a7d-a836-8b5f6b129a53,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-9b5ffae0-f7f8-4338-9e7c-319430b8904f,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-41f41ab2-6e02-45dd-aa0c-12444fff8edb,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-9b0f5b17-896e-41ae-9009-20f3c3799636,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-5f845846-8e57-41ba-b819-518f39d453a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-b7c8933a-b0d5-41c2-9691-22205e663b89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053776686-172.17.0.19-1595964492907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42447,DS-3b62ab25-6aab-414e-8eb3-c3a463a1334b,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-df79b6ba-caf3-42eb-a3c4-5a4fd4da72c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-01c78992-fe14-42ec-925a-cc88f733bf49,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-5a454ee1-37c1-439e-8702-e3bc1805b682,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-3ed22a11-6505-43c8-a455-6e8ba9441dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-38e51749-e59e-494b-b665-18d2db61fceb,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-b2c4fd26-2aeb-4186-abaf-a06411ff3565,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-8261ca80-032b-4b2f-87f6-e553266700a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053776686-172.17.0.19-1595964492907:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42447,DS-3b62ab25-6aab-414e-8eb3-c3a463a1334b,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-df79b6ba-caf3-42eb-a3c4-5a4fd4da72c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-01c78992-fe14-42ec-925a-cc88f733bf49,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-5a454ee1-37c1-439e-8702-e3bc1805b682,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-3ed22a11-6505-43c8-a455-6e8ba9441dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-38e51749-e59e-494b-b665-18d2db61fceb,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-b2c4fd26-2aeb-4186-abaf-a06411ff3565,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-8261ca80-032b-4b2f-87f6-e553266700a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668032120-172.17.0.19-1595964964896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46085,DS-6160383c-4aed-4452-884f-7bf188728a70,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-9392face-d6a4-4d6c-863e-457da156c258,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-20321bdc-0735-47eb-a609-f86951a8ebb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-d4947b70-ddc0-4e1d-a051-a047db938785,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-8b9db7fc-b0ec-4c09-bd27-5648a2f40c53,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-adfbec2c-a2c0-4860-a32a-d3fc3b45380d,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-72611671-51aa-4afa-86d6-a9dd47afdfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-8ad21d90-3015-4352-bd25-926b6601aa12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668032120-172.17.0.19-1595964964896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46085,DS-6160383c-4aed-4452-884f-7bf188728a70,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-9392face-d6a4-4d6c-863e-457da156c258,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-20321bdc-0735-47eb-a609-f86951a8ebb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-d4947b70-ddc0-4e1d-a051-a047db938785,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-8b9db7fc-b0ec-4c09-bd27-5648a2f40c53,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-adfbec2c-a2c0-4860-a32a-d3fc3b45380d,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-72611671-51aa-4afa-86d6-a9dd47afdfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-8ad21d90-3015-4352-bd25-926b6601aa12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424082861-172.17.0.19-1595965101076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39375,DS-0241559c-4cd6-41b6-9870-9bcd8a17cdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-335a4719-c36b-49e2-b3b3-19845107d82f,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-1178134e-f43e-4862-8944-5dd2e139bbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-f79a0780-99f7-4e39-a921-1e5080fbc770,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-e669fb75-6506-4868-9344-4e3ad729bd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-7d829bdf-a3b0-4884-97e7-57a1ce38427c,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-d0f29bb9-738c-465e-8288-411769b0f6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-9670219a-9b56-4c00-9090-4e4b05006264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424082861-172.17.0.19-1595965101076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39375,DS-0241559c-4cd6-41b6-9870-9bcd8a17cdc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-335a4719-c36b-49e2-b3b3-19845107d82f,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-1178134e-f43e-4862-8944-5dd2e139bbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-f79a0780-99f7-4e39-a921-1e5080fbc770,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-e669fb75-6506-4868-9344-4e3ad729bd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-7d829bdf-a3b0-4884-97e7-57a1ce38427c,DISK], DatanodeInfoWithStorage[127.0.0.1:40471,DS-d0f29bb9-738c-465e-8288-411769b0f6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-9670219a-9b56-4c00-9090-4e4b05006264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275459189-172.17.0.19-1595965912239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39088,DS-47173497-250d-4dd0-929a-f938d3896f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-6ba5dcaf-13b2-4843-b98b-88515f03e36f,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-dc4b0c0d-5ec5-4a45-a785-6200db5eb032,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-1384fe6b-fcf3-43fb-9bd9-753267d78eba,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-2b9220f2-538d-423e-86a0-839351ce6303,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-c10c46ef-404e-4c10-b60c-5ea9e3b83378,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-38c104a6-3923-46f7-8e98-ba43b7420575,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-82b85f24-70f5-4e3b-b8db-9a7e58d498d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275459189-172.17.0.19-1595965912239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39088,DS-47173497-250d-4dd0-929a-f938d3896f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-6ba5dcaf-13b2-4843-b98b-88515f03e36f,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-dc4b0c0d-5ec5-4a45-a785-6200db5eb032,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-1384fe6b-fcf3-43fb-9bd9-753267d78eba,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-2b9220f2-538d-423e-86a0-839351ce6303,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-c10c46ef-404e-4c10-b60c-5ea9e3b83378,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-38c104a6-3923-46f7-8e98-ba43b7420575,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-82b85f24-70f5-4e3b-b8db-9a7e58d498d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009202383-172.17.0.19-1595966020586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44025,DS-b40ef936-c625-41ae-a348-31fa8cdc26ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-8496f3d4-bf03-4982-aae2-1ed1dcaab7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-0b3b11bc-2cc8-433a-bc18-59d270324ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-6a704167-c74e-45a3-a191-38306938273d,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-c494c649-ddcb-461b-8324-3bdab56cdc47,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-8b54fbc2-84fc-4640-95ab-595cf9c15cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-b2f03b27-e3f5-4af2-914c-87f3fbd85077,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-6c66b013-79be-4ccf-aa46-85b2d2090ca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009202383-172.17.0.19-1595966020586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44025,DS-b40ef936-c625-41ae-a348-31fa8cdc26ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-8496f3d4-bf03-4982-aae2-1ed1dcaab7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-0b3b11bc-2cc8-433a-bc18-59d270324ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-6a704167-c74e-45a3-a191-38306938273d,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-c494c649-ddcb-461b-8324-3bdab56cdc47,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-8b54fbc2-84fc-4640-95ab-595cf9c15cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-b2f03b27-e3f5-4af2-914c-87f3fbd85077,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-6c66b013-79be-4ccf-aa46-85b2d2090ca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59834572-172.17.0.19-1595966425015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40602,DS-a15e6612-bd1e-4c7d-b1ad-7541fb09d4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-a56c40ef-4a89-401e-90a2-346ceab4edcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-d0e4245d-3290-4d96-838e-efd3f4d0aa29,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-94e06d37-63e1-498a-bf92-9179b82e7a05,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-5246ceb8-5b7f-412f-a541-f907b7b472bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-347dfebf-2144-4572-afc1-736beb44233f,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-ea318c5c-dc2a-40b2-bf5d-7650099be605,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-77208cbf-7e8c-434f-8820-a115819a12a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59834572-172.17.0.19-1595966425015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40602,DS-a15e6612-bd1e-4c7d-b1ad-7541fb09d4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-a56c40ef-4a89-401e-90a2-346ceab4edcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-d0e4245d-3290-4d96-838e-efd3f4d0aa29,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-94e06d37-63e1-498a-bf92-9179b82e7a05,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-5246ceb8-5b7f-412f-a541-f907b7b472bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-347dfebf-2144-4572-afc1-736beb44233f,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-ea318c5c-dc2a-40b2-bf5d-7650099be605,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-77208cbf-7e8c-434f-8820-a115819a12a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.op.size
component: hdfs:NameNode
v1: 52428800
v2: 40960
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132599001-172.17.0.19-1595966634845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38632,DS-b71d76c3-de38-4d48-8f71-598c4893e9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-c5faff05-fd31-420f-8bad-25998b301703,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-2b91b2f8-efaa-42b3-803e-73d588c8f242,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-7e87636e-8afa-4b52-9b0c-aeccdb8607f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-1012f9d3-6edc-4ec6-b67d-31100ed08883,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-f25974bb-67de-4541-af47-22c0e7ccfd43,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-813e0297-d8e1-4a7e-8dd3-4f3b26080f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-3ca07590-b5a2-4f8d-b637-587de151ed60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132599001-172.17.0.19-1595966634845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38632,DS-b71d76c3-de38-4d48-8f71-598c4893e9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-c5faff05-fd31-420f-8bad-25998b301703,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-2b91b2f8-efaa-42b3-803e-73d588c8f242,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-7e87636e-8afa-4b52-9b0c-aeccdb8607f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-1012f9d3-6edc-4ec6-b67d-31100ed08883,DISK], DatanodeInfoWithStorage[127.0.0.1:38530,DS-f25974bb-67de-4541-af47-22c0e7ccfd43,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-813e0297-d8e1-4a7e-8dd3-4f3b26080f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-3ca07590-b5a2-4f8d-b637-587de151ed60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5172
