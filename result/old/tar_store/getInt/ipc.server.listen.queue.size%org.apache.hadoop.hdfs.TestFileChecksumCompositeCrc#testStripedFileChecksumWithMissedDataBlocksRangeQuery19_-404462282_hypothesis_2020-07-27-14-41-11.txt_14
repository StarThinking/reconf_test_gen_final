reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812551642-172.17.0.21-1595861119817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-8f86247e-cafc-4c9f-9c0b-241b1c41c6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-0da2f85d-c16e-49e2-bb94-7771633f324a,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-cca055a0-11a2-407a-83f0-3d8d9debcf97,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-050f1f83-587e-46b8-a66b-61207260ccde,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-8e9b222a-6055-4848-bc3e-a9bfb3c6c6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-04a173ac-ef09-411d-ae59-1c952fc384b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-3af1a48f-0202-4734-9086-3cb80d14d3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-b14b1364-72be-4a72-ad74-4f9dd0e03e75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812551642-172.17.0.21-1595861119817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44790,DS-8f86247e-cafc-4c9f-9c0b-241b1c41c6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-0da2f85d-c16e-49e2-bb94-7771633f324a,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-cca055a0-11a2-407a-83f0-3d8d9debcf97,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-050f1f83-587e-46b8-a66b-61207260ccde,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-8e9b222a-6055-4848-bc3e-a9bfb3c6c6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-04a173ac-ef09-411d-ae59-1c952fc384b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-3af1a48f-0202-4734-9086-3cb80d14d3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-b14b1364-72be-4a72-ad74-4f9dd0e03e75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420968532-172.17.0.21-1595861527506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42317,DS-1b8bceaf-6a4d-4184-b901-6cb01fc2a6da,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-3fbf92f2-c457-4aa2-87c3-148b2aad426c,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-8a9d8cbc-d20d-49e9-b48f-27a3b759079d,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-9804fb10-e5ee-4a60-83d6-d5ddf9dcea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-512a1724-d897-4983-8c15-63c0e249105c,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-f7fe641c-914f-440f-a41c-b4c4c5ac226c,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-194b0edb-8b53-417a-924d-48169b1179e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-733e5040-5286-4e39-890c-a722a9d1425f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420968532-172.17.0.21-1595861527506:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42317,DS-1b8bceaf-6a4d-4184-b901-6cb01fc2a6da,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-3fbf92f2-c457-4aa2-87c3-148b2aad426c,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-8a9d8cbc-d20d-49e9-b48f-27a3b759079d,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-9804fb10-e5ee-4a60-83d6-d5ddf9dcea8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-512a1724-d897-4983-8c15-63c0e249105c,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-f7fe641c-914f-440f-a41c-b4c4c5ac226c,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-194b0edb-8b53-417a-924d-48169b1179e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-733e5040-5286-4e39-890c-a722a9d1425f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650801912-172.17.0.21-1595861850601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42985,DS-16db0fbe-4b80-4835-8c45-f44278e186b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-36f2d07a-99c6-4101-a199-07405e0d526f,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-2238691e-e694-4b76-a98f-392b3817c70e,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-77737473-85ed-4a66-b3d7-247cfa71a200,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-c1b6c16d-3313-4767-a133-e3ec8aaa9745,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-2ff78620-9dd9-4b62-8ced-658a6520dd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-44bc9b9e-fe6e-46c0-b882-24ddabea4cae,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-6d09d39a-55b7-4bd5-81bb-e5c35e07a08c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650801912-172.17.0.21-1595861850601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42985,DS-16db0fbe-4b80-4835-8c45-f44278e186b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-36f2d07a-99c6-4101-a199-07405e0d526f,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-2238691e-e694-4b76-a98f-392b3817c70e,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-77737473-85ed-4a66-b3d7-247cfa71a200,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-c1b6c16d-3313-4767-a133-e3ec8aaa9745,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-2ff78620-9dd9-4b62-8ced-658a6520dd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-44bc9b9e-fe6e-46c0-b882-24ddabea4cae,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-6d09d39a-55b7-4bd5-81bb-e5c35e07a08c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1992889242-172.17.0.21-1595861895234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40581,DS-d06dc6d8-b372-4309-99a0-d63a48f9a55f,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-9fe23c37-3e7f-4c4d-88b9-b231b3702bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-597dd2f1-302a-49f6-8f92-ab390fe94d63,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-e5bc77e6-8e78-4e61-8f60-2bba3046ecf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-f4481e08-9cee-4795-ad46-d7901b3f3312,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-6fee434c-26e2-44e9-8d70-e107e77fcdac,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-bc1be40f-a747-4839-9aed-47d641ac55ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-ff879059-8c4c-495a-a524-b1b16377b3cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1992889242-172.17.0.21-1595861895234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40581,DS-d06dc6d8-b372-4309-99a0-d63a48f9a55f,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-9fe23c37-3e7f-4c4d-88b9-b231b3702bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-597dd2f1-302a-49f6-8f92-ab390fe94d63,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-e5bc77e6-8e78-4e61-8f60-2bba3046ecf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-f4481e08-9cee-4795-ad46-d7901b3f3312,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-6fee434c-26e2-44e9-8d70-e107e77fcdac,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-bc1be40f-a747-4839-9aed-47d641ac55ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-ff879059-8c4c-495a-a524-b1b16377b3cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121696666-172.17.0.21-1595862224346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36836,DS-f4e47afb-ceb2-4ebb-bf09-96edb3b51cca,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-d8cb92b9-b0b7-4251-8ae7-0ace00f3ea81,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-53945d3a-84b0-4cce-a9b8-3abe2792f6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-0bf6e61f-ff6d-42f1-9490-7a8695a463c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-56b4b25a-913f-4629-8490-77809953eeea,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-37dafda6-5792-4650-8bf2-8860789a4576,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-9533f71f-6a1b-4244-891d-63923aee5128,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-ca479b36-ecdc-4eab-b505-cd1e987a518c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-121696666-172.17.0.21-1595862224346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36836,DS-f4e47afb-ceb2-4ebb-bf09-96edb3b51cca,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-d8cb92b9-b0b7-4251-8ae7-0ace00f3ea81,DISK], DatanodeInfoWithStorage[127.0.0.1:41479,DS-53945d3a-84b0-4cce-a9b8-3abe2792f6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-0bf6e61f-ff6d-42f1-9490-7a8695a463c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-56b4b25a-913f-4629-8490-77809953eeea,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-37dafda6-5792-4650-8bf2-8860789a4576,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-9533f71f-6a1b-4244-891d-63923aee5128,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-ca479b36-ecdc-4eab-b505-cd1e987a518c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148168208-172.17.0.21-1595862414968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36166,DS-21385641-803a-47e2-a9f3-4f6a983e03ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-62fc2f12-7a2d-4110-bd5d-4effef0af41b,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-367fe3a1-8b44-48ad-a416-f997f8f0f208,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-28bece90-d2c5-457f-b57f-07ed901be797,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-1c2b222d-d39b-44f0-a46f-3796c9d33501,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-43e99d81-b309-4888-98b2-eb6fa10704ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-1e0660bf-dd23-4781-977b-c5a5b5c42d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-9901fe1d-de4d-41a7-97d3-0fb3b64abfa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148168208-172.17.0.21-1595862414968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36166,DS-21385641-803a-47e2-a9f3-4f6a983e03ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-62fc2f12-7a2d-4110-bd5d-4effef0af41b,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-367fe3a1-8b44-48ad-a416-f997f8f0f208,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-28bece90-d2c5-457f-b57f-07ed901be797,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-1c2b222d-d39b-44f0-a46f-3796c9d33501,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-43e99d81-b309-4888-98b2-eb6fa10704ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-1e0660bf-dd23-4781-977b-c5a5b5c42d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-9901fe1d-de4d-41a7-97d3-0fb3b64abfa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441932083-172.17.0.21-1595862454443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34919,DS-5a93b4a8-d7b4-4b02-a62d-8f6466763e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-c48a75aa-788e-44c0-bb06-6cb4981dab5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-9471ff55-d6bb-4e4c-bcb2-4e50fafb20f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-d32b8edc-8632-425e-a902-b3f3be8aada8,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-348c9622-7502-4a1b-b777-185bb2b6f385,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-733f8bc8-a8c9-4f73-98c9-d32101c0ad4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-dc00816f-9e7f-42d0-8a4a-6eefa27362cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-3ffb0c64-2367-4e4b-8cdc-3a18d1b13efb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-441932083-172.17.0.21-1595862454443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34919,DS-5a93b4a8-d7b4-4b02-a62d-8f6466763e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-c48a75aa-788e-44c0-bb06-6cb4981dab5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-9471ff55-d6bb-4e4c-bcb2-4e50fafb20f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-d32b8edc-8632-425e-a902-b3f3be8aada8,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-348c9622-7502-4a1b-b777-185bb2b6f385,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-733f8bc8-a8c9-4f73-98c9-d32101c0ad4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-dc00816f-9e7f-42d0-8a4a-6eefa27362cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-3ffb0c64-2367-4e4b-8cdc-3a18d1b13efb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1191890455-172.17.0.21-1595862906998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40281,DS-682760af-5a2c-44e9-9b0f-3765add97d71,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-c605ef50-72ec-4e6b-90da-4766720deb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-a1454d2b-4812-4d3a-9d15-122133b91eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-a42eed1f-f6b6-494d-beec-a2cbf5b443de,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-2f3971a7-310a-420c-ba8f-3a5bc5de8617,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-9c85cbf2-937d-45da-9317-827b79f0b5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-cb2afae0-4e7a-4002-bf84-180bc333f6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-09530590-a4c1-435b-a018-4a2ad4d1bde5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1191890455-172.17.0.21-1595862906998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40281,DS-682760af-5a2c-44e9-9b0f-3765add97d71,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-c605ef50-72ec-4e6b-90da-4766720deb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-a1454d2b-4812-4d3a-9d15-122133b91eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-a42eed1f-f6b6-494d-beec-a2cbf5b443de,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-2f3971a7-310a-420c-ba8f-3a5bc5de8617,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-9c85cbf2-937d-45da-9317-827b79f0b5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-cb2afae0-4e7a-4002-bf84-180bc333f6a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-09530590-a4c1-435b-a018-4a2ad4d1bde5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656257478-172.17.0.21-1595863153966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44499,DS-f40c3df0-26b2-4b73-8e7b-8bcea95f2b81,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-8fc37820-0a88-4114-8ea9-c871026f1acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-4087fb69-b370-4d94-a7f0-038d9c58bd62,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-a58fa61d-8586-46be-ae84-1daa67e778d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-7172c22a-ad25-4a89-a567-7d15340d9ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-a84b131d-1a8b-4ebd-97ad-96da795608a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-d0998113-860c-4939-aa65-6f67ce8fbf34,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-5c22632b-e1bd-4d23-9bf9-31c5e18f760e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656257478-172.17.0.21-1595863153966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44499,DS-f40c3df0-26b2-4b73-8e7b-8bcea95f2b81,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-8fc37820-0a88-4114-8ea9-c871026f1acf,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-4087fb69-b370-4d94-a7f0-038d9c58bd62,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-a58fa61d-8586-46be-ae84-1daa67e778d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-7172c22a-ad25-4a89-a567-7d15340d9ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-a84b131d-1a8b-4ebd-97ad-96da795608a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-d0998113-860c-4939-aa65-6f67ce8fbf34,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-5c22632b-e1bd-4d23-9bf9-31c5e18f760e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338761741-172.17.0.21-1595863282802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35368,DS-5c87c849-b574-4363-9a15-48ea94bfb392,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-044553de-d92d-4fdd-a56e-c902bdc1da0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-731fbf1e-23e5-4494-a06b-c18ca598f501,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-3ff5a960-34af-4770-8753-c9e1a3682fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-4b3d061b-33a2-4b7a-8311-e800657d7699,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-f60f32d0-62fb-485f-a534-5f9fe43a6fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-85d48bf6-f375-482d-8aed-17a8b2760cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-9f4c5024-3c72-43b1-a331-ed4ba70cb735,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338761741-172.17.0.21-1595863282802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35368,DS-5c87c849-b574-4363-9a15-48ea94bfb392,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-044553de-d92d-4fdd-a56e-c902bdc1da0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-731fbf1e-23e5-4494-a06b-c18ca598f501,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-3ff5a960-34af-4770-8753-c9e1a3682fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-4b3d061b-33a2-4b7a-8311-e800657d7699,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-f60f32d0-62fb-485f-a534-5f9fe43a6fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-85d48bf6-f375-482d-8aed-17a8b2760cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-9f4c5024-3c72-43b1-a331-ed4ba70cb735,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1584893780-172.17.0.21-1595864529550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40090,DS-cba8feaf-ab9a-4de6-8d86-4ff14519166f,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-6e0d9be3-aa3d-4e99-a4d4-87994afd0bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-7f2e3051-5231-4087-ae3c-ddae6083670f,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-0471d961-6a7f-4aaf-b2bd-9d6a83c62666,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-3de59e4d-734a-4a84-96a3-8a9b5afaddb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-56d6ec4c-ccaa-4c04-bb7c-722f4f441af7,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-a34615eb-9c0e-4fa6-9883-2fd75163f991,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-08f8fc6f-708c-4cdb-90ee-a0ee6d5ffe8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1584893780-172.17.0.21-1595864529550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40090,DS-cba8feaf-ab9a-4de6-8d86-4ff14519166f,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-6e0d9be3-aa3d-4e99-a4d4-87994afd0bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-7f2e3051-5231-4087-ae3c-ddae6083670f,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-0471d961-6a7f-4aaf-b2bd-9d6a83c62666,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-3de59e4d-734a-4a84-96a3-8a9b5afaddb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-56d6ec4c-ccaa-4c04-bb7c-722f4f441af7,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-a34615eb-9c0e-4fa6-9883-2fd75163f991,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-08f8fc6f-708c-4cdb-90ee-a0ee6d5ffe8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-523921290-172.17.0.21-1595864605775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44378,DS-730aaa8d-5c20-4012-9aab-d6f7e5367e58,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-ca520fac-82bf-4ce5-82c9-91a4647d1af6,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-152f4524-fff8-4093-986d-c3ad6be15bba,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-47b7fa65-ba07-4687-a666-988d8e64906c,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-a7bfaeab-28e6-410e-8459-59d08c7bf394,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-cf7a1c1f-8122-446b-b3d3-e4cc7850534b,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-d0f25f4f-f8d8-483c-be8e-687632b632f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-1cbe31c1-93d2-4db5-960a-28006821a3c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-523921290-172.17.0.21-1595864605775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44378,DS-730aaa8d-5c20-4012-9aab-d6f7e5367e58,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-ca520fac-82bf-4ce5-82c9-91a4647d1af6,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-152f4524-fff8-4093-986d-c3ad6be15bba,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-47b7fa65-ba07-4687-a666-988d8e64906c,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-a7bfaeab-28e6-410e-8459-59d08c7bf394,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-cf7a1c1f-8122-446b-b3d3-e4cc7850534b,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-d0f25f4f-f8d8-483c-be8e-687632b632f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-1cbe31c1-93d2-4db5-960a-28006821a3c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945815800-172.17.0.21-1595864979814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40282,DS-bfad0c94-fa3f-4891-bafa-8dc50d0b39e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-f35dbbc2-5322-42fa-aad3-d62076440e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-88e004e0-6f4a-41c5-babf-e4e8868e2aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-709dd459-62c7-46e1-8adc-44a3429ed324,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-e8cfb528-717d-4b29-b6db-a71c305ebedb,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-5b74623c-8a8c-4fc5-8616-a67069b8a344,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-7e92385a-6c51-4bf5-a68e-c772ea0f2ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-f7904f50-5133-4483-a29f-a5d3736e337d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945815800-172.17.0.21-1595864979814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40282,DS-bfad0c94-fa3f-4891-bafa-8dc50d0b39e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-f35dbbc2-5322-42fa-aad3-d62076440e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-88e004e0-6f4a-41c5-babf-e4e8868e2aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41518,DS-709dd459-62c7-46e1-8adc-44a3429ed324,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-e8cfb528-717d-4b29-b6db-a71c305ebedb,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-5b74623c-8a8c-4fc5-8616-a67069b8a344,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-7e92385a-6c51-4bf5-a68e-c772ea0f2ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-f7904f50-5133-4483-a29f-a5d3736e337d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672139003-172.17.0.21-1595865198679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40568,DS-d5efbb87-e81d-4f07-99b9-393f52401af4,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-3de73aa5-7381-4a81-a278-8ca2e7579966,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-ad9692de-c9ba-49a1-a0c3-a523e07391de,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-323477fd-1d80-4a1d-9c7e-9e457528d412,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-fb84afc4-a51f-4977-841a-63c4ad2d30d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-5f54c67c-800f-46fe-8b90-671ba6a636ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-de9d82e1-82c8-4a37-88d3-59c677b87528,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-48d93d54-2dec-4ea5-90f1-f725b8f2eb81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-672139003-172.17.0.21-1595865198679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40568,DS-d5efbb87-e81d-4f07-99b9-393f52401af4,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-3de73aa5-7381-4a81-a278-8ca2e7579966,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-ad9692de-c9ba-49a1-a0c3-a523e07391de,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-323477fd-1d80-4a1d-9c7e-9e457528d412,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-fb84afc4-a51f-4977-841a-63c4ad2d30d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-5f54c67c-800f-46fe-8b90-671ba6a636ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-de9d82e1-82c8-4a37-88d3-59c677b87528,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-48d93d54-2dec-4ea5-90f1-f725b8f2eb81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306301051-172.17.0.21-1595865942026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-38fe6c06-0602-4e0a-9be7-094834ef045a,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-5c8a3885-ab28-4901-b308-f51a91189185,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-2ad02f63-0cb4-456e-b012-c51aa1002c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-f3e5201d-0c86-47ad-849e-929caa81f046,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-54fb064a-a8c6-4c2e-9615-1955d4c0b3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-18c669b3-0e95-4cd0-9c19-4dd125a67ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-dece7868-901e-4e4c-a44c-4ff474e49799,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-4c034789-f226-4dae-a7be-6fb85cfb5d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306301051-172.17.0.21-1595865942026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-38fe6c06-0602-4e0a-9be7-094834ef045a,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-5c8a3885-ab28-4901-b308-f51a91189185,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-2ad02f63-0cb4-456e-b012-c51aa1002c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-f3e5201d-0c86-47ad-849e-929caa81f046,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-54fb064a-a8c6-4c2e-9615-1955d4c0b3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-18c669b3-0e95-4cd0-9c19-4dd125a67ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-dece7868-901e-4e4c-a44c-4ff474e49799,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-4c034789-f226-4dae-a7be-6fb85cfb5d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088000863-172.17.0.21-1595866157585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41539,DS-9cb700d8-6530-40d9-9c7b-d240678cf5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-db213bfa-8316-4697-8f41-357d77ce6dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-e2110d92-93d4-4c1a-bdc5-61aa349c5e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-fef27164-f00a-43b3-b39c-6ebb1e3a262c,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-9b937880-2fd6-4b3e-9129-9d8806210253,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-5a7fdb5e-7d4d-4966-8b01-adc79c4fa6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-a7572622-fff9-4208-9170-b47a157e650f,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-a9cd3604-3f72-4a10-b666-3102a45d4832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088000863-172.17.0.21-1595866157585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41539,DS-9cb700d8-6530-40d9-9c7b-d240678cf5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-db213bfa-8316-4697-8f41-357d77ce6dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-e2110d92-93d4-4c1a-bdc5-61aa349c5e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-fef27164-f00a-43b3-b39c-6ebb1e3a262c,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-9b937880-2fd6-4b3e-9129-9d8806210253,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-5a7fdb5e-7d4d-4966-8b01-adc79c4fa6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-a7572622-fff9-4208-9170-b47a157e650f,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-a9cd3604-3f72-4a10-b666-3102a45d4832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1546500776-172.17.0.21-1595866803136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35767,DS-be0adfcc-7f39-45db-bff0-52835959737e,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-f894ce73-d083-4f80-b3e5-f54c023d80a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-f62410f7-3cc7-4bbc-a395-35dc4e516094,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-6b3b5025-aa55-4eba-91fc-9af130ac98f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-f92e4e50-b79e-4cf1-b343-cfbdf0f7d4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-0b7e8e6d-4d86-4397-acd4-62137436135e,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-900d6e17-7bf8-4f38-a948-fbecebb18916,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-2aa01f40-95f8-4c79-8e27-3c96ff7da7d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1546500776-172.17.0.21-1595866803136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35767,DS-be0adfcc-7f39-45db-bff0-52835959737e,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-f894ce73-d083-4f80-b3e5-f54c023d80a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-f62410f7-3cc7-4bbc-a395-35dc4e516094,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-6b3b5025-aa55-4eba-91fc-9af130ac98f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-f92e4e50-b79e-4cf1-b343-cfbdf0f7d4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-0b7e8e6d-4d86-4397-acd4-62137436135e,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-900d6e17-7bf8-4f38-a948-fbecebb18916,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-2aa01f40-95f8-4c79-8e27-3c96ff7da7d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938437140-172.17.0.21-1595866840048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34243,DS-75204401-b5fd-454a-9efc-07999e7a1cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-13e597dd-b0a0-41d6-b57e-db1bbf948977,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-50698809-591f-4749-8f89-f7245662f2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-b684709a-3ee3-4ed3-a66d-cf382a30ba85,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-8f5a39a6-a964-476f-8bc1-276fbb6d4984,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-ed65fbd5-ff3b-416c-a2c9-4e5a7bf5ca80,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-ec8c066f-9b5d-4a18-b183-7b43e0f3d64e,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-1dc33933-7a18-4b7a-babc-b688c180ae11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1938437140-172.17.0.21-1595866840048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34243,DS-75204401-b5fd-454a-9efc-07999e7a1cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-13e597dd-b0a0-41d6-b57e-db1bbf948977,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-50698809-591f-4749-8f89-f7245662f2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-b684709a-3ee3-4ed3-a66d-cf382a30ba85,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-8f5a39a6-a964-476f-8bc1-276fbb6d4984,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-ed65fbd5-ff3b-416c-a2c9-4e5a7bf5ca80,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-ec8c066f-9b5d-4a18-b183-7b43e0f3d64e,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-1dc33933-7a18-4b7a-babc-b688c180ae11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105968220-172.17.0.21-1595867235593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34067,DS-662048d6-17af-431c-bc48-0b4bb33d6487,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-e071ff82-6d15-450d-9d06-65c434127895,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-7f49d9c2-4f42-4083-99bf-5e6dc2c7557b,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-6dc29fff-c9b3-4ea1-9e71-0b8892e12eab,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-86bef13f-61c2-4dca-95c3-b27b4b3ca70b,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-51d69218-ac93-4a71-a730-2574d1f088ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-d717a702-ec96-4264-a0ba-ad7b7458bd96,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-b75efb75-2d03-47d6-bdb9-cbd52d7ed69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105968220-172.17.0.21-1595867235593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34067,DS-662048d6-17af-431c-bc48-0b4bb33d6487,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-e071ff82-6d15-450d-9d06-65c434127895,DISK], DatanodeInfoWithStorage[127.0.0.1:36111,DS-7f49d9c2-4f42-4083-99bf-5e6dc2c7557b,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-6dc29fff-c9b3-4ea1-9e71-0b8892e12eab,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-86bef13f-61c2-4dca-95c3-b27b4b3ca70b,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-51d69218-ac93-4a71-a730-2574d1f088ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-d717a702-ec96-4264-a0ba-ad7b7458bd96,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-b75efb75-2d03-47d6-bdb9-cbd52d7ed69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:NameNode
v1: 2
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775041760-172.17.0.21-1595867406068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36369,DS-4a2195e4-dcac-4c9d-9e0c-2e505ce0567f,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-88edb054-ead4-49c3-8acd-eac19b0de754,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-8780c6aa-d84b-4243-bd88-2718517ce780,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-80d97e39-92a0-4920-89a6-1d0568bb9869,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-2e40f510-879b-49eb-9daa-c5ce4fcee588,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-64eaa900-a9ce-414c-95f2-c3393589318b,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-08f85594-80d3-4323-ad2a-71aac904dedc,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-c69f7e7d-9517-47c3-9b73-20ccf955bc37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775041760-172.17.0.21-1595867406068:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36369,DS-4a2195e4-dcac-4c9d-9e0c-2e505ce0567f,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-88edb054-ead4-49c3-8acd-eac19b0de754,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-8780c6aa-d84b-4243-bd88-2718517ce780,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-80d97e39-92a0-4920-89a6-1d0568bb9869,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-2e40f510-879b-49eb-9daa-c5ce4fcee588,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-64eaa900-a9ce-414c-95f2-c3393589318b,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-08f85594-80d3-4323-ad2a-71aac904dedc,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-c69f7e7d-9517-47c3-9b73-20ccf955bc37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6560
