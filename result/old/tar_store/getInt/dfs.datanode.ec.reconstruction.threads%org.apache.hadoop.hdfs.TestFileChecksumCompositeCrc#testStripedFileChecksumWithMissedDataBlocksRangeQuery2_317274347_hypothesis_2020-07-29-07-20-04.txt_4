reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577056676-172.17.0.7-1596009578313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43127,DS-0db50bda-813a-40f4-8b27-adfe33e957be,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-5f8fdc6c-65ac-4d63-a630-62b782180d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-fb158508-0212-4316-8efa-6c935c1c056f,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-fb54f2c6-a4eb-42ca-8d41-c9aa10392273,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-c57c086b-e1d4-4dbd-a464-9bf772592cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-f29ba981-14c3-4971-9df1-095c986805e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-3f11b0f7-01d4-4f71-b87d-5af235e9ea8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-2bbf2b31-d025-450d-88c0-58e23d685006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577056676-172.17.0.7-1596009578313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43127,DS-0db50bda-813a-40f4-8b27-adfe33e957be,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-5f8fdc6c-65ac-4d63-a630-62b782180d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-fb158508-0212-4316-8efa-6c935c1c056f,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-fb54f2c6-a4eb-42ca-8d41-c9aa10392273,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-c57c086b-e1d4-4dbd-a464-9bf772592cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-f29ba981-14c3-4971-9df1-095c986805e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-3f11b0f7-01d4-4f71-b87d-5af235e9ea8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-2bbf2b31-d025-450d-88c0-58e23d685006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277148278-172.17.0.7-1596009814451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34432,DS-8991e9e8-c040-4bca-8e3a-f9774c6dd82f,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-83c72cc9-d6b6-4855-a3cc-a01e232073f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-00f26bff-7bee-4a64-a78b-84ba946d9f03,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-1adba9b6-a19c-4faf-86cd-ad964dd98a06,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-958517a5-4067-4ece-b054-4b9a3cafa062,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-ad54a493-cb9f-4d9e-86fc-db4692115e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-42530d52-27a9-42d8-9cb0-2005bd45fd57,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-10b7a98c-e4ec-4c29-b410-75fe07086954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277148278-172.17.0.7-1596009814451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34432,DS-8991e9e8-c040-4bca-8e3a-f9774c6dd82f,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-83c72cc9-d6b6-4855-a3cc-a01e232073f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-00f26bff-7bee-4a64-a78b-84ba946d9f03,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-1adba9b6-a19c-4faf-86cd-ad964dd98a06,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-958517a5-4067-4ece-b054-4b9a3cafa062,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-ad54a493-cb9f-4d9e-86fc-db4692115e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-42530d52-27a9-42d8-9cb0-2005bd45fd57,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-10b7a98c-e4ec-4c29-b410-75fe07086954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229156259-172.17.0.7-1596009974254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36121,DS-c1ea8b12-749b-4fa5-84c3-40c2cd313eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-c1cbd37e-2110-4f7f-a604-935bfc6b768e,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-4c3f95b5-a13f-49f4-a772-d5909c539c62,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-486f0a88-716a-49ac-8076-7ec4e29f70aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-244b19b1-73a1-4f51-8875-73775a2a8ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-3ed7a7dd-b695-421d-a778-8cddcf47a079,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-92328765-bef7-45ab-b80a-c7d7c4128e48,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-8431dcc1-0e86-487c-bc26-43b3780169d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229156259-172.17.0.7-1596009974254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36121,DS-c1ea8b12-749b-4fa5-84c3-40c2cd313eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-c1cbd37e-2110-4f7f-a604-935bfc6b768e,DISK], DatanodeInfoWithStorage[127.0.0.1:44795,DS-4c3f95b5-a13f-49f4-a772-d5909c539c62,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-486f0a88-716a-49ac-8076-7ec4e29f70aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-244b19b1-73a1-4f51-8875-73775a2a8ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-3ed7a7dd-b695-421d-a778-8cddcf47a079,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-92328765-bef7-45ab-b80a-c7d7c4128e48,DISK], DatanodeInfoWithStorage[127.0.0.1:35115,DS-8431dcc1-0e86-487c-bc26-43b3780169d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964395575-172.17.0.7-1596010103879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33714,DS-837249ae-ee8a-46ad-bab5-91a0db1a5f47,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-25f811a2-5117-4447-ab1a-ffc9fce28319,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-e07f7482-674c-4d7b-9515-90f05326038b,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-ba042f54-910f-4bf0-94d5-681df0762e36,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-4510fd5c-8df3-4338-8352-00d835da20bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-920e1ba4-eef9-49a8-9fd3-aca156969d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-74bed2cf-0086-4151-8243-dce4be6fd3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-b4750dd6-338d-43ec-bda0-136d7c428825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964395575-172.17.0.7-1596010103879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33714,DS-837249ae-ee8a-46ad-bab5-91a0db1a5f47,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-25f811a2-5117-4447-ab1a-ffc9fce28319,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-e07f7482-674c-4d7b-9515-90f05326038b,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-ba042f54-910f-4bf0-94d5-681df0762e36,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-4510fd5c-8df3-4338-8352-00d835da20bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-920e1ba4-eef9-49a8-9fd3-aca156969d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-74bed2cf-0086-4151-8243-dce4be6fd3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-b4750dd6-338d-43ec-bda0-136d7c428825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057631720-172.17.0.7-1596010495582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41306,DS-3e7befcb-8572-4fc5-b469-9f84b383476a,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-fab253bc-1927-4cc4-a1c6-1c3e09f09596,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-dbcbf91c-ec4f-4a77-89aa-bb3ee7b24491,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-0fcb0260-b996-4a48-a44b-6a9bac9ccc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-d91a1af1-eeef-4892-a8ed-0c23a35533ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-4d8ec03e-eb71-4792-a39f-1907d12fa5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-1d0b5ca2-4cba-40f0-9634-a0937b719d26,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-3ed13ec3-8409-4927-9ef7-571e2e9f764e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1057631720-172.17.0.7-1596010495582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41306,DS-3e7befcb-8572-4fc5-b469-9f84b383476a,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-fab253bc-1927-4cc4-a1c6-1c3e09f09596,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-dbcbf91c-ec4f-4a77-89aa-bb3ee7b24491,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-0fcb0260-b996-4a48-a44b-6a9bac9ccc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-d91a1af1-eeef-4892-a8ed-0c23a35533ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-4d8ec03e-eb71-4792-a39f-1907d12fa5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-1d0b5ca2-4cba-40f0-9634-a0937b719d26,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-3ed13ec3-8409-4927-9ef7-571e2e9f764e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066891338-172.17.0.7-1596010737878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33649,DS-514a4d5b-159e-48a2-89de-778f5db2feb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-347b2cb3-3553-4cad-9e05-0cb9da22ea26,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-3cf0525a-0a56-4a42-af49-e7b17415c5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-66b051e1-da0e-4467-8d27-2f2b25ec1c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-0bfba086-0192-490f-8b0c-ebe12e9694d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-34b27309-658b-4ebe-a85c-2997019696be,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-a2963f35-6539-496c-b191-cae0b6a48daf,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-6e4f2ed1-9bd7-4ac1-becf-eb175fa9ff35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1066891338-172.17.0.7-1596010737878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33649,DS-514a4d5b-159e-48a2-89de-778f5db2feb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-347b2cb3-3553-4cad-9e05-0cb9da22ea26,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-3cf0525a-0a56-4a42-af49-e7b17415c5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-66b051e1-da0e-4467-8d27-2f2b25ec1c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-0bfba086-0192-490f-8b0c-ebe12e9694d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-34b27309-658b-4ebe-a85c-2997019696be,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-a2963f35-6539-496c-b191-cae0b6a48daf,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-6e4f2ed1-9bd7-4ac1-becf-eb175fa9ff35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862612920-172.17.0.7-1596011175015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42615,DS-3f9dff3d-0f02-4e53-aac4-41decc55b72d,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-89e2f2d5-48c5-42ba-83f3-384ffd3e299e,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-6b6f3722-45d4-41dc-89bc-7386527e4d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-515da39f-0999-48ad-8e0a-fbafdc3ba6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-33016967-f03f-4967-a450-ac856ca8b35f,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-e8d5d8e4-72b4-4a99-b309-3b7b98e4ae05,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-6600abc2-83ce-4ca3-8807-419f665e9c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-fb68a846-01bc-46ad-ba6f-bffcebf4d743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-862612920-172.17.0.7-1596011175015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42615,DS-3f9dff3d-0f02-4e53-aac4-41decc55b72d,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-89e2f2d5-48c5-42ba-83f3-384ffd3e299e,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-6b6f3722-45d4-41dc-89bc-7386527e4d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-515da39f-0999-48ad-8e0a-fbafdc3ba6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-33016967-f03f-4967-a450-ac856ca8b35f,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-e8d5d8e4-72b4-4a99-b309-3b7b98e4ae05,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-6600abc2-83ce-4ca3-8807-419f665e9c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-fb68a846-01bc-46ad-ba6f-bffcebf4d743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250884682-172.17.0.7-1596011799266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-bf37efc7-8515-4469-8058-ffc8e565c27f,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-737ea1ef-405d-44e2-a4fb-44b4a4e2c2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-81eeafbd-2c9b-47e3-809c-39110e7c3344,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-47a70c05-86e7-4d41-9c9a-965216ba9142,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-49b71ca7-5809-4f50-9397-a2db1eb3c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-4edea968-b55f-4a15-bc28-cd7d7a8bf467,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-242ddd60-13c0-4a0a-af44-523615d7a687,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-d26f1d6a-a693-4c21-8439-84d3a1eef82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-250884682-172.17.0.7-1596011799266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-bf37efc7-8515-4469-8058-ffc8e565c27f,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-737ea1ef-405d-44e2-a4fb-44b4a4e2c2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-81eeafbd-2c9b-47e3-809c-39110e7c3344,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-47a70c05-86e7-4d41-9c9a-965216ba9142,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-49b71ca7-5809-4f50-9397-a2db1eb3c3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-4edea968-b55f-4a15-bc28-cd7d7a8bf467,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-242ddd60-13c0-4a0a-af44-523615d7a687,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-d26f1d6a-a693-4c21-8439-84d3a1eef82a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602196674-172.17.0.7-1596011867196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35474,DS-2e7e2001-8c0e-4132-829c-d5a7fe30c6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-a056ab16-937e-417e-a536-ba380c1c1988,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-26e32f5d-5129-4b3c-b924-6a2375fb0543,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-c4694739-071f-4fa5-9cf4-b366ccbc65f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-c4a744e4-0c35-45cd-be68-5db68f8a7ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-a84e95a3-3c6b-431d-8b6d-049621662f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-c444c8b8-afa2-4884-90cf-ab13f79e6ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-80ee63be-1a85-4728-84d1-ee7d338e616d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602196674-172.17.0.7-1596011867196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35474,DS-2e7e2001-8c0e-4132-829c-d5a7fe30c6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-a056ab16-937e-417e-a536-ba380c1c1988,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-26e32f5d-5129-4b3c-b924-6a2375fb0543,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-c4694739-071f-4fa5-9cf4-b366ccbc65f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-c4a744e4-0c35-45cd-be68-5db68f8a7ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-a84e95a3-3c6b-431d-8b6d-049621662f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-c444c8b8-afa2-4884-90cf-ab13f79e6ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-80ee63be-1a85-4728-84d1-ee7d338e616d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672908147-172.17.0.7-1596012247096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44328,DS-378ebeaa-5116-4cd3-9d50-ba450ef6760e,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-8d7e7c1a-d982-4274-9590-8dbbbe661197,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-df40fc79-67f0-4fc6-8ea3-6984314e002a,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-1eff251f-c813-4c26-a15d-bc46873105d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-7fe56374-2c29-4477-8e9c-56a24b25ad95,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-a4947ce9-59c1-4cd5-b5ed-37d4605e4124,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-7e3f967c-bfa4-418f-a9ea-8150d4388f97,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-c69cc1a4-49f5-4f03-aea5-e0f8ece80580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672908147-172.17.0.7-1596012247096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44328,DS-378ebeaa-5116-4cd3-9d50-ba450ef6760e,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-8d7e7c1a-d982-4274-9590-8dbbbe661197,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-df40fc79-67f0-4fc6-8ea3-6984314e002a,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-1eff251f-c813-4c26-a15d-bc46873105d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34197,DS-7fe56374-2c29-4477-8e9c-56a24b25ad95,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-a4947ce9-59c1-4cd5-b5ed-37d4605e4124,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-7e3f967c-bfa4-418f-a9ea-8150d4388f97,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-c69cc1a4-49f5-4f03-aea5-e0f8ece80580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854272850-172.17.0.7-1596012284514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42929,DS-302bfab8-d52d-4e7a-8c13-b4b4252147ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-bd3b26d6-369d-4ff1-8d23-a3966acce796,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-8a72a709-837b-4a2d-9f6f-f7a99da831fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-7d9bbd50-1377-49f6-a22d-b9b56f2c209e,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-7bd3913c-5ec9-41fe-a9fc-35b2c37c525d,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-5af768b9-cbe0-4b0b-9607-093b0c60c5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-95e607e0-6173-4af4-961a-e371cb2bd70d,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-c19d8f23-7826-4a72-8ec9-2ebaa9acec43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854272850-172.17.0.7-1596012284514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42929,DS-302bfab8-d52d-4e7a-8c13-b4b4252147ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-bd3b26d6-369d-4ff1-8d23-a3966acce796,DISK], DatanodeInfoWithStorage[127.0.0.1:44622,DS-8a72a709-837b-4a2d-9f6f-f7a99da831fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-7d9bbd50-1377-49f6-a22d-b9b56f2c209e,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-7bd3913c-5ec9-41fe-a9fc-35b2c37c525d,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-5af768b9-cbe0-4b0b-9607-093b0c60c5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-95e607e0-6173-4af4-961a-e371cb2bd70d,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-c19d8f23-7826-4a72-8ec9-2ebaa9acec43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110281996-172.17.0.7-1596012415553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38414,DS-3b6a4f58-199e-49c3-a16d-18dc255a71fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-a8738fef-b2aa-43a7-8c9a-eea63d6bcc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-7c18528b-33c1-4915-b5d9-58ba088a783d,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-b6cb6c9c-9835-4101-ba88-cd10f53e0e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-4ee650ec-17b4-4fed-a47e-725c6425b012,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-bd97b0a0-19d8-43c0-bceb-5cdd0f250969,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-0b01c52b-a8b8-474b-b632-463d0168f30d,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-1780dd88-c4c8-4537-a2c8-ea04c570c5bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110281996-172.17.0.7-1596012415553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38414,DS-3b6a4f58-199e-49c3-a16d-18dc255a71fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-a8738fef-b2aa-43a7-8c9a-eea63d6bcc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-7c18528b-33c1-4915-b5d9-58ba088a783d,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-b6cb6c9c-9835-4101-ba88-cd10f53e0e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-4ee650ec-17b4-4fed-a47e-725c6425b012,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-bd97b0a0-19d8-43c0-bceb-5cdd0f250969,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-0b01c52b-a8b8-474b-b632-463d0168f30d,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-1780dd88-c4c8-4537-a2c8-ea04c570c5bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690047655-172.17.0.7-1596012731026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40087,DS-4023304c-0341-4fff-b2a2-1e79238e6a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-847e98bc-a59a-4d26-9cba-b525f33aedab,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-096a454b-b5ae-4626-9219-9025d8b108f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-c8950e60-67d4-4d4d-a788-5484290144ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-fe523263-fbe8-4cd2-bd2f-7169c9976293,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-22ba3b8e-0a0e-43b9-a862-7ef47fb89534,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-dcc21899-5ee6-40f9-9001-b03f640ced2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-6c623e3c-4450-4954-b59a-9490821da63c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690047655-172.17.0.7-1596012731026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40087,DS-4023304c-0341-4fff-b2a2-1e79238e6a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-847e98bc-a59a-4d26-9cba-b525f33aedab,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-096a454b-b5ae-4626-9219-9025d8b108f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-c8950e60-67d4-4d4d-a788-5484290144ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-fe523263-fbe8-4cd2-bd2f-7169c9976293,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-22ba3b8e-0a0e-43b9-a862-7ef47fb89534,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-dcc21899-5ee6-40f9-9001-b03f640ced2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44781,DS-6c623e3c-4450-4954-b59a-9490821da63c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5751
