reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771161856-172.17.0.21-1595874998518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46318,DS-eb0f8bfe-ab5f-4302-b67d-c3cb04d02c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-637e0287-eeb8-4479-b09d-de6e019c068b,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-ddf657bd-e98f-448e-b4cd-c639b2076257,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-fd22311d-6e67-4531-9064-f429ea5b265b,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-492991dd-ca1a-47f7-8ab5-c92a5bf53155,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-c8740f41-826a-4b9d-82c7-4c2560af121d,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-5cf35897-a64b-434f-ab33-84b6026b4576,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-839a4e79-a4f2-4985-b95e-2e42cc06f3af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771161856-172.17.0.21-1595874998518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46318,DS-eb0f8bfe-ab5f-4302-b67d-c3cb04d02c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-637e0287-eeb8-4479-b09d-de6e019c068b,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-ddf657bd-e98f-448e-b4cd-c639b2076257,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-fd22311d-6e67-4531-9064-f429ea5b265b,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-492991dd-ca1a-47f7-8ab5-c92a5bf53155,DISK], DatanodeInfoWithStorage[127.0.0.1:39474,DS-c8740f41-826a-4b9d-82c7-4c2560af121d,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-5cf35897-a64b-434f-ab33-84b6026b4576,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-839a4e79-a4f2-4985-b95e-2e42cc06f3af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721612083-172.17.0.21-1595875042454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35159,DS-af9f8408-9bab-46bb-aa30-9ff432c21e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-4a764c2f-c239-4332-90bc-696a154be5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-213ff948-f127-4ecd-ae20-12a6cc9c11e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-b4fc7de7-3fc3-4aaa-9389-72a92deb2a97,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-75c146cf-627e-4ffb-bcb8-ba1e1c93613e,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-786154ee-49f4-4a86-9a09-cc3f7ccbca91,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-18dae5cc-10e4-45af-b40a-e62a96c5c0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-0d94bd90-3b9c-48d2-b671-acecf81f49a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721612083-172.17.0.21-1595875042454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35159,DS-af9f8408-9bab-46bb-aa30-9ff432c21e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-4a764c2f-c239-4332-90bc-696a154be5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-213ff948-f127-4ecd-ae20-12a6cc9c11e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-b4fc7de7-3fc3-4aaa-9389-72a92deb2a97,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-75c146cf-627e-4ffb-bcb8-ba1e1c93613e,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-786154ee-49f4-4a86-9a09-cc3f7ccbca91,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-18dae5cc-10e4-45af-b40a-e62a96c5c0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-0d94bd90-3b9c-48d2-b671-acecf81f49a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948146531-172.17.0.21-1595875090812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43136,DS-9399d687-13d7-4bd4-b5db-cc1ae3d5cb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-b11b0f4e-9abe-4564-82ad-dce8ebc79ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-c405057b-6550-4c87-b37b-4864622c04e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-2bc1eee2-b649-4fc8-bbfd-db962113c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-164e66e2-de01-41b9-a604-5bdc58f205d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-3238a6af-72de-4593-ad01-64de7f157df9,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-38405b5a-b62b-4e32-8410-c9ed85931d89,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-e8f1797c-e490-46bb-ae8b-a7d954427131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948146531-172.17.0.21-1595875090812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43136,DS-9399d687-13d7-4bd4-b5db-cc1ae3d5cb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-b11b0f4e-9abe-4564-82ad-dce8ebc79ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-c405057b-6550-4c87-b37b-4864622c04e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-2bc1eee2-b649-4fc8-bbfd-db962113c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-164e66e2-de01-41b9-a604-5bdc58f205d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-3238a6af-72de-4593-ad01-64de7f157df9,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-38405b5a-b62b-4e32-8410-c9ed85931d89,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-e8f1797c-e490-46bb-ae8b-a7d954427131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692028675-172.17.0.21-1595875368194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34718,DS-d7753fa1-98dd-476f-91ea-4cb6bed6c628,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-da388382-9eee-4c8f-9672-4d6dbfc2d456,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-26069f38-02c5-4788-87b9-a9f502103b22,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-852a8bba-3e7a-4c86-adc5-164dd04b0b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-36044a69-9df0-4fd8-b3b8-472687b9de4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-f32ab542-a041-4229-8d07-942a2fab5520,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-14b6016a-1801-466e-9229-633ee06113fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-929c460a-3e07-444d-bf4b-ebb67c9f5bb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692028675-172.17.0.21-1595875368194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34718,DS-d7753fa1-98dd-476f-91ea-4cb6bed6c628,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-da388382-9eee-4c8f-9672-4d6dbfc2d456,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-26069f38-02c5-4788-87b9-a9f502103b22,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-852a8bba-3e7a-4c86-adc5-164dd04b0b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-36044a69-9df0-4fd8-b3b8-472687b9de4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-f32ab542-a041-4229-8d07-942a2fab5520,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-14b6016a-1801-466e-9229-633ee06113fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-929c460a-3e07-444d-bf4b-ebb67c9f5bb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974168523-172.17.0.21-1595875452202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42831,DS-72bfae72-042b-4ca0-9acd-fbe1fbe1bd21,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-7b159527-2865-41dc-b820-988a8b2b2761,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-ddf2f8bd-57d1-45c2-ac6e-126c99d9ac92,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-0be99f8d-393b-4037-82fd-f8c20619c18c,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-cf42860f-0b96-4f28-a1f6-a79f6984f3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-ad0891b6-eeb1-4577-bd46-1218281940e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-4c2f547a-a42f-425c-b2e2-b78deb4ac995,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-d0c085f3-6859-4457-8e65-05da7636f71e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-974168523-172.17.0.21-1595875452202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42831,DS-72bfae72-042b-4ca0-9acd-fbe1fbe1bd21,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-7b159527-2865-41dc-b820-988a8b2b2761,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-ddf2f8bd-57d1-45c2-ac6e-126c99d9ac92,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-0be99f8d-393b-4037-82fd-f8c20619c18c,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-cf42860f-0b96-4f28-a1f6-a79f6984f3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-ad0891b6-eeb1-4577-bd46-1218281940e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-4c2f547a-a42f-425c-b2e2-b78deb4ac995,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-d0c085f3-6859-4457-8e65-05da7636f71e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227512848-172.17.0.21-1595875621744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39684,DS-3cfa8ea2-6f4d-4ff7-a428-a7334976f8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-04a2fbf3-ba7b-4791-bd3b-3ad10e639e69,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-cde275e7-e652-488e-a764-eaa8dbfd3c37,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-2ee7933b-6fba-45bd-b304-832d85448d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-302b9423-6e15-45fd-98bb-ed21d7604d11,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-5cd89953-278a-413c-a5bc-edaa76f7edcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-c7933959-955b-424d-ac6a-c66fff2b395c,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-4c3a63d5-743d-4b4a-8204-67842562b65a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227512848-172.17.0.21-1595875621744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39684,DS-3cfa8ea2-6f4d-4ff7-a428-a7334976f8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-04a2fbf3-ba7b-4791-bd3b-3ad10e639e69,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-cde275e7-e652-488e-a764-eaa8dbfd3c37,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-2ee7933b-6fba-45bd-b304-832d85448d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-302b9423-6e15-45fd-98bb-ed21d7604d11,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-5cd89953-278a-413c-a5bc-edaa76f7edcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-c7933959-955b-424d-ac6a-c66fff2b395c,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-4c3a63d5-743d-4b4a-8204-67842562b65a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719543437-172.17.0.21-1595875713136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40662,DS-83d26279-3cdd-499d-9a5e-b1bb779a9dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-5b124d28-f50a-4ff0-a568-648c77562cca,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-1308324f-355a-4ab3-8a64-18c1fffddf89,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-dfbfbafe-f6b1-4778-bc2a-114e6471c0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-0da3961d-a23a-45c6-a216-bcd343af5839,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-ffea6d4a-993c-4c50-b9f4-ab328d228c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-8cd514e8-8e84-4adb-b1c7-bfcb54ed3340,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-531c6df3-6225-448d-afda-ebbe70cc7327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719543437-172.17.0.21-1595875713136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40662,DS-83d26279-3cdd-499d-9a5e-b1bb779a9dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-5b124d28-f50a-4ff0-a568-648c77562cca,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-1308324f-355a-4ab3-8a64-18c1fffddf89,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-dfbfbafe-f6b1-4778-bc2a-114e6471c0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-0da3961d-a23a-45c6-a216-bcd343af5839,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-ffea6d4a-993c-4c50-b9f4-ab328d228c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-8cd514e8-8e84-4adb-b1c7-bfcb54ed3340,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-531c6df3-6225-448d-afda-ebbe70cc7327,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501320011-172.17.0.21-1595875971851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41189,DS-679d38f9-00b1-46ef-b15f-fca7aed453d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-d1e7eddc-709b-48e6-8af7-d2cf210d81ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-952ce5b0-6ed8-4647-b722-8a754ff22d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-cbd56365-4412-4e1b-aa81-6f3100c78648,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-c8d9886d-8893-4af7-bdfc-8d0b29e0c478,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-086e9ea0-223a-417c-a50d-90bd6730edeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-65054a6d-aad3-4bd5-aca7-3737f7cd8c11,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-0b798430-6eea-42c1-9322-7d88ea20a151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1501320011-172.17.0.21-1595875971851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41189,DS-679d38f9-00b1-46ef-b15f-fca7aed453d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-d1e7eddc-709b-48e6-8af7-d2cf210d81ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-952ce5b0-6ed8-4647-b722-8a754ff22d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-cbd56365-4412-4e1b-aa81-6f3100c78648,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-c8d9886d-8893-4af7-bdfc-8d0b29e0c478,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-086e9ea0-223a-417c-a50d-90bd6730edeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-65054a6d-aad3-4bd5-aca7-3737f7cd8c11,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-0b798430-6eea-42c1-9322-7d88ea20a151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652897493-172.17.0.21-1595876418622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39835,DS-7d59fe6b-f596-468e-9ed1-1093767b6b94,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-5a5e24e7-44f1-4c04-95ba-02fcc70c23fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-0a045a4d-7e11-4b7e-86f2-551269d51c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-ac7ce2a0-5071-485d-adec-7398caf58470,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-6d239d3d-9bcc-4d8e-82a4-33de7abf46e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-f0deec67-925f-4da2-86c0-38243e1e8b45,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-cdcaa942-45ea-4655-ab89-6c2c9b89212c,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-36577cc4-12b5-4aae-b797-dda1ad644b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652897493-172.17.0.21-1595876418622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39835,DS-7d59fe6b-f596-468e-9ed1-1093767b6b94,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-5a5e24e7-44f1-4c04-95ba-02fcc70c23fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-0a045a4d-7e11-4b7e-86f2-551269d51c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-ac7ce2a0-5071-485d-adec-7398caf58470,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-6d239d3d-9bcc-4d8e-82a4-33de7abf46e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-f0deec67-925f-4da2-86c0-38243e1e8b45,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-cdcaa942-45ea-4655-ab89-6c2c9b89212c,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-36577cc4-12b5-4aae-b797-dda1ad644b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88560437-172.17.0.21-1595876554522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34046,DS-4f6af87b-f143-4a3a-a6cd-0b0945db3eee,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-28e8a432-43ce-4d13-8649-0ea40d3359ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-98b61d41-b172-4f3e-a8c1-9c5170adb8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-f7649f0f-444f-4ee0-915c-e7d0a76a1c59,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-9f237e75-920c-4165-a8ef-e829d26a8795,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-75709cc8-9e21-4a8a-89c8-728dc6f471c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-195ab82d-d1e9-4597-9b45-2b195d1f3380,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-dc4ea693-066e-4683-9ce4-9a87e19469a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88560437-172.17.0.21-1595876554522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34046,DS-4f6af87b-f143-4a3a-a6cd-0b0945db3eee,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-28e8a432-43ce-4d13-8649-0ea40d3359ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-98b61d41-b172-4f3e-a8c1-9c5170adb8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-f7649f0f-444f-4ee0-915c-e7d0a76a1c59,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-9f237e75-920c-4165-a8ef-e829d26a8795,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-75709cc8-9e21-4a8a-89c8-728dc6f471c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34849,DS-195ab82d-d1e9-4597-9b45-2b195d1f3380,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-dc4ea693-066e-4683-9ce4-9a87e19469a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-521638059-172.17.0.21-1595876599515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-e1c0f58d-8e22-4932-9656-72a756a1e5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-35812f32-82bf-4cd1-8450-19138a5ad42b,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-7450c07d-bf0a-483f-8571-61f9b33907ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-4f8e6398-afa2-4360-ac26-93a3df8835eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-26e13dc4-e098-436e-8528-10b42335a973,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-0ce8a8ee-3dea-43a9-aef4-64efcbd317cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-5ca0e7ef-6e13-4716-9904-a8feb720664e,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-40ed3ebc-6ad4-4afd-8daf-43feff1bc48c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-521638059-172.17.0.21-1595876599515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44940,DS-e1c0f58d-8e22-4932-9656-72a756a1e5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-35812f32-82bf-4cd1-8450-19138a5ad42b,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-7450c07d-bf0a-483f-8571-61f9b33907ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-4f8e6398-afa2-4360-ac26-93a3df8835eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-26e13dc4-e098-436e-8528-10b42335a973,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-0ce8a8ee-3dea-43a9-aef4-64efcbd317cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-5ca0e7ef-6e13-4716-9904-a8feb720664e,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-40ed3ebc-6ad4-4afd-8daf-43feff1bc48c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-893462734-172.17.0.21-1595876802402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34788,DS-ad73d89d-95bd-4405-aa46-db5867224462,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-4e658828-659d-49de-a0c1-7d964932391f,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-23781434-5a5d-4c37-b693-c5409353223c,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-8d773a85-e35d-4fa8-a6e8-27993a4787e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-139a6a1f-d9e1-413c-913f-d31e39c46a46,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-569e0572-0d47-4d46-bc84-dbf9525b67ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-d6a31051-8a0d-48af-b156-9d5b440c6c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-1cfd8437-8ea2-4645-b9a7-2573cf6884e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-893462734-172.17.0.21-1595876802402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34788,DS-ad73d89d-95bd-4405-aa46-db5867224462,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-4e658828-659d-49de-a0c1-7d964932391f,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-23781434-5a5d-4c37-b693-c5409353223c,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-8d773a85-e35d-4fa8-a6e8-27993a4787e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-139a6a1f-d9e1-413c-913f-d31e39c46a46,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-569e0572-0d47-4d46-bc84-dbf9525b67ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-d6a31051-8a0d-48af-b156-9d5b440c6c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-1cfd8437-8ea2-4645-b9a7-2573cf6884e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370819510-172.17.0.21-1595876849457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42585,DS-76800d18-2bfe-468c-ab89-bbb733e84cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-02e18a49-25a7-4b82-ab33-c733508cb926,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-b92d066f-58fd-4a9f-90f4-b0e9230f5fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-0a904dfa-5855-4e00-9124-64c247af18db,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-362bd926-1138-40de-a46a-5b643724aa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-3cfea7e7-8ead-4d05-8900-72d05c492533,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-b8d780e3-dc95-401f-b152-a2a79f9af355,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-42346134-2c7f-47ef-8fcf-63c755247a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370819510-172.17.0.21-1595876849457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42585,DS-76800d18-2bfe-468c-ab89-bbb733e84cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-02e18a49-25a7-4b82-ab33-c733508cb926,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-b92d066f-58fd-4a9f-90f4-b0e9230f5fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-0a904dfa-5855-4e00-9124-64c247af18db,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-362bd926-1138-40de-a46a-5b643724aa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-3cfea7e7-8ead-4d05-8900-72d05c492533,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-b8d780e3-dc95-401f-b152-a2a79f9af355,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-42346134-2c7f-47ef-8fcf-63c755247a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274015018-172.17.0.21-1595877180550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34172,DS-7a1ce0a5-2923-4558-b916-0be6ff3b2e67,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-bf367a12-2f1b-4fa5-a23e-a08d68ee7123,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-c11ffb10-54a9-49ca-bdd4-7907e9880d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-aa618969-0979-4488-ac60-f8c3a2cfad3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-bc5e6179-19cd-45ea-8291-3fe83ae5be48,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-989e6561-b1bc-433c-b546-c5779af3d331,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-bbb00aa1-6668-4406-8bb5-7c927b0f5b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-4638ac20-a556-41b9-8e10-be59695a795a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274015018-172.17.0.21-1595877180550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34172,DS-7a1ce0a5-2923-4558-b916-0be6ff3b2e67,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-bf367a12-2f1b-4fa5-a23e-a08d68ee7123,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-c11ffb10-54a9-49ca-bdd4-7907e9880d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-aa618969-0979-4488-ac60-f8c3a2cfad3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-bc5e6179-19cd-45ea-8291-3fe83ae5be48,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-989e6561-b1bc-433c-b546-c5779af3d331,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-bbb00aa1-6668-4406-8bb5-7c927b0f5b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-4638ac20-a556-41b9-8e10-be59695a795a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476992723-172.17.0.21-1595877305873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35784,DS-94504662-9022-4d7d-be98-51a278fb64fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-4ed3d073-cd7e-4b07-b310-900b381975fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-bac12723-4338-474a-9e52-870464ad2b59,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-c294ab3e-452f-4ea5-9065-f76f3ff791d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-6cdb63fa-17c9-4e3a-ab46-d568d6c99860,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-16f56b8d-50b7-4fb0-8743-4c0f19564d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-91d8837d-b0a9-4b1b-b79c-5f012e6fc08f,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-63951828-eff1-42cf-bf89-64ca5c2b41f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476992723-172.17.0.21-1595877305873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35784,DS-94504662-9022-4d7d-be98-51a278fb64fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-4ed3d073-cd7e-4b07-b310-900b381975fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-bac12723-4338-474a-9e52-870464ad2b59,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-c294ab3e-452f-4ea5-9065-f76f3ff791d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-6cdb63fa-17c9-4e3a-ab46-d568d6c99860,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-16f56b8d-50b7-4fb0-8743-4c0f19564d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-91d8837d-b0a9-4b1b-b79c-5f012e6fc08f,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-63951828-eff1-42cf-bf89-64ca5c2b41f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564147568-172.17.0.21-1595877517639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33727,DS-2139f842-f2de-4291-9e5d-3cda42612350,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-6aa9ac69-ed20-4047-88a3-94b7bc59892f,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-927de149-bdb4-4f58-9729-074e907bd23b,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-b440cb35-4adf-4ad5-adc9-71760a69364e,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-ff914ca2-b75e-4585-917c-3fcf2e0dee35,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-067f0e8a-049b-4dbc-991e-eb05d45bed0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-0b22df85-5cbf-4eb1-bbed-7dde9d87ef1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-55823fb4-d721-40fc-8ab1-5b16b69d1c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564147568-172.17.0.21-1595877517639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33727,DS-2139f842-f2de-4291-9e5d-3cda42612350,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-6aa9ac69-ed20-4047-88a3-94b7bc59892f,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-927de149-bdb4-4f58-9729-074e907bd23b,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-b440cb35-4adf-4ad5-adc9-71760a69364e,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-ff914ca2-b75e-4585-917c-3fcf2e0dee35,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-067f0e8a-049b-4dbc-991e-eb05d45bed0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-0b22df85-5cbf-4eb1-bbed-7dde9d87ef1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-55823fb4-d721-40fc-8ab1-5b16b69d1c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385829466-172.17.0.21-1595877728786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37864,DS-2070bb0c-0cfa-4a64-a974-06eb20207bde,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-e6a36db0-08a6-4db7-a630-fd890eb53f37,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-bee3360e-eb5d-4f90-93b9-49c14298c756,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-2e44dd4e-bbb3-418f-8d44-8e8598896861,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-8329068d-a7b9-4448-85e7-9e605b985892,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-e9304097-d007-4fc9-a705-e074cb41a153,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-726f40ab-1f33-427d-a441-05af93b3211c,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-b7638e9d-69e5-4af3-84f9-9a30d1e367a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-385829466-172.17.0.21-1595877728786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37864,DS-2070bb0c-0cfa-4a64-a974-06eb20207bde,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-e6a36db0-08a6-4db7-a630-fd890eb53f37,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-bee3360e-eb5d-4f90-93b9-49c14298c756,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-2e44dd4e-bbb3-418f-8d44-8e8598896861,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-8329068d-a7b9-4448-85e7-9e605b985892,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-e9304097-d007-4fc9-a705-e074cb41a153,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-726f40ab-1f33-427d-a441-05af93b3211c,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-b7638e9d-69e5-4af3-84f9-9a30d1e367a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1554787327-172.17.0.21-1595878054342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42338,DS-dbf43286-8d36-4f01-ac09-fd8efacf11a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-d3a46b71-0fb7-4589-af64-248ce2883a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-8ac9da88-ae55-4369-b842-f2d7696e6452,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-7e927815-4c1a-4523-99ab-ca36ecfdbfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-380a4bfa-358b-42cb-88fc-00a19558620e,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-f9a76f61-9ae9-4536-af10-b6395205ab79,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-eb355b41-d8c2-40c0-98ec-4bf16600ad0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-9984b3a8-2222-47d0-983d-4384ad9e2c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1554787327-172.17.0.21-1595878054342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42338,DS-dbf43286-8d36-4f01-ac09-fd8efacf11a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-d3a46b71-0fb7-4589-af64-248ce2883a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-8ac9da88-ae55-4369-b842-f2d7696e6452,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-7e927815-4c1a-4523-99ab-ca36ecfdbfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-380a4bfa-358b-42cb-88fc-00a19558620e,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-f9a76f61-9ae9-4536-af10-b6395205ab79,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-eb355b41-d8c2-40c0-98ec-4bf16600ad0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-9984b3a8-2222-47d0-983d-4384ad9e2c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156567401-172.17.0.21-1595878135879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38098,DS-1ae879a4-ebce-4d70-8102-37f87724efb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-ad9df1c7-0075-4444-80f9-b4d1f247d581,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-1c112bc3-adb5-459e-8011-66cd005da7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-3fa9172d-1208-4dfd-aadf-5f151e8abe73,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-b39f43df-8402-44ed-9ede-b8091df319fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-77a269e2-e472-4ac9-b41c-7e0ee371a7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-b6efa25c-9325-49a9-9821-4b676618cd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-0a8d7906-614a-495d-84de-b7122b1d552b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156567401-172.17.0.21-1595878135879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38098,DS-1ae879a4-ebce-4d70-8102-37f87724efb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-ad9df1c7-0075-4444-80f9-b4d1f247d581,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-1c112bc3-adb5-459e-8011-66cd005da7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-3fa9172d-1208-4dfd-aadf-5f151e8abe73,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-b39f43df-8402-44ed-9ede-b8091df319fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-77a269e2-e472-4ac9-b41c-7e0ee371a7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-b6efa25c-9325-49a9-9821-4b676618cd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-0a8d7906-614a-495d-84de-b7122b1d552b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163580085-172.17.0.21-1595878252801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37959,DS-66fdb566-f3df-481a-8da8-b533f6c098f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-ef20dc1d-5cf5-4d85-a0b1-fae70f61bf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-c429e273-a710-4655-86cd-bfdd4d5f1f00,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-5f99e948-f49f-4e25-8a07-2c7ddc964317,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-fd88efbf-3db7-4b10-833d-a620deb5a01b,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-f647c90e-a3fc-49cc-8bc7-821e9ac94a18,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-f6fd5592-dae6-4bef-adff-6292014a4a40,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-8d2dea73-827f-4802-9374-98c69e5ac00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-163580085-172.17.0.21-1595878252801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37959,DS-66fdb566-f3df-481a-8da8-b533f6c098f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-ef20dc1d-5cf5-4d85-a0b1-fae70f61bf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-c429e273-a710-4655-86cd-bfdd4d5f1f00,DISK], DatanodeInfoWithStorage[127.0.0.1:39318,DS-5f99e948-f49f-4e25-8a07-2c7ddc964317,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-fd88efbf-3db7-4b10-833d-a620deb5a01b,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-f647c90e-a3fc-49cc-8bc7-821e9ac94a18,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-f6fd5592-dae6-4bef-adff-6292014a4a40,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-8d2dea73-827f-4802-9374-98c69e5ac00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010623852-172.17.0.21-1595878716658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33460,DS-de64c9d2-9ef2-44de-b148-90cdb7582d25,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-f19dbbf4-2693-48fc-9b25-fe80f36d421f,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-4d110078-0484-4244-ba4a-b89790b2c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-e9718a95-a9d4-41d5-a7bc-d48284582503,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-dea25440-7750-45f5-a70a-9587fed0bdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-503d9122-1041-4020-8b7c-9389db7e7c37,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-e21434b7-8eb9-4c59-9804-29c3a9604ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-57c97a5d-f5f4-4993-bd84-7ca5f160d54a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1010623852-172.17.0.21-1595878716658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33460,DS-de64c9d2-9ef2-44de-b148-90cdb7582d25,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-f19dbbf4-2693-48fc-9b25-fe80f36d421f,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-4d110078-0484-4244-ba4a-b89790b2c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-e9718a95-a9d4-41d5-a7bc-d48284582503,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-dea25440-7750-45f5-a70a-9587fed0bdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-503d9122-1041-4020-8b7c-9389db7e7c37,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-e21434b7-8eb9-4c59-9804-29c3a9604ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-57c97a5d-f5f4-4993-bd84-7ca5f160d54a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833351490-172.17.0.21-1595878800038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44346,DS-caa668d8-ffa1-4e82-8712-85a271235952,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-b6e59144-48df-4bf8-9324-3020af098569,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-f27babb8-5b7d-4189-a167-6e6079473ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-7fc505cd-10dd-4f9b-99e6-4c05d2c807e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-8a26d7aa-f20d-44ba-8856-21b97454d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-cf68cb7c-9baf-4132-9e67-3c45d5a5e8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-34ee85d9-8fc2-4cf3-8a03-444f4156d6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-55cd18eb-4550-4327-9a7d-e51dd5195813,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833351490-172.17.0.21-1595878800038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44346,DS-caa668d8-ffa1-4e82-8712-85a271235952,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-b6e59144-48df-4bf8-9324-3020af098569,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-f27babb8-5b7d-4189-a167-6e6079473ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-7fc505cd-10dd-4f9b-99e6-4c05d2c807e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-8a26d7aa-f20d-44ba-8856-21b97454d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-cf68cb7c-9baf-4132-9e67-3c45d5a5e8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-34ee85d9-8fc2-4cf3-8a03-444f4156d6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-55cd18eb-4550-4327-9a7d-e51dd5195813,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929416299-172.17.0.21-1595879171700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45863,DS-e4ac7fd6-642a-432f-8540-d5b5af94f3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-8a0b77d7-a130-41ea-bff9-90bb9873fa22,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-ca8b10ee-0c91-4937-9ccb-a16da8c5ecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-41fc2cd3-a29f-487e-8eb1-3d5958968cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-04270728-148d-48d6-a6a0-a1dc68f6e0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-da292025-55f4-4e5c-83fb-f0c3180c1b57,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-c04a9a36-cac0-42c6-b7f4-e84110a0898a,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-199a7438-0983-4ac9-8e10-62e1867e28f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929416299-172.17.0.21-1595879171700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45863,DS-e4ac7fd6-642a-432f-8540-d5b5af94f3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-8a0b77d7-a130-41ea-bff9-90bb9873fa22,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-ca8b10ee-0c91-4937-9ccb-a16da8c5ecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-41fc2cd3-a29f-487e-8eb1-3d5958968cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-04270728-148d-48d6-a6a0-a1dc68f6e0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-da292025-55f4-4e5c-83fb-f0c3180c1b57,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-c04a9a36-cac0-42c6-b7f4-e84110a0898a,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-199a7438-0983-4ac9-8e10-62e1867e28f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734900024-172.17.0.21-1595879993542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34256,DS-0d093440-74fa-470a-a63a-cef05e6f6dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-d179bfaa-7a3b-4671-a2a4-2c77dee73e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-27e4dc3a-7d36-45bf-a31c-1f0083bc54f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-336ea16d-170f-4651-aaee-cca0b266c48f,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-d549a5b4-a90e-469b-9d8d-fcd74b3848ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-1ce52646-452f-4803-aa29-4c9de597db2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-c8db51cb-4bc3-4d58-b6b5-b2de9d210ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-5b514332-4a2a-46df-866a-4136b4de271f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734900024-172.17.0.21-1595879993542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34256,DS-0d093440-74fa-470a-a63a-cef05e6f6dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-d179bfaa-7a3b-4671-a2a4-2c77dee73e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-27e4dc3a-7d36-45bf-a31c-1f0083bc54f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-336ea16d-170f-4651-aaee-cca0b266c48f,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-d549a5b4-a90e-469b-9d8d-fcd74b3848ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34015,DS-1ce52646-452f-4803-aa29-4c9de597db2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-c8db51cb-4bc3-4d58-b6b5-b2de9d210ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-5b514332-4a2a-46df-866a-4136b4de271f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026163934-172.17.0.21-1595880219230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-3e8d81d9-748c-46e5-8e85-dc53b4b04225,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-04d12542-1b98-48d2-97d2-32dc5a10f524,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-4a6671f8-8d86-4398-bf20-65276436f936,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-d4079ad2-647e-42f5-bede-46678c3ffcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-4a860e86-9bda-4183-ba91-7549e3e1c597,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-84b6a184-fdc8-4a92-a0c7-762c661e0709,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-03db845b-4835-4c8b-845d-226d65ef1c02,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-b1094fda-0deb-4bc3-b763-d475f6fe5885,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026163934-172.17.0.21-1595880219230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-3e8d81d9-748c-46e5-8e85-dc53b4b04225,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-04d12542-1b98-48d2-97d2-32dc5a10f524,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-4a6671f8-8d86-4398-bf20-65276436f936,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-d4079ad2-647e-42f5-bede-46678c3ffcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-4a860e86-9bda-4183-ba91-7549e3e1c597,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-84b6a184-fdc8-4a92-a0c7-762c661e0709,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-03db845b-4835-4c8b-845d-226d65ef1c02,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-b1094fda-0deb-4bc3-b763-d475f6fe5885,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427114864-172.17.0.21-1595880648191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38116,DS-3d03d48c-ac18-4f22-8cc1-b1959935aa54,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-bfe74ef1-171e-47ea-82d3-cd4df32d63ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-0e75bcbc-1dff-41e4-9a21-0d7de8fbcea4,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-6b95cdfd-1883-4c5f-8dc6-c0fb4ca1b736,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-8f2780e3-6392-47cb-977a-3e7a5fbdba25,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-0fc99bec-f774-485f-8132-18f011861c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-c0b115db-ef84-4939-88e4-70a8ae09ccce,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-2e532df5-29b2-498b-ac67-5c399aa35adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1427114864-172.17.0.21-1595880648191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38116,DS-3d03d48c-ac18-4f22-8cc1-b1959935aa54,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-bfe74ef1-171e-47ea-82d3-cd4df32d63ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-0e75bcbc-1dff-41e4-9a21-0d7de8fbcea4,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-6b95cdfd-1883-4c5f-8dc6-c0fb4ca1b736,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-8f2780e3-6392-47cb-977a-3e7a5fbdba25,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-0fc99bec-f774-485f-8132-18f011861c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39172,DS-c0b115db-ef84-4939-88e4-70a8ae09ccce,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-2e532df5-29b2-498b-ac67-5c399aa35adb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808712694-172.17.0.21-1595881040921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34954,DS-7dfa1f57-9205-4729-8798-2388e8007156,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-79a52ca7-b19a-40ab-bcc8-8220ad26c737,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-bad2ea12-4a52-405e-bd57-bd876aff71c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-27f5f04e-d339-4ff5-8102-af633de24698,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-8d15952e-d9c4-488d-83a9-958aaa52cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-0837bd46-b1d0-41ae-a114-86df47bc2f31,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-2da51409-d7db-4c6b-9dab-0d644e4df555,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-f78e8a1e-01db-4c36-ad6a-eb6fb9796a88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1808712694-172.17.0.21-1595881040921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34954,DS-7dfa1f57-9205-4729-8798-2388e8007156,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-79a52ca7-b19a-40ab-bcc8-8220ad26c737,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-bad2ea12-4a52-405e-bd57-bd876aff71c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-27f5f04e-d339-4ff5-8102-af633de24698,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-8d15952e-d9c4-488d-83a9-958aaa52cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:45921,DS-0837bd46-b1d0-41ae-a114-86df47bc2f31,DISK], DatanodeInfoWithStorage[127.0.0.1:44042,DS-2da51409-d7db-4c6b-9dab-0d644e4df555,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-f78e8a1e-01db-4c36-ad6a-eb6fb9796a88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.socket.send.buffer.size
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256441475-172.17.0.21-1595881075751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45600,DS-edc5cd46-2d7a-4e71-90b0-353a32f3f898,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-0e9b903c-49fc-48bd-b24b-bacdf06961ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-deda2b3f-4eaa-4897-930c-5f3f4b25ff0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-07953223-9ba6-449e-bb97-5e9a25418b66,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-07c78504-2245-4086-bb94-ffe6e23be1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-041def98-bd52-4d64-85dc-67a4e4cbc669,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-88735c64-2868-4a87-a90b-4f3ad5be6e54,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-f3272fa6-1d0f-429a-8c31-72f37d1ec274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-256441475-172.17.0.21-1595881075751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45600,DS-edc5cd46-2d7a-4e71-90b0-353a32f3f898,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-0e9b903c-49fc-48bd-b24b-bacdf06961ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-deda2b3f-4eaa-4897-930c-5f3f4b25ff0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-07953223-9ba6-449e-bb97-5e9a25418b66,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-07c78504-2245-4086-bb94-ffe6e23be1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-041def98-bd52-4d64-85dc-67a4e4cbc669,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-88735c64-2868-4a87-a90b-4f3ad5be6e54,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-f3272fa6-1d0f-429a-8c31-72f37d1ec274,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 6372
