reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483246723-172.17.0.19-1595569672158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43809,DS-35205b97-c9fe-4186-acb0-dcc01161b01e,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-14f8d22a-117a-4437-a066-1eb8d2be5b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-28995da3-4ad3-40c0-9574-830fcfefee53,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-3d0a1657-7d70-421a-84d6-dea4a47333e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-9c4f8362-68fe-4875-a8aa-952a65a573e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-4a516aa6-b8ea-4a48-9aa6-71679eb8bfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-4c1c2366-9bc2-48b2-8828-72389004dbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-eacb58f4-d424-4bfa-9e2e-90a56c6e6615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483246723-172.17.0.19-1595569672158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43809,DS-35205b97-c9fe-4186-acb0-dcc01161b01e,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-14f8d22a-117a-4437-a066-1eb8d2be5b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-28995da3-4ad3-40c0-9574-830fcfefee53,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-3d0a1657-7d70-421a-84d6-dea4a47333e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-9c4f8362-68fe-4875-a8aa-952a65a573e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-4a516aa6-b8ea-4a48-9aa6-71679eb8bfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-4c1c2366-9bc2-48b2-8828-72389004dbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-eacb58f4-d424-4bfa-9e2e-90a56c6e6615,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639445994-172.17.0.19-1595570272406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42379,DS-e2b9d03c-cfcb-4124-9fbc-f6455799bdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-74cfaa7e-30fc-4b86-82ed-793dda2f73a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-e8f061ce-45b8-499e-a447-b193d4c6d7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-415e2918-d09e-4f38-94b5-dd1b74b66e75,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-d93e12f7-d55f-4108-ae9b-9a774aa8663b,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-ba650ead-957d-456d-9e09-98241bc77728,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-ec73198f-0e54-4b19-8cf9-35992a0fa5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-48484737-6679-4da8-8591-cde813c2b490,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639445994-172.17.0.19-1595570272406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42379,DS-e2b9d03c-cfcb-4124-9fbc-f6455799bdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-74cfaa7e-30fc-4b86-82ed-793dda2f73a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-e8f061ce-45b8-499e-a447-b193d4c6d7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34312,DS-415e2918-d09e-4f38-94b5-dd1b74b66e75,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-d93e12f7-d55f-4108-ae9b-9a774aa8663b,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-ba650ead-957d-456d-9e09-98241bc77728,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-ec73198f-0e54-4b19-8cf9-35992a0fa5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40441,DS-48484737-6679-4da8-8591-cde813c2b490,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209453020-172.17.0.19-1595570504510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43272,DS-b4886349-a66b-4848-a5f5-d31133487652,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-206cac8f-188a-4229-87af-0b9301b82b03,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-4947a7e9-2c49-4f5b-bd38-1a270157ec65,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-8d9a3130-1e2a-4981-9e7e-65d1868f84af,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-d4aa5890-55df-4cc3-89e8-768a502afec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-ad7be51e-5a39-482c-a71c-17b9d5c3fc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-453094be-b43f-4d0b-9918-feacb2375336,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-a6928895-8517-48c5-b998-9565128497c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209453020-172.17.0.19-1595570504510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43272,DS-b4886349-a66b-4848-a5f5-d31133487652,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-206cac8f-188a-4229-87af-0b9301b82b03,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-4947a7e9-2c49-4f5b-bd38-1a270157ec65,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-8d9a3130-1e2a-4981-9e7e-65d1868f84af,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-d4aa5890-55df-4cc3-89e8-768a502afec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-ad7be51e-5a39-482c-a71c-17b9d5c3fc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-453094be-b43f-4d0b-9918-feacb2375336,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-a6928895-8517-48c5-b998-9565128497c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142588582-172.17.0.19-1595571961274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37510,DS-de0f789a-72a1-4a21-853e-f651a114e147,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-cd2afb7d-2512-4577-9f84-48d1180fe3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-741978a4-29b2-4e32-9b3b-88b499c594d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-0384c432-430f-4ce1-8ad8-6008038935f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-085c4598-4a63-42f9-9bc7-2fe4792c4ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-b56fcfd4-f37a-4fc3-ae91-828ffc4c3d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-6715f13f-b92e-4acc-8ae0-2cc5e56b5555,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-a3a38295-a76f-4a06-bc1b-373179d0b119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-142588582-172.17.0.19-1595571961274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37510,DS-de0f789a-72a1-4a21-853e-f651a114e147,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-cd2afb7d-2512-4577-9f84-48d1180fe3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-741978a4-29b2-4e32-9b3b-88b499c594d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-0384c432-430f-4ce1-8ad8-6008038935f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-085c4598-4a63-42f9-9bc7-2fe4792c4ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-b56fcfd4-f37a-4fc3-ae91-828ffc4c3d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-6715f13f-b92e-4acc-8ae0-2cc5e56b5555,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-a3a38295-a76f-4a06-bc1b-373179d0b119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385228186-172.17.0.19-1595572065231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39166,DS-f1e4119b-869c-41e7-9ed9-ba8b806aee4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-258a32c5-044a-4994-b80a-070907d84fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-3087f150-4a10-4427-bd2f-ff922c4a99b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-4949e759-7b94-4b92-81a8-2f4e72d1d498,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-4a516cc5-d22f-4e6a-9331-a349ecbe3fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-f9528728-3bd3-443f-b9d0-c69e2f093ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-4a5b5cd5-94df-4948-8052-7b925fb1fff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-663450d8-0a01-4ce6-ab55-1d57ae8cff2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385228186-172.17.0.19-1595572065231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39166,DS-f1e4119b-869c-41e7-9ed9-ba8b806aee4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-258a32c5-044a-4994-b80a-070907d84fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-3087f150-4a10-4427-bd2f-ff922c4a99b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-4949e759-7b94-4b92-81a8-2f4e72d1d498,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-4a516cc5-d22f-4e6a-9331-a349ecbe3fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-f9528728-3bd3-443f-b9d0-c69e2f093ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-4a5b5cd5-94df-4948-8052-7b925fb1fff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-663450d8-0a01-4ce6-ab55-1d57ae8cff2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486008729-172.17.0.19-1595572305165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36150,DS-ba54ac7e-e1e0-4821-81cc-1984d4976ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-2856f2ca-affd-4c1c-a6d6-6dec23e02f27,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-50723047-2341-4f13-8f09-7d93f232e757,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-4dedc16c-ff7f-444e-85e5-e1b813c94428,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-aec1ce74-72ce-48ab-8ac5-c2ca61c10135,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-da012154-84c3-4d6e-b55b-d888c0fa562b,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-ff2d49dc-492a-4a38-ba3d-97fca3ee843f,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-402c01bd-7262-47ee-a92a-dee375220533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486008729-172.17.0.19-1595572305165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36150,DS-ba54ac7e-e1e0-4821-81cc-1984d4976ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-2856f2ca-affd-4c1c-a6d6-6dec23e02f27,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-50723047-2341-4f13-8f09-7d93f232e757,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-4dedc16c-ff7f-444e-85e5-e1b813c94428,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-aec1ce74-72ce-48ab-8ac5-c2ca61c10135,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-da012154-84c3-4d6e-b55b-d888c0fa562b,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-ff2d49dc-492a-4a38-ba3d-97fca3ee843f,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-402c01bd-7262-47ee-a92a-dee375220533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085914185-172.17.0.19-1595572348702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43939,DS-dbc706e0-78c3-47c0-8cdb-1e9a08ef960c,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-9c6ceedf-79e4-49ab-951d-d81581336195,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-90ee1487-ac32-4b3d-900e-90a9a25f8728,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-d5a156a5-f359-4ce9-b5bf-a6646e39a6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-ca494d27-dc31-4d35-860f-f38b0fda93f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-b079ba9d-72d8-4dc3-b994-fccae9a7870c,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-06c57d3c-e5f3-41ce-bd13-4accf6b36b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-310550aa-6640-4c92-bc4d-97dc13f156f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085914185-172.17.0.19-1595572348702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43939,DS-dbc706e0-78c3-47c0-8cdb-1e9a08ef960c,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-9c6ceedf-79e4-49ab-951d-d81581336195,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-90ee1487-ac32-4b3d-900e-90a9a25f8728,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-d5a156a5-f359-4ce9-b5bf-a6646e39a6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-ca494d27-dc31-4d35-860f-f38b0fda93f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-b079ba9d-72d8-4dc3-b994-fccae9a7870c,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-06c57d3c-e5f3-41ce-bd13-4accf6b36b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-310550aa-6640-4c92-bc4d-97dc13f156f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820482965-172.17.0.19-1595573219073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35473,DS-438b20f3-c56d-4e0b-b18d-a20c199a6514,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-66e91de1-01ec-4dd5-a252-b7797e8fe788,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-79aec127-5c41-4a53-95f5-1c26078e3de1,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-9163ebdc-1d2c-4685-8001-661ea552a193,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-f93b6330-545f-4edb-a3c7-094fbfd755af,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-224dab8d-dda8-40e7-aa86-776ab25ae3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-8dda6a70-80aa-4f47-a916-2f9068873836,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-7458c6ec-0995-4328-ac63-1070a1316b8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820482965-172.17.0.19-1595573219073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35473,DS-438b20f3-c56d-4e0b-b18d-a20c199a6514,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-66e91de1-01ec-4dd5-a252-b7797e8fe788,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-79aec127-5c41-4a53-95f5-1c26078e3de1,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-9163ebdc-1d2c-4685-8001-661ea552a193,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-f93b6330-545f-4edb-a3c7-094fbfd755af,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-224dab8d-dda8-40e7-aa86-776ab25ae3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-8dda6a70-80aa-4f47-a916-2f9068873836,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-7458c6ec-0995-4328-ac63-1070a1316b8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108603729-172.17.0.19-1595574047533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36889,DS-0bc14704-2b03-45b3-a169-6c1adadaa47b,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-2f02f070-7dc1-4fdb-ab82-114be73a38df,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-32076f0a-a6e0-440f-a06a-ff78901e8f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-1670ba02-0d40-4fac-b4e6-1e428867e933,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-c665b64e-7433-4173-a73f-7bd43a664fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-35dd36e4-4e2a-4a14-9300-eb28369c71cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-4b983a14-3fdc-47e3-861f-0895d310bc13,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-23dc80e4-8f10-4e6e-80ea-75dab5af401f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108603729-172.17.0.19-1595574047533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36889,DS-0bc14704-2b03-45b3-a169-6c1adadaa47b,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-2f02f070-7dc1-4fdb-ab82-114be73a38df,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-32076f0a-a6e0-440f-a06a-ff78901e8f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-1670ba02-0d40-4fac-b4e6-1e428867e933,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-c665b64e-7433-4173-a73f-7bd43a664fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-35dd36e4-4e2a-4a14-9300-eb28369c71cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-4b983a14-3fdc-47e3-861f-0895d310bc13,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-23dc80e4-8f10-4e6e-80ea-75dab5af401f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188949542-172.17.0.19-1595574271275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41185,DS-1fa2619e-03d3-4b13-806d-94ebaa9b2f34,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-4538628f-9d9a-43c5-b39a-6f4963224044,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-bd3bc5e9-6c05-4864-8bb2-f0855091ef16,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-5cd5fb41-7a19-49a1-8c01-5a0728480d52,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-bb0f89ee-63ca-4bf9-badc-121ffaa9812a,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-f650b188-2119-47cf-8fea-20cfbcdcebc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-19ec37d0-0932-4ab7-a6d8-b4081919425f,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-3567a333-9cfa-48af-9c0f-6cf46b28a868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188949542-172.17.0.19-1595574271275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41185,DS-1fa2619e-03d3-4b13-806d-94ebaa9b2f34,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-4538628f-9d9a-43c5-b39a-6f4963224044,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-bd3bc5e9-6c05-4864-8bb2-f0855091ef16,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-5cd5fb41-7a19-49a1-8c01-5a0728480d52,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-bb0f89ee-63ca-4bf9-badc-121ffaa9812a,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-f650b188-2119-47cf-8fea-20cfbcdcebc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-19ec37d0-0932-4ab7-a6d8-b4081919425f,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-3567a333-9cfa-48af-9c0f-6cf46b28a868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962355825-172.17.0.19-1595574351676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39992,DS-b66e06cd-5084-4681-aacd-afd2c87314d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-e2c8216c-8ca5-47c2-a998-eb74e97e7d62,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-f2b2fbc4-2867-4269-9c19-8d216f71d044,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-e8f46d72-ec7c-4591-bf53-b33844c9f73e,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-d5b93555-d610-4316-a5c8-7fc020bb22ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-0b103ab7-7cb1-40b4-aad6-3a6e1f4c7d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-41bb9156-598d-420d-84c8-e0916631367b,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-4a4277ce-167e-4d59-9ab4-0b273c8b33fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962355825-172.17.0.19-1595574351676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39992,DS-b66e06cd-5084-4681-aacd-afd2c87314d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-e2c8216c-8ca5-47c2-a998-eb74e97e7d62,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-f2b2fbc4-2867-4269-9c19-8d216f71d044,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-e8f46d72-ec7c-4591-bf53-b33844c9f73e,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-d5b93555-d610-4316-a5c8-7fc020bb22ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-0b103ab7-7cb1-40b4-aad6-3a6e1f4c7d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-41bb9156-598d-420d-84c8-e0916631367b,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-4a4277ce-167e-4d59-9ab4-0b273c8b33fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308749646-172.17.0.19-1595574779584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40594,DS-7e520387-a7f7-43e9-84d8-1f09b3b5de03,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-75459535-b96f-4ed2-9882-c66b6e267ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-febecf11-efe3-47b9-89fa-a45dee87b77d,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-27ca5673-9474-4098-b8fa-44085ec575d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-a782a0d8-9126-4d5d-b6c2-67acdbebff86,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-30d7c6f8-bdbb-46f3-859c-516ecc0f63a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-8d3019f4-b26d-4294-aee1-abd7df7dc795,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-8b471349-6836-43b0-a9c0-cfc3f6c1b685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308749646-172.17.0.19-1595574779584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40594,DS-7e520387-a7f7-43e9-84d8-1f09b3b5de03,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-75459535-b96f-4ed2-9882-c66b6e267ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-febecf11-efe3-47b9-89fa-a45dee87b77d,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-27ca5673-9474-4098-b8fa-44085ec575d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-a782a0d8-9126-4d5d-b6c2-67acdbebff86,DISK], DatanodeInfoWithStorage[127.0.0.1:42923,DS-30d7c6f8-bdbb-46f3-859c-516ecc0f63a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-8d3019f4-b26d-4294-aee1-abd7df7dc795,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-8b471349-6836-43b0-a9c0-cfc3f6c1b685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053428448-172.17.0.19-1595575032674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36351,DS-6d3c1a69-8843-439a-a31d-d200816c795c,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-b7844e05-9527-443a-abf3-a50306d6e8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-e3dfd412-ca6b-45a0-a227-ef740bb7a4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-4cf6d414-7477-42c8-b4c6-83a11e5d2512,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-e762f2ca-5ba6-431a-bec2-2c96a3bf9962,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-02d8201b-2af4-45f9-bdc1-cfd027f8f18b,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-5344f426-02f3-4c18-8a2f-014eb84cfa10,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-b027dcff-bc7b-4333-9b1e-955bdea551cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053428448-172.17.0.19-1595575032674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36351,DS-6d3c1a69-8843-439a-a31d-d200816c795c,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-b7844e05-9527-443a-abf3-a50306d6e8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-e3dfd412-ca6b-45a0-a227-ef740bb7a4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-4cf6d414-7477-42c8-b4c6-83a11e5d2512,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-e762f2ca-5ba6-431a-bec2-2c96a3bf9962,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-02d8201b-2af4-45f9-bdc1-cfd027f8f18b,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-5344f426-02f3-4c18-8a2f-014eb84cfa10,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-b027dcff-bc7b-4333-9b1e-955bdea551cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363971077-172.17.0.19-1595575643659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41299,DS-64801495-aae4-44f6-970e-f23e25d5391d,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-f358eb4c-3083-43af-baa2-09ae0417bfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-ac5005ef-a5d1-4fb7-8879-4d4e1706ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-f398146c-a7d7-4fa8-9153-3a6dae338087,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-0cc0f124-928c-4c45-8135-1a4d7cf86173,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-0fc8801e-c20f-4a45-8438-1273eeba3462,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-02032413-cfb2-436a-9937-b5997da10ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-81482b80-9693-409c-ae8b-b9fc62e93e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363971077-172.17.0.19-1595575643659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41299,DS-64801495-aae4-44f6-970e-f23e25d5391d,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-f358eb4c-3083-43af-baa2-09ae0417bfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-ac5005ef-a5d1-4fb7-8879-4d4e1706ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-f398146c-a7d7-4fa8-9153-3a6dae338087,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-0cc0f124-928c-4c45-8135-1a4d7cf86173,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-0fc8801e-c20f-4a45-8438-1273eeba3462,DISK], DatanodeInfoWithStorage[127.0.0.1:43176,DS-02032413-cfb2-436a-9937-b5997da10ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-81482b80-9693-409c-ae8b-b9fc62e93e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6740
